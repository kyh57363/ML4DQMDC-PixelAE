{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba412492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import SubHistStruct\n",
    "importlib.reload(SubHistStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed Controls and Run Mode\n",
    "\n",
    "# Disables all plots for large datasets where speed is more important\n",
    "createPlots = True\n",
    "\n",
    "# Control for the notebook - turn off user-friendly mode to enable faster runtimes\n",
    "userfriendly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2020c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation Parameters\n",
    "\n",
    "# Select the bias towards recall against precision, treated as a factor (so < 1 biases towards precision, 1 is equal importance, and > 1 biases towards recall)\n",
    "wpBiasFactor = 20\n",
    "fmBiasFactor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4590f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = '../data/'\n",
    "\n",
    "# Select a list of good runs to train on in development training_mode\n",
    "# Should be validated by eye\n",
    "trainrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                   \"297598\":[[-1]],\n",
    "#                   \"297604\":[[-1]],   # A decently clean histogram\n",
    "                   \"297620\":[[-1]],   # A decently clean histogram\n",
    "                   \"297659\":[[-1]],   # An okay histogram\n",
    "                   \"297670\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                   \"299065\":[[-1]],   # A decently clean histogram\n",
    "                   \"299067\":[[-1]],   # A decently clean histogram\n",
    "                   \"299096\":[[-1]],\n",
    "                   \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "#                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "                   '2017C': {\n",
    "                      \"299370\":[[-1]],\n",
    "                      \"299394\":[[-1]],\n",
    "                      \"299420\":[[-1]],\n",
    "                      \"299477\":[[-1]],\n",
    "                      \"299593\":[[-1]],\n",
    "                      \"299597\":[[-1]],\n",
    "                      \"299617\":[[-1]],\n",
    "                      \"300018\":[[-1]],\n",
    "                      \"300105\":[[-1]],\n",
    "                      \"300117\":[[-1]],\n",
    "                      \"300124\":[[-1]],\n",
    "                      \"300234\":[[-1]],\n",
    "                      \"300237\":[[-1]],\n",
    "                      \"300240\":[[-1]],\n",
    "                      \"300370\":[[-1]],\n",
    "                      \"300157\":[[-1]],\n",
    "                      \"300373\":[[-1]],\n",
    "                      \"300392\":[[-1]],\n",
    "                      \"300395\":[[-1]],\n",
    "                      \"300401\":[[-1]],\n",
    "                      \"300462\":[[-1]],\n",
    "                      \"300466\":[[-1]],\n",
    "                      \"300514\":[[-1]],\n",
    "                      \"300517\":[[-1]],\n",
    "                      \"300538\":[[-1]],\n",
    "                      \"300539\":[[-1]],\n",
    "                      \"300364\":[[-1]],\n",
    "                 },'2017F':{\n",
    "                      \"305310\":[[-1]],\n",
    "                      \"305040\":[[-1]],\n",
    "                      \"305043\":[[-1]],\n",
    "                      \"305185\":[[-1]],\n",
    "                      \"305204\":[[-1]],\n",
    "                      \"305234\":[[-1]],\n",
    "                      \"305247\":[[-1]],\n",
    "                      \"305313\":[[-1]],\n",
    "                      \"305338\":[[-1]],\n",
    "                      \"305350\":[[-1]],\n",
    "                      \"305364\":[[-1]],\n",
    "                      \"305376\":[[-1]],\n",
    "                      \"306042\":[[-1]],\n",
    "                      \"306051\":[[-1]],\n",
    "                      \"305406\":[[-1]],\n",
    "                      \"306122\":[[-1]],\n",
    "                      \"306134\":[[-1]],\n",
    "                      \"306137\":[[-1]],\n",
    "                      \"306154\":[[-1]],\n",
    "                      \"306170\":[[-1]],\n",
    "                      \"306417\":[[-1]],\n",
    "                      \"306432\":[[-1]],\n",
    "                      \"306456\":[[-1]],\n",
    "                      \"305516\":[[-1]],\n",
    "                      \"305586\":[[-1]],\n",
    "                      \"305588\":[[-1]],\n",
    "                      \"305590\":[[-1]],\n",
    "                      \"305809\":[[-1]],\n",
    "                      \"305832\":[[-1]],\n",
    "                      \"305840\":[[-1]],\n",
    "                      \"305898\":[[-1]],\n",
    "                      \"306029\":[[-1]],\n",
    "                      \"306037\":[[-1]],\n",
    "                      \"306095\":[[-1]],\n",
    "                },\n",
    "                '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "# Select a list of good runs to test on in development training_mode\n",
    "# Should be validated by eye\n",
    "goodrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                    \"297598\":[[-1]],\n",
    "#                    \"297604\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297620\":[[-1]],   # A decently clean histogram\n",
    "                    \"297659\":[[-1]],   # An okay histogram\n",
    "                    \"297670\":[[-1]],   # A decently clean histogram\n",
    "                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                    \"299065\":[[-1]],   # A decently clean histogram\n",
    "                    \"299067\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299096\":[[-1]],\n",
    "#                    \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "                '2017C':{\n",
    "                      \"299370\":[[-1]],\n",
    "                      \"299394\":[[-1]],\n",
    "                      \"299420\":[[-1]],\n",
    "                      \"299477\":[[-1]],\n",
    "                      \"299593\":[[-1]],\n",
    "                      \"299597\":[[-1]],\n",
    "                      \"299617\":[[-1]],\n",
    "                      \"300018\":[[-1]],\n",
    "                      \"300105\":[[-1]],\n",
    "                      \"300117\":[[-1]],\n",
    "                      \"300124\":[[-1]],\n",
    "                      \"300234\":[[-1]],\n",
    "                      \"300237\":[[-1]],\n",
    "                      \"300240\":[[-1]],\n",
    "                      \"300370\":[[-1]],\n",
    "                      \"300157\":[[-1]],\n",
    "                      \"300373\":[[-1]],\n",
    "                      \"300392\":[[-1]],\n",
    "                      \"300395\":[[-1]],\n",
    "                      \"300401\":[[-1]],\n",
    "                      \"300462\":[[-1]],\n",
    "                      \"300466\":[[-1]],\n",
    "                      \"300514\":[[-1]],\n",
    "                      \"300517\":[[-1]],\n",
    "                      \"300538\":[[-1]],\n",
    "                      \"300539\":[[-1]],\n",
    "                      \"300364\":[[-1]],\n",
    "                },'2017F':{\n",
    "                      \"305310\":[[-1]],\n",
    "                      \"305040\":[[-1]],\n",
    "                      \"305043\":[[-1]],\n",
    "                      \"305185\":[[-1]],\n",
    "                      \"305204\":[[-1]],\n",
    "                      \"305234\":[[-1]],\n",
    "                      \"305247\":[[-1]],\n",
    "                      \"305313\":[[-1]],\n",
    "                      \"305338\":[[-1]],\n",
    "                      \"305350\":[[-1]],\n",
    "                      \"305364\":[[-1]],\n",
    "                      \"305376\":[[-1]],\n",
    "                      \"306042\":[[-1]],\n",
    "                      \"306051\":[[-1]],\n",
    "                      \"305406\":[[-1]],\n",
    "                      \"306122\":[[-1]],\n",
    "                      \"306134\":[[-1]],\n",
    "                      \"306137\":[[-1]],\n",
    "                      \"306154\":[[-1]],\n",
    "                      \"306170\":[[-1]],\n",
    "                      \"306417\":[[-1]],\n",
    "                      \"306432\":[[-1]],\n",
    "                      \"306456\":[[-1]],\n",
    "                      \"305516\":[[-1]],\n",
    "                      \"305586\":[[-1]],\n",
    "                      \"305588\":[[-1]],\n",
    "                      \"305590\":[[-1]],\n",
    "                      \"305809\":[[-1]],\n",
    "                      \"305832\":[[-1]],\n",
    "                      \"305840\":[[-1]],\n",
    "                      \"305898\":[[-1]],\n",
    "                      \"306029\":[[-1]],\n",
    "                      \"306037\":[[-1]],\n",
    "                      \"306095\":[[-1]],\n",
    "                },\n",
    "                '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "\n",
    "badrunsls = {'2017B':\n",
    "                {\n",
    "                    #\"297048\":[[-1]],\n",
    "                    #\"297282\":[[-1]],\n",
    "                    #\"297283\":[[-1]],\n",
    "                    #\"297284\":[[-1]],\n",
    "                    #\"297287\":[[-1]],\n",
    "                    #\"297288\":[[-1]],\n",
    "                    #\"297289\":[[-1]],\n",
    "                    \"299316\":[[-1]],\n",
    "                    \"299317\":[[-1]],\n",
    "                    \"299318\":[[-1]],\n",
    "                    \"299324\":[[-1]],\n",
    "                    \"299326\":[[-1]],\n",
    "                    #\"301086\":[[88,126]],\n",
    "                    #\"301086\":[[89,89]],\n",
    "                    #\"303948\":[[1710,1710]],\n",
    "                    \"297047\":[[-1]], #close but, true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297211\":[[-1]], #Reconstructs well\n",
    "#                   \"299325\":[[-1]], #Reconstructs well\n",
    "                    \"297664\":[[-1]], #true bad for all 8\n",
    "                    \"299317\":[[-1]], #true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297502\":[[-1]]\n",
    "                },\n",
    "             '2017C':{\n",
    "#                 \"300781\":[[-1]], # bad for tracking (pixels were excluded.\n",
    "                 \"300079\":[[-1]], # is bad for strips and then also for tracking\n",
    "#                 \"302029\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good \n",
    "#                 \"300576\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"300574\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"300282\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"301912\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "#                 \"301086\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "#                 \"300283\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300282\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "#                 \"300281\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "#                 \"300239\":[[-1]], # Half bad for pixels (lost HV or readout card)\n",
    "#                 \"301394\":[[-1]], # Marginal for pixels\n",
    "#                 \"301183\":[[-1]], # Marginal for pixels\n",
    "                 \"300398\":[[-1]], # Marginal for pixels\n",
    "                 \"300389\":[[-1]], # Marginal for pixels\n",
    "#                 \"300365\":[[-1]]  # Marginal for pixels\n",
    "              },\n",
    "             '2017E':{\n",
    "                 \"304740\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304776\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304506\":[[-1]], # Portcard problem for pixels\n",
    "                 \"304507\":[[-1]], # Portcard problem for pixels \n",
    "                 \"303989\":[[-1]], # Bad for pixels, power supply died\n",
    "                 \"303824\":[[-1]]  # Partly bad for strips due to a test\n",
    "             },\n",
    "             '2017F':{\n",
    "                 \"306422\":[[-1]], # Partly bad for strips - 2 data readouts failed \n",
    "#                 \"306423\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "#                 \"306425\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "#                 \"305440\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "#                 \"305441\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "                 \"305249\":[[-1]], # Bad for pixels - half of disk failed \n",
    "                 \"305250\":[[-1]], # Bad for pixels - half of disk failed\n",
    "#                 \"305064\":[[-1]], # Marginal for pixels - some readout failed\n",
    "             },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "\n",
    "# The year and era being used\n",
    "year = '2017'\n",
    "era = 'B'\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = [\n",
    "    ['NormalizedHitResiduals_TIB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1', 'NormalizedHitResiduals_TIB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2',\n",
    "     'NormalizedHitResiduals_TIB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3' , 'NormalizedHitResiduals_TIB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4'],\n",
    "    ['chargeInner_PXLayer_1', 'chargeOuter_PXLayer_1', 'adc_PXLayer_1', 'size_PXLayer_1'],\n",
    "    ['chargeInner_PXLayer_2', 'chargeOuter_PXLayer_2', 'adc_PXLayer_2', 'size_PXLayer_2'],\n",
    "    ['chargeInner_PXLayer_3', 'chargeOuter_PXLayer_3', 'adc_PXLayer_3', 'size_PXLayer_3'],\n",
    "    ['chargeInner_PXLayer_4', 'chargeOuter_PXLayer_4', 'adc_PXLayer_4', 'size_PXLayer_4'],\n",
    "    ['charge_PXDisk_+1', 'adc_PXDisk_+1'],\n",
    "    ['charge_PXDisk_-1', 'adc_PXDisk_-1'],\n",
    "    ['charge_PXDisk_+2', 'adc_PXDisk_+2'],\n",
    "    ['charge_PXDisk_-2', 'adc_PXDisk_-2'],\n",
    "    ['charge_PXDisk_+3', 'adc_PXDisk_+3'],\n",
    "    ['charge_PXDisk_-3', 'adc_PXDisk_-3'],\n",
    "    ['NormalizedHitResiduals_TOB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__1', 'NormalizedHitResiduals_TOB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__2',\n",
    "     'NormalizedHitResiduals_TOB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__3' , 'NormalizedHitResiduals_TOB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__4']\n",
    "]\n",
    "\n",
    "# Read new data or use previously saved data & should data be saved\n",
    "readnew = True\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0ffebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Set whether to train globally or locally or in a development/testing mode\n",
    "training_mode = 'development'\n",
    "\n",
    "# Selects whether to create a new histstruct or use a saved one\n",
    "readnew = True\n",
    "\n",
    "# Select whether to save a new histstruct\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6394238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames\n",
    "\n",
    "# Evaluate models seperately, as an ensemble, both, or neither\n",
    "individualEval = True\n",
    "ensembleEval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4051dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected runs/lumisections for training: \n",
      "{'297175': [[-1]], '297620': [[-1]], '297659': [[-1]], '297670': [[-1]], '299065': [[-1]], '299067': [[-1]], '299096': [[-1]], '299149': [[-1]]}\n",
      "selected runs/lumisections as good test set:\n",
      "{'297175': [[-1]], '297659': [[-1]], '297670': [[-1]], '297674': [[-1]], '297722': [[-1]], '299065': [[-1]], '299067': [[-1]], '299185': [[-1]], '299327': [[-1]], '299480': [[-1]]}\n",
      "selected runs/lumisections as bad test set:\n",
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n"
     ]
    }
   ],
   "source": [
    "### Define Training Mode Parameters - Combined Autoencoder\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use averages of training set)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    # - this only works for a single era\n",
    "    \n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+era+'_'+histnames[0][0]+'.csv') ) )\n",
    "    # Cherry picked really bad run\n",
    "    run_application = 299316\n",
    "    #run_application = 299317\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5\n",
    "        offset = 0 # normal case: offset = 0 (just use 5 previous runs)\n",
    "        \n",
    "        # Selects the 5 previous runs for training\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    #runsls_bad = badrunsls[year]\n",
    "    #runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_good = runsls_training\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)\n",
    "        \n",
    "elif training_mode == 'development':\n",
    "    # train on a user-defined subset of runs\n",
    "    \n",
    "    # Select runs to be used in training from the user-defined list\n",
    "    runsls_training = trainrunsls[year + era]\n",
    "    # Select bad runs to test on in the user-defined list\n",
    "    runsls_bad = badrunsls[year + era]\n",
    "    # Select good runs to test on in the user-defined list\n",
    "    runsls_good = goodrunsls[year + era]\n",
    "    \n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54180f06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Classifiers cleared to preserve consistency\n",
      "Adding NormalizedHitResiduals_TIB__Layer__1...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1...\n",
      "(2831, 102)\n",
      "Adding NormalizedHitResiduals_TIB__Layer__2...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2...\n",
      "(2831, 102)\n",
      "Adding NormalizedHitResiduals_TIB__Layer__3...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3...\n",
      "(2831, 102)\n",
      "Adding NormalizedHitResiduals_TIB__Layer__4...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4...\n",
      "(2831, 102)\n",
      "Adding chargeInner_PXLayer_1...\n",
      "(2831, 102)\n",
      "Adding chargeOuter_PXLayer_1...\n",
      "(2831, 102)\n",
      "Adding adc_PXLayer_1...\n",
      "(2831, 102)\n",
      "Adding size_PXLayer_1...\n",
      "(2831, 102)\n",
      "Adding chargeInner_PXLayer_2...\n",
      "(2831, 102)\n",
      "Adding chargeOuter_PXLayer_2...\n",
      "(2831, 102)\n",
      "Adding adc_PXLayer_2...\n",
      "(2831, 102)\n",
      "Adding size_PXLayer_2...\n",
      "(2831, 102)\n",
      "Adding chargeInner_PXLayer_3...\n",
      "(2831, 102)\n",
      "Adding chargeOuter_PXLayer_3...\n",
      "(2831, 102)\n",
      "Adding adc_PXLayer_3...\n",
      "(2831, 102)\n",
      "Adding size_PXLayer_3...\n",
      "(2831, 102)\n",
      "Adding chargeInner_PXLayer_4...\n",
      "(2831, 102)\n",
      "Adding chargeOuter_PXLayer_4...\n",
      "(2831, 102)\n",
      "Adding adc_PXLayer_4...\n",
      "(2831, 102)\n",
      "Adding size_PXLayer_4...\n",
      "(2831, 102)\n",
      "Adding charge_PXDisk_+1...\n",
      "(2831, 102)\n",
      "Adding adc_PXDisk_+1...\n",
      "(2831, 102)\n",
      "Adding charge_PXDisk_-1...\n",
      "(2831, 102)\n",
      "Adding adc_PXDisk_-1...\n",
      "(2831, 102)\n",
      "Adding charge_PXDisk_+2...\n",
      "(2831, 102)\n",
      "Adding adc_PXDisk_+2...\n",
      "(2831, 102)\n",
      "Adding charge_PXDisk_-2...\n",
      "(2831, 102)\n",
      "Adding adc_PXDisk_-2...\n",
      "(2831, 102)\n",
      "Adding charge_PXDisk_+3...\n",
      "(2831, 102)\n",
      "Adding adc_PXDisk_+3...\n",
      "(2831, 102)\n",
      "Adding charge_PXDisk_-3...\n",
      "(2831, 102)\n",
      "Adding adc_PXDisk_-3...\n",
      "(2831, 102)\n",
      "Adding NormalizedHitResiduals_TOB__Layer__1...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1...\n",
      "(2831, 102)\n",
      "Adding NormalizedHitResiduals_TOB__Layer__2...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2...\n",
      "(2831, 102)\n",
      "Adding NormalizedHitResiduals_TOB__Layer__3...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3...\n",
      "(2831, 102)\n",
      "Adding NormalizedHitResiduals_TOB__Layer__4...\n",
      "(2831, 102)\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4...\n",
      "(2831, 102)\n",
      "Found 2831 histograms\n",
      "Created a histstruct with the following properties:\n",
      "- number of histogram types: 44\n",
      "- number of lumisections: 2831\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "\n",
    "# Create a new HistStruct from the data\n",
    "if readnew:\n",
    "    # Initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = SubHistStruct.SubHistStruct()\n",
    "    histstruct.reset_histlist(histnames)\n",
    "    \n",
    "    # Unpack histnames and add every histogram individually\n",
    "    for histnamegroup in histnames:\n",
    "        for histname in histnamegroup:\n",
    "            print('Adding {}...'.format(histname))\n",
    "            \n",
    "            # Bring the histograms into memory from storage for later use\n",
    "            filename = datadir + year + era + '/DF' + year + era + '_' + histname + '.csv'\n",
    "            df = dloader.get_dataframe_from_file( filename )\n",
    "            \n",
    "            # In case of local training, we can remove most of the histograms\n",
    "            if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "                runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "                df = dfu.select_runsls( df, runsls_total )\n",
    "                \n",
    "            # Store the data in the histstruct object managing this whole thing\n",
    "            histstruct.add_dataframe( df, rebinningfactor = 1, standardbincount = 102 )\n",
    "        \n",
    "    print('Found {} histograms'.format(len(histstruct.runnbs)))\n",
    "\n",
    "# Load a previously saved HistStruct\n",
    "else:\n",
    "    # Load histstruct from storage\n",
    "    histstruct = HistStruct.HistStruct.load('test.pk1')\n",
    "    \n",
    "    # Count of bad runs, presumably for later use\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "if userfriendly:\n",
    "    print('Created a histstruct with the following properties:')\n",
    "    print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "    print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45931fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n",
      "Assigned masks: ['dcson', 'golden', 'highstat', 'lowstat', 'training', 'good', 'bad', 'bad0', 'bad1', 'bad2', 'bad3', 'bad4', 'bad5', 'bad6', 'bad7']\n"
     ]
    }
   ],
   "source": [
    "### Add Masks to Data\n",
    "\n",
    "if readnew:\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat' )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=100 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        print(runsls_bad)\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    if save:\n",
    "        histstruct.save('test.pk1')\n",
    "if userfriendly: print('Assigned masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30d6a8ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22600/1357729287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# training and application runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n\u001b[0m\u001b[1;32m      7\u001b[0m                                 \u001b[0mlabellist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                 \u001b[0mcolorlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/HistStruct.py\u001b[0m in \u001b[0;36mplot_histograms\u001b[0;34m(self, histnames, masknames, histograms, ncols, colorlist, labellist, transparencylist, titledict, xaxtitledict, physicalxax, yaxtitledict, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistnames1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             fig1d,axs1d = self.plot_histograms_1d( histnames=histnames1d, \n\u001b[0;32m--> 943\u001b[0;31m                             \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                             \u001b[0mmasknames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasknames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                             \u001b[0mhistograms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistograms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/HistStruct.py\u001b[0m in \u001b[0;36mplot_histograms_1d\u001b[0;34m(self, histnames, masknames, histograms, ncols, colorlist, labellist, transparencylist, titledict, xaxtitledict, physicalxax, yaxtitledict, **kwargs)\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;31m# make the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             pu.plot_sets( histlist,\n\u001b[0;32m-> 1000\u001b[0;31m                         \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m                         \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxaxtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxaxtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxlims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaxtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaxtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                         \u001b[0mcolorlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolorlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabellist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabellist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransparencylist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransparencylist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../utils/plot_utils.py\u001b[0m in \u001b[0;36mplot_sets\u001b[0;34m(setlist, fig, ax, colorlist, labellist, transparencylist, title, titlesize, xaxtitle, xaxtitlesize, xlims, remove_underflow, remove_overflow, yaxtitle, yaxtitlesize, ylims, ymaxfactor, legendsize, opaque_legend, ticksize)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolorlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransparencylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mymaxfactor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mymax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x, y, where, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_in_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drawstyle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'steps-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhex\u001b[0m \u001b[0mstrings\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m'#008000'\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[0;32m-> 1604\u001b[0;31m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 **kwargs)\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 **kwargs)\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 **kwargs)\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mnormalize_kwargs\u001b[0;34m(kw, alias_mapping, required, forbidden, allowed)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \"\"\"\n\u001b[0;32m-> 1779\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArtist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x3960 with 44 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plotting the input data for analysis\n",
    "\n",
    "if((training_mode=='local' or training_mode == 'development') and createPlots):\n",
    "\n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )\n",
    "    \n",
    "elif( training_mode=='global' and createPlots):\n",
    "    \n",
    "    # bad test runs\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "                                labellist = ['typical good histograms','bad'],\n",
    "                                colorlist = ['blue','red'],\n",
    "                                transparencylist = [0.01,1.]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dc93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_concatamash_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            if userfriendly:\n",
    "                print('\\nNow Defining model {}/'.format(i + 1) \n",
    "                      + str(len(histnames)))\n",
    "                print(' - Size of training set: {}'.format(X_train.shape))\n",
    "            \n",
    "            # Half the total bin count\n",
    "            arch = 51 * len(histnamegroup)\n",
    "            \n",
    "            ## Model parameters\n",
    "            print(X_train.shape)\n",
    "            \n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(arch * 2, activation=\"tanh\")(conc_layer)\n",
    "            #encoder = Dense(128, activation='relu')(encoder)\n",
    "            #\n",
    "            #encoder = Dense(32, activation='relu')(encoder)\n",
    "            \n",
    "            decoder = Dense(arch, activation=\"relu\")(encoder)\n",
    "            #decoder = Dense(256, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoder.summary()\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c76ea4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now Defining model 1/12\n",
      " - Size of training set: (990, 8, 102)\n",
      "(990, 8, 102)\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_43 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 816)          0           input_41[0][0]                   \n",
      "                                                                 input_42[0][0]                   \n",
      "                                                                 input_43[0][0]                   \n",
      "                                                                 input_44[0][0]                   \n",
      "                                                                 input_45[0][0]                   \n",
      "                                                                 input_46[0][0]                   \n",
      "                                                                 input_47[0][0]                   \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 816)          666672      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 408)          333336      dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 102)          41718       dense_65[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,333,752\n",
      "Trainable params: 1,333,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 2/12\n",
      " - Size of training set: (990, 4, 102)\n",
      "(990, 4, 102)\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_49 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_51 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 408)          0           input_49[0][0]                   \n",
      "                                                                 input_50[0][0]                   \n",
      "                                                                 input_51[0][0]                   \n",
      "                                                                 input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 408)          166872      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 204)          83436       dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 102)          20910       dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 102)          20910       dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 102)          20910       dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 102)          20910       dense_75[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 333,948\n",
      "Trainable params: 333,948\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 3/12\n",
      " - Size of training set: (990, 4, 102)\n",
      "(990, 4, 102)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_55 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 408)          0           input_53[0][0]                   \n",
      "                                                                 input_54[0][0]                   \n",
      "                                                                 input_55[0][0]                   \n",
      "                                                                 input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 408)          166872      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 204)          83436       dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 102)          20910       dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 102)          20910       dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 102)          20910       dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 102)          20910       dense_81[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 333,948\n",
      "Trainable params: 333,948\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 4/12\n",
      " - Size of training set: (990, 4, 102)\n",
      "(990, 4, 102)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_57 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_59 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 408)          0           input_57[0][0]                   \n",
      "                                                                 input_58[0][0]                   \n",
      "                                                                 input_59[0][0]                   \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 408)          166872      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 204)          83436       dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 102)          20910       dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 102)          20910       dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 102)          20910       dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 102)          20910       dense_87[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 333,948\n",
      "Trainable params: 333,948\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 5/12\n",
      " - Size of training set: (990, 4, 102)\n",
      "(990, 4, 102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_63 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_64 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 408)          0           input_61[0][0]                   \n",
      "                                                                 input_62[0][0]                   \n",
      "                                                                 input_63[0][0]                   \n",
      "                                                                 input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 408)          166872      concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 204)          83436       dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 102)          20910       dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 102)          20910       dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 102)          20910       dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 102)          20910       dense_93[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 333,948\n",
      "Trainable params: 333,948\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 6/12\n",
      " - Size of training set: (990, 2, 102)\n",
      "(990, 2, 102)\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_66 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 204)          0           input_65[0][0]                   \n",
      "                                                                 input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 204)          41820       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 102)          20910       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 102)          10506       dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 102)          10506       dense_99[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 83,742\n",
      "Trainable params: 83,742\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 7/12\n",
      " - Size of training set: (990, 2, 102)\n",
      "(990, 2, 102)\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_67 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_68 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 204)          0           input_67[0][0]                   \n",
      "                                                                 input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 204)          41820       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 102)          20910       dense_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 102)          10506       dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 102)          10506       dense_103[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 83,742\n",
      "Trainable params: 83,742\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 8/12\n",
      " - Size of training set: (990, 2, 102)\n",
      "(990, 2, 102)\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_69 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_70 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 204)          0           input_69[0][0]                   \n",
      "                                                                 input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 204)          41820       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 102)          20910       dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 102)          10506       dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 102)          10506       dense_107[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 83,742\n",
      "Trainable params: 83,742\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 9/12\n",
      " - Size of training set: (990, 2, 102)\n",
      "(990, 2, 102)\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_72 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 204)          0           input_71[0][0]                   \n",
      "                                                                 input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 204)          41820       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 102)          20910       dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 102)          10506       dense_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 102)          10506       dense_111[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 83,742\n",
      "Trainable params: 83,742\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 10/12\n",
      " - Size of training set: (990, 2, 102)\n",
      "(990, 2, 102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_73 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_74 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 204)          0           input_73[0][0]                   \n",
      "                                                                 input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 204)          41820       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 102)          20910       dense_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 102)          10506       dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 102)          10506       dense_115[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 83,742\n",
      "Trainable params: 83,742\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 11/12\n",
      " - Size of training set: (990, 2, 102)\n",
      "(990, 2, 102)\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_75 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_76 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 204)          0           input_75[0][0]                   \n",
      "                                                                 input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 204)          41820       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 102)          20910       dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 102)          10506       dense_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 102)          10506       dense_119[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 83,742\n",
      "Trainable params: 83,742\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 12/12\n",
      " - Size of training set: (990, 8, 102)\n",
      "(990, 8, 102)\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_77 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_79 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_81 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_82 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_83 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 816)          0           input_77[0][0]                   \n",
      "                                                                 input_78[0][0]                   \n",
      "                                                                 input_79[0][0]                   \n",
      "                                                                 input_80[0][0]                   \n",
      "                                                                 input_81[0][0]                   \n",
      "                                                                 input_82[0][0]                   \n",
      "                                                                 input_83[0][0]                   \n",
      "                                                                 input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 816)          666672      concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 408)          333336      dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_125 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_128 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 102)          41718       dense_123[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,333,752\n",
      "Trainable params: 1,333,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(histslist, vallist, autoencoders, train_normhist) = define_concatamash_autoencoder(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a44e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders):\n",
    "    \n",
    "    # Iterate through the training data to train corresponding autoencoders\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        if userfriendly: print('\\nNow training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 500\n",
    "        batch_size = 50\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                            epochs=nb_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                            verbose=1,\n",
    "                            callbacks= [earlystop],    \n",
    "                            )\n",
    "        \n",
    "        # Create a plot of the model\n",
    "        \n",
    "        tf.keras.utils.plot_model(\n",
    "            autoencoder,\n",
    "            to_file=\"models/modelConcatamash{}.png\".format(i),\n",
    "            show_shapes=True,\n",
    "            show_dtype=False,\n",
    "            show_layer_names=False,\n",
    "            rankdir=\"TB\")\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52397fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now training model 1/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 38ms/step - loss: 0.0013 - dense_66_loss: 1.2371e-04 - dense_67_loss: 1.7670e-04 - dense_68_loss: 1.4109e-04 - dense_69_loss: 1.7935e-04 - dense_70_loss: 1.6264e-04 - dense_71_loss: 1.8325e-04 - dense_72_loss: 1.6352e-04 - dense_73_loss: 1.9466e-04 - val_loss: 1.3648e-04 - val_dense_66_loss: 1.3644e-05 - val_dense_67_loss: 2.1692e-05 - val_dense_68_loss: 1.6783e-05 - val_dense_69_loss: 1.5891e-05 - val_dense_70_loss: 1.5169e-05 - val_dense_71_loss: 1.7129e-05 - val_dense_72_loss: 1.7013e-05 - val_dense_73_loss: 1.9162e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 6.6833e-05 - dense_66_loss: 8.0176e-06 - dense_67_loss: 9.4118e-06 - dense_68_loss: 8.2731e-06 - dense_69_loss: 7.2902e-06 - dense_70_loss: 7.7419e-06 - dense_71_loss: 7.2116e-06 - dense_72_loss: 8.9295e-06 - dense_73_loss: 9.9576e-06 - val_loss: 1.9003e-05 - val_dense_66_loss: 2.6031e-06 - val_dense_67_loss: 2.7247e-06 - val_dense_68_loss: 2.0972e-06 - val_dense_69_loss: 2.5496e-06 - val_dense_70_loss: 2.2074e-06 - val_dense_71_loss: 2.0067e-06 - val_dense_72_loss: 2.4208e-06 - val_dense_73_loss: 2.3932e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0743e-05 - dense_66_loss: 1.1984e-06 - dense_67_loss: 1.7544e-06 - dense_68_loss: 1.1178e-06 - dense_69_loss: 1.3591e-06 - dense_70_loss: 1.2126e-06 - dense_71_loss: 1.2114e-06 - dense_72_loss: 1.4352e-06 - dense_73_loss: 1.4545e-06 - val_loss: 5.0671e-06 - val_dense_66_loss: 4.7212e-07 - val_dense_67_loss: 9.3840e-07 - val_dense_68_loss: 4.6806e-07 - val_dense_69_loss: 6.4091e-07 - val_dense_70_loss: 6.1280e-07 - val_dense_71_loss: 6.0544e-07 - val_dense_72_loss: 6.5065e-07 - val_dense_73_loss: 6.7875e-07\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.0595e-06 - dense_66_loss: 3.2538e-07 - dense_67_loss: 8.4675e-07 - dense_68_loss: 3.2195e-07 - dense_69_loss: 5.8851e-07 - dense_70_loss: 4.5406e-07 - dense_71_loss: 5.1473e-07 - dense_72_loss: 4.9680e-07 - dense_73_loss: 5.1135e-07 - val_loss: 3.1551e-06 - val_dense_66_loss: 2.2347e-07 - val_dense_67_loss: 7.0098e-07 - val_dense_68_loss: 2.4226e-07 - val_dense_69_loss: 4.6643e-07 - val_dense_70_loss: 3.3225e-07 - val_dense_71_loss: 4.3733e-07 - val_dense_72_loss: 3.7865e-07 - val_dense_73_loss: 3.7374e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.1541e-06 - dense_66_loss: 2.2298e-07 - dense_67_loss: 7.2298e-07 - dense_68_loss: 2.2830e-07 - dense_69_loss: 4.7993e-07 - dense_70_loss: 3.3501e-07 - dense_71_loss: 4.1180e-07 - dense_72_loss: 3.7199e-07 - dense_73_loss: 3.8116e-07 - val_loss: 3.3047e-06 - val_dense_66_loss: 2.5015e-07 - val_dense_67_loss: 7.0887e-07 - val_dense_68_loss: 2.6210e-07 - val_dense_69_loss: 4.9748e-07 - val_dense_70_loss: 3.7336e-07 - val_dense_71_loss: 4.2437e-07 - val_dense_72_loss: 3.8849e-07 - val_dense_73_loss: 3.9992e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.5755e-06 - dense_66_loss: 4.5697e-07 - dense_67_loss: 8.6384e-07 - dense_68_loss: 3.9429e-07 - dense_69_loss: 6.9316e-07 - dense_70_loss: 5.1979e-07 - dense_71_loss: 5.6307e-07 - dense_72_loss: 5.4168e-07 - dense_73_loss: 5.4274e-07 - val_loss: 1.1126e-05 - val_dense_66_loss: 1.5845e-06 - val_dense_67_loss: 1.6015e-06 - val_dense_68_loss: 9.8445e-07 - val_dense_69_loss: 1.6444e-06 - val_dense_70_loss: 1.3587e-06 - val_dense_71_loss: 1.3968e-06 - val_dense_72_loss: 1.2882e-06 - val_dense_73_loss: 1.2679e-06\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 4.8128e-06 - dense_66_loss: 4.8420e-07 - dense_67_loss: 8.8760e-07 - dense_68_loss: 4.0942e-07 - dense_69_loss: 7.0408e-07 - dense_70_loss: 5.5458e-07 - dense_71_loss: 6.2883e-07 - dense_72_loss: 5.7819e-07 - dense_73_loss: 5.6594e-07 - val_loss: 3.6523e-06 - val_dense_66_loss: 2.8052e-07 - val_dense_67_loss: 7.3085e-07 - val_dense_68_loss: 2.8391e-07 - val_dense_69_loss: 5.3036e-07 - val_dense_70_loss: 4.2733e-07 - val_dense_71_loss: 4.7608e-07 - val_dense_72_loss: 4.7739e-07 - val_dense_73_loss: 4.4582e-07\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.5730e-06 - dense_66_loss: 2.8488e-07 - dense_67_loss: 7.4875e-07 - dense_68_loss: 2.9174e-07 - dense_69_loss: 5.1056e-07 - dense_70_loss: 4.0909e-07 - dense_71_loss: 4.5847e-07 - dense_72_loss: 4.3644e-07 - dense_73_loss: 4.3311e-07 - val_loss: 3.8640e-06 - val_dense_66_loss: 3.5068e-07 - val_dense_67_loss: 7.2729e-07 - val_dense_68_loss: 3.5752e-07 - val_dense_69_loss: 5.4191e-07 - val_dense_70_loss: 4.6862e-07 - val_dense_71_loss: 4.7517e-07 - val_dense_72_loss: 4.5055e-07 - val_dense_73_loss: 4.9227e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.4198e-06 - dense_66_loss: 2.7288e-07 - dense_67_loss: 7.1069e-07 - dense_68_loss: 2.8112e-07 - dense_69_loss: 4.8615e-07 - dense_70_loss: 4.0423e-07 - dense_71_loss: 4.4006e-07 - dense_72_loss: 4.1019e-07 - dense_73_loss: 4.1443e-07 - val_loss: 2.7724e-06 - val_dense_66_loss: 1.9305e-07 - val_dense_67_loss: 6.2713e-07 - val_dense_68_loss: 2.0711e-07 - val_dense_69_loss: 4.0323e-07 - val_dense_70_loss: 3.1763e-07 - val_dense_71_loss: 3.4669e-07 - val_dense_72_loss: 3.4868e-07 - val_dense_73_loss: 3.2884e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 7.0658e-06 - dense_66_loss: 7.3605e-07 - dense_67_loss: 1.1240e-06 - dense_68_loss: 7.3177e-07 - dense_69_loss: 9.2449e-07 - dense_70_loss: 8.4830e-07 - dense_71_loss: 9.5321e-07 - dense_72_loss: 8.3187e-07 - dense_73_loss: 9.1617e-07 - val_loss: 4.7131e-06 - val_dense_66_loss: 4.7949e-07 - val_dense_67_loss: 8.4213e-07 - val_dense_68_loss: 4.6582e-07 - val_dense_69_loss: 6.4235e-07 - val_dense_70_loss: 5.4739e-07 - val_dense_71_loss: 5.7300e-07 - val_dense_72_loss: 5.9266e-07 - val_dense_73_loss: 5.7029e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.8461e-06 - dense_66_loss: 3.3925e-07 - dense_67_loss: 7.4744e-07 - dense_68_loss: 3.4430e-07 - dense_69_loss: 5.3656e-07 - dense_70_loss: 4.5957e-07 - dense_71_loss: 4.7935e-07 - dense_72_loss: 4.8925e-07 - dense_73_loss: 4.5034e-07 - val_loss: 5.8806e-06 - val_dense_66_loss: 6.5204e-07 - val_dense_67_loss: 9.6806e-07 - val_dense_68_loss: 4.8278e-07 - val_dense_69_loss: 8.4600e-07 - val_dense_70_loss: 7.7203e-07 - val_dense_71_loss: 7.7373e-07 - val_dense_72_loss: 7.2576e-07 - val_dense_73_loss: 6.6023e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 8.2740e-06 - dense_66_loss: 9.4009e-07 - dense_67_loss: 1.3747e-06 - dense_68_loss: 7.5736e-07 - dense_69_loss: 1.1251e-06 - dense_70_loss: 1.0255e-06 - dense_71_loss: 1.0703e-06 - dense_72_loss: 1.0350e-06 - dense_73_loss: 9.4585e-07 - val_loss: 4.5439e-06 - val_dense_66_loss: 5.3161e-07 - val_dense_67_loss: 8.1059e-07 - val_dense_68_loss: 3.5353e-07 - val_dense_69_loss: 6.5283e-07 - val_dense_70_loss: 5.6497e-07 - val_dense_71_loss: 5.4141e-07 - val_dense_72_loss: 5.8006e-07 - val_dense_73_loss: 5.0886e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 4.0070e-06 - dense_66_loss: 3.8568e-07 - dense_67_loss: 7.5037e-07 - dense_68_loss: 3.5525e-07 - dense_69_loss: 5.6169e-07 - dense_70_loss: 4.8112e-07 - dense_71_loss: 4.8598e-07 - dense_72_loss: 4.9882e-07 - dense_73_loss: 4.8807e-07 - val_loss: 3.0028e-06 - val_dense_66_loss: 2.2849e-07 - val_dense_67_loss: 6.0855e-07 - val_dense_68_loss: 2.6275e-07 - val_dense_69_loss: 4.2909e-07 - val_dense_70_loss: 3.3946e-07 - val_dense_71_loss: 3.8746e-07 - val_dense_72_loss: 4.0043e-07 - val_dense_73_loss: 3.4660e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.6299e-06 - dense_66_loss: 3.1276e-07 - dense_67_loss: 6.9104e-07 - dense_68_loss: 3.2852e-07 - dense_69_loss: 5.3291e-07 - dense_70_loss: 4.4126e-07 - dense_71_loss: 4.4247e-07 - dense_72_loss: 4.3894e-07 - dense_73_loss: 4.4203e-07 - val_loss: 4.1577e-06 - val_dense_66_loss: 3.9428e-07 - val_dense_67_loss: 7.3718e-07 - val_dense_68_loss: 4.1193e-07 - val_dense_69_loss: 5.6525e-07 - val_dense_70_loss: 5.0105e-07 - val_dense_71_loss: 5.0929e-07 - val_dense_72_loss: 5.3207e-07 - val_dense_73_loss: 5.0664e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.4556e-06 - dense_66_loss: 3.0892e-07 - dense_67_loss: 6.6365e-07 - dense_68_loss: 2.9654e-07 - dense_69_loss: 4.8262e-07 - dense_70_loss: 4.2073e-07 - dense_71_loss: 4.1184e-07 - dense_72_loss: 4.4621e-07 - dense_73_loss: 4.2509e-07 - val_loss: 4.6485e-06 - val_dense_66_loss: 5.3450e-07 - val_dense_67_loss: 7.3483e-07 - val_dense_68_loss: 4.7985e-07 - val_dense_69_loss: 6.2304e-07 - val_dense_70_loss: 5.9636e-07 - val_dense_71_loss: 4.7415e-07 - val_dense_72_loss: 5.9110e-07 - val_dense_73_loss: 6.1464e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.1644e-06 - dense_66_loss: 3.8760e-07 - dense_67_loss: 7.4425e-07 - dense_68_loss: 4.0210e-07 - dense_69_loss: 5.7092e-07 - dense_70_loss: 5.0267e-07 - dense_71_loss: 4.9511e-07 - dense_72_loss: 5.3572e-07 - dense_73_loss: 5.2608e-07 - val_loss: 2.5874e-06 - val_dense_66_loss: 1.9411e-07 - val_dense_67_loss: 5.4079e-07 - val_dense_68_loss: 2.0056e-07 - val_dense_69_loss: 3.6245e-07 - val_dense_70_loss: 3.1110e-07 - val_dense_71_loss: 3.3185e-07 - val_dense_72_loss: 3.4040e-07 - val_dense_73_loss: 3.0611e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.7596e-06 - dense_66_loss: 4.7341e-07 - dense_67_loss: 8.0506e-07 - dense_68_loss: 4.5906e-07 - dense_69_loss: 7.0107e-07 - dense_70_loss: 5.9538e-07 - dense_71_loss: 5.6899e-07 - dense_72_loss: 5.6990e-07 - dense_73_loss: 5.8676e-07 - val_loss: 3.3747e-06 - val_dense_66_loss: 3.0001e-07 - val_dense_67_loss: 6.3585e-07 - val_dense_68_loss: 2.8367e-07 - val_dense_69_loss: 5.0737e-07 - val_dense_70_loss: 3.8277e-07 - val_dense_71_loss: 4.1359e-07 - val_dense_72_loss: 4.4155e-07 - val_dense_73_loss: 4.0990e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.7378e-06 - dense_66_loss: 3.4916e-07 - dense_67_loss: 6.7774e-07 - dense_68_loss: 3.4483e-07 - dense_69_loss: 5.1856e-07 - dense_70_loss: 4.5351e-07 - dense_71_loss: 4.6590e-07 - dense_72_loss: 4.8584e-07 - dense_73_loss: 4.4229e-07 - val_loss: 5.2230e-06 - val_dense_66_loss: 5.7201e-07 - val_dense_67_loss: 8.1288e-07 - val_dense_68_loss: 5.2345e-07 - val_dense_69_loss: 7.3798e-07 - val_dense_70_loss: 6.0097e-07 - val_dense_71_loss: 6.0154e-07 - val_dense_72_loss: 7.1334e-07 - val_dense_73_loss: 6.6083e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.2506e-06 - dense_66_loss: 5.5904e-07 - dense_67_loss: 8.2921e-07 - dense_68_loss: 5.5085e-07 - dense_69_loss: 7.1052e-07 - dense_70_loss: 6.4889e-07 - dense_71_loss: 6.2781e-07 - dense_72_loss: 6.6184e-07 - dense_73_loss: 6.6243e-07 - val_loss: 9.1195e-06 - val_dense_66_loss: 9.8070e-07 - val_dense_67_loss: 1.3078e-06 - val_dense_68_loss: 1.0671e-06 - val_dense_69_loss: 1.0476e-06 - val_dense_70_loss: 1.0435e-06 - val_dense_71_loss: 1.2671e-06 - val_dense_72_loss: 1.2004e-06 - val_dense_73_loss: 1.2054e-06\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.5118e-06 - dense_66_loss: 4.3568e-07 - dense_67_loss: 7.7528e-07 - dense_68_loss: 4.5006e-07 - dense_69_loss: 5.8460e-07 - dense_70_loss: 5.4722e-07 - dense_71_loss: 5.5520e-07 - dense_72_loss: 5.9915e-07 - dense_73_loss: 5.6460e-07 - val_loss: 3.2578e-06 - val_dense_66_loss: 3.0706e-07 - val_dense_67_loss: 6.1862e-07 - val_dense_68_loss: 2.7495e-07 - val_dense_69_loss: 4.3225e-07 - val_dense_70_loss: 4.1757e-07 - val_dense_71_loss: 3.8594e-07 - val_dense_72_loss: 4.3040e-07 - val_dense_73_loss: 3.9096e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.6654e-06 - dense_66_loss: 3.3665e-07 - dense_67_loss: 6.7661e-07 - dense_68_loss: 3.3570e-07 - dense_69_loss: 4.9741e-07 - dense_70_loss: 4.4894e-07 - dense_71_loss: 4.3638e-07 - dense_72_loss: 4.8162e-07 - dense_73_loss: 4.5206e-07 - val_loss: 3.7438e-06 - val_dense_66_loss: 4.0527e-07 - val_dense_67_loss: 6.2796e-07 - val_dense_68_loss: 3.4850e-07 - val_dense_69_loss: 5.0732e-07 - val_dense_70_loss: 4.6479e-07 - val_dense_71_loss: 4.1762e-07 - val_dense_72_loss: 4.9883e-07 - val_dense_73_loss: 4.7350e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.8533e-06 - dense_66_loss: 6.2761e-07 - dense_67_loss: 8.7828e-07 - dense_68_loss: 5.8550e-07 - dense_69_loss: 7.8706e-07 - dense_70_loss: 6.6144e-07 - dense_71_loss: 8.5908e-07 - dense_72_loss: 7.7494e-07 - dense_73_loss: 6.7937e-07 - val_loss: 3.7121e-06 - val_dense_66_loss: 3.9416e-07 - val_dense_67_loss: 6.2703e-07 - val_dense_68_loss: 2.8761e-07 - val_dense_69_loss: 4.8613e-07 - val_dense_70_loss: 4.8464e-07 - val_dense_71_loss: 4.7286e-07 - val_dense_72_loss: 5.1074e-07 - val_dense_73_loss: 4.4892e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.8652e-06 - dense_66_loss: 3.6659e-07 - dense_67_loss: 6.8725e-07 - dense_68_loss: 3.5891e-07 - dense_69_loss: 5.3023e-07 - dense_70_loss: 4.7399e-07 - dense_71_loss: 4.8199e-07 - dense_72_loss: 5.0148e-07 - dense_73_loss: 4.6473e-07 - val_loss: 4.8597e-06 - val_dense_66_loss: 5.2202e-07 - val_dense_67_loss: 8.5409e-07 - val_dense_68_loss: 4.6101e-07 - val_dense_69_loss: 5.8921e-07 - val_dense_70_loss: 6.0696e-07 - val_dense_71_loss: 5.6759e-07 - val_dense_72_loss: 6.2652e-07 - val_dense_73_loss: 6.3228e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.6929e-06 - dense_66_loss: 4.8591e-07 - dense_67_loss: 8.6156e-07 - dense_68_loss: 4.2621e-07 - dense_69_loss: 6.4455e-07 - dense_70_loss: 5.6244e-07 - dense_71_loss: 5.4780e-07 - dense_72_loss: 5.9272e-07 - dense_73_loss: 5.7176e-07 - val_loss: 3.9495e-06 - val_dense_66_loss: 3.5345e-07 - val_dense_67_loss: 6.8969e-07 - val_dense_68_loss: 3.3329e-07 - val_dense_69_loss: 5.4543e-07 - val_dense_70_loss: 4.6823e-07 - val_dense_71_loss: 5.2348e-07 - val_dense_72_loss: 5.5862e-07 - val_dense_73_loss: 4.7728e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.6325e-06 - dense_66_loss: 3.2368e-07 - dense_67_loss: 6.6058e-07 - dense_68_loss: 3.3147e-07 - dense_69_loss: 5.0447e-07 - dense_70_loss: 4.3503e-07 - dense_71_loss: 4.4708e-07 - dense_72_loss: 4.9820e-07 - dense_73_loss: 4.3195e-07 - val_loss: 3.3549e-06 - val_dense_66_loss: 2.9801e-07 - val_dense_67_loss: 6.1259e-07 - val_dense_68_loss: 2.9233e-07 - val_dense_69_loss: 4.5898e-07 - val_dense_70_loss: 4.1849e-07 - val_dense_71_loss: 4.4980e-07 - val_dense_72_loss: 4.3935e-07 - val_dense_73_loss: 3.8540e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.6483e-06 - dense_66_loss: 3.5422e-07 - dense_67_loss: 6.6105e-07 - dense_68_loss: 3.3175e-07 - dense_69_loss: 4.9431e-07 - dense_70_loss: 4.5736e-07 - dense_71_loss: 4.3931e-07 - dense_72_loss: 4.7865e-07 - dense_73_loss: 4.3165e-07 - val_loss: 3.0514e-06 - val_dense_66_loss: 2.8234e-07 - val_dense_67_loss: 5.6256e-07 - val_dense_68_loss: 2.4155e-07 - val_dense_69_loss: 4.4111e-07 - val_dense_70_loss: 3.9393e-07 - val_dense_71_loss: 3.7280e-07 - val_dense_72_loss: 3.7143e-07 - val_dense_73_loss: 3.8571e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.9100e-06 - dense_66_loss: 3.9238e-07 - dense_67_loss: 6.9348e-07 - dense_68_loss: 3.6143e-07 - dense_69_loss: 5.2613e-07 - dense_70_loss: 4.8817e-07 - dense_71_loss: 4.5707e-07 - dense_72_loss: 5.1170e-07 - dense_73_loss: 4.7969e-07 - val_loss: 4.2670e-06 - val_dense_66_loss: 4.0957e-07 - val_dense_67_loss: 7.6142e-07 - val_dense_68_loss: 4.1102e-07 - val_dense_69_loss: 5.8829e-07 - val_dense_70_loss: 4.8471e-07 - val_dense_71_loss: 5.0804e-07 - val_dense_72_loss: 6.0397e-07 - val_dense_73_loss: 4.9997e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.5577e-06 - dense_66_loss: 4.5250e-07 - dense_67_loss: 7.7421e-07 - dense_68_loss: 4.1913e-07 - dense_69_loss: 6.4777e-07 - dense_70_loss: 5.8689e-07 - dense_71_loss: 5.2956e-07 - dense_72_loss: 5.8733e-07 - dense_73_loss: 5.6029e-07 - val_loss: 4.7923e-06 - val_dense_66_loss: 4.2581e-07 - val_dense_67_loss: 7.7320e-07 - val_dense_68_loss: 4.7307e-07 - val_dense_69_loss: 6.0946e-07 - val_dense_70_loss: 6.2238e-07 - val_dense_71_loss: 5.9355e-07 - val_dense_72_loss: 6.2837e-07 - val_dense_73_loss: 6.6649e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 4.0589e-06 - dense_66_loss: 3.6860e-07 - dense_67_loss: 7.2537e-07 - dense_68_loss: 3.8521e-07 - dense_69_loss: 5.3672e-07 - dense_70_loss: 5.2206e-07 - dense_71_loss: 4.9392e-07 - dense_72_loss: 5.3150e-07 - dense_73_loss: 4.9556e-07 - val_loss: 3.8188e-06 - val_dense_66_loss: 3.7171e-07 - val_dense_67_loss: 6.6003e-07 - val_dense_68_loss: 3.4641e-07 - val_dense_69_loss: 5.4370e-07 - val_dense_70_loss: 4.2017e-07 - val_dense_71_loss: 4.4076e-07 - val_dense_72_loss: 5.6665e-07 - val_dense_73_loss: 4.6937e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.8202e-06 - dense_66_loss: 3.4555e-07 - dense_67_loss: 6.9798e-07 - dense_68_loss: 3.6079e-07 - dense_69_loss: 5.2669e-07 - dense_70_loss: 4.4632e-07 - dense_71_loss: 4.4908e-07 - dense_72_loss: 5.2083e-07 - dense_73_loss: 4.7294e-07 - val_loss: 3.7311e-06 - val_dense_66_loss: 3.7547e-07 - val_dense_67_loss: 6.3360e-07 - val_dense_68_loss: 3.7057e-07 - val_dense_69_loss: 4.9291e-07 - val_dense_70_loss: 4.3147e-07 - val_dense_71_loss: 4.3525e-07 - val_dense_72_loss: 5.0134e-07 - val_dense_73_loss: 4.9046e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.5284e-06 - dense_66_loss: 3.2399e-07 - dense_67_loss: 6.4248e-07 - dense_68_loss: 3.3526e-07 - dense_69_loss: 4.6345e-07 - dense_70_loss: 4.4201e-07 - dense_71_loss: 4.1624e-07 - dense_72_loss: 4.7758e-07 - dense_73_loss: 4.2741e-07 - val_loss: 3.1008e-06 - val_dense_66_loss: 2.9705e-07 - val_dense_67_loss: 5.5078e-07 - val_dense_68_loss: 2.9811e-07 - val_dense_69_loss: 4.0934e-07 - val_dense_70_loss: 3.9020e-07 - val_dense_71_loss: 3.7024e-07 - val_dense_72_loss: 4.0593e-07 - val_dense_73_loss: 3.7920e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.7122e-06 - dense_66_loss: 4.5904e-07 - dense_67_loss: 7.3595e-07 - dense_68_loss: 4.8236e-07 - dense_69_loss: 6.3599e-07 - dense_70_loss: 6.0132e-07 - dense_71_loss: 5.8638e-07 - dense_72_loss: 6.2901e-07 - dense_73_loss: 5.8219e-07 - val_loss: 4.0213e-06 - val_dense_66_loss: 3.8963e-07 - val_dense_67_loss: 6.5879e-07 - val_dense_68_loss: 4.2413e-07 - val_dense_69_loss: 4.7850e-07 - val_dense_70_loss: 5.6200e-07 - val_dense_71_loss: 4.9863e-07 - val_dense_72_loss: 5.3283e-07 - val_dense_73_loss: 4.7676e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.2357e-06 - dense_66_loss: 2.9604e-07 - dense_67_loss: 5.8981e-07 - dense_68_loss: 3.1756e-07 - dense_69_loss: 4.3222e-07 - dense_70_loss: 4.0998e-07 - dense_71_loss: 3.7033e-07 - dense_72_loss: 4.3856e-07 - dense_73_loss: 3.8125e-07 - val_loss: 3.5661e-06 - val_dense_66_loss: 3.5481e-07 - val_dense_67_loss: 5.6014e-07 - val_dense_68_loss: 3.2137e-07 - val_dense_69_loss: 5.3151e-07 - val_dense_70_loss: 4.7754e-07 - val_dense_71_loss: 3.8695e-07 - val_dense_72_loss: 4.9510e-07 - val_dense_73_loss: 4.3869e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.7912e-06 - dense_66_loss: 5.1951e-07 - dense_67_loss: 7.3486e-07 - dense_68_loss: 4.6380e-07 - dense_69_loss: 6.6440e-07 - dense_70_loss: 5.8241e-07 - dense_71_loss: 5.4187e-07 - dense_72_loss: 6.6891e-07 - dense_73_loss: 6.1547e-07 - val_loss: 3.6190e-06 - val_dense_66_loss: 3.4555e-07 - val_dense_67_loss: 6.3249e-07 - val_dense_68_loss: 3.5349e-07 - val_dense_69_loss: 4.8466e-07 - val_dense_70_loss: 4.0639e-07 - val_dense_71_loss: 4.0817e-07 - val_dense_72_loss: 5.0058e-07 - val_dense_73_loss: 4.8772e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.3418e-06 - dense_66_loss: 4.1940e-07 - dense_67_loss: 7.0279e-07 - dense_68_loss: 4.2468e-07 - dense_69_loss: 5.9997e-07 - dense_70_loss: 5.1183e-07 - dense_71_loss: 5.3336e-07 - dense_72_loss: 5.9172e-07 - dense_73_loss: 5.5808e-07 - val_loss: 3.9249e-06 - val_dense_66_loss: 4.4469e-07 - val_dense_67_loss: 7.1095e-07 - val_dense_68_loss: 3.5870e-07 - val_dense_69_loss: 5.3985e-07 - val_dense_70_loss: 4.4653e-07 - val_dense_71_loss: 4.6433e-07 - val_dense_72_loss: 5.1469e-07 - val_dense_73_loss: 4.4512e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.9039e-06 - dense_66_loss: 4.0075e-07 - dense_67_loss: 6.9721e-07 - dense_68_loss: 3.6420e-07 - dense_69_loss: 4.9767e-07 - dense_70_loss: 4.8882e-07 - dense_71_loss: 4.7814e-07 - dense_72_loss: 5.2227e-07 - dense_73_loss: 4.5480e-07 - val_loss: 2.7485e-06 - val_dense_66_loss: 2.6226e-07 - val_dense_67_loss: 5.2739e-07 - val_dense_68_loss: 2.4344e-07 - val_dense_69_loss: 3.4775e-07 - val_dense_70_loss: 3.5350e-07 - val_dense_71_loss: 3.2322e-07 - val_dense_72_loss: 3.8251e-07 - val_dense_73_loss: 3.0840e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "\n",
      "Now training model 2/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 16ms/step - loss: 0.0012 - dense_76_loss: 1.5438e-04 - dense_77_loss: 1.8037e-04 - dense_78_loss: 2.8063e-04 - dense_79_loss: 6.0495e-04 - val_loss: 2.4374e-04 - val_dense_76_loss: 3.8702e-05 - val_dense_77_loss: 4.1448e-05 - val_dense_78_loss: 5.0062e-05 - val_dense_79_loss: 1.1353e-04\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2569e-04 - dense_76_loss: 2.4343e-05 - dense_77_loss: 2.0715e-05 - dense_78_loss: 4.1049e-05 - dense_79_loss: 3.9578e-05 - val_loss: 5.9955e-05 - val_dense_76_loss: 1.2671e-05 - val_dense_77_loss: 1.0015e-05 - val_dense_78_loss: 2.6759e-05 - val_dense_79_loss: 1.0510e-05\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 5.1337e-05 - dense_76_loss: 1.0593e-05 - dense_77_loss: 7.2214e-06 - dense_78_loss: 2.5032e-05 - dense_79_loss: 8.4898e-06 - val_loss: 4.1946e-05 - val_dense_76_loss: 8.1080e-06 - val_dense_77_loss: 5.0725e-06 - val_dense_78_loss: 2.2466e-05 - val_dense_79_loss: 6.2993e-06\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.1869e-05 - dense_76_loss: 8.5012e-06 - dense_77_loss: 5.0195e-06 - dense_78_loss: 2.1490e-05 - dense_79_loss: 6.8581e-06 - val_loss: 3.8050e-05 - val_dense_76_loss: 7.5087e-06 - val_dense_77_loss: 4.1485e-06 - val_dense_78_loss: 2.0630e-05 - val_dense_79_loss: 5.7634e-06\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.8738e-05 - dense_76_loss: 8.1173e-06 - dense_77_loss: 4.4291e-06 - dense_78_loss: 1.9593e-05 - dense_79_loss: 6.5985e-06 - val_loss: 3.5116e-05 - val_dense_76_loss: 7.2788e-06 - val_dense_77_loss: 3.7412e-06 - val_dense_78_loss: 1.8356e-05 - val_dense_79_loss: 5.7399e-06\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.5631e-05 - dense_76_loss: 7.8725e-06 - dense_77_loss: 3.9819e-06 - dense_78_loss: 1.7164e-05 - dense_79_loss: 6.6126e-06 - val_loss: 3.2155e-05 - val_dense_76_loss: 7.1974e-06 - val_dense_77_loss: 3.4049e-06 - val_dense_78_loss: 1.5738e-05 - val_dense_79_loss: 5.8149e-06\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.1856e-05 - dense_76_loss: 7.5921e-06 - dense_77_loss: 3.4790e-06 - dense_78_loss: 1.4171e-05 - dense_79_loss: 6.6146e-06 - val_loss: 2.7850e-05 - val_dense_76_loss: 6.9099e-06 - val_dense_77_loss: 2.8676e-06 - val_dense_78_loss: 1.2304e-05 - val_dense_79_loss: 5.7686e-06\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.6673e-05 - dense_76_loss: 7.1430e-06 - dense_77_loss: 2.8171e-06 - dense_78_loss: 1.0321e-05 - dense_79_loss: 6.3918e-06 - val_loss: 2.2411e-05 - val_dense_76_loss: 6.4338e-06 - val_dense_77_loss: 2.2626e-06 - val_dense_78_loss: 8.2768e-06 - val_dense_79_loss: 5.4382e-06\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.1067e-05 - dense_76_loss: 6.4888e-06 - dense_77_loss: 2.1628e-06 - dense_78_loss: 6.5565e-06 - dense_79_loss: 5.8586e-06 - val_loss: 1.7001e-05 - val_dense_76_loss: 5.7579e-06 - val_dense_77_loss: 1.6922e-06 - val_dense_78_loss: 4.7995e-06 - val_dense_79_loss: 4.7511e-06\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.6104e-05 - dense_76_loss: 5.7641e-06 - dense_77_loss: 1.5865e-06 - dense_78_loss: 3.6174e-06 - dense_79_loss: 5.1362e-06 - val_loss: 1.3154e-05 - val_dense_76_loss: 5.1728e-06 - val_dense_77_loss: 1.3023e-06 - val_dense_78_loss: 2.5592e-06 - val_dense_79_loss: 4.1198e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.2820e-05 - dense_76_loss: 5.0481e-06 - dense_77_loss: 1.2173e-06 - dense_78_loss: 2.0426e-06 - dense_79_loss: 4.5124e-06 - val_loss: 1.0809e-05 - val_dense_76_loss: 4.6491e-06 - val_dense_77_loss: 1.0106e-06 - val_dense_78_loss: 1.4881e-06 - val_dense_79_loss: 3.6610e-06\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1075e-05 - dense_76_loss: 4.5690e-06 - dense_77_loss: 1.0339e-06 - dense_78_loss: 1.3730e-06 - dense_79_loss: 4.0995e-06 - val_loss: 9.4788e-06 - val_dense_76_loss: 4.1107e-06 - val_dense_77_loss: 9.0565e-07 - val_dense_78_loss: 1.1310e-06 - val_dense_79_loss: 3.3313e-06\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0078e-05 - dense_76_loss: 4.1444e-06 - dense_77_loss: 9.8505e-07 - dense_78_loss: 1.1487e-06 - dense_79_loss: 3.7994e-06 - val_loss: 8.5633e-06 - val_dense_76_loss: 3.6591e-06 - val_dense_77_loss: 8.5289e-07 - val_dense_78_loss: 9.6063e-07 - val_dense_79_loss: 3.0907e-06\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.2292e-06 - dense_76_loss: 3.7144e-06 - dense_77_loss: 9.6049e-07 - dense_78_loss: 1.0411e-06 - dense_79_loss: 3.5132e-06 - val_loss: 7.8071e-06 - val_dense_76_loss: 3.2560e-06 - val_dense_77_loss: 8.3280e-07 - val_dense_78_loss: 8.8750e-07 - val_dense_79_loss: 2.8308e-06\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.4008e-06 - dense_76_loss: 3.2630e-06 - dense_77_loss: 9.5872e-07 - dense_78_loss: 9.7854e-07 - dense_79_loss: 3.2005e-06 - val_loss: 7.1279e-06 - val_dense_76_loss: 2.8659e-06 - val_dense_77_loss: 8.4514e-07 - val_dense_78_loss: 8.4754e-07 - val_dense_79_loss: 2.5694e-06\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 7.6126e-06 - dense_76_loss: 2.8273e-06 - dense_77_loss: 9.7510e-07 - dense_78_loss: 9.4018e-07 - dense_79_loss: 2.8700e-06 - val_loss: 6.2853e-06 - val_dense_76_loss: 2.4436e-06 - val_dense_77_loss: 8.3297e-07 - val_dense_78_loss: 7.9118e-07 - val_dense_79_loss: 2.2176e-06\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 6.4819e-06 - dense_76_loss: 2.3290e-06 - dense_77_loss: 9.1614e-07 - dense_78_loss: 8.4213e-07 - dense_79_loss: 2.3946e-06 - val_loss: 5.4014e-06 - val_dense_76_loss: 2.0222e-06 - val_dense_77_loss: 8.0863e-07 - val_dense_78_loss: 7.1552e-07 - val_dense_79_loss: 1.8551e-06\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 5.4749e-06 - dense_76_loss: 1.9117e-06 - dense_77_loss: 8.6506e-07 - dense_78_loss: 7.5035e-07 - dense_79_loss: 1.9478e-06 - val_loss: 4.5075e-06 - val_dense_76_loss: 1.6790e-06 - val_dense_77_loss: 7.2490e-07 - val_dense_78_loss: 6.3619e-07 - val_dense_79_loss: 1.4674e-06\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4.4803e-06 - dense_76_loss: 1.5699e-06 - dense_77_loss: 7.7591e-07 - dense_78_loss: 6.3538e-07 - dense_79_loss: 1.4991e-06 - val_loss: 3.7764e-06 - val_dense_76_loss: 1.4541e-06 - val_dense_77_loss: 6.6305e-07 - val_dense_78_loss: 5.5384e-07 - val_dense_79_loss: 1.1054e-06\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.7375e-06 - dense_76_loss: 1.3515e-06 - dense_77_loss: 7.0448e-07 - dense_78_loss: 5.5345e-07 - dense_79_loss: 1.1281e-06 - val_loss: 3.1781e-06 - val_dense_76_loss: 1.2487e-06 - val_dense_77_loss: 6.1081e-07 - val_dense_78_loss: 4.8697e-07 - val_dense_79_loss: 8.3166e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.1540e-06 - dense_76_loss: 1.1724e-06 - dense_77_loss: 6.4669e-07 - dense_78_loss: 4.8311e-07 - dense_79_loss: 8.5178e-07 - val_loss: 2.8284e-06 - val_dense_76_loss: 1.1165e-06 - val_dense_77_loss: 5.9911e-07 - val_dense_78_loss: 4.5114e-07 - val_dense_79_loss: 6.6162e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.8281e-06 - dense_76_loss: 1.0829e-06 - dense_77_loss: 6.2023e-07 - dense_78_loss: 4.5059e-07 - dense_79_loss: 6.7431e-07 - val_loss: 2.5330e-06 - val_dense_76_loss: 1.0446e-06 - val_dense_77_loss: 5.4942e-07 - val_dense_78_loss: 4.1452e-07 - val_dense_79_loss: 5.2450e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.5401e-06 - dense_76_loss: 9.8101e-07 - dense_77_loss: 5.9360e-07 - dense_78_loss: 4.2094e-07 - dense_79_loss: 5.4460e-07 - val_loss: 2.2560e-06 - val_dense_76_loss: 9.2142e-07 - val_dense_77_loss: 5.2759e-07 - val_dense_78_loss: 3.8343e-07 - val_dense_79_loss: 4.2354e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.3105e-06 - dense_76_loss: 8.9956e-07 - dense_77_loss: 5.7022e-07 - dense_78_loss: 3.8704e-07 - dense_79_loss: 4.5369e-07 - val_loss: 2.0694e-06 - val_dense_76_loss: 8.3774e-07 - val_dense_77_loss: 4.9796e-07 - val_dense_78_loss: 3.7352e-07 - val_dense_79_loss: 3.6014e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.1967e-06 - dense_76_loss: 8.4025e-07 - dense_77_loss: 5.6509e-07 - dense_78_loss: 3.8291e-07 - dense_79_loss: 4.0847e-07 - val_loss: 2.4261e-06 - val_dense_76_loss: 9.1117e-07 - val_dense_77_loss: 6.1490e-07 - val_dense_78_loss: 4.3637e-07 - val_dense_79_loss: 4.6365e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.3673e-06 - dense_76_loss: 8.6694e-07 - dense_77_loss: 6.2656e-07 - dense_78_loss: 4.2390e-07 - dense_79_loss: 4.4994e-07 - val_loss: 2.1275e-06 - val_dense_76_loss: 7.8532e-07 - val_dense_77_loss: 5.6327e-07 - val_dense_78_loss: 4.0124e-07 - val_dense_79_loss: 3.7767e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.0529e-06 - dense_76_loss: 7.5240e-07 - dense_77_loss: 5.6809e-07 - dense_78_loss: 3.6281e-07 - dense_79_loss: 3.6960e-07 - val_loss: 1.7640e-06 - val_dense_76_loss: 6.6542e-07 - val_dense_77_loss: 4.8702e-07 - val_dense_78_loss: 3.1336e-07 - val_dense_79_loss: 2.9818e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.8014e-06 - dense_76_loss: 6.5966e-07 - dense_77_loss: 5.1983e-07 - dense_78_loss: 3.1135e-07 - dense_79_loss: 3.1055e-07 - val_loss: 1.7042e-06 - val_dense_76_loss: 6.2604e-07 - val_dense_77_loss: 4.7721e-07 - val_dense_78_loss: 3.1736e-07 - val_dense_79_loss: 2.8358e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.7910e-06 - dense_76_loss: 6.3285e-07 - dense_77_loss: 5.2776e-07 - dense_78_loss: 3.1453e-07 - dense_79_loss: 3.1585e-07 - val_loss: 1.6110e-06 - val_dense_76_loss: 5.8306e-07 - val_dense_77_loss: 4.7777e-07 - val_dense_78_loss: 2.8747e-07 - val_dense_79_loss: 2.6276e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.8069e-06 - dense_76_loss: 6.2006e-07 - dense_77_loss: 5.4305e-07 - dense_78_loss: 3.1593e-07 - dense_79_loss: 3.2789e-07 - val_loss: 1.9387e-06 - val_dense_76_loss: 6.3070e-07 - val_dense_77_loss: 5.6964e-07 - val_dense_78_loss: 3.6982e-07 - val_dense_79_loss: 3.6857e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.7137e-06 - dense_76_loss: 5.7183e-07 - dense_77_loss: 5.2444e-07 - dense_78_loss: 2.9994e-07 - dense_79_loss: 3.1747e-07 - val_loss: 1.5440e-06 - val_dense_76_loss: 5.3105e-07 - val_dense_77_loss: 4.7042e-07 - val_dense_78_loss: 2.6498e-07 - val_dense_79_loss: 2.7757e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.5033e-06 - dense_76_loss: 4.8878e-07 - dense_77_loss: 4.8640e-07 - dense_78_loss: 2.5584e-07 - dense_79_loss: 2.7231e-07 - val_loss: 1.4846e-06 - val_dense_76_loss: 4.7328e-07 - val_dense_77_loss: 4.8354e-07 - val_dense_78_loss: 2.6149e-07 - val_dense_79_loss: 2.6630e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.5237e-06 - dense_76_loss: 4.7446e-07 - dense_77_loss: 5.0062e-07 - dense_78_loss: 2.6095e-07 - dense_79_loss: 2.8770e-07 - val_loss: 1.2320e-06 - val_dense_76_loss: 3.9611e-07 - val_dense_77_loss: 4.1157e-07 - val_dense_78_loss: 2.1695e-07 - val_dense_79_loss: 2.0742e-07\n",
      "Epoch 34/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step - loss: 1.3576e-06 - dense_76_loss: 4.1005e-07 - dense_77_loss: 4.6687e-07 - dense_78_loss: 2.2950e-07 - dense_79_loss: 2.5114e-07 - val_loss: 1.4385e-06 - val_dense_76_loss: 4.4799e-07 - val_dense_77_loss: 4.7650e-07 - val_dense_78_loss: 2.4718e-07 - val_dense_79_loss: 2.6686e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6467e-06 - dense_76_loss: 4.7147e-07 - dense_77_loss: 5.5114e-07 - dense_78_loss: 2.9770e-07 - dense_79_loss: 3.2640e-07 - val_loss: 1.3529e-06 - val_dense_76_loss: 3.9315e-07 - val_dense_77_loss: 4.6520e-07 - val_dense_78_loss: 2.4835e-07 - val_dense_79_loss: 2.4617e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.3738e-06 - dense_76_loss: 3.7652e-07 - dense_77_loss: 4.8333e-07 - dense_78_loss: 2.4507e-07 - dense_79_loss: 2.6885e-07 - val_loss: 1.3471e-06 - val_dense_76_loss: 3.8245e-07 - val_dense_77_loss: 4.3646e-07 - val_dense_78_loss: 2.6118e-07 - val_dense_79_loss: 2.6705e-07\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.5749e-06 - dense_76_loss: 4.2051e-07 - dense_77_loss: 5.3238e-07 - dense_78_loss: 2.8997e-07 - dense_79_loss: 3.3205e-07 - val_loss: 1.3340e-06 - val_dense_76_loss: 3.8387e-07 - val_dense_77_loss: 4.5255e-07 - val_dense_78_loss: 2.3450e-07 - val_dense_79_loss: 2.6305e-07\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2215e-06 - dense_76_loss: 3.1678e-07 - dense_77_loss: 4.4921e-07 - dense_78_loss: 2.0426e-07 - dense_79_loss: 2.5128e-07 - val_loss: 1.1319e-06 - val_dense_76_loss: 3.0897e-07 - val_dense_77_loss: 4.0360e-07 - val_dense_78_loss: 1.9896e-07 - val_dense_79_loss: 2.2037e-07\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1545e-06 - dense_76_loss: 2.8769e-07 - dense_77_loss: 4.3683e-07 - dense_78_loss: 1.9747e-07 - dense_79_loss: 2.3250e-07 - val_loss: 1.0826e-06 - val_dense_76_loss: 2.8545e-07 - val_dense_77_loss: 3.9899e-07 - val_dense_78_loss: 1.8103e-07 - val_dense_79_loss: 2.1710e-07\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.4948e-06 - dense_76_loss: 3.6679e-07 - dense_77_loss: 5.3147e-07 - dense_78_loss: 2.6288e-07 - dense_79_loss: 3.3367e-07 - val_loss: 1.2353e-06 - val_dense_76_loss: 2.9533e-07 - val_dense_77_loss: 4.4389e-07 - val_dense_78_loss: 2.4120e-07 - val_dense_79_loss: 2.5488e-07\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.3885e-06 - dense_76_loss: 3.2819e-07 - dense_77_loss: 4.9215e-07 - dense_78_loss: 2.6106e-07 - dense_79_loss: 3.0711e-07 - val_loss: 1.2690e-06 - val_dense_76_loss: 3.0109e-07 - val_dense_77_loss: 4.2959e-07 - val_dense_78_loss: 2.4463e-07 - val_dense_79_loss: 2.9373e-07\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1603e-06 - dense_76_loss: 2.5837e-07 - dense_77_loss: 4.3379e-07 - dense_78_loss: 2.1231e-07 - dense_79_loss: 2.5587e-07 - val_loss: 1.1761e-06 - val_dense_76_loss: 2.6163e-07 - val_dense_77_loss: 4.0510e-07 - val_dense_78_loss: 2.3550e-07 - val_dense_79_loss: 2.7388e-07\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0541e-06 - dense_76_loss: 2.3129e-07 - dense_77_loss: 4.1586e-07 - dense_78_loss: 1.7869e-07 - dense_79_loss: 2.2827e-07 - val_loss: 8.4133e-07 - val_dense_76_loss: 1.9194e-07 - val_dense_77_loss: 3.4251e-07 - val_dense_78_loss: 1.4499e-07 - val_dense_79_loss: 1.6188e-07\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0930e-06 - dense_76_loss: 2.3984e-07 - dense_77_loss: 4.2652e-07 - dense_78_loss: 1.9915e-07 - dense_79_loss: 2.2748e-07 - val_loss: 1.1645e-06 - val_dense_76_loss: 2.5229e-07 - val_dense_77_loss: 4.1581e-07 - val_dense_78_loss: 2.3380e-07 - val_dense_79_loss: 2.6262e-07\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2017e-06 - dense_76_loss: 2.5595e-07 - dense_77_loss: 4.4654e-07 - dense_78_loss: 2.2441e-07 - dense_79_loss: 2.7477e-07 - val_loss: 1.2263e-06 - val_dense_76_loss: 2.8914e-07 - val_dense_77_loss: 4.4457e-07 - val_dense_78_loss: 2.3108e-07 - val_dense_79_loss: 2.6154e-07\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.8804e-07 - dense_76_loss: 2.0896e-07 - dense_77_loss: 4.0079e-07 - dense_78_loss: 1.6882e-07 - dense_79_loss: 2.0947e-07 - val_loss: 9.4586e-07 - val_dense_76_loss: 2.0870e-07 - val_dense_77_loss: 3.6896e-07 - val_dense_78_loss: 1.6476e-07 - val_dense_79_loss: 2.0344e-07\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2830e-06 - dense_76_loss: 2.9217e-07 - dense_77_loss: 4.6600e-07 - dense_78_loss: 2.3112e-07 - dense_79_loss: 2.9373e-07 - val_loss: 1.8384e-06 - val_dense_76_loss: 4.5797e-07 - val_dense_77_loss: 5.7705e-07 - val_dense_78_loss: 3.5214e-07 - val_dense_79_loss: 4.5119e-07\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0617e-06 - dense_76_loss: 2.2699e-07 - dense_77_loss: 4.1161e-07 - dense_78_loss: 1.8601e-07 - dense_79_loss: 2.3712e-07 - val_loss: 7.9236e-07 - val_dense_76_loss: 1.6550e-07 - val_dense_77_loss: 3.3475e-07 - val_dense_78_loss: 1.3322e-07 - val_dense_79_loss: 1.5888e-07\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0199e-06 - dense_76_loss: 2.1016e-07 - dense_77_loss: 4.0484e-07 - dense_78_loss: 1.8151e-07 - dense_79_loss: 2.2342e-07 - val_loss: 1.0246e-06 - val_dense_76_loss: 2.2401e-07 - val_dense_77_loss: 4.0484e-07 - val_dense_78_loss: 1.8869e-07 - val_dense_79_loss: 2.0703e-07\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.1724e-07 - dense_76_loss: 1.8340e-07 - dense_77_loss: 3.8004e-07 - dense_78_loss: 1.5590e-07 - dense_79_loss: 1.9789e-07 - val_loss: 9.7516e-07 - val_dense_76_loss: 2.2041e-07 - val_dense_77_loss: 3.7817e-07 - val_dense_78_loss: 1.8375e-07 - val_dense_79_loss: 1.9284e-07\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.9306e-07 - dense_76_loss: 2.0369e-07 - dense_77_loss: 4.0290e-07 - dense_78_loss: 1.7049e-07 - dense_79_loss: 2.1598e-07 - val_loss: 8.9274e-07 - val_dense_76_loss: 2.0452e-07 - val_dense_77_loss: 3.5273e-07 - val_dense_78_loss: 1.5122e-07 - val_dense_79_loss: 1.8426e-07\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.5047e-06 - dense_76_loss: 3.2943e-07 - dense_77_loss: 5.5230e-07 - dense_78_loss: 2.8590e-07 - dense_79_loss: 3.3707e-07 - val_loss: 1.2428e-06 - val_dense_76_loss: 2.8802e-07 - val_dense_77_loss: 4.3101e-07 - val_dense_78_loss: 2.4297e-07 - val_dense_79_loss: 2.8079e-07\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0096e-06 - dense_76_loss: 2.0907e-07 - dense_77_loss: 4.0167e-07 - dense_78_loss: 1.8122e-07 - dense_79_loss: 2.1766e-07 - val_loss: 7.8845e-07 - val_dense_76_loss: 1.7729e-07 - val_dense_77_loss: 3.2252e-07 - val_dense_78_loss: 1.3560e-07 - val_dense_79_loss: 1.5304e-07\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.6016e-07 - dense_76_loss: 1.7064e-07 - dense_77_loss: 3.6582e-07 - dense_78_loss: 1.4079e-07 - dense_79_loss: 1.8290e-07 - val_loss: 9.9285e-07 - val_dense_76_loss: 2.2999e-07 - val_dense_77_loss: 3.6493e-07 - val_dense_78_loss: 1.7532e-07 - val_dense_79_loss: 2.2261e-07\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.8725e-07 - dense_76_loss: 2.0310e-07 - dense_77_loss: 3.9349e-07 - dense_78_loss: 1.7364e-07 - dense_79_loss: 2.1703e-07 - val_loss: 1.0122e-06 - val_dense_76_loss: 2.1471e-07 - val_dense_77_loss: 4.0685e-07 - val_dense_78_loss: 1.9212e-07 - val_dense_79_loss: 1.9848e-07\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.4526e-07 - dense_76_loss: 1.8988e-07 - dense_77_loss: 3.8834e-07 - dense_78_loss: 1.6005e-07 - dense_79_loss: 2.0700e-07 - val_loss: 9.4911e-07 - val_dense_76_loss: 2.0665e-07 - val_dense_77_loss: 3.6497e-07 - val_dense_78_loss: 1.8186e-07 - val_dense_79_loss: 1.9563e-07\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0933e-06 - dense_76_loss: 2.2685e-07 - dense_77_loss: 4.0966e-07 - dense_78_loss: 2.0232e-07 - dense_79_loss: 2.5443e-07 - val_loss: 1.1536e-06 - val_dense_76_loss: 2.5509e-07 - val_dense_77_loss: 4.1332e-07 - val_dense_78_loss: 2.1383e-07 - val_dense_79_loss: 2.7141e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0349e-06 - dense_76_loss: 2.1256e-07 - dense_77_loss: 3.9779e-07 - dense_78_loss: 1.9172e-07 - dense_79_loss: 2.3287e-07 - val_loss: 1.4249e-06 - val_dense_76_loss: 3.6344e-07 - val_dense_77_loss: 4.6792e-07 - val_dense_78_loss: 2.9157e-07 - val_dense_79_loss: 3.0198e-07\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.4213e-06 - dense_76_loss: 3.3596e-07 - dense_77_loss: 4.9171e-07 - dense_78_loss: 2.6789e-07 - dense_79_loss: 3.2573e-07 - val_loss: 1.4755e-06 - val_dense_76_loss: 3.3389e-07 - val_dense_77_loss: 5.1164e-07 - val_dense_78_loss: 3.1034e-07 - val_dense_79_loss: 3.1963e-07\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1032e-06 - dense_76_loss: 2.3252e-07 - dense_77_loss: 4.2106e-07 - dense_78_loss: 2.1285e-07 - dense_79_loss: 2.3675e-07 - val_loss: 7.8010e-07 - val_dense_76_loss: 1.5662e-07 - val_dense_77_loss: 3.2881e-07 - val_dense_78_loss: 1.3406e-07 - val_dense_79_loss: 1.6061e-07\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.2721e-07 - dense_76_loss: 1.6139e-07 - dense_77_loss: 3.4893e-07 - dense_78_loss: 1.3675e-07 - dense_79_loss: 1.8013e-07 - val_loss: 7.8275e-07 - val_dense_76_loss: 1.6099e-07 - val_dense_77_loss: 3.2128e-07 - val_dense_78_loss: 1.4220e-07 - val_dense_79_loss: 1.5829e-07\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.6902e-07 - dense_76_loss: 1.7726e-07 - dense_77_loss: 3.6266e-07 - dense_78_loss: 1.4478e-07 - dense_79_loss: 1.8431e-07 - val_loss: 9.0871e-07 - val_dense_76_loss: 2.0277e-07 - val_dense_77_loss: 3.6649e-07 - val_dense_78_loss: 1.5248e-07 - val_dense_79_loss: 1.8697e-07\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1461e-06 - dense_76_loss: 2.4021e-07 - dense_77_loss: 4.2950e-07 - dense_78_loss: 2.1416e-07 - dense_79_loss: 2.6219e-07 - val_loss: 1.4613e-06 - val_dense_76_loss: 2.9757e-07 - val_dense_77_loss: 4.5927e-07 - val_dense_78_loss: 3.4911e-07 - val_dense_79_loss: 3.5536e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "\n",
      "Now training model 3/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 16ms/step - loss: 0.0012 - dense_82_loss: 2.1480e-04 - dense_83_loss: 2.3018e-04 - dense_84_loss: 3.0186e-04 - dense_85_loss: 5.0064e-04 - val_loss: 1.6376e-04 - val_dense_82_loss: 2.6307e-05 - val_dense_83_loss: 3.4939e-05 - val_dense_84_loss: 3.4755e-05 - val_dense_85_loss: 6.7759e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.1294e-05 - dense_82_loss: 1.8317e-05 - dense_83_loss: 2.1570e-05 - dense_84_loss: 2.7004e-05 - dense_85_loss: 2.4403e-05 - val_loss: 3.5489e-05 - val_dense_82_loss: 7.2680e-06 - val_dense_83_loss: 8.2969e-06 - val_dense_84_loss: 1.4994e-05 - val_dense_85_loss: 4.9307e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 2.4755e-05 - dense_82_loss: 4.6975e-06 - dense_83_loss: 4.7498e-06 - dense_84_loss: 1.2272e-05 - dense_85_loss: 3.0355e-06 - val_loss: 1.8641e-05 - val_dense_82_loss: 3.0515e-06 - val_dense_83_loss: 2.7813e-06 - val_dense_84_loss: 1.1187e-05 - val_dense_85_loss: 1.6219e-06\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6827e-05 - dense_82_loss: 2.8201e-06 - dense_83_loss: 2.5471e-06 - dense_84_loss: 1.0134e-05 - dense_85_loss: 1.3260e-06 - val_loss: 1.5786e-05 - val_dense_82_loss: 2.3936e-06 - val_dense_83_loss: 2.1410e-06 - val_dense_84_loss: 1.0092e-05 - val_dense_85_loss: 1.1594e-06\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.5327e-05 - dense_82_loss: 2.4821e-06 - dense_83_loss: 2.2083e-06 - dense_84_loss: 9.5154e-06 - dense_85_loss: 1.1209e-06 - val_loss: 1.4952e-05 - val_dense_82_loss: 2.2790e-06 - val_dense_83_loss: 2.0004e-06 - val_dense_84_loss: 9.5606e-06 - val_dense_85_loss: 1.1116e-06\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.4628e-05 - dense_82_loss: 2.3988e-06 - dense_83_loss: 2.1434e-06 - dense_84_loss: 8.9752e-06 - dense_85_loss: 1.1106e-06 - val_loss: 1.4266e-05 - val_dense_82_loss: 2.2285e-06 - val_dense_83_loss: 1.9820e-06 - val_dense_84_loss: 8.9363e-06 - val_dense_85_loss: 1.1187e-06\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.3964e-05 - dense_82_loss: 2.3863e-06 - dense_83_loss: 2.1186e-06 - dense_84_loss: 8.3176e-06 - dense_85_loss: 1.1419e-06 - val_loss: 1.3553e-05 - val_dense_82_loss: 2.2188e-06 - val_dense_83_loss: 1.9610e-06 - val_dense_84_loss: 8.2030e-06 - val_dense_85_loss: 1.1704e-06\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2977e-05 - dense_82_loss: 2.3140e-06 - dense_83_loss: 2.0601e-06 - dense_84_loss: 7.4550e-06 - dense_85_loss: 1.1476e-06 - val_loss: 1.2344e-05 - val_dense_82_loss: 2.1378e-06 - val_dense_83_loss: 1.9072e-06 - val_dense_84_loss: 7.1531e-06 - val_dense_85_loss: 1.1460e-06\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1681e-05 - dense_82_loss: 2.2107e-06 - dense_83_loss: 1.9835e-06 - dense_84_loss: 6.3453e-06 - dense_85_loss: 1.1413e-06 - val_loss: 1.0778e-05 - val_dense_82_loss: 2.0008e-06 - val_dense_83_loss: 1.8193e-06 - val_dense_84_loss: 5.8253e-06 - val_dense_85_loss: 1.1327e-06\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0033e-05 - dense_82_loss: 2.0604e-06 - dense_83_loss: 1.8742e-06 - dense_84_loss: 4.9805e-06 - dense_85_loss: 1.1176e-06 - val_loss: 8.7575e-06 - val_dense_82_loss: 1.8023e-06 - val_dense_83_loss: 1.6660e-06 - val_dense_84_loss: 4.2166e-06 - val_dense_85_loss: 1.0726e-06\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 7.8225e-06 - dense_82_loss: 1.8022e-06 - dense_83_loss: 1.6532e-06 - dense_84_loss: 3.3757e-06 - dense_85_loss: 9.9144e-07 - val_loss: 6.4401e-06 - val_dense_82_loss: 1.4983e-06 - val_dense_83_loss: 1.4041e-06 - val_dense_84_loss: 2.6554e-06 - val_dense_85_loss: 8.8219e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 5.6443e-06 - dense_82_loss: 1.4835e-06 - dense_83_loss: 1.3826e-06 - dense_84_loss: 1.9813e-06 - dense_85_loss: 7.9691e-07 - val_loss: 4.2954e-06 - val_dense_82_loss: 1.1610e-06 - val_dense_83_loss: 1.1084e-06 - val_dense_84_loss: 1.3778e-06 - val_dense_85_loss: 6.4822e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.8030e-06 - dense_82_loss: 1.1539e-06 - dense_83_loss: 1.0889e-06 - dense_84_loss: 9.9371e-07 - dense_85_loss: 5.6644e-07 - val_loss: 2.8275e-06 - val_dense_82_loss: 8.8961e-07 - val_dense_83_loss: 8.5398e-07 - val_dense_84_loss: 6.4457e-07 - val_dense_85_loss: 4.3935e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.7475e-06 - dense_82_loss: 9.3103e-07 - dense_83_loss: 8.8651e-07 - dense_84_loss: 5.2280e-07 - dense_85_loss: 4.0718e-07 - val_loss: 2.1274e-06 - val_dense_82_loss: 7.2792e-07 - val_dense_83_loss: 7.0520e-07 - val_dense_84_loss: 3.8040e-07 - val_dense_85_loss: 3.1386e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.2866e-06 - dense_82_loss: 8.1288e-07 - dense_83_loss: 7.8385e-07 - dense_84_loss: 3.5979e-07 - dense_85_loss: 3.3007e-07 - val_loss: 1.9195e-06 - val_dense_82_loss: 6.8655e-07 - val_dense_83_loss: 6.5751e-07 - val_dense_84_loss: 2.9610e-07 - val_dense_85_loss: 2.7933e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.1551e-06 - dense_82_loss: 7.7950e-07 - dense_83_loss: 7.5016e-07 - dense_84_loss: 3.1495e-07 - dense_85_loss: 3.1053e-07 - val_loss: 1.9258e-06 - val_dense_82_loss: 6.8535e-07 - val_dense_83_loss: 6.5092e-07 - val_dense_84_loss: 2.8687e-07 - val_dense_85_loss: 3.0267e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.1309e-06 - dense_82_loss: 7.7086e-07 - dense_83_loss: 7.3885e-07 - dense_84_loss: 3.0762e-07 - dense_85_loss: 3.1354e-07 - val_loss: 1.7723e-06 - val_dense_82_loss: 6.3935e-07 - val_dense_83_loss: 6.1060e-07 - val_dense_84_loss: 2.6186e-07 - val_dense_85_loss: 2.6052e-07\n",
      "Epoch 18/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0519e-06 - dense_82_loss: 7.4752e-07 - dense_83_loss: 7.1454e-07 - dense_84_loss: 2.9171e-07 - dense_85_loss: 2.9808e-07 - val_loss: 1.7872e-06 - val_dense_82_loss: 6.3816e-07 - val_dense_83_loss: 6.1189e-07 - val_dense_84_loss: 2.6748e-07 - val_dense_85_loss: 2.6962e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0514e-06 - dense_82_loss: 7.4198e-07 - dense_83_loss: 7.0887e-07 - dense_84_loss: 2.9620e-07 - dense_85_loss: 3.0437e-07 - val_loss: 1.7997e-06 - val_dense_82_loss: 6.4120e-07 - val_dense_83_loss: 6.0748e-07 - val_dense_84_loss: 2.7530e-07 - val_dense_85_loss: 2.7577e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0368e-06 - dense_82_loss: 7.3541e-07 - dense_83_loss: 7.0304e-07 - dense_84_loss: 2.9293e-07 - dense_85_loss: 3.0538e-07 - val_loss: 1.7762e-06 - val_dense_82_loss: 6.4542e-07 - val_dense_83_loss: 6.1236e-07 - val_dense_84_loss: 2.5455e-07 - val_dense_85_loss: 2.6392e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0061e-06 - dense_82_loss: 7.2550e-07 - dense_83_loss: 6.9199e-07 - dense_84_loss: 2.8839e-07 - dense_85_loss: 3.0023e-07 - val_loss: 1.7688e-06 - val_dense_82_loss: 6.2336e-07 - val_dense_83_loss: 6.0309e-07 - val_dense_84_loss: 2.6072e-07 - val_dense_85_loss: 2.8161e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.0423e-06 - dense_82_loss: 7.2858e-07 - dense_83_loss: 7.0103e-07 - dense_84_loss: 2.9953e-07 - dense_85_loss: 3.1313e-07 - val_loss: 1.7635e-06 - val_dense_82_loss: 6.1882e-07 - val_dense_83_loss: 5.9444e-07 - val_dense_84_loss: 2.6835e-07 - val_dense_85_loss: 2.8188e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0088e-06 - dense_82_loss: 7.1561e-07 - dense_83_loss: 6.8713e-07 - dense_84_loss: 2.9612e-07 - dense_85_loss: 3.0991e-07 - val_loss: 1.8602e-06 - val_dense_82_loss: 6.5289e-07 - val_dense_83_loss: 6.2184e-07 - val_dense_84_loss: 2.7242e-07 - val_dense_85_loss: 3.1306e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0981e-06 - dense_82_loss: 7.3340e-07 - dense_83_loss: 7.0708e-07 - dense_84_loss: 3.1772e-07 - dense_85_loss: 3.3988e-07 - val_loss: 1.8830e-06 - val_dense_82_loss: 6.4438e-07 - val_dense_83_loss: 6.2894e-07 - val_dense_84_loss: 3.0668e-07 - val_dense_85_loss: 3.0301e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0570e-06 - dense_82_loss: 7.1740e-07 - dense_83_loss: 6.9450e-07 - dense_84_loss: 3.1256e-07 - dense_85_loss: 3.3253e-07 - val_loss: 1.7284e-06 - val_dense_82_loss: 6.0524e-07 - val_dense_83_loss: 5.7779e-07 - val_dense_84_loss: 2.6759e-07 - val_dense_85_loss: 2.7774e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.0239e-06 - dense_82_loss: 7.0653e-07 - dense_83_loss: 6.7889e-07 - dense_84_loss: 3.0599e-07 - dense_85_loss: 3.3248e-07 - val_loss: 1.8051e-06 - val_dense_82_loss: 6.2425e-07 - val_dense_83_loss: 5.9609e-07 - val_dense_84_loss: 2.7529e-07 - val_dense_85_loss: 3.0950e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.0382e-06 - dense_82_loss: 7.0691e-07 - dense_83_loss: 6.8224e-07 - dense_84_loss: 3.0804e-07 - dense_85_loss: 3.4097e-07 - val_loss: 1.8392e-06 - val_dense_82_loss: 6.2708e-07 - val_dense_83_loss: 6.0466e-07 - val_dense_84_loss: 3.0075e-07 - val_dense_85_loss: 3.0672e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.1031e-06 - dense_82_loss: 7.1523e-07 - dense_83_loss: 6.9403e-07 - dense_84_loss: 3.3063e-07 - dense_85_loss: 3.6326e-07 - val_loss: 1.7159e-06 - val_dense_82_loss: 5.8539e-07 - val_dense_83_loss: 5.6806e-07 - val_dense_84_loss: 2.7752e-07 - val_dense_85_loss: 2.8490e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0219e-06 - dense_82_loss: 6.8684e-07 - dense_83_loss: 6.7280e-07 - dense_84_loss: 3.1811e-07 - dense_85_loss: 3.4414e-07 - val_loss: 1.9240e-06 - val_dense_82_loss: 6.2482e-07 - val_dense_83_loss: 6.0647e-07 - val_dense_84_loss: 3.2548e-07 - val_dense_85_loss: 3.6726e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0570e-06 - dense_82_loss: 6.9370e-07 - dense_83_loss: 6.7662e-07 - dense_84_loss: 3.2867e-07 - dense_85_loss: 3.5806e-07 - val_loss: 2.1193e-06 - val_dense_82_loss: 6.8492e-07 - val_dense_83_loss: 6.8402e-07 - val_dense_84_loss: 3.6647e-07 - val_dense_85_loss: 3.8387e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.2443e-06 - dense_82_loss: 7.2597e-07 - dense_83_loss: 7.2194e-07 - dense_84_loss: 3.7766e-07 - dense_85_loss: 4.1874e-07 - val_loss: 1.9576e-06 - val_dense_82_loss: 6.0682e-07 - val_dense_83_loss: 6.2447e-07 - val_dense_84_loss: 3.4192e-07 - val_dense_85_loss: 3.8438e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.2125e-06 - dense_82_loss: 7.2389e-07 - dense_83_loss: 7.0727e-07 - dense_84_loss: 3.7759e-07 - dense_85_loss: 4.0380e-07 - val_loss: 1.7163e-06 - val_dense_82_loss: 5.7113e-07 - val_dense_83_loss: 5.5399e-07 - val_dense_84_loss: 2.9249e-07 - val_dense_85_loss: 2.9869e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.8880e-06 - dense_82_loss: 6.3171e-07 - dense_83_loss: 6.2572e-07 - dense_84_loss: 3.0581e-07 - dense_85_loss: 3.2474e-07 - val_loss: 1.8021e-06 - val_dense_82_loss: 5.6399e-07 - val_dense_83_loss: 5.7000e-07 - val_dense_84_loss: 3.2935e-07 - val_dense_85_loss: 3.3874e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.9255e-06 - dense_82_loss: 6.2891e-07 - dense_83_loss: 6.2542e-07 - dense_84_loss: 3.2418e-07 - dense_85_loss: 3.4700e-07 - val_loss: 1.6529e-06 - val_dense_82_loss: 5.3714e-07 - val_dense_83_loss: 5.3219e-07 - val_dense_84_loss: 2.9326e-07 - val_dense_85_loss: 2.9028e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.9266e-06 - dense_82_loss: 6.2855e-07 - dense_83_loss: 6.2353e-07 - dense_84_loss: 3.2516e-07 - dense_85_loss: 3.4932e-07 - val_loss: 1.9393e-06 - val_dense_82_loss: 5.8491e-07 - val_dense_83_loss: 5.9087e-07 - val_dense_84_loss: 3.3369e-07 - val_dense_85_loss: 4.2981e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.3366e-06 - dense_82_loss: 7.0724e-07 - dense_83_loss: 7.1733e-07 - dense_84_loss: 4.2563e-07 - dense_85_loss: 4.8645e-07 - val_loss: 1.7940e-06 - val_dense_82_loss: 5.4896e-07 - val_dense_83_loss: 5.5406e-07 - val_dense_84_loss: 3.4076e-07 - val_dense_85_loss: 3.5024e-07\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.8813e-06 - dense_82_loss: 5.9670e-07 - dense_83_loss: 6.0125e-07 - dense_84_loss: 3.3070e-07 - dense_85_loss: 3.5269e-07 - val_loss: 1.8147e-06 - val_dense_82_loss: 5.5425e-07 - val_dense_83_loss: 5.4886e-07 - val_dense_84_loss: 3.3791e-07 - val_dense_85_loss: 3.7365e-07\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2.4256e-06 - dense_82_loss: 7.2733e-07 - dense_83_loss: 7.2297e-07 - dense_84_loss: 4.3987e-07 - dense_85_loss: 5.3544e-07 - val_loss: 2.1780e-06 - val_dense_82_loss: 6.3545e-07 - val_dense_83_loss: 6.5663e-07 - val_dense_84_loss: 4.2230e-07 - val_dense_85_loss: 4.6366e-07\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.9592e-06 - dense_82_loss: 6.0181e-07 - dense_83_loss: 6.0668e-07 - dense_84_loss: 3.5823e-07 - dense_85_loss: 3.9248e-07 - val_loss: 1.8004e-06 - val_dense_82_loss: 5.4288e-07 - val_dense_83_loss: 5.4887e-07 - val_dense_84_loss: 3.4852e-07 - val_dense_85_loss: 3.6014e-07\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.9421e-06 - dense_82_loss: 5.9885e-07 - dense_83_loss: 5.9855e-07 - dense_84_loss: 3.6052e-07 - dense_85_loss: 3.8418e-07 - val_loss: 1.5678e-06 - val_dense_82_loss: 4.8116e-07 - val_dense_83_loss: 4.8835e-07 - val_dense_84_loss: 2.8994e-07 - val_dense_85_loss: 3.0834e-07\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0642e-06 - dense_82_loss: 5.9797e-07 - dense_83_loss: 6.1650e-07 - dense_84_loss: 3.8882e-07 - dense_85_loss: 4.6089e-07 - val_loss: 2.0578e-06 - val_dense_82_loss: 5.5126e-07 - val_dense_83_loss: 6.0739e-07 - val_dense_84_loss: 4.0054e-07 - val_dense_85_loss: 4.9861e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.8955e-06 - dense_82_loss: 5.5688e-07 - dense_83_loss: 5.7906e-07 - dense_84_loss: 3.6007e-07 - dense_85_loss: 3.9953e-07 - val_loss: 1.6432e-06 - val_dense_82_loss: 4.9904e-07 - val_dense_83_loss: 4.9627e-07 - val_dense_84_loss: 3.1047e-07 - val_dense_85_loss: 3.3741e-07\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.8746e-06 - dense_82_loss: 5.5129e-07 - dense_83_loss: 5.6558e-07 - dense_84_loss: 3.6613e-07 - dense_85_loss: 3.9156e-07 - val_loss: 1.6917e-06 - val_dense_82_loss: 4.7872e-07 - val_dense_83_loss: 5.2288e-07 - val_dense_84_loss: 3.2101e-07 - val_dense_85_loss: 3.6912e-07\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.8452e-06 - dense_82_loss: 5.2990e-07 - dense_83_loss: 5.4978e-07 - dense_84_loss: 3.5955e-07 - dense_85_loss: 4.0594e-07 - val_loss: 1.7870e-06 - val_dense_82_loss: 4.8258e-07 - val_dense_83_loss: 5.2753e-07 - val_dense_84_loss: 3.6783e-07 - val_dense_85_loss: 4.0905e-07\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 2.2564e-06 - dense_82_loss: 6.5850e-07 - dense_83_loss: 6.5322e-07 - dense_84_loss: 4.5985e-07 - dense_85_loss: 4.8478e-07 - val_loss: 1.7532e-06 - val_dense_82_loss: 4.7879e-07 - val_dense_83_loss: 5.0557e-07 - val_dense_84_loss: 3.5474e-07 - val_dense_85_loss: 4.1405e-07\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.8458e-06 - dense_82_loss: 5.1441e-07 - dense_83_loss: 5.4117e-07 - dense_84_loss: 3.8391e-07 - dense_85_loss: 4.0627e-07 - val_loss: 1.5142e-06 - val_dense_82_loss: 4.3397e-07 - val_dense_83_loss: 4.5046e-07 - val_dense_84_loss: 3.0418e-07 - val_dense_85_loss: 3.2557e-07\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.6332e-06 - dense_82_loss: 4.5327e-07 - dense_83_loss: 4.8216e-07 - dense_84_loss: 3.3493e-07 - dense_85_loss: 3.6284e-07 - val_loss: 1.5130e-06 - val_dense_82_loss: 4.2804e-07 - val_dense_83_loss: 4.3782e-07 - val_dense_84_loss: 3.1799e-07 - val_dense_85_loss: 3.2920e-07\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6756e-06 - dense_82_loss: 4.5179e-07 - dense_83_loss: 4.7725e-07 - dense_84_loss: 3.4666e-07 - dense_85_loss: 3.9995e-07 - val_loss: 1.4549e-06 - val_dense_82_loss: 4.0179e-07 - val_dense_83_loss: 4.1360e-07 - val_dense_84_loss: 2.9672e-07 - val_dense_85_loss: 3.4281e-07\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6833e-06 - dense_82_loss: 4.5385e-07 - dense_83_loss: 4.7595e-07 - dense_84_loss: 3.4846e-07 - dense_85_loss: 4.0498e-07 - val_loss: 1.7420e-06 - val_dense_82_loss: 4.5578e-07 - val_dense_83_loss: 4.9774e-07 - val_dense_84_loss: 3.3877e-07 - val_dense_85_loss: 4.4971e-07\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.7165e-06 - dense_82_loss: 4.4763e-07 - dense_83_loss: 4.9125e-07 - dense_84_loss: 3.5209e-07 - dense_85_loss: 4.2555e-07 - val_loss: 1.7343e-06 - val_dense_82_loss: 4.3906e-07 - val_dense_83_loss: 4.9316e-07 - val_dense_84_loss: 3.8153e-07 - val_dense_85_loss: 4.2054e-07\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6290e-06 - dense_82_loss: 4.2201e-07 - dense_83_loss: 4.5331e-07 - dense_84_loss: 3.5847e-07 - dense_85_loss: 3.9518e-07 - val_loss: 1.8349e-06 - val_dense_82_loss: 4.5259e-07 - val_dense_83_loss: 5.0741e-07 - val_dense_84_loss: 4.0391e-07 - val_dense_85_loss: 4.7101e-07\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.8159e-06 - dense_82_loss: 4.5593e-07 - dense_83_loss: 5.1464e-07 - dense_84_loss: 3.9130e-07 - dense_85_loss: 4.5403e-07 - val_loss: 1.4880e-06 - val_dense_82_loss: 3.7604e-07 - val_dense_83_loss: 4.2809e-07 - val_dense_84_loss: 3.2551e-07 - val_dense_85_loss: 3.5838e-07\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.5772e-06 - dense_82_loss: 4.0326e-07 - dense_83_loss: 4.3720e-07 - dense_84_loss: 3.4905e-07 - dense_85_loss: 3.8767e-07 - val_loss: 1.5285e-06 - val_dense_82_loss: 3.7084e-07 - val_dense_83_loss: 4.3660e-07 - val_dense_84_loss: 3.3042e-07 - val_dense_85_loss: 3.9065e-07\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6069e-06 - dense_82_loss: 3.9863e-07 - dense_83_loss: 4.4348e-07 - dense_84_loss: 3.5097e-07 - dense_85_loss: 4.1379e-07 - val_loss: 2.6245e-06 - val_dense_82_loss: 6.0295e-07 - val_dense_83_loss: 7.9517e-07 - val_dense_84_loss: 5.7245e-07 - val_dense_85_loss: 6.5392e-07\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.7911e-06 - dense_82_loss: 4.3853e-07 - dense_83_loss: 4.9181e-07 - dense_84_loss: 4.0266e-07 - dense_85_loss: 4.5813e-07 - val_loss: 1.7944e-06 - val_dense_82_loss: 4.4295e-07 - val_dense_83_loss: 4.7996e-07 - val_dense_84_loss: 4.2111e-07 - val_dense_85_loss: 4.5033e-07\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.5197e-06 - dense_82_loss: 3.7605e-07 - dense_83_loss: 3.9731e-07 - dense_84_loss: 3.5263e-07 - dense_85_loss: 3.9366e-07 - val_loss: 1.3887e-06 - val_dense_82_loss: 3.6152e-07 - val_dense_83_loss: 3.5385e-07 - val_dense_84_loss: 3.3365e-07 - val_dense_85_loss: 3.3964e-07\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.4177e-06 - dense_82_loss: 3.5204e-07 - dense_83_loss: 3.8004e-07 - dense_84_loss: 3.2238e-07 - dense_85_loss: 3.6328e-07 - val_loss: 1.2701e-06 - val_dense_82_loss: 3.2400e-07 - val_dense_83_loss: 3.5240e-07 - val_dense_84_loss: 2.8293e-07 - val_dense_85_loss: 3.1076e-07\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.4078e-06 - dense_82_loss: 3.5303e-07 - dense_83_loss: 3.7953e-07 - dense_84_loss: 3.1660e-07 - dense_85_loss: 3.5866e-07 - val_loss: 1.1225e-06 - val_dense_82_loss: 2.9199e-07 - val_dense_83_loss: 3.0516e-07 - val_dense_84_loss: 2.4913e-07 - val_dense_85_loss: 2.7624e-07\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2408e-06 - dense_82_loss: 3.0540e-07 - dense_83_loss: 3.2996e-07 - dense_84_loss: 2.8712e-07 - dense_85_loss: 3.1835e-07 - val_loss: 1.1298e-06 - val_dense_82_loss: 2.8125e-07 - val_dense_83_loss: 3.1527e-07 - val_dense_84_loss: 2.4845e-07 - val_dense_85_loss: 2.8486e-07\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.4106e-06 - dense_82_loss: 3.5119e-07 - dense_83_loss: 3.7114e-07 - dense_84_loss: 3.0976e-07 - dense_85_loss: 3.7846e-07 - val_loss: 1.5968e-06 - val_dense_82_loss: 4.3267e-07 - val_dense_83_loss: 3.9988e-07 - val_dense_84_loss: 3.3821e-07 - val_dense_85_loss: 4.2607e-07\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.5255e-06 - dense_82_loss: 3.9604e-07 - dense_83_loss: 3.8099e-07 - dense_84_loss: 3.3831e-07 - dense_85_loss: 4.1013e-07 - val_loss: 1.1546e-06 - val_dense_82_loss: 2.9432e-07 - val_dense_83_loss: 3.0455e-07 - val_dense_84_loss: 2.7101e-07 - val_dense_85_loss: 2.8468e-07\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.3672e-06 - dense_82_loss: 3.3818e-07 - dense_83_loss: 3.6343e-07 - dense_84_loss: 3.0891e-07 - dense_85_loss: 3.5667e-07 - val_loss: 1.1028e-06 - val_dense_82_loss: 2.7425e-07 - val_dense_83_loss: 3.1511e-07 - val_dense_84_loss: 2.4294e-07 - val_dense_85_loss: 2.7047e-07\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2262e-06 - dense_82_loss: 3.0065e-07 - dense_83_loss: 3.2145e-07 - dense_84_loss: 2.8102e-07 - dense_85_loss: 3.2304e-07 - val_loss: 1.1732e-06 - val_dense_82_loss: 3.1484e-07 - val_dense_83_loss: 3.0789e-07 - val_dense_84_loss: 2.5628e-07 - val_dense_85_loss: 2.9418e-07\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.6250e-06 - dense_82_loss: 4.0192e-07 - dense_83_loss: 4.2143e-07 - dense_84_loss: 3.5999e-07 - dense_85_loss: 4.4167e-07 - val_loss: 1.1895e-06 - val_dense_82_loss: 3.1783e-07 - val_dense_83_loss: 3.1463e-07 - val_dense_84_loss: 2.6095e-07 - val_dense_85_loss: 2.9613e-07\n",
      "Epoch 65/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1353e-06 - dense_82_loss: 2.8235e-07 - dense_83_loss: 2.9639e-07 - dense_84_loss: 2.5761e-07 - dense_85_loss: 2.9896e-07 - val_loss: 1.0078e-06 - val_dense_82_loss: 2.5530e-07 - val_dense_83_loss: 2.6774e-07 - val_dense_84_loss: 2.3304e-07 - val_dense_85_loss: 2.5176e-07\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2000e-06 - dense_82_loss: 3.0091e-07 - dense_83_loss: 3.1111e-07 - dense_84_loss: 2.7526e-07 - dense_85_loss: 3.1268e-07 - val_loss: 1.1052e-06 - val_dense_82_loss: 2.6165e-07 - val_dense_83_loss: 2.8980e-07 - val_dense_84_loss: 2.3697e-07 - val_dense_85_loss: 3.1677e-07\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1672e-06 - dense_82_loss: 2.9390e-07 - dense_83_loss: 3.0856e-07 - dense_84_loss: 2.5798e-07 - dense_85_loss: 3.0671e-07 - val_loss: 1.0419e-06 - val_dense_82_loss: 2.8368e-07 - val_dense_83_loss: 2.6558e-07 - val_dense_84_loss: 2.3967e-07 - val_dense_85_loss: 2.5296e-07\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.3038e-06 - dense_82_loss: 3.1780e-07 - dense_83_loss: 3.2960e-07 - dense_84_loss: 2.9665e-07 - dense_85_loss: 3.5972e-07 - val_loss: 1.1818e-06 - val_dense_82_loss: 3.1192e-07 - val_dense_83_loss: 3.2594e-07 - val_dense_84_loss: 2.7397e-07 - val_dense_85_loss: 2.6992e-07\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.4268e-06 - dense_82_loss: 3.4890e-07 - dense_83_loss: 3.8737e-07 - dense_84_loss: 3.2187e-07 - dense_85_loss: 3.6863e-07 - val_loss: 1.1024e-06 - val_dense_82_loss: 2.8381e-07 - val_dense_83_loss: 2.9943e-07 - val_dense_84_loss: 2.2444e-07 - val_dense_85_loss: 2.9476e-07\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1693e-06 - dense_82_loss: 3.0179e-07 - dense_83_loss: 3.0356e-07 - dense_84_loss: 2.6467e-07 - dense_85_loss: 2.9930e-07 - val_loss: 1.4903e-06 - val_dense_82_loss: 3.9241e-07 - val_dense_83_loss: 4.0632e-07 - val_dense_84_loss: 3.0553e-07 - val_dense_85_loss: 3.8606e-07\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.2603e-06 - dense_82_loss: 3.2019e-07 - dense_83_loss: 3.2253e-07 - dense_84_loss: 2.7934e-07 - dense_85_loss: 3.3819e-07 - val_loss: 1.0166e-06 - val_dense_82_loss: 2.7310e-07 - val_dense_83_loss: 2.5098e-07 - val_dense_84_loss: 2.3122e-07 - val_dense_85_loss: 2.6128e-07\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2675e-06 - dense_82_loss: 3.1527e-07 - dense_83_loss: 3.2780e-07 - dense_84_loss: 2.7379e-07 - dense_85_loss: 3.5063e-07 - val_loss: 1.1812e-06 - val_dense_82_loss: 2.9400e-07 - val_dense_83_loss: 2.8960e-07 - val_dense_84_loss: 2.6016e-07 - val_dense_85_loss: 3.3744e-07\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2514e-06 - dense_82_loss: 3.1656e-07 - dense_83_loss: 3.1959e-07 - dense_84_loss: 2.8206e-07 - dense_85_loss: 3.3314e-07 - val_loss: 1.3250e-06 - val_dense_82_loss: 3.6362e-07 - val_dense_83_loss: 3.4966e-07 - val_dense_84_loss: 2.9914e-07 - val_dense_85_loss: 3.1262e-07\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.3222e-06 - dense_82_loss: 3.2898e-07 - dense_83_loss: 3.3569e-07 - dense_84_loss: 2.9497e-07 - dense_85_loss: 3.6259e-07 - val_loss: 1.1997e-06 - val_dense_82_loss: 3.0365e-07 - val_dense_83_loss: 3.1672e-07 - val_dense_84_loss: 2.5944e-07 - val_dense_85_loss: 3.1992e-07\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1843e-06 - dense_82_loss: 3.0638e-07 - dense_83_loss: 2.9494e-07 - dense_84_loss: 2.7557e-07 - dense_85_loss: 3.0744e-07 - val_loss: 9.9433e-07 - val_dense_82_loss: 2.5047e-07 - val_dense_83_loss: 2.5120e-07 - val_dense_84_loss: 2.2658e-07 - val_dense_85_loss: 2.6607e-07\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.2822e-06 - dense_82_loss: 3.1522e-07 - dense_83_loss: 3.3645e-07 - dense_84_loss: 2.9522e-07 - dense_85_loss: 3.3532e-07 - val_loss: 1.6034e-06 - val_dense_82_loss: 4.2595e-07 - val_dense_83_loss: 4.2818e-07 - val_dense_84_loss: 3.6229e-07 - val_dense_85_loss: 3.8702e-07\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1306e-06 - dense_82_loss: 2.8093e-07 - dense_83_loss: 2.8970e-07 - dense_84_loss: 2.6305e-07 - dense_85_loss: 2.9694e-07 - val_loss: 1.2229e-06 - val_dense_82_loss: 3.0092e-07 - val_dense_83_loss: 3.3044e-07 - val_dense_84_loss: 2.7454e-07 - val_dense_85_loss: 3.1703e-07\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2207e-06 - dense_82_loss: 3.1001e-07 - dense_83_loss: 3.1437e-07 - dense_84_loss: 2.6875e-07 - dense_85_loss: 3.2757e-07 - val_loss: 9.9268e-07 - val_dense_82_loss: 2.5810e-07 - val_dense_83_loss: 2.6635e-07 - val_dense_84_loss: 1.9736e-07 - val_dense_85_loss: 2.7086e-07\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0850e-06 - dense_82_loss: 2.8211e-07 - dense_83_loss: 2.7680e-07 - dense_84_loss: 2.3810e-07 - dense_85_loss: 2.8800e-07 - val_loss: 1.0210e-06 - val_dense_82_loss: 2.7689e-07 - val_dense_83_loss: 2.6012e-07 - val_dense_84_loss: 2.1247e-07 - val_dense_85_loss: 2.7150e-07\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6991e-07 - dense_82_loss: 2.4359e-07 - dense_83_loss: 2.5159e-07 - dense_84_loss: 2.1280e-07 - dense_85_loss: 2.6194e-07 - val_loss: 1.1913e-06 - val_dense_82_loss: 2.9860e-07 - val_dense_83_loss: 3.3842e-07 - val_dense_84_loss: 2.6844e-07 - val_dense_85_loss: 2.8580e-07\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0387e-06 - dense_82_loss: 2.6569e-07 - dense_83_loss: 2.7241e-07 - dense_84_loss: 2.3127e-07 - dense_85_loss: 2.6931e-07 - val_loss: 9.8283e-07 - val_dense_82_loss: 2.5581e-07 - val_dense_83_loss: 2.6315e-07 - val_dense_84_loss: 1.9941e-07 - val_dense_85_loss: 2.6446e-07\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1220e-06 - dense_82_loss: 2.8547e-07 - dense_83_loss: 2.8684e-07 - dense_84_loss: 2.4669e-07 - dense_85_loss: 3.0300e-07 - val_loss: 9.8497e-07 - val_dense_82_loss: 2.6109e-07 - val_dense_83_loss: 2.6421e-07 - val_dense_84_loss: 1.9734e-07 - val_dense_85_loss: 2.6233e-07\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2270e-06 - dense_82_loss: 3.2152e-07 - dense_83_loss: 3.2594e-07 - dense_84_loss: 2.6598e-07 - dense_85_loss: 3.1360e-07 - val_loss: 1.0403e-06 - val_dense_82_loss: 2.7551e-07 - val_dense_83_loss: 2.9097e-07 - val_dense_84_loss: 1.9806e-07 - val_dense_85_loss: 2.7574e-07\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2334e-06 - dense_82_loss: 3.1337e-07 - dense_83_loss: 3.2436e-07 - dense_84_loss: 2.6366e-07 - dense_85_loss: 3.3204e-07 - val_loss: 1.8998e-06 - val_dense_82_loss: 4.5761e-07 - val_dense_83_loss: 5.9842e-07 - val_dense_84_loss: 3.6867e-07 - val_dense_85_loss: 4.7508e-07\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2884e-06 - dense_82_loss: 3.2164e-07 - dense_83_loss: 3.5767e-07 - dense_84_loss: 2.7629e-07 - dense_85_loss: 3.3276e-07 - val_loss: 1.1733e-06 - val_dense_82_loss: 3.3517e-07 - val_dense_83_loss: 2.9808e-07 - val_dense_84_loss: 2.4972e-07 - val_dense_85_loss: 2.9030e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "\n",
      "Now training model 4/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 17ms/step - loss: 0.0017 - dense_88_loss: 3.0065e-04 - dense_89_loss: 2.0456e-04 - dense_90_loss: 2.8819e-04 - dense_91_loss: 8.6977e-04 - val_loss: 2.9146e-04 - val_dense_88_loss: 5.1930e-05 - val_dense_89_loss: 3.9852e-05 - val_dense_90_loss: 4.7855e-05 - val_dense_91_loss: 1.5182e-04\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.2982e-04 - dense_88_loss: 2.7577e-05 - dense_89_loss: 2.0513e-05 - dense_90_loss: 3.2921e-05 - dense_91_loss: 4.8811e-05 - val_loss: 4.0977e-05 - val_dense_88_loss: 1.0831e-05 - val_dense_89_loss: 8.3468e-06 - val_dense_90_loss: 1.4430e-05 - val_dense_91_loss: 7.3693e-06\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step - loss: 2.5274e-05 - dense_88_loss: 6.0945e-06 - dense_89_loss: 5.2236e-06 - dense_90_loss: 1.0374e-05 - dense_91_loss: 3.5816e-06 - val_loss: 1.6143e-05 - val_dense_88_loss: 3.3688e-06 - val_dense_89_loss: 3.1894e-06 - val_dense_90_loss: 7.8259e-06 - val_dense_91_loss: 1.7593e-06\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.3854e-05 - dense_88_loss: 2.9435e-06 - dense_89_loss: 2.8352e-06 - dense_90_loss: 7.0559e-06 - dense_91_loss: 1.0192e-06 - val_loss: 1.2842e-05 - val_dense_88_loss: 2.6045e-06 - val_dense_89_loss: 2.6136e-06 - val_dense_90_loss: 6.8125e-06 - val_dense_91_loss: 8.1132e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2203e-05 - dense_88_loss: 2.5408e-06 - dense_89_loss: 2.5185e-06 - dense_90_loss: 6.4519e-06 - dense_91_loss: 6.9207e-07 - val_loss: 1.2201e-05 - val_dense_88_loss: 2.4889e-06 - val_dense_89_loss: 2.4830e-06 - val_dense_90_loss: 6.5691e-06 - val_dense_91_loss: 6.5946e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2031e-05 - dense_88_loss: 2.4994e-06 - dense_89_loss: 2.4989e-06 - dense_90_loss: 6.3533e-06 - dense_91_loss: 6.7989e-07 - val_loss: 1.2020e-05 - val_dense_88_loss: 2.4563e-06 - val_dense_89_loss: 2.4757e-06 - val_dense_90_loss: 6.3985e-06 - val_dense_91_loss: 6.8936e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1613e-05 - dense_88_loss: 2.4324e-06 - dense_89_loss: 2.4260e-06 - dense_90_loss: 6.0493e-06 - dense_91_loss: 7.0569e-07 - val_loss: 1.1661e-05 - val_dense_88_loss: 2.4074e-06 - val_dense_89_loss: 2.4006e-06 - val_dense_90_loss: 6.1170e-06 - val_dense_91_loss: 7.3641e-07\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1317e-05 - dense_88_loss: 2.4037e-06 - dense_89_loss: 2.3725e-06 - dense_90_loss: 5.7886e-06 - dense_91_loss: 7.5188e-07 - val_loss: 1.1274e-05 - val_dense_88_loss: 2.3602e-06 - val_dense_89_loss: 2.3338e-06 - val_dense_90_loss: 5.8009e-06 - val_dense_91_loss: 7.7961e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0844e-05 - dense_88_loss: 2.3297e-06 - dense_89_loss: 2.2932e-06 - dense_90_loss: 5.4204e-06 - dense_91_loss: 8.0041e-07 - val_loss: 1.0799e-05 - val_dense_88_loss: 2.2922e-06 - val_dense_89_loss: 2.2673e-06 - val_dense_90_loss: 5.3930e-06 - val_dense_91_loss: 8.4626e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0276e-05 - dense_88_loss: 2.2441e-06 - dense_89_loss: 2.1919e-06 - dense_90_loss: 4.9768e-06 - dense_91_loss: 8.6282e-07 - val_loss: 1.0185e-05 - val_dense_88_loss: 2.1983e-06 - val_dense_89_loss: 2.1531e-06 - val_dense_90_loss: 4.9223e-06 - val_dense_91_loss: 9.1141e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.5816e-06 - dense_88_loss: 2.1249e-06 - dense_89_loss: 2.0656e-06 - dense_90_loss: 4.4649e-06 - dense_91_loss: 9.2623e-07 - val_loss: 9.1689e-06 - val_dense_88_loss: 2.0252e-06 - val_dense_89_loss: 1.9639e-06 - val_dense_90_loss: 4.2174e-06 - val_dense_91_loss: 9.6248e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.4965e-06 - dense_88_loss: 1.9246e-06 - dense_89_loss: 1.8533e-06 - dense_90_loss: 3.7491e-06 - dense_91_loss: 9.6951e-07 - val_loss: 8.1313e-06 - val_dense_88_loss: 1.8285e-06 - val_dense_89_loss: 1.7653e-06 - val_dense_90_loss: 3.5068e-06 - val_dense_91_loss: 1.0307e-06\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 7.1965e-06 - dense_88_loss: 1.6645e-06 - dense_89_loss: 1.5976e-06 - dense_90_loss: 2.9484e-06 - dense_91_loss: 9.8599e-07 - val_loss: 6.4347e-06 - val_dense_88_loss: 1.4795e-06 - val_dense_89_loss: 1.4325e-06 - val_dense_90_loss: 2.5646e-06 - val_dense_91_loss: 9.5810e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 5.5484e-06 - dense_88_loss: 1.3098e-06 - dense_89_loss: 1.2628e-06 - dense_90_loss: 2.0855e-06 - dense_91_loss: 8.9027e-07 - val_loss: 4.7102e-06 - val_dense_88_loss: 1.1069e-06 - val_dense_89_loss: 1.0858e-06 - val_dense_90_loss: 1.6917e-06 - val_dense_91_loss: 8.2577e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.8864e-06 - dense_88_loss: 9.3193e-07 - dense_89_loss: 9.1580e-07 - dense_90_loss: 1.3049e-06 - dense_91_loss: 7.3371e-07 - val_loss: 3.1637e-06 - val_dense_88_loss: 7.5917e-07 - val_dense_89_loss: 7.5453e-07 - val_dense_90_loss: 1.0132e-06 - val_dense_91_loss: 6.3679e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.5740e-06 - dense_88_loss: 6.3360e-07 - dense_89_loss: 6.2970e-07 - dense_90_loss: 7.6443e-07 - dense_91_loss: 5.4629e-07 - val_loss: 2.0071e-06 - val_dense_88_loss: 5.0018e-07 - val_dense_89_loss: 5.0178e-07 - val_dense_90_loss: 5.5962e-07 - val_dense_91_loss: 4.4552e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6635e-06 - dense_88_loss: 4.2569e-07 - dense_89_loss: 4.2651e-07 - dense_90_loss: 4.3309e-07 - dense_91_loss: 3.7823e-07 - val_loss: 1.3899e-06 - val_dense_88_loss: 3.6706e-07 - val_dense_89_loss: 3.6095e-07 - val_dense_90_loss: 3.3912e-07 - val_dense_91_loss: 3.2280e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1835e-06 - dense_88_loss: 3.1736e-07 - dense_89_loss: 3.0793e-07 - dense_90_loss: 2.8365e-07 - dense_91_loss: 2.7452e-07 - val_loss: 9.8301e-07 - val_dense_88_loss: 2.7402e-07 - val_dense_89_loss: 2.5671e-07 - val_dense_90_loss: 2.2673e-07 - val_dense_91_loss: 2.2556e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.3377e-07 - dense_88_loss: 2.6058e-07 - dense_89_loss: 2.4739e-07 - dense_90_loss: 2.1461e-07 - dense_91_loss: 2.1119e-07 - val_loss: 8.6944e-07 - val_dense_88_loss: 2.4927e-07 - val_dense_89_loss: 2.3553e-07 - val_dense_90_loss: 1.8962e-07 - val_dense_91_loss: 1.9502e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.6323e-07 - dense_88_loss: 2.4943e-07 - dense_89_loss: 2.3527e-07 - dense_90_loss: 1.9067e-07 - dense_91_loss: 1.8787e-07 - val_loss: 8.2255e-07 - val_dense_88_loss: 2.4033e-07 - val_dense_89_loss: 2.2333e-07 - val_dense_90_loss: 1.7801e-07 - val_dense_91_loss: 1.8088e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 8.5057e-07 - dense_88_loss: 2.4607e-07 - dense_89_loss: 2.2777e-07 - dense_90_loss: 1.9789e-07 - dense_91_loss: 1.7884e-07 - val_loss: 8.2957e-07 - val_dense_88_loss: 2.5083e-07 - val_dense_89_loss: 2.2753e-07 - val_dense_90_loss: 1.7642e-07 - val_dense_91_loss: 1.7479e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 8.1455e-07 - dense_88_loss: 2.3938e-07 - dense_89_loss: 2.2809e-07 - dense_90_loss: 1.7914e-07 - dense_91_loss: 1.6793e-07 - val_loss: 7.2801e-07 - val_dense_88_loss: 2.2627e-07 - val_dense_89_loss: 2.0736e-07 - val_dense_90_loss: 1.4845e-07 - val_dense_91_loss: 1.4593e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 7.9607e-07 - dense_88_loss: 2.3596e-07 - dense_89_loss: 2.2392e-07 - dense_90_loss: 1.7693e-07 - dense_91_loss: 1.5926e-07 - val_loss: 7.6972e-07 - val_dense_88_loss: 2.3085e-07 - val_dense_89_loss: 2.2072e-07 - val_dense_90_loss: 1.6377e-07 - val_dense_91_loss: 1.5437e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.4018e-07 - dense_88_loss: 2.4523e-07 - dense_89_loss: 2.3487e-07 - dense_90_loss: 1.9291e-07 - dense_91_loss: 1.6716e-07 - val_loss: 8.0950e-07 - val_dense_88_loss: 2.4873e-07 - val_dense_89_loss: 2.2736e-07 - val_dense_90_loss: 1.7484e-07 - val_dense_91_loss: 1.5857e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.2465e-07 - dense_88_loss: 2.4302e-07 - dense_89_loss: 2.3133e-07 - dense_90_loss: 1.9012e-07 - dense_91_loss: 1.6018e-07 - val_loss: 9.0477e-07 - val_dense_88_loss: 2.7198e-07 - val_dense_89_loss: 2.5507e-07 - val_dense_90_loss: 2.0667e-07 - val_dense_91_loss: 1.7105e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.3527e-07 - dense_88_loss: 2.4902e-07 - dense_89_loss: 2.3317e-07 - dense_90_loss: 1.9102e-07 - dense_91_loss: 1.6207e-07 - val_loss: 7.6252e-07 - val_dense_88_loss: 2.2807e-07 - val_dense_89_loss: 2.1482e-07 - val_dense_90_loss: 1.7140e-07 - val_dense_91_loss: 1.4824e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.8858e-07 - dense_88_loss: 2.5744e-07 - dense_89_loss: 2.4831e-07 - dense_90_loss: 2.0649e-07 - dense_91_loss: 1.7635e-07 - val_loss: 9.4096e-07 - val_dense_88_loss: 2.6688e-07 - val_dense_89_loss: 2.7686e-07 - val_dense_90_loss: 1.9623e-07 - val_dense_91_loss: 2.0098e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.8168e-07 - dense_88_loss: 2.7543e-07 - dense_89_loss: 2.7474e-07 - dense_90_loss: 2.3003e-07 - dense_91_loss: 2.0148e-07 - val_loss: 7.9035e-07 - val_dense_88_loss: 2.3280e-07 - val_dense_89_loss: 2.2141e-07 - val_dense_90_loss: 1.7647e-07 - val_dense_91_loss: 1.5966e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.7483e-07 - dense_88_loss: 2.5780e-07 - dense_89_loss: 2.4484e-07 - dense_90_loss: 2.0118e-07 - dense_91_loss: 1.7101e-07 - val_loss: 9.4535e-07 - val_dense_88_loss: 2.6735e-07 - val_dense_89_loss: 2.5781e-07 - val_dense_90_loss: 2.1702e-07 - val_dense_91_loss: 2.0318e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6762e-07 - dense_88_loss: 2.7893e-07 - dense_89_loss: 2.6758e-07 - dense_90_loss: 2.2697e-07 - dense_91_loss: 1.9414e-07 - val_loss: 1.3493e-06 - val_dense_88_loss: 4.3992e-07 - val_dense_89_loss: 3.6042e-07 - val_dense_90_loss: 2.8998e-07 - val_dense_91_loss: 2.5893e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0999e-06 - dense_88_loss: 3.2617e-07 - dense_89_loss: 3.0007e-07 - dense_90_loss: 2.5764e-07 - dense_91_loss: 2.1606e-07 - val_loss: 1.1563e-06 - val_dense_88_loss: 3.3770e-07 - val_dense_89_loss: 3.0162e-07 - val_dense_90_loss: 2.8301e-07 - val_dense_91_loss: 2.3394e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0607e-06 - dense_88_loss: 3.0621e-07 - dense_89_loss: 2.9240e-07 - dense_90_loss: 2.4304e-07 - dense_91_loss: 2.1903e-07 - val_loss: 9.9924e-07 - val_dense_88_loss: 3.0414e-07 - val_dense_89_loss: 2.8835e-07 - val_dense_90_loss: 2.0918e-07 - val_dense_91_loss: 1.9758e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2449e-06 - dense_88_loss: 3.3362e-07 - dense_89_loss: 3.5550e-07 - dense_90_loss: 2.9225e-07 - dense_91_loss: 2.6350e-07 - val_loss: 8.6256e-07 - val_dense_88_loss: 2.5154e-07 - val_dense_89_loss: 2.3938e-07 - val_dense_90_loss: 2.0197e-07 - val_dense_91_loss: 1.6967e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.8586e-07 - dense_88_loss: 2.6315e-07 - dense_89_loss: 2.4363e-07 - dense_90_loss: 2.0575e-07 - dense_91_loss: 1.7334e-07 - val_loss: 7.3509e-07 - val_dense_88_loss: 2.1718e-07 - val_dense_89_loss: 2.0697e-07 - val_dense_90_loss: 1.6646e-07 - val_dense_91_loss: 1.4449e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 8.5477e-07 - dense_88_loss: 2.4775e-07 - dense_89_loss: 2.3914e-07 - dense_90_loss: 1.9897e-07 - dense_91_loss: 1.6891e-07 - val_loss: 9.1150e-07 - val_dense_88_loss: 2.6668e-07 - val_dense_89_loss: 2.6544e-07 - val_dense_90_loss: 2.0140e-07 - val_dense_91_loss: 1.7798e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.2144e-07 - dense_88_loss: 2.6500e-07 - dense_89_loss: 2.5884e-07 - dense_90_loss: 2.1354e-07 - dense_91_loss: 1.8405e-07 - val_loss: 7.3010e-07 - val_dense_88_loss: 2.1868e-07 - val_dense_89_loss: 2.1126e-07 - val_dense_90_loss: 1.5534e-07 - val_dense_91_loss: 1.4482e-07\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.3423e-07 - dense_88_loss: 2.7373e-07 - dense_89_loss: 2.5559e-07 - dense_90_loss: 2.1905e-07 - dense_91_loss: 1.8585e-07 - val_loss: 1.3731e-06 - val_dense_88_loss: 3.7145e-07 - val_dense_89_loss: 3.6874e-07 - val_dense_90_loss: 3.3304e-07 - val_dense_91_loss: 2.9992e-07\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.3130e-06 - dense_88_loss: 3.4234e-07 - dense_89_loss: 3.7430e-07 - dense_90_loss: 3.1737e-07 - dense_91_loss: 2.7900e-07 - val_loss: 9.6926e-07 - val_dense_88_loss: 2.7537e-07 - val_dense_89_loss: 2.6692e-07 - val_dense_90_loss: 2.3417e-07 - val_dense_91_loss: 1.9280e-07\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.3659e-07 - dense_88_loss: 2.6436e-07 - dense_89_loss: 2.6504e-07 - dense_90_loss: 2.1356e-07 - dense_91_loss: 1.9363e-07 - val_loss: 1.2042e-06 - val_dense_88_loss: 3.3352e-07 - val_dense_89_loss: 3.5000e-07 - val_dense_90_loss: 2.7260e-07 - val_dense_91_loss: 2.4803e-07\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1641e-06 - dense_88_loss: 3.3974e-07 - dense_89_loss: 3.1242e-07 - dense_90_loss: 2.7385e-07 - dense_91_loss: 2.3804e-07 - val_loss: 7.5368e-07 - val_dense_88_loss: 2.1684e-07 - val_dense_89_loss: 2.1287e-07 - val_dense_90_loss: 1.7485e-07 - val_dense_91_loss: 1.4912e-07\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.1883e-07 - dense_88_loss: 2.7571e-07 - dense_89_loss: 2.5875e-07 - dense_90_loss: 2.0667e-07 - dense_91_loss: 1.7770e-07 - val_loss: 8.9184e-07 - val_dense_88_loss: 2.7044e-07 - val_dense_89_loss: 2.4894e-07 - val_dense_90_loss: 1.8845e-07 - val_dense_91_loss: 1.8401e-07\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0064e-06 - dense_88_loss: 2.8469e-07 - dense_89_loss: 2.8040e-07 - dense_90_loss: 2.3382e-07 - dense_91_loss: 2.0753e-07 - val_loss: 1.1894e-06 - val_dense_88_loss: 3.2892e-07 - val_dense_89_loss: 3.6655e-07 - val_dense_90_loss: 2.6776e-07 - val_dense_91_loss: 2.2621e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "\n",
      "Now training model 5/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 19ms/step - loss: 0.0024 - dense_94_loss: 2.9835e-04 - dense_95_loss: 2.9980e-04 - dense_96_loss: 3.9474e-04 - dense_97_loss: 0.0014 - val_loss: 6.6637e-04 - val_dense_94_loss: 1.0096e-04 - val_dense_95_loss: 6.9184e-05 - val_dense_96_loss: 1.1618e-04 - val_dense_97_loss: 3.8005e-04\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.4647e-04 - dense_94_loss: 4.2552e-05 - dense_95_loss: 3.6094e-05 - dense_96_loss: 5.4986e-05 - dense_97_loss: 1.1284e-04 - val_loss: 6.7422e-05 - val_dense_94_loss: 1.4887e-05 - val_dense_95_loss: 1.5490e-05 - val_dense_96_loss: 2.5796e-05 - val_dense_97_loss: 1.1248e-05\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4.0148e-05 - dense_94_loss: 8.0569e-06 - dense_95_loss: 7.6109e-06 - dense_96_loss: 1.8380e-05 - dense_97_loss: 6.1005e-06 - val_loss: 2.3329e-05 - val_dense_94_loss: 3.2834e-06 - val_dense_95_loss: 3.7531e-06 - val_dense_96_loss: 1.3874e-05 - val_dense_97_loss: 2.4185e-06\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.9882e-05 - dense_94_loss: 2.8164e-06 - dense_95_loss: 2.6697e-06 - dense_96_loss: 1.2706e-05 - dense_97_loss: 1.6906e-06 - val_loss: 1.7976e-05 - val_dense_94_loss: 2.4511e-06 - val_dense_95_loss: 2.2140e-06 - val_dense_96_loss: 1.2223e-05 - val_dense_97_loss: 1.0883e-06\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.7120e-05 - dense_94_loss: 2.2832e-06 - dense_95_loss: 2.0275e-06 - dense_96_loss: 1.1796e-05 - dense_97_loss: 1.0136e-06 - val_loss: 1.7045e-05 - val_dense_94_loss: 2.2742e-06 - val_dense_95_loss: 2.0043e-06 - val_dense_96_loss: 1.1805e-05 - val_dense_97_loss: 9.6080e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.6485e-05 - dense_94_loss: 2.2127e-06 - dense_95_loss: 1.9275e-06 - dense_96_loss: 1.1376e-05 - dense_97_loss: 9.6822e-07 - val_loss: 1.6555e-05 - val_dense_94_loss: 2.2518e-06 - val_dense_95_loss: 1.9626e-06 - val_dense_96_loss: 1.1344e-05 - val_dense_97_loss: 9.9675e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.5999e-05 - dense_94_loss: 2.2033e-06 - dense_95_loss: 1.9024e-06 - dense_96_loss: 1.0877e-05 - dense_97_loss: 1.0159e-06 - val_loss: 1.5996e-05 - val_dense_94_loss: 2.2399e-06 - val_dense_95_loss: 1.9323e-06 - val_dense_96_loss: 1.0774e-05 - val_dense_97_loss: 1.0496e-06\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 6ms/step - loss: 1.5407e-05 - dense_94_loss: 2.1975e-06 - dense_95_loss: 1.8761e-06 - dense_96_loss: 1.0255e-05 - dense_97_loss: 1.0784e-06 - val_loss: 1.5269e-05 - val_dense_94_loss: 2.2186e-06 - val_dense_95_loss: 1.8974e-06 - val_dense_96_loss: 1.0030e-05 - val_dense_97_loss: 1.1228e-06\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.4507e-05 - dense_94_loss: 2.1505e-06 - dense_95_loss: 1.8235e-06 - dense_96_loss: 9.3839e-06 - dense_97_loss: 1.1496e-06 - val_loss: 1.4232e-05 - val_dense_94_loss: 2.1692e-06 - val_dense_95_loss: 1.8325e-06 - val_dense_96_loss: 9.0295e-06 - val_dense_97_loss: 1.2005e-06\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.3371e-05 - dense_94_loss: 2.0877e-06 - dense_95_loss: 1.7525e-06 - dense_96_loss: 8.3062e-06 - dense_97_loss: 1.2246e-06 - val_loss: 1.2839e-05 - val_dense_94_loss: 2.0490e-06 - val_dense_95_loss: 1.7353e-06 - val_dense_96_loss: 7.7963e-06 - val_dense_97_loss: 1.2579e-06\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1878e-05 - dense_94_loss: 1.9561e-06 - dense_95_loss: 1.6468e-06 - dense_96_loss: 7.0162e-06 - dense_97_loss: 1.2591e-06 - val_loss: 1.1088e-05 - val_dense_94_loss: 1.9061e-06 - val_dense_95_loss: 1.6187e-06 - val_dense_96_loss: 6.2603e-06 - val_dense_97_loss: 1.3034e-06\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 9.8698e-06 - dense_94_loss: 1.7336e-06 - dense_95_loss: 1.4900e-06 - dense_96_loss: 5.4110e-06 - dense_97_loss: 1.2352e-06 - val_loss: 8.6611e-06 - val_dense_94_loss: 1.5611e-06 - val_dense_95_loss: 1.3774e-06 - val_dense_96_loss: 4.5572e-06 - val_dense_97_loss: 1.1654e-06\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 7.2349e-06 - dense_94_loss: 1.3316e-06 - dense_95_loss: 1.2043e-06 - dense_96_loss: 3.6730e-06 - dense_97_loss: 1.0261e-06 - val_loss: 5.8228e-06 - val_dense_94_loss: 1.1033e-06 - val_dense_95_loss: 1.0409e-06 - val_dense_96_loss: 2.8080e-06 - val_dense_97_loss: 8.7055e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.6540e-06 - dense_94_loss: 8.8094e-07 - dense_95_loss: 8.7732e-07 - dense_96_loss: 2.1833e-06 - dense_97_loss: 7.1242e-07 - val_loss: 3.5206e-06 - val_dense_94_loss: 6.7692e-07 - val_dense_95_loss: 7.1451e-07 - val_dense_96_loss: 1.5923e-06 - val_dense_97_loss: 5.3686e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.7236e-06 - dense_94_loss: 5.1713e-07 - dense_95_loss: 5.8409e-07 - dense_96_loss: 1.2093e-06 - dense_97_loss: 4.1302e-07 - val_loss: 2.0532e-06 - val_dense_94_loss: 3.8251e-07 - val_dense_95_loss: 4.7228e-07 - val_dense_96_loss: 8.9231e-07 - val_dense_97_loss: 3.0612e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6963e-06 - dense_94_loss: 3.2868e-07 - dense_95_loss: 4.0322e-07 - dense_96_loss: 7.0844e-07 - dense_97_loss: 2.5600e-07 - val_loss: 1.3357e-06 - val_dense_94_loss: 2.6637e-07 - val_dense_95_loss: 3.3616e-07 - val_dense_96_loss: 5.3786e-07 - val_dense_97_loss: 1.9529e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2234e-06 - dense_94_loss: 2.6069e-07 - dense_95_loss: 3.1324e-07 - dense_96_loss: 4.5483e-07 - dense_97_loss: 1.9468e-07 - val_loss: 1.0286e-06 - val_dense_94_loss: 2.3159e-07 - val_dense_95_loss: 2.7196e-07 - val_dense_96_loss: 3.5925e-07 - val_dense_97_loss: 1.6575e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0112e-06 - dense_94_loss: 2.4323e-07 - dense_95_loss: 2.7431e-07 - dense_96_loss: 3.2029e-07 - dense_97_loss: 1.7334e-07 - val_loss: 9.3415e-07 - val_dense_94_loss: 2.3896e-07 - val_dense_95_loss: 2.7012e-07 - val_dense_96_loss: 2.6431e-07 - val_dense_97_loss: 1.6076e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.0421e-07 - dense_94_loss: 2.3559e-07 - dense_95_loss: 2.6249e-07 - dense_96_loss: 2.4384e-07 - dense_97_loss: 1.6229e-07 - val_loss: 8.3392e-07 - val_dense_94_loss: 2.2474e-07 - val_dense_95_loss: 2.5388e-07 - val_dense_96_loss: 2.0750e-07 - val_dense_97_loss: 1.4779e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.4939e-07 - dense_94_loss: 2.3312e-07 - dense_95_loss: 2.5778e-07 - dense_96_loss: 2.0177e-07 - dense_97_loss: 1.5672e-07 - val_loss: 7.6126e-07 - val_dense_94_loss: 2.1696e-07 - val_dense_95_loss: 2.3784e-07 - val_dense_96_loss: 1.6838e-07 - val_dense_97_loss: 1.3807e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.1601e-07 - dense_94_loss: 2.3091e-07 - dense_95_loss: 2.5579e-07 - dense_96_loss: 1.7464e-07 - dense_97_loss: 1.5468e-07 - val_loss: 7.6384e-07 - val_dense_94_loss: 2.2714e-07 - val_dense_95_loss: 2.4225e-07 - val_dense_96_loss: 1.5672e-07 - val_dense_97_loss: 1.3773e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.1131e-07 - dense_94_loss: 2.3496e-07 - dense_95_loss: 2.5655e-07 - dense_96_loss: 1.6300e-07 - dense_97_loss: 1.5680e-07 - val_loss: 8.1854e-07 - val_dense_94_loss: 2.3013e-07 - val_dense_95_loss: 2.7089e-07 - val_dense_96_loss: 1.6105e-07 - val_dense_97_loss: 1.5647e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.1662e-07 - dense_94_loss: 2.3804e-07 - dense_95_loss: 2.6134e-07 - dense_96_loss: 1.5833e-07 - dense_97_loss: 1.5891e-07 - val_loss: 7.5626e-07 - val_dense_94_loss: 2.2260e-07 - val_dense_95_loss: 2.4766e-07 - val_dense_96_loss: 1.4277e-07 - val_dense_97_loss: 1.4324e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.5428e-07 - dense_94_loss: 2.4437e-07 - dense_95_loss: 2.7386e-07 - dense_96_loss: 1.6652e-07 - dense_97_loss: 1.6953e-07 - val_loss: 8.7198e-07 - val_dense_94_loss: 2.4335e-07 - val_dense_95_loss: 2.8096e-07 - val_dense_96_loss: 1.6618e-07 - val_dense_97_loss: 1.8150e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.5080e-07 - dense_94_loss: 2.4684e-07 - dense_95_loss: 2.6930e-07 - dense_96_loss: 1.6398e-07 - dense_97_loss: 1.7068e-07 - val_loss: 8.0940e-07 - val_dense_94_loss: 2.3493e-07 - val_dense_95_loss: 2.6835e-07 - val_dense_96_loss: 1.4492e-07 - val_dense_97_loss: 1.6120e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.6191e-07 - dense_94_loss: 2.4888e-07 - dense_95_loss: 2.7822e-07 - dense_96_loss: 1.6469e-07 - dense_97_loss: 1.7011e-07 - val_loss: 8.2363e-07 - val_dense_94_loss: 2.3769e-07 - val_dense_95_loss: 2.6572e-07 - val_dense_96_loss: 1.4936e-07 - val_dense_97_loss: 1.7086e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2164e-06 - dense_94_loss: 3.2711e-07 - dense_95_loss: 3.7833e-07 - dense_96_loss: 2.4680e-07 - dense_97_loss: 2.6418e-07 - val_loss: 8.9883e-07 - val_dense_94_loss: 2.6684e-07 - val_dense_95_loss: 2.8181e-07 - val_dense_96_loss: 1.7368e-07 - val_dense_97_loss: 1.7650e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0167e-06 - dense_94_loss: 2.9205e-07 - dense_95_loss: 3.1566e-07 - dense_96_loss: 1.9764e-07 - dense_97_loss: 2.1134e-07 - val_loss: 8.2265e-07 - val_dense_94_loss: 2.4812e-07 - val_dense_95_loss: 2.6044e-07 - val_dense_96_loss: 1.5402e-07 - val_dense_97_loss: 1.6007e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.7618e-07 - dense_94_loss: 2.5661e-07 - dense_95_loss: 2.8220e-07 - dense_96_loss: 1.5976e-07 - dense_97_loss: 1.7760e-07 - val_loss: 8.2435e-07 - val_dense_94_loss: 2.4305e-07 - val_dense_95_loss: 2.6606e-07 - val_dense_96_loss: 1.4925e-07 - val_dense_97_loss: 1.6598e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.2147e-07 - dense_94_loss: 2.6373e-07 - dense_95_loss: 2.9506e-07 - dense_96_loss: 1.7626e-07 - dense_97_loss: 1.8642e-07 - val_loss: 7.8939e-07 - val_dense_94_loss: 2.2997e-07 - val_dense_95_loss: 2.6317e-07 - val_dense_96_loss: 1.4091e-07 - val_dense_97_loss: 1.5534e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.2745e-07 - dense_94_loss: 2.7291e-07 - dense_95_loss: 2.9432e-07 - dense_96_loss: 1.7411e-07 - dense_97_loss: 1.8611e-07 - val_loss: 8.5839e-07 - val_dense_94_loss: 2.5742e-07 - val_dense_95_loss: 2.6698e-07 - val_dense_96_loss: 1.5834e-07 - val_dense_97_loss: 1.7566e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.7866e-07 - dense_94_loss: 2.5756e-07 - dense_95_loss: 2.7691e-07 - dense_96_loss: 1.6924e-07 - dense_97_loss: 1.7495e-07 - val_loss: 9.9578e-07 - val_dense_94_loss: 3.0379e-07 - val_dense_95_loss: 3.0459e-07 - val_dense_96_loss: 1.8419e-07 - val_dense_97_loss: 2.0321e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0314e-06 - dense_94_loss: 2.9188e-07 - dense_95_loss: 3.2440e-07 - dense_96_loss: 2.0087e-07 - dense_97_loss: 2.1426e-07 - val_loss: 1.2347e-06 - val_dense_94_loss: 3.4282e-07 - val_dense_95_loss: 3.6266e-07 - val_dense_96_loss: 2.7811e-07 - val_dense_97_loss: 2.5111e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.7746e-07 - dense_94_loss: 2.8143e-07 - dense_95_loss: 3.0245e-07 - dense_96_loss: 1.9362e-07 - dense_97_loss: 1.9996e-07 - val_loss: 9.8028e-07 - val_dense_94_loss: 2.8725e-07 - val_dense_95_loss: 2.9876e-07 - val_dense_96_loss: 1.8779e-07 - val_dense_97_loss: 2.0648e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1578e-06 - dense_94_loss: 3.1881e-07 - dense_95_loss: 3.5360e-07 - dense_96_loss: 2.3939e-07 - dense_97_loss: 2.4602e-07 - val_loss: 1.1939e-06 - val_dense_94_loss: 3.4532e-07 - val_dense_95_loss: 3.6843e-07 - val_dense_96_loss: 2.4005e-07 - val_dense_97_loss: 2.4010e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1239e-06 - dense_94_loss: 3.1669e-07 - dense_95_loss: 3.4354e-07 - dense_96_loss: 2.2783e-07 - dense_97_loss: 2.3580e-07 - val_loss: 7.4327e-07 - val_dense_94_loss: 2.2663e-07 - val_dense_95_loss: 2.4872e-07 - val_dense_96_loss: 1.2679e-07 - val_dense_97_loss: 1.4112e-07\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.9297e-07 - dense_94_loss: 2.6247e-07 - dense_95_loss: 2.8054e-07 - dense_96_loss: 1.7030e-07 - dense_97_loss: 1.7966e-07 - val_loss: 8.8161e-07 - val_dense_94_loss: 2.6786e-07 - val_dense_95_loss: 2.8688e-07 - val_dense_96_loss: 1.4832e-07 - val_dense_97_loss: 1.7856e-07\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6861e-06 - dense_94_loss: 4.4677e-07 - dense_95_loss: 5.3150e-07 - dense_96_loss: 3.2675e-07 - dense_97_loss: 3.8110e-07 - val_loss: 1.4012e-06 - val_dense_94_loss: 3.7922e-07 - val_dense_95_loss: 4.1960e-07 - val_dense_96_loss: 2.9763e-07 - val_dense_97_loss: 3.0470e-07\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.2248e-07 - dense_94_loss: 2.6805e-07 - dense_95_loss: 2.9496e-07 - dense_96_loss: 1.7413e-07 - dense_97_loss: 1.8535e-07 - val_loss: 9.9664e-07 - val_dense_94_loss: 2.9016e-07 - val_dense_95_loss: 3.0580e-07 - val_dense_96_loss: 1.9603e-07 - val_dense_97_loss: 2.0465e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "\n",
      "Now training model 6/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 3.9871e-04 - dense_100_loss: 2.1058e-04 - dense_101_loss: 1.8813e-04 - val_loss: 5.4680e-05 - val_dense_100_loss: 3.4037e-05 - val_dense_101_loss: 2.0643e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.1990e-05 - dense_100_loss: 1.3228e-05 - dense_101_loss: 8.7620e-06 - val_loss: 8.6314e-06 - val_dense_100_loss: 5.3777e-06 - val_dense_101_loss: 3.2537e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.5227e-06 - dense_100_loss: 2.7644e-06 - dense_101_loss: 1.7583e-06 - val_loss: 2.0108e-06 - val_dense_100_loss: 1.3430e-06 - val_dense_101_loss: 6.6784e-07\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.7777e-06 - dense_100_loss: 1.2725e-06 - dense_101_loss: 5.0519e-07 - val_loss: 1.2850e-06 - val_dense_100_loss: 8.8995e-07 - val_dense_101_loss: 3.9505e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4533e-06 - dense_100_loss: 1.0742e-06 - dense_101_loss: 3.7915e-07 - val_loss: 1.1511e-06 - val_dense_100_loss: 8.2576e-07 - val_dense_101_loss: 3.2532e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3737e-06 - dense_100_loss: 1.0258e-06 - dense_101_loss: 3.4790e-07 - val_loss: 1.1023e-06 - val_dense_100_loss: 7.9993e-07 - val_dense_101_loss: 3.0241e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3195e-06 - dense_100_loss: 9.9223e-07 - dense_101_loss: 3.2726e-07 - val_loss: 1.1076e-06 - val_dense_100_loss: 7.9813e-07 - val_dense_101_loss: 3.0946e-07\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2914e-06 - dense_100_loss: 9.7493e-07 - dense_101_loss: 3.1644e-07 - val_loss: 1.0443e-06 - val_dense_100_loss: 7.6469e-07 - val_dense_101_loss: 2.7965e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2593e-06 - dense_100_loss: 9.5397e-07 - dense_101_loss: 3.0532e-07 - val_loss: 1.0202e-06 - val_dense_100_loss: 7.4913e-07 - val_dense_101_loss: 2.7110e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2481e-06 - dense_100_loss: 9.4769e-07 - dense_101_loss: 3.0045e-07 - val_loss: 1.0290e-06 - val_dense_100_loss: 7.5178e-07 - val_dense_101_loss: 2.7717e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2307e-06 - dense_100_loss: 9.3307e-07 - dense_101_loss: 2.9758e-07 - val_loss: 1.0079e-06 - val_dense_100_loss: 7.4139e-07 - val_dense_101_loss: 2.6652e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2078e-06 - dense_100_loss: 9.1715e-07 - dense_101_loss: 2.9063e-07 - val_loss: 9.8667e-07 - val_dense_100_loss: 7.2336e-07 - val_dense_101_loss: 2.6332e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1890e-06 - dense_100_loss: 9.0318e-07 - dense_101_loss: 2.8586e-07 - val_loss: 9.8141e-07 - val_dense_100_loss: 7.1734e-07 - val_dense_101_loss: 2.6407e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1855e-06 - dense_100_loss: 8.9924e-07 - dense_101_loss: 2.8623e-07 - val_loss: 9.7501e-07 - val_dense_100_loss: 7.0873e-07 - val_dense_101_loss: 2.6628e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1718e-06 - dense_100_loss: 8.8590e-07 - dense_101_loss: 2.8586e-07 - val_loss: 9.8369e-07 - val_dense_100_loss: 7.1168e-07 - val_dense_101_loss: 2.7201e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1663e-06 - dense_100_loss: 8.7985e-07 - dense_101_loss: 2.8650e-07 - val_loss: 9.5278e-07 - val_dense_100_loss: 6.9238e-07 - val_dense_101_loss: 2.6040e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1497e-06 - dense_100_loss: 8.6616e-07 - dense_101_loss: 2.8357e-07 - val_loss: 9.6009e-07 - val_dense_100_loss: 6.8937e-07 - val_dense_101_loss: 2.7073e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1481e-06 - dense_100_loss: 8.6067e-07 - dense_101_loss: 2.8743e-07 - val_loss: 9.5318e-07 - val_dense_100_loss: 6.8771e-07 - val_dense_101_loss: 2.6547e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1381e-06 - dense_100_loss: 8.5164e-07 - dense_101_loss: 2.8644e-07 - val_loss: 9.5385e-07 - val_dense_100_loss: 6.8736e-07 - val_dense_101_loss: 2.6649e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1284e-06 - dense_100_loss: 8.4252e-07 - dense_101_loss: 2.8586e-07 - val_loss: 9.1748e-07 - val_dense_100_loss: 6.6369e-07 - val_dense_101_loss: 2.5379e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1048e-06 - dense_100_loss: 8.2457e-07 - dense_101_loss: 2.8027e-07 - val_loss: 9.1733e-07 - val_dense_100_loss: 6.5874e-07 - val_dense_101_loss: 2.5859e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1053e-06 - dense_100_loss: 8.2059e-07 - dense_101_loss: 2.8472e-07 - val_loss: 9.0014e-07 - val_dense_100_loss: 6.4457e-07 - val_dense_101_loss: 2.5556e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0907e-06 - dense_100_loss: 8.0651e-07 - dense_101_loss: 2.8416e-07 - val_loss: 8.9836e-07 - val_dense_100_loss: 6.3977e-07 - val_dense_101_loss: 2.5859e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0846e-06 - dense_100_loss: 8.0105e-07 - dense_101_loss: 2.8352e-07 - val_loss: 8.9452e-07 - val_dense_100_loss: 6.3505e-07 - val_dense_101_loss: 2.5947e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0762e-06 - dense_100_loss: 7.9070e-07 - dense_101_loss: 2.8547e-07 - val_loss: 8.8292e-07 - val_dense_100_loss: 6.2622e-07 - val_dense_101_loss: 2.5671e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0791e-06 - dense_100_loss: 7.8835e-07 - dense_101_loss: 2.9070e-07 - val_loss: 8.8316e-07 - val_dense_100_loss: 6.2171e-07 - val_dense_101_loss: 2.6144e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0537e-06 - dense_100_loss: 7.6840e-07 - dense_101_loss: 2.8534e-07 - val_loss: 8.7607e-07 - val_dense_100_loss: 6.1821e-07 - val_dense_101_loss: 2.5786e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0502e-06 - dense_100_loss: 7.6320e-07 - dense_101_loss: 2.8703e-07 - val_loss: 8.6122e-07 - val_dense_100_loss: 6.0254e-07 - val_dense_101_loss: 2.5868e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0388e-06 - dense_100_loss: 7.4998e-07 - dense_101_loss: 2.8880e-07 - val_loss: 8.5263e-07 - val_dense_100_loss: 5.9351e-07 - val_dense_101_loss: 2.5912e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0194e-06 - dense_100_loss: 7.3225e-07 - dense_101_loss: 2.8718e-07 - val_loss: 8.4016e-07 - val_dense_100_loss: 5.8295e-07 - val_dense_101_loss: 2.5721e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0006e-06 - dense_100_loss: 7.1783e-07 - dense_101_loss: 2.8274e-07 - val_loss: 8.3400e-07 - val_dense_100_loss: 5.7735e-07 - val_dense_101_loss: 2.5665e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.9493e-07 - dense_100_loss: 7.0842e-07 - dense_101_loss: 2.8651e-07 - val_loss: 8.2539e-07 - val_dense_100_loss: 5.6607e-07 - val_dense_101_loss: 2.5932e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.7978e-07 - dense_100_loss: 6.9199e-07 - dense_101_loss: 2.8779e-07 - val_loss: 8.0390e-07 - val_dense_100_loss: 5.4948e-07 - val_dense_101_loss: 2.5442e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.6705e-07 - dense_100_loss: 6.7958e-07 - dense_101_loss: 2.8748e-07 - val_loss: 8.0155e-07 - val_dense_100_loss: 5.4277e-07 - val_dense_101_loss: 2.5877e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5773e-07 - dense_100_loss: 6.6768e-07 - dense_101_loss: 2.9005e-07 - val_loss: 7.9564e-07 - val_dense_100_loss: 5.3295e-07 - val_dense_101_loss: 2.6270e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.4275e-07 - dense_100_loss: 6.5380e-07 - dense_101_loss: 2.8895e-07 - val_loss: 7.7956e-07 - val_dense_100_loss: 5.2310e-07 - val_dense_101_loss: 2.5647e-07\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2175e-07 - dense_100_loss: 6.3441e-07 - dense_101_loss: 2.8734e-07 - val_loss: 7.8807e-07 - val_dense_100_loss: 5.1602e-07 - val_dense_101_loss: 2.7206e-07\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.1045e-07 - dense_100_loss: 6.2039e-07 - dense_101_loss: 2.9006e-07 - val_loss: 7.7293e-07 - val_dense_100_loss: 5.0771e-07 - val_dense_101_loss: 2.6522e-07\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0071e-07 - dense_100_loss: 6.0960e-07 - dense_101_loss: 2.9111e-07 - val_loss: 7.5307e-07 - val_dense_100_loss: 4.8767e-07 - val_dense_101_loss: 2.6540e-07\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.6700e-07 - dense_100_loss: 5.8247e-07 - dense_101_loss: 2.8454e-07 - val_loss: 7.4293e-07 - val_dense_100_loss: 4.8398e-07 - val_dense_101_loss: 2.5895e-07\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.5322e-07 - dense_100_loss: 5.6957e-07 - dense_101_loss: 2.8366e-07 - val_loss: 6.9940e-07 - val_dense_100_loss: 4.4957e-07 - val_dense_101_loss: 2.4983e-07\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.3187e-07 - dense_100_loss: 5.4887e-07 - dense_101_loss: 2.8301e-07 - val_loss: 6.9045e-07 - val_dense_100_loss: 4.4026e-07 - val_dense_101_loss: 2.5019e-07\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.0354e-07 - dense_100_loss: 5.2490e-07 - dense_101_loss: 2.7864e-07 - val_loss: 6.7851e-07 - val_dense_100_loss: 4.2763e-07 - val_dense_101_loss: 2.5087e-07\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.9174e-07 - dense_100_loss: 5.1128e-07 - dense_101_loss: 2.8046e-07 - val_loss: 6.5931e-07 - val_dense_100_loss: 4.1347e-07 - val_dense_101_loss: 2.4584e-07\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.7244e-07 - dense_100_loss: 4.9345e-07 - dense_101_loss: 2.7899e-07 - val_loss: 6.6225e-07 - val_dense_100_loss: 4.0350e-07 - val_dense_101_loss: 2.5876e-07\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.5929e-07 - dense_100_loss: 4.7790e-07 - dense_101_loss: 2.8139e-07 - val_loss: 6.3824e-07 - val_dense_100_loss: 3.8837e-07 - val_dense_101_loss: 2.4986e-07\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.1812e-07 - dense_100_loss: 4.4890e-07 - dense_101_loss: 2.6922e-07 - val_loss: 6.0666e-07 - val_dense_100_loss: 3.6775e-07 - val_dense_101_loss: 2.3891e-07\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.9275e-07 - dense_100_loss: 4.2863e-07 - dense_101_loss: 2.6412e-07 - val_loss: 6.2003e-07 - val_dense_100_loss: 3.6597e-07 - val_dense_101_loss: 2.5406e-07\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.8605e-07 - dense_100_loss: 4.1416e-07 - dense_101_loss: 2.7189e-07 - val_loss: 5.8811e-07 - val_dense_100_loss: 3.4305e-07 - val_dense_101_loss: 2.4506e-07\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.6358e-07 - dense_100_loss: 3.9774e-07 - dense_101_loss: 2.6584e-07 - val_loss: 5.8595e-07 - val_dense_100_loss: 3.3940e-07 - val_dense_101_loss: 2.4654e-07\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.4590e-07 - dense_100_loss: 3.8235e-07 - dense_101_loss: 2.6355e-07 - val_loss: 5.5540e-07 - val_dense_100_loss: 3.1704e-07 - val_dense_101_loss: 2.3837e-07\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1663e-07 - dense_100_loss: 3.5970e-07 - dense_101_loss: 2.5693e-07 - val_loss: 5.3742e-07 - val_dense_100_loss: 3.0459e-07 - val_dense_101_loss: 2.3283e-07\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.8613e-07 - dense_100_loss: 3.3834e-07 - dense_101_loss: 2.4778e-07 - val_loss: 4.9920e-07 - val_dense_100_loss: 2.8046e-07 - val_dense_101_loss: 2.1875e-07\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.5863e-07 - dense_100_loss: 3.1992e-07 - dense_101_loss: 2.3871e-07 - val_loss: 4.9193e-07 - val_dense_100_loss: 2.6961e-07 - val_dense_101_loss: 2.2233e-07\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.3710e-07 - dense_100_loss: 3.0278e-07 - dense_101_loss: 2.3432e-07 - val_loss: 4.6912e-07 - val_dense_100_loss: 2.5797e-07 - val_dense_101_loss: 2.1114e-07\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.1759e-07 - dense_100_loss: 2.9068e-07 - dense_101_loss: 2.2691e-07 - val_loss: 4.6032e-07 - val_dense_100_loss: 2.5105e-07 - val_dense_101_loss: 2.0927e-07\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.0208e-07 - dense_100_loss: 2.7702e-07 - dense_101_loss: 2.2507e-07 - val_loss: 4.5373e-07 - val_dense_100_loss: 2.4390e-07 - val_dense_101_loss: 2.0983e-07\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.7610e-07 - dense_100_loss: 2.6076e-07 - dense_101_loss: 2.1534e-07 - val_loss: 4.2167e-07 - val_dense_100_loss: 2.2654e-07 - val_dense_101_loss: 1.9513e-07\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step - loss: 4.7064e-07 - dense_100_loss: 2.5288e-07 - dense_101_loss: 2.1776e-07 - val_loss: 4.6299e-07 - val_dense_100_loss: 2.4639e-07 - val_dense_101_loss: 2.1661e-07\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.6470e-07 - dense_100_loss: 2.4916e-07 - dense_101_loss: 2.1554e-07 - val_loss: 4.2268e-07 - val_dense_100_loss: 2.1982e-07 - val_dense_101_loss: 2.0286e-07\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.4507e-07 - dense_100_loss: 2.3448e-07 - dense_101_loss: 2.1060e-07 - val_loss: 4.1516e-07 - val_dense_100_loss: 2.1599e-07 - val_dense_101_loss: 1.9917e-07\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.3726e-07 - dense_100_loss: 2.2809e-07 - dense_101_loss: 2.0916e-07 - val_loss: 4.5583e-07 - val_dense_100_loss: 2.2830e-07 - val_dense_101_loss: 2.2753e-07\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.3005e-07 - dense_100_loss: 2.2376e-07 - dense_101_loss: 2.0629e-07 - val_loss: 4.3469e-07 - val_dense_100_loss: 2.1995e-07 - val_dense_101_loss: 2.1474e-07\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.3315e-07 - dense_100_loss: 2.2381e-07 - dense_101_loss: 2.0934e-07 - val_loss: 4.2713e-07 - val_dense_100_loss: 2.1309e-07 - val_dense_101_loss: 2.1404e-07\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.0782e-07 - dense_100_loss: 2.1010e-07 - dense_101_loss: 1.9773e-07 - val_loss: 3.6360e-07 - val_dense_100_loss: 1.8598e-07 - val_dense_101_loss: 1.7762e-07\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.8446e-07 - dense_100_loss: 1.9815e-07 - dense_101_loss: 1.8630e-07 - val_loss: 3.8903e-07 - val_dense_100_loss: 1.9701e-07 - val_dense_101_loss: 1.9202e-07\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.0624e-07 - dense_100_loss: 2.0470e-07 - dense_101_loss: 2.0154e-07 - val_loss: 3.6023e-07 - val_dense_100_loss: 1.8132e-07 - val_dense_101_loss: 1.7891e-07\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.7587e-07 - dense_100_loss: 1.9134e-07 - dense_101_loss: 1.8453e-07 - val_loss: 3.8181e-07 - val_dense_100_loss: 1.7924e-07 - val_dense_101_loss: 2.0257e-07\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.0221e-07 - dense_100_loss: 1.9951e-07 - dense_101_loss: 2.0271e-07 - val_loss: 3.5361e-07 - val_dense_100_loss: 1.8041e-07 - val_dense_101_loss: 1.7321e-07\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.5048e-07 - dense_100_loss: 1.7831e-07 - dense_101_loss: 1.7217e-07 - val_loss: 3.3555e-07 - val_dense_100_loss: 1.6780e-07 - val_dense_101_loss: 1.6774e-07\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.7655e-07 - dense_100_loss: 1.8945e-07 - dense_101_loss: 1.8710e-07 - val_loss: 3.7589e-07 - val_dense_100_loss: 1.8696e-07 - val_dense_101_loss: 1.8893e-07\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.7720e-07 - dense_100_loss: 1.8782e-07 - dense_101_loss: 1.8938e-07 - val_loss: 3.8884e-07 - val_dense_100_loss: 1.9228e-07 - val_dense_101_loss: 1.9656e-07\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.0831e-07 - dense_100_loss: 2.0473e-07 - dense_101_loss: 2.0357e-07 - val_loss: 3.6128e-07 - val_dense_100_loss: 1.7851e-07 - val_dense_101_loss: 1.8277e-07\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.6191e-07 - dense_100_loss: 1.8213e-07 - dense_101_loss: 1.7978e-07 - val_loss: 3.6184e-07 - val_dense_100_loss: 1.7597e-07 - val_dense_101_loss: 1.8587e-07\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.6803e-07 - dense_100_loss: 1.8388e-07 - dense_101_loss: 1.8415e-07 - val_loss: 3.2305e-07 - val_dense_100_loss: 1.6124e-07 - val_dense_101_loss: 1.6181e-07\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.7408e-07 - dense_100_loss: 1.8351e-07 - dense_101_loss: 1.9057e-07 - val_loss: 4.5836e-07 - val_dense_100_loss: 2.2006e-07 - val_dense_101_loss: 2.3830e-07\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.9109e-07 - dense_100_loss: 1.9246e-07 - dense_101_loss: 1.9863e-07 - val_loss: 3.2355e-07 - val_dense_100_loss: 1.6365e-07 - val_dense_101_loss: 1.5990e-07\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2897e-07 - dense_100_loss: 1.6585e-07 - dense_101_loss: 1.6313e-07 - val_loss: 3.4838e-07 - val_dense_100_loss: 1.7563e-07 - val_dense_101_loss: 1.7275e-07\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.4374e-07 - dense_100_loss: 1.7157e-07 - dense_101_loss: 1.7217e-07 - val_loss: 3.2726e-07 - val_dense_100_loss: 1.6600e-07 - val_dense_101_loss: 1.6126e-07\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.3371e-07 - dense_100_loss: 1.6677e-07 - dense_101_loss: 1.6694e-07 - val_loss: 3.6326e-07 - val_dense_100_loss: 1.7974e-07 - val_dense_101_loss: 1.8351e-07\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.4041e-07 - dense_100_loss: 1.6889e-07 - dense_101_loss: 1.7151e-07 - val_loss: 3.1859e-07 - val_dense_100_loss: 1.5905e-07 - val_dense_101_loss: 1.5954e-07\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.6037e-07 - dense_100_loss: 1.7998e-07 - dense_101_loss: 1.8039e-07 - val_loss: 3.8425e-07 - val_dense_100_loss: 1.8626e-07 - val_dense_101_loss: 1.9799e-07\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.3959e-07 - dense_100_loss: 1.6932e-07 - dense_101_loss: 1.7027e-07 - val_loss: 3.3399e-07 - val_dense_100_loss: 1.6493e-07 - val_dense_101_loss: 1.6906e-07\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.5885e-07 - dense_100_loss: 1.7720e-07 - dense_101_loss: 1.8165e-07 - val_loss: 4.2874e-07 - val_dense_100_loss: 1.9967e-07 - val_dense_101_loss: 2.2907e-07\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.4625e-07 - dense_100_loss: 1.7134e-07 - dense_101_loss: 1.7492e-07 - val_loss: 3.4177e-07 - val_dense_100_loss: 1.6723e-07 - val_dense_101_loss: 1.7455e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "\n",
      "Now training model 7/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 5.0811e-04 - dense_104_loss: 2.2397e-04 - dense_105_loss: 2.8414e-04 - val_loss: 1.0181e-04 - val_dense_104_loss: 4.3645e-05 - val_dense_105_loss: 5.8165e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.4290e-05 - dense_104_loss: 1.7765e-05 - dense_105_loss: 1.6525e-05 - val_loss: 9.2602e-06 - val_dense_104_loss: 4.6499e-06 - val_dense_105_loss: 4.6104e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.3202e-06 - dense_104_loss: 3.1127e-06 - dense_105_loss: 2.2075e-06 - val_loss: 2.3480e-06 - val_dense_104_loss: 1.5707e-06 - val_dense_105_loss: 7.7738e-07\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.0982e-06 - dense_104_loss: 1.5332e-06 - dense_105_loss: 5.6500e-07 - val_loss: 1.4124e-06 - val_dense_104_loss: 1.0476e-06 - val_dense_105_loss: 3.6476e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.6058e-06 - dense_104_loss: 1.2488e-06 - dense_105_loss: 3.5708e-07 - val_loss: 1.2191e-06 - val_dense_104_loss: 9.2338e-07 - val_dense_105_loss: 2.9569e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4911e-06 - dense_104_loss: 1.1711e-06 - dense_105_loss: 3.2000e-07 - val_loss: 1.1804e-06 - val_dense_104_loss: 8.9438e-07 - val_dense_105_loss: 2.8606e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4250e-06 - dense_104_loss: 1.1207e-06 - dense_105_loss: 3.0437e-07 - val_loss: 1.1289e-06 - val_dense_104_loss: 8.5526e-07 - val_dense_105_loss: 2.7361e-07\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3898e-06 - dense_104_loss: 1.0866e-06 - dense_105_loss: 3.0320e-07 - val_loss: 1.1163e-06 - val_dense_104_loss: 8.3577e-07 - val_dense_105_loss: 2.8053e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3517e-06 - dense_104_loss: 1.0505e-06 - dense_105_loss: 3.0117e-07 - val_loss: 1.0725e-06 - val_dense_104_loss: 8.0065e-07 - val_dense_105_loss: 2.7181e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3024e-06 - dense_104_loss: 1.0116e-06 - dense_105_loss: 2.9079e-07 - val_loss: 1.0340e-06 - val_dense_104_loss: 7.7218e-07 - val_dense_105_loss: 2.6185e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2763e-06 - dense_104_loss: 9.8555e-07 - dense_105_loss: 2.9079e-07 - val_loss: 1.0367e-06 - val_dense_104_loss: 7.6478e-07 - val_dense_105_loss: 2.7187e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2421e-06 - dense_104_loss: 9.5547e-07 - dense_105_loss: 2.8662e-07 - val_loss: 9.9824e-07 - val_dense_104_loss: 7.3691e-07 - val_dense_105_loss: 2.6133e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2116e-06 - dense_104_loss: 9.2818e-07 - dense_105_loss: 2.8345e-07 - val_loss: 9.8026e-07 - val_dense_104_loss: 7.1713e-07 - val_dense_105_loss: 2.6314e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2066e-06 - dense_104_loss: 9.1411e-07 - dense_105_loss: 2.9247e-07 - val_loss: 9.7478e-07 - val_dense_104_loss: 7.0838e-07 - val_dense_105_loss: 2.6640e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1838e-06 - dense_104_loss: 8.9125e-07 - dense_105_loss: 2.9258e-07 - val_loss: 9.5738e-07 - val_dense_104_loss: 6.9088e-07 - val_dense_105_loss: 2.6650e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1700e-06 - dense_104_loss: 8.7660e-07 - dense_105_loss: 2.9344e-07 - val_loss: 9.6356e-07 - val_dense_104_loss: 6.8554e-07 - val_dense_105_loss: 2.7802e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1450e-06 - dense_104_loss: 8.5162e-07 - dense_105_loss: 2.9340e-07 - val_loss: 9.2621e-07 - val_dense_104_loss: 6.5873e-07 - val_dense_105_loss: 2.6748e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1279e-06 - dense_104_loss: 8.3293e-07 - dense_105_loss: 2.9498e-07 - val_loss: 9.0933e-07 - val_dense_104_loss: 6.4317e-07 - val_dense_105_loss: 2.6616e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0990e-06 - dense_104_loss: 8.0642e-07 - dense_105_loss: 2.9259e-07 - val_loss: 8.8474e-07 - val_dense_104_loss: 6.2212e-07 - val_dense_105_loss: 2.6262e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0729e-06 - dense_104_loss: 7.8060e-07 - dense_105_loss: 2.9231e-07 - val_loss: 8.8012e-07 - val_dense_104_loss: 6.1324e-07 - val_dense_105_loss: 2.6688e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0652e-06 - dense_104_loss: 7.6827e-07 - dense_105_loss: 2.9690e-07 - val_loss: 8.5610e-07 - val_dense_104_loss: 5.9052e-07 - val_dense_105_loss: 2.6558e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0386e-06 - dense_104_loss: 7.4061e-07 - dense_105_loss: 2.9798e-07 - val_loss: 8.6882e-07 - val_dense_104_loss: 5.8700e-07 - val_dense_105_loss: 2.8183e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0132e-06 - dense_104_loss: 7.1449e-07 - dense_105_loss: 2.9867e-07 - val_loss: 8.2325e-07 - val_dense_104_loss: 5.5290e-07 - val_dense_105_loss: 2.7035e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.8484e-07 - dense_104_loss: 6.8549e-07 - dense_105_loss: 2.9935e-07 - val_loss: 8.0009e-07 - val_dense_104_loss: 5.3093e-07 - val_dense_105_loss: 2.6916e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5368e-07 - dense_104_loss: 6.5497e-07 - dense_105_loss: 2.9871e-07 - val_loss: 7.8076e-07 - val_dense_104_loss: 5.1402e-07 - val_dense_105_loss: 2.6674e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.3418e-07 - dense_104_loss: 6.3200e-07 - dense_105_loss: 3.0218e-07 - val_loss: 7.6816e-07 - val_dense_104_loss: 4.9383e-07 - val_dense_105_loss: 2.7433e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0992e-07 - dense_104_loss: 6.0545e-07 - dense_105_loss: 3.0447e-07 - val_loss: 7.3506e-07 - val_dense_104_loss: 4.6690e-07 - val_dense_105_loss: 2.6816e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.7640e-07 - dense_104_loss: 5.7307e-07 - dense_105_loss: 3.0332e-07 - val_loss: 7.3023e-07 - val_dense_104_loss: 4.5311e-07 - val_dense_105_loss: 2.7712e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.3416e-07 - dense_104_loss: 5.3690e-07 - dense_105_loss: 2.9726e-07 - val_loss: 7.0027e-07 - val_dense_104_loss: 4.2843e-07 - val_dense_105_loss: 2.7183e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.9180e-07 - dense_104_loss: 5.0008e-07 - dense_105_loss: 2.9172e-07 - val_loss: 6.6233e-07 - val_dense_104_loss: 3.9776e-07 - val_dense_105_loss: 2.6457e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.5703e-07 - dense_104_loss: 4.6887e-07 - dense_105_loss: 2.8817e-07 - val_loss: 6.2207e-07 - val_dense_104_loss: 3.6391e-07 - val_dense_105_loss: 2.5816e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.1657e-07 - dense_104_loss: 4.3336e-07 - dense_105_loss: 2.8320e-07 - val_loss: 5.9481e-07 - val_dense_104_loss: 3.4150e-07 - val_dense_105_loss: 2.5331e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.7288e-07 - dense_104_loss: 3.9773e-07 - dense_105_loss: 2.7515e-07 - val_loss: 5.6986e-07 - val_dense_104_loss: 3.1921e-07 - val_dense_105_loss: 2.5064e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.4404e-07 - dense_104_loss: 3.7228e-07 - dense_105_loss: 2.7176e-07 - val_loss: 5.3150e-07 - val_dense_104_loss: 2.9389e-07 - val_dense_105_loss: 2.3761e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.9275e-07 - dense_104_loss: 3.3355e-07 - dense_105_loss: 2.5920e-07 - val_loss: 5.2809e-07 - val_dense_104_loss: 2.8914e-07 - val_dense_105_loss: 2.3895e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.7027e-07 - dense_104_loss: 3.1431e-07 - dense_105_loss: 2.5596e-07 - val_loss: 4.8722e-07 - val_dense_104_loss: 2.5503e-07 - val_dense_105_loss: 2.3218e-07\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.2426e-07 - dense_104_loss: 2.8214e-07 - dense_105_loss: 2.4212e-07 - val_loss: 4.5230e-07 - val_dense_104_loss: 2.3240e-07 - val_dense_105_loss: 2.1990e-07\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.9566e-07 - dense_104_loss: 2.6110e-07 - dense_105_loss: 2.3457e-07 - val_loss: 4.3748e-07 - val_dense_104_loss: 2.2192e-07 - val_dense_105_loss: 2.1556e-07\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.6196e-07 - dense_104_loss: 2.3806e-07 - dense_105_loss: 2.2390e-07 - val_loss: 4.1754e-07 - val_dense_104_loss: 2.0583e-07 - val_dense_105_loss: 2.1171e-07\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.3788e-07 - dense_104_loss: 2.2109e-07 - dense_105_loss: 2.1679e-07 - val_loss: 4.0913e-07 - val_dense_104_loss: 1.9346e-07 - val_dense_105_loss: 2.1568e-07\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.2756e-07 - dense_104_loss: 2.1121e-07 - dense_105_loss: 2.1635e-07 - val_loss: 3.7965e-07 - val_dense_104_loss: 1.8409e-07 - val_dense_105_loss: 1.9557e-07\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.0184e-07 - dense_104_loss: 1.9534e-07 - dense_105_loss: 2.0650e-07 - val_loss: 3.7596e-07 - val_dense_104_loss: 1.7878e-07 - val_dense_105_loss: 1.9718e-07\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.9458e-07 - dense_104_loss: 1.9039e-07 - dense_105_loss: 2.0419e-07 - val_loss: 3.9397e-07 - val_dense_104_loss: 1.8988e-07 - val_dense_105_loss: 2.0409e-07\n",
      "Epoch 44/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 4ms/step - loss: 3.7808e-07 - dense_104_loss: 1.8068e-07 - dense_105_loss: 1.9740e-07 - val_loss: 4.0615e-07 - val_dense_104_loss: 1.8675e-07 - val_dense_105_loss: 2.1940e-07\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.6679e-07 - dense_104_loss: 1.7382e-07 - dense_105_loss: 1.9297e-07 - val_loss: 3.3279e-07 - val_dense_104_loss: 1.5603e-07 - val_dense_105_loss: 1.7676e-07\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.4168e-07 - dense_104_loss: 1.6142e-07 - dense_105_loss: 1.8026e-07 - val_loss: 3.2790e-07 - val_dense_104_loss: 1.5141e-07 - val_dense_105_loss: 1.7649e-07\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.4148e-07 - dense_104_loss: 1.6028e-07 - dense_105_loss: 1.8120e-07 - val_loss: 3.6964e-07 - val_dense_104_loss: 1.8359e-07 - val_dense_105_loss: 1.8605e-07\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.3092e-07 - dense_104_loss: 1.5637e-07 - dense_105_loss: 1.7455e-07 - val_loss: 3.1461e-07 - val_dense_104_loss: 1.4631e-07 - val_dense_105_loss: 1.6830e-07\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2252e-07 - dense_104_loss: 1.5066e-07 - dense_105_loss: 1.7186e-07 - val_loss: 3.1576e-07 - val_dense_104_loss: 1.4579e-07 - val_dense_105_loss: 1.6996e-07\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2770e-07 - dense_104_loss: 1.5339e-07 - dense_105_loss: 1.7431e-07 - val_loss: 3.7148e-07 - val_dense_104_loss: 1.7140e-07 - val_dense_105_loss: 2.0008e-07\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2690e-07 - dense_104_loss: 1.5145e-07 - dense_105_loss: 1.7545e-07 - val_loss: 3.1095e-07 - val_dense_104_loss: 1.4306e-07 - val_dense_105_loss: 1.6789e-07\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.0767e-07 - dense_104_loss: 1.4182e-07 - dense_105_loss: 1.6585e-07 - val_loss: 3.1029e-07 - val_dense_104_loss: 1.4288e-07 - val_dense_105_loss: 1.6741e-07\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2103e-07 - dense_104_loss: 1.5030e-07 - dense_105_loss: 1.7073e-07 - val_loss: 3.7948e-07 - val_dense_104_loss: 1.7411e-07 - val_dense_105_loss: 2.0537e-07\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2232e-07 - dense_104_loss: 1.4959e-07 - dense_105_loss: 1.7273e-07 - val_loss: 3.1188e-07 - val_dense_104_loss: 1.4170e-07 - val_dense_105_loss: 1.7018e-07\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.1867e-07 - dense_104_loss: 1.4915e-07 - dense_105_loss: 1.6953e-07 - val_loss: 3.2668e-07 - val_dense_104_loss: 1.4837e-07 - val_dense_105_loss: 1.7832e-07\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2234e-07 - dense_104_loss: 1.5062e-07 - dense_105_loss: 1.7172e-07 - val_loss: 3.1789e-07 - val_dense_104_loss: 1.4875e-07 - val_dense_105_loss: 1.6914e-07\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.1485e-07 - dense_104_loss: 1.4718e-07 - dense_105_loss: 1.6767e-07 - val_loss: 3.2942e-07 - val_dense_104_loss: 1.5437e-07 - val_dense_105_loss: 1.7504e-07\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.1372e-07 - dense_104_loss: 1.4666e-07 - dense_105_loss: 1.6706e-07 - val_loss: 2.9315e-07 - val_dense_104_loss: 1.3552e-07 - val_dense_105_loss: 1.5763e-07\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.1170e-07 - dense_104_loss: 1.4620e-07 - dense_105_loss: 1.6550e-07 - val_loss: 2.8626e-07 - val_dense_104_loss: 1.3164e-07 - val_dense_105_loss: 1.5463e-07\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.0053e-07 - dense_104_loss: 1.3994e-07 - dense_105_loss: 1.6058e-07 - val_loss: 3.2967e-07 - val_dense_104_loss: 1.5045e-07 - val_dense_105_loss: 1.7922e-07\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.0162e-07 - dense_104_loss: 1.4142e-07 - dense_105_loss: 1.6020e-07 - val_loss: 3.0755e-07 - val_dense_104_loss: 1.4076e-07 - val_dense_105_loss: 1.6679e-07\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.9167e-07 - dense_104_loss: 1.3601e-07 - dense_105_loss: 1.5566e-07 - val_loss: 2.9504e-07 - val_dense_104_loss: 1.3705e-07 - val_dense_105_loss: 1.5798e-07\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.0062e-07 - dense_104_loss: 1.3890e-07 - dense_105_loss: 1.6172e-07 - val_loss: 3.0877e-07 - val_dense_104_loss: 1.4258e-07 - val_dense_105_loss: 1.6619e-07\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.0141e-07 - dense_104_loss: 1.4098e-07 - dense_105_loss: 1.6043e-07 - val_loss: 3.1682e-07 - val_dense_104_loss: 1.4468e-07 - val_dense_105_loss: 1.7214e-07\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.0300e-07 - dense_104_loss: 1.4258e-07 - dense_105_loss: 1.6041e-07 - val_loss: 3.1770e-07 - val_dense_104_loss: 1.5129e-07 - val_dense_105_loss: 1.6641e-07\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.2984e-07 - dense_104_loss: 1.5528e-07 - dense_105_loss: 1.7456e-07 - val_loss: 3.1697e-07 - val_dense_104_loss: 1.4962e-07 - val_dense_105_loss: 1.6735e-07\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.1749e-07 - dense_104_loss: 1.5008e-07 - dense_105_loss: 1.6741e-07 - val_loss: 3.1900e-07 - val_dense_104_loss: 1.5050e-07 - val_dense_105_loss: 1.6850e-07\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.5964e-07 - dense_104_loss: 1.6738e-07 - dense_105_loss: 1.9226e-07 - val_loss: 3.7262e-07 - val_dense_104_loss: 1.7942e-07 - val_dense_105_loss: 1.9320e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "\n",
      "Now training model 8/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 3.9438e-04 - dense_108_loss: 1.7660e-04 - dense_109_loss: 2.1779e-04 - val_loss: 6.1883e-05 - val_dense_108_loss: 2.8196e-05 - val_dense_109_loss: 3.3687e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.2106e-05 - dense_108_loss: 1.0424e-05 - dense_109_loss: 1.1682e-05 - val_loss: 7.6428e-06 - val_dense_108_loss: 5.0685e-06 - val_dense_109_loss: 2.5743e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4.3792e-06 - dense_108_loss: 2.7720e-06 - dense_109_loss: 1.6072e-06 - val_loss: 1.7420e-06 - val_dense_108_loss: 1.0773e-06 - val_dense_109_loss: 6.6471e-07\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.6099e-06 - dense_108_loss: 1.1301e-06 - dense_109_loss: 4.7982e-07 - val_loss: 1.1254e-06 - val_dense_108_loss: 8.0059e-07 - val_dense_109_loss: 3.2482e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2847e-06 - dense_108_loss: 9.6105e-07 - dense_109_loss: 3.2363e-07 - val_loss: 1.0499e-06 - val_dense_108_loss: 7.5681e-07 - val_dense_109_loss: 2.9308e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2275e-06 - dense_108_loss: 9.2777e-07 - dense_109_loss: 2.9977e-07 - val_loss: 1.0147e-06 - val_dense_108_loss: 7.3587e-07 - val_dense_109_loss: 2.7880e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2159e-06 - dense_108_loss: 9.1866e-07 - dense_109_loss: 2.9724e-07 - val_loss: 1.0057e-06 - val_dense_108_loss: 7.2856e-07 - val_dense_109_loss: 2.7710e-07\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1882e-06 - dense_108_loss: 9.0145e-07 - dense_109_loss: 2.8671e-07 - val_loss: 9.7596e-07 - val_dense_108_loss: 7.1084e-07 - val_dense_109_loss: 2.6513e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1779e-06 - dense_108_loss: 8.9279e-07 - dense_109_loss: 2.8511e-07 - val_loss: 9.7661e-07 - val_dense_108_loss: 7.1112e-07 - val_dense_109_loss: 2.6549e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1621e-06 - dense_108_loss: 8.8130e-07 - dense_109_loss: 2.8078e-07 - val_loss: 9.6062e-07 - val_dense_108_loss: 6.9805e-07 - val_dense_109_loss: 2.6257e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1523e-06 - dense_108_loss: 8.7316e-07 - dense_109_loss: 2.7917e-07 - val_loss: 9.6837e-07 - val_dense_108_loss: 7.0380e-07 - val_dense_109_loss: 2.6458e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1459e-06 - dense_108_loss: 8.6715e-07 - dense_109_loss: 2.7870e-07 - val_loss: 9.5247e-07 - val_dense_108_loss: 6.8953e-07 - val_dense_109_loss: 2.6294e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1318e-06 - dense_108_loss: 8.5568e-07 - dense_109_loss: 2.7614e-07 - val_loss: 9.4658e-07 - val_dense_108_loss: 6.8498e-07 - val_dense_109_loss: 2.6160e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.1304e-06 - dense_108_loss: 8.5475e-07 - dense_109_loss: 2.7568e-07 - val_loss: 9.3742e-07 - val_dense_108_loss: 6.8121e-07 - val_dense_109_loss: 2.5621e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1254e-06 - dense_108_loss: 8.5049e-07 - dense_109_loss: 2.7489e-07 - val_loss: 9.3991e-07 - val_dense_108_loss: 6.8100e-07 - val_dense_109_loss: 2.5891e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1140e-06 - dense_108_loss: 8.4047e-07 - dense_109_loss: 2.7350e-07 - val_loss: 9.2736e-07 - val_dense_108_loss: 6.6861e-07 - val_dense_109_loss: 2.5875e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1048e-06 - dense_108_loss: 8.3168e-07 - dense_109_loss: 2.7315e-07 - val_loss: 9.1968e-07 - val_dense_108_loss: 6.6543e-07 - val_dense_109_loss: 2.5426e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1043e-06 - dense_108_loss: 8.3216e-07 - dense_109_loss: 2.7216e-07 - val_loss: 9.2284e-07 - val_dense_108_loss: 6.6879e-07 - val_dense_109_loss: 2.5405e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1040e-06 - dense_108_loss: 8.2875e-07 - dense_109_loss: 2.7522e-07 - val_loss: 9.5399e-07 - val_dense_108_loss: 6.8043e-07 - val_dense_109_loss: 2.7356e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1027e-06 - dense_108_loss: 8.2463e-07 - dense_109_loss: 2.7808e-07 - val_loss: 9.1399e-07 - val_dense_108_loss: 6.5476e-07 - val_dense_109_loss: 2.5923e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0870e-06 - dense_108_loss: 8.1392e-07 - dense_109_loss: 2.7310e-07 - val_loss: 9.0795e-07 - val_dense_108_loss: 6.5245e-07 - val_dense_109_loss: 2.5550e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0964e-06 - dense_108_loss: 8.1815e-07 - dense_109_loss: 2.7822e-07 - val_loss: 9.2787e-07 - val_dense_108_loss: 6.6019e-07 - val_dense_109_loss: 2.6768e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0889e-06 - dense_108_loss: 8.1148e-07 - dense_109_loss: 2.7746e-07 - val_loss: 9.0167e-07 - val_dense_108_loss: 6.4661e-07 - val_dense_109_loss: 2.5506e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0864e-06 - dense_108_loss: 8.0927e-07 - dense_109_loss: 2.7709e-07 - val_loss: 9.0564e-07 - val_dense_108_loss: 6.4640e-07 - val_dense_109_loss: 2.5924e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0819e-06 - dense_108_loss: 8.0509e-07 - dense_109_loss: 2.7678e-07 - val_loss: 9.1421e-07 - val_dense_108_loss: 6.5702e-07 - val_dense_109_loss: 2.5719e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0732e-06 - dense_108_loss: 7.9751e-07 - dense_109_loss: 2.7566e-07 - val_loss: 8.9507e-07 - val_dense_108_loss: 6.3801e-07 - val_dense_109_loss: 2.5707e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0709e-06 - dense_108_loss: 7.9592e-07 - dense_109_loss: 2.7499e-07 - val_loss: 8.8897e-07 - val_dense_108_loss: 6.3285e-07 - val_dense_109_loss: 2.5612e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0757e-06 - dense_108_loss: 7.9866e-07 - dense_109_loss: 2.7702e-07 - val_loss: 9.0518e-07 - val_dense_108_loss: 6.3624e-07 - val_dense_109_loss: 2.6894e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0675e-06 - dense_108_loss: 7.8817e-07 - dense_109_loss: 2.7935e-07 - val_loss: 8.9270e-07 - val_dense_108_loss: 6.3370e-07 - val_dense_109_loss: 2.5901e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0644e-06 - dense_108_loss: 7.8713e-07 - dense_109_loss: 2.7728e-07 - val_loss: 8.8463e-07 - val_dense_108_loss: 6.2886e-07 - val_dense_109_loss: 2.5577e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0657e-06 - dense_108_loss: 7.8594e-07 - dense_109_loss: 2.7974e-07 - val_loss: 8.8109e-07 - val_dense_108_loss: 6.2600e-07 - val_dense_109_loss: 2.5509e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0570e-06 - dense_108_loss: 7.7796e-07 - dense_109_loss: 2.7904e-07 - val_loss: 8.7838e-07 - val_dense_108_loss: 6.2230e-07 - val_dense_109_loss: 2.5608e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0440e-06 - dense_108_loss: 7.6775e-07 - dense_109_loss: 2.7626e-07 - val_loss: 8.7233e-07 - val_dense_108_loss: 6.1811e-07 - val_dense_109_loss: 2.5422e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0561e-06 - dense_108_loss: 7.7585e-07 - dense_109_loss: 2.8028e-07 - val_loss: 8.6825e-07 - val_dense_108_loss: 6.1025e-07 - val_dense_109_loss: 2.5800e-07\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0416e-06 - dense_108_loss: 7.6284e-07 - dense_109_loss: 2.7873e-07 - val_loss: 8.7290e-07 - val_dense_108_loss: 6.1329e-07 - val_dense_109_loss: 2.5961e-07\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0431e-06 - dense_108_loss: 7.6196e-07 - dense_109_loss: 2.8115e-07 - val_loss: 8.7402e-07 - val_dense_108_loss: 6.1054e-07 - val_dense_109_loss: 2.6348e-07\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0407e-06 - dense_108_loss: 7.5619e-07 - dense_109_loss: 2.8452e-07 - val_loss: 8.6219e-07 - val_dense_108_loss: 6.0326e-07 - val_dense_109_loss: 2.5893e-07\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0436e-06 - dense_108_loss: 7.5604e-07 - dense_109_loss: 2.8752e-07 - val_loss: 8.7203e-07 - val_dense_108_loss: 6.0979e-07 - val_dense_109_loss: 2.6225e-07\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0354e-06 - dense_108_loss: 7.5038e-07 - dense_109_loss: 2.8501e-07 - val_loss: 8.7615e-07 - val_dense_108_loss: 6.0652e-07 - val_dense_109_loss: 2.6963e-07\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0307e-06 - dense_108_loss: 7.4521e-07 - dense_109_loss: 2.8547e-07 - val_loss: 8.6400e-07 - val_dense_108_loss: 5.9533e-07 - val_dense_109_loss: 2.6867e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "\n",
      "Now training model 9/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 12ms/step - loss: 5.2757e-04 - dense_112_loss: 2.5700e-04 - dense_113_loss: 2.7058e-04 - val_loss: 1.1857e-04 - val_dense_112_loss: 6.0804e-05 - val_dense_113_loss: 5.7764e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.4333e-05 - dense_112_loss: 2.2890e-05 - dense_113_loss: 2.1443e-05 - val_loss: 8.0713e-06 - val_dense_112_loss: 3.9242e-06 - val_dense_113_loss: 4.1471e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.9976e-06 - dense_112_loss: 2.8290e-06 - dense_113_loss: 2.1686e-06 - val_loss: 2.6364e-06 - val_dense_112_loss: 1.5096e-06 - val_dense_113_loss: 1.1268e-06\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.0047e-06 - dense_112_loss: 1.2878e-06 - dense_113_loss: 7.1683e-07 - val_loss: 1.2085e-06 - val_dense_112_loss: 8.1825e-07 - val_dense_113_loss: 3.9026e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.3627e-06 - dense_112_loss: 9.7447e-07 - dense_113_loss: 3.8820e-07 - val_loss: 1.0611e-06 - val_dense_112_loss: 7.3623e-07 - val_dense_113_loss: 3.2483e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.2421e-06 - dense_112_loss: 9.0547e-07 - dense_113_loss: 3.3663e-07 - val_loss: 9.8778e-07 - val_dense_112_loss: 6.9302e-07 - val_dense_113_loss: 2.9475e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.1773e-06 - dense_112_loss: 8.6429e-07 - dense_113_loss: 3.1302e-07 - val_loss: 9.4326e-07 - val_dense_112_loss: 6.6461e-07 - val_dense_113_loss: 2.7865e-07\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1401e-06 - dense_112_loss: 8.3805e-07 - dense_113_loss: 3.0209e-07 - val_loss: 9.1505e-07 - val_dense_112_loss: 6.4442e-07 - val_dense_113_loss: 2.7062e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1146e-06 - dense_112_loss: 8.1780e-07 - dense_113_loss: 2.9684e-07 - val_loss: 9.0371e-07 - val_dense_112_loss: 6.3473e-07 - val_dense_113_loss: 2.6898e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0901e-06 - dense_112_loss: 8.0054e-07 - dense_113_loss: 2.8953e-07 - val_loss: 8.7794e-07 - val_dense_112_loss: 6.1706e-07 - val_dense_113_loss: 2.6088e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0725e-06 - dense_112_loss: 7.8455e-07 - dense_113_loss: 2.8799e-07 - val_loss: 8.8066e-07 - val_dense_112_loss: 6.1312e-07 - val_dense_113_loss: 2.6754e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0405e-06 - dense_112_loss: 7.6152e-07 - dense_113_loss: 2.7897e-07 - val_loss: 8.5500e-07 - val_dense_112_loss: 5.9772e-07 - val_dense_113_loss: 2.5729e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0362e-06 - dense_112_loss: 7.5649e-07 - dense_113_loss: 2.7967e-07 - val_loss: 8.3856e-07 - val_dense_112_loss: 5.8537e-07 - val_dense_113_loss: 2.5318e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0152e-06 - dense_112_loss: 7.4157e-07 - dense_113_loss: 2.7367e-07 - val_loss: 8.3197e-07 - val_dense_112_loss: 5.8081e-07 - val_dense_113_loss: 2.5116e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.9896e-07 - dense_112_loss: 7.2824e-07 - dense_113_loss: 2.7072e-07 - val_loss: 8.3575e-07 - val_dense_112_loss: 5.7931e-07 - val_dense_113_loss: 2.5644e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.9167e-07 - dense_112_loss: 7.2111e-07 - dense_113_loss: 2.7055e-07 - val_loss: 8.1732e-07 - val_dense_112_loss: 5.6700e-07 - val_dense_113_loss: 2.5032e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.8359e-07 - dense_112_loss: 7.1269e-07 - dense_113_loss: 2.7091e-07 - val_loss: 8.1494e-07 - val_dense_112_loss: 5.6483e-07 - val_dense_113_loss: 2.5011e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.7542e-07 - dense_112_loss: 7.0627e-07 - dense_113_loss: 2.6915e-07 - val_loss: 8.0852e-07 - val_dense_112_loss: 5.5861e-07 - val_dense_113_loss: 2.4990e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.7013e-07 - dense_112_loss: 7.0018e-07 - dense_113_loss: 2.6995e-07 - val_loss: 8.0728e-07 - val_dense_112_loss: 5.5718e-07 - val_dense_113_loss: 2.5010e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.6917e-07 - dense_112_loss: 6.9823e-07 - dense_113_loss: 2.7094e-07 - val_loss: 8.2062e-07 - val_dense_112_loss: 5.6030e-07 - val_dense_113_loss: 2.6032e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.6709e-07 - dense_112_loss: 6.9693e-07 - dense_113_loss: 2.7017e-07 - val_loss: 7.9705e-07 - val_dense_112_loss: 5.4920e-07 - val_dense_113_loss: 2.4785e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5856e-07 - dense_112_loss: 6.8766e-07 - dense_113_loss: 2.7090e-07 - val_loss: 7.9404e-07 - val_dense_112_loss: 5.4480e-07 - val_dense_113_loss: 2.4924e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.4683e-07 - dense_112_loss: 6.7994e-07 - dense_113_loss: 2.6689e-07 - val_loss: 7.8141e-07 - val_dense_112_loss: 5.3596e-07 - val_dense_113_loss: 2.4545e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.4193e-07 - dense_112_loss: 6.7514e-07 - dense_113_loss: 2.6678e-07 - val_loss: 7.8356e-07 - val_dense_112_loss: 5.3702e-07 - val_dense_113_loss: 2.4655e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.4502e-07 - dense_112_loss: 6.7409e-07 - dense_113_loss: 2.7093e-07 - val_loss: 7.8856e-07 - val_dense_112_loss: 5.4004e-07 - val_dense_113_loss: 2.4851e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5254e-07 - dense_112_loss: 6.7734e-07 - dense_113_loss: 2.7520e-07 - val_loss: 7.9580e-07 - val_dense_112_loss: 5.3710e-07 - val_dense_113_loss: 2.5870e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.3396e-07 - dense_112_loss: 6.6369e-07 - dense_113_loss: 2.7027e-07 - val_loss: 7.7536e-07 - val_dense_112_loss: 5.2905e-07 - val_dense_113_loss: 2.4631e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2231e-07 - dense_112_loss: 6.5697e-07 - dense_113_loss: 2.6534e-07 - val_loss: 7.6628e-07 - val_dense_112_loss: 5.2337e-07 - val_dense_113_loss: 2.4291e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.1762e-07 - dense_112_loss: 6.5180e-07 - dense_113_loss: 2.6582e-07 - val_loss: 7.7983e-07 - val_dense_112_loss: 5.2902e-07 - val_dense_113_loss: 2.5081e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2466e-07 - dense_112_loss: 6.5670e-07 - dense_113_loss: 2.6797e-07 - val_loss: 7.7225e-07 - val_dense_112_loss: 5.2744e-07 - val_dense_113_loss: 2.4482e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0938e-07 - dense_112_loss: 6.4449e-07 - dense_113_loss: 2.6490e-07 - val_loss: 7.6164e-07 - val_dense_112_loss: 5.1430e-07 - val_dense_113_loss: 2.4734e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.1932e-07 - dense_112_loss: 6.4831e-07 - dense_113_loss: 2.7101e-07 - val_loss: 7.6172e-07 - val_dense_112_loss: 5.1380e-07 - val_dense_113_loss: 2.4792e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.1086e-07 - dense_112_loss: 6.4116e-07 - dense_113_loss: 2.6970e-07 - val_loss: 7.6408e-07 - val_dense_112_loss: 5.1433e-07 - val_dense_113_loss: 2.4975e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "\n",
      "Now training model 10/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 12ms/step - loss: 4.2474e-04 - dense_116_loss: 1.6831e-04 - dense_117_loss: 2.5643e-04 - val_loss: 7.9273e-05 - val_dense_116_loss: 3.3597e-05 - val_dense_117_loss: 4.5676e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.0870e-05 - dense_116_loss: 1.4340e-05 - dense_117_loss: 1.6530e-05 - val_loss: 6.8367e-06 - val_dense_116_loss: 4.0931e-06 - val_dense_117_loss: 2.7436e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.2982e-06 - dense_116_loss: 2.6118e-06 - dense_117_loss: 1.6864e-06 - val_loss: 2.1850e-06 - val_dense_116_loss: 1.2837e-06 - val_dense_117_loss: 9.0129e-07\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.5581e-06 - dense_116_loss: 9.9247e-07 - dense_117_loss: 5.6568e-07 - val_loss: 1.1189e-06 - val_dense_116_loss: 7.1415e-07 - val_dense_117_loss: 4.0472e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1853e-06 - dense_116_loss: 8.0376e-07 - dense_117_loss: 3.8159e-07 - val_loss: 9.3329e-07 - val_dense_116_loss: 6.1965e-07 - val_dense_117_loss: 3.1365e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0965e-06 - dense_116_loss: 7.6156e-07 - dense_117_loss: 3.3498e-07 - val_loss: 9.1026e-07 - val_dense_116_loss: 6.0531e-07 - val_dense_117_loss: 3.0496e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0938e-06 - dense_116_loss: 7.5960e-07 - dense_117_loss: 3.3420e-07 - val_loss: 9.1263e-07 - val_dense_116_loss: 6.0785e-07 - val_dense_117_loss: 3.0478e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0717e-06 - dense_116_loss: 7.4706e-07 - dense_117_loss: 3.2465e-07 - val_loss: 9.0493e-07 - val_dense_116_loss: 5.9975e-07 - val_dense_117_loss: 3.0518e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0524e-06 - dense_116_loss: 7.3746e-07 - dense_117_loss: 3.1492e-07 - val_loss: 8.8069e-07 - val_dense_116_loss: 5.9150e-07 - val_dense_117_loss: 2.8919e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0189e-06 - dense_116_loss: 7.1907e-07 - dense_117_loss: 2.9980e-07 - val_loss: 8.5276e-07 - val_dense_116_loss: 5.7044e-07 - val_dense_117_loss: 2.8232e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0021e-06 - dense_116_loss: 7.0887e-07 - dense_117_loss: 2.9321e-07 - val_loss: 8.4891e-07 - val_dense_116_loss: 5.6904e-07 - val_dense_117_loss: 2.7988e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0075e-06 - dense_116_loss: 7.1317e-07 - dense_117_loss: 2.9430e-07 - val_loss: 8.4018e-07 - val_dense_116_loss: 5.6514e-07 - val_dense_117_loss: 2.7504e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.9061e-07 - dense_116_loss: 7.0382e-07 - dense_117_loss: 2.8679e-07 - val_loss: 8.2875e-07 - val_dense_116_loss: 5.5716e-07 - val_dense_117_loss: 2.7159e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.7123e-07 - dense_116_loss: 6.9029e-07 - dense_117_loss: 2.8094e-07 - val_loss: 8.1426e-07 - val_dense_116_loss: 5.5406e-07 - val_dense_117_loss: 2.6021e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.6036e-07 - dense_116_loss: 6.8394e-07 - dense_117_loss: 2.7642e-07 - val_loss: 8.0819e-07 - val_dense_116_loss: 5.4714e-07 - val_dense_117_loss: 2.6105e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5370e-07 - dense_116_loss: 6.7848e-07 - dense_117_loss: 2.7522e-07 - val_loss: 8.2741e-07 - val_dense_116_loss: 5.6120e-07 - val_dense_117_loss: 2.6621e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5608e-07 - dense_116_loss: 6.8004e-07 - dense_117_loss: 2.7604e-07 - val_loss: 8.1390e-07 - val_dense_116_loss: 5.4899e-07 - val_dense_117_loss: 2.6491e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5066e-07 - dense_116_loss: 6.7717e-07 - dense_117_loss: 2.7349e-07 - val_loss: 7.9440e-07 - val_dense_116_loss: 5.3717e-07 - val_dense_117_loss: 2.5723e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.3664e-07 - dense_116_loss: 6.6993e-07 - dense_117_loss: 2.6671e-07 - val_loss: 7.8409e-07 - val_dense_116_loss: 5.3333e-07 - val_dense_117_loss: 2.5076e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2624e-07 - dense_116_loss: 6.6270e-07 - dense_117_loss: 2.6354e-07 - val_loss: 7.8161e-07 - val_dense_116_loss: 5.2951e-07 - val_dense_117_loss: 2.5210e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2698e-07 - dense_116_loss: 6.6057e-07 - dense_117_loss: 2.6641e-07 - val_loss: 7.8237e-07 - val_dense_116_loss: 5.2777e-07 - val_dense_117_loss: 2.5459e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2133e-07 - dense_116_loss: 6.5769e-07 - dense_117_loss: 2.6363e-07 - val_loss: 7.8048e-07 - val_dense_116_loss: 5.3331e-07 - val_dense_117_loss: 2.4717e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2095e-07 - dense_116_loss: 6.5609e-07 - dense_117_loss: 2.6486e-07 - val_loss: 7.7950e-07 - val_dense_116_loss: 5.2673e-07 - val_dense_117_loss: 2.5277e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2240e-07 - dense_116_loss: 6.5759e-07 - dense_117_loss: 2.6481e-07 - val_loss: 7.7950e-07 - val_dense_116_loss: 5.2811e-07 - val_dense_117_loss: 2.5139e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0686e-07 - dense_116_loss: 6.4884e-07 - dense_117_loss: 2.5801e-07 - val_loss: 7.6253e-07 - val_dense_116_loss: 5.1765e-07 - val_dense_117_loss: 2.4488e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0541e-07 - dense_116_loss: 6.4424e-07 - dense_117_loss: 2.6116e-07 - val_loss: 7.6882e-07 - val_dense_116_loss: 5.2062e-07 - val_dense_117_loss: 2.4820e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.1301e-07 - dense_116_loss: 6.4792e-07 - dense_117_loss: 2.6509e-07 - val_loss: 7.6986e-07 - val_dense_116_loss: 5.2023e-07 - val_dense_117_loss: 2.4963e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.1218e-07 - dense_116_loss: 6.4382e-07 - dense_117_loss: 2.6836e-07 - val_loss: 7.6564e-07 - val_dense_116_loss: 5.1551e-07 - val_dense_117_loss: 2.5013e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.9331e-07 - dense_116_loss: 6.3433e-07 - dense_117_loss: 2.5898e-07 - val_loss: 7.6901e-07 - val_dense_116_loss: 5.2003e-07 - val_dense_117_loss: 2.4898e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.8725e-07 - dense_116_loss: 6.3067e-07 - dense_117_loss: 2.5658e-07 - val_loss: 7.5740e-07 - val_dense_116_loss: 5.1326e-07 - val_dense_117_loss: 2.4414e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.8990e-07 - dense_116_loss: 6.3098e-07 - dense_117_loss: 2.5892e-07 - val_loss: 7.4913e-07 - val_dense_116_loss: 5.0676e-07 - val_dense_117_loss: 2.4237e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.8436e-07 - dense_116_loss: 6.2717e-07 - dense_117_loss: 2.5720e-07 - val_loss: 7.4041e-07 - val_dense_116_loss: 5.0012e-07 - val_dense_117_loss: 2.4030e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.7756e-07 - dense_116_loss: 6.2264e-07 - dense_117_loss: 2.5492e-07 - val_loss: 7.4922e-07 - val_dense_116_loss: 5.0599e-07 - val_dense_117_loss: 2.4323e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "\n",
      "Now training model 11/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 4.7321e-04 - dense_120_loss: 2.5617e-04 - dense_121_loss: 2.1704e-04 - val_loss: 9.3865e-05 - val_dense_120_loss: 6.8350e-05 - val_dense_121_loss: 2.5515e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3.4875e-05 - dense_120_loss: 2.3762e-05 - dense_121_loss: 1.1113e-05 - val_loss: 6.4792e-06 - val_dense_120_loss: 3.4970e-06 - val_dense_121_loss: 2.9822e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.1526e-06 - dense_120_loss: 2.5376e-06 - dense_121_loss: 1.6150e-06 - val_loss: 2.3038e-06 - val_dense_120_loss: 1.3939e-06 - val_dense_121_loss: 9.0986e-07\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4891e-06 - dense_120_loss: 9.8663e-07 - dense_121_loss: 5.0244e-07 - val_loss: 9.4344e-07 - val_dense_120_loss: 6.2674e-07 - val_dense_121_loss: 3.1671e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0607e-06 - dense_120_loss: 7.4305e-07 - dense_121_loss: 3.1765e-07 - val_loss: 8.5681e-07 - val_dense_120_loss: 5.8073e-07 - val_dense_121_loss: 2.7608e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.9329e-07 - dense_120_loss: 7.0239e-07 - dense_121_loss: 2.9091e-07 - val_loss: 8.3504e-07 - val_dense_120_loss: 5.6666e-07 - val_dense_121_loss: 2.6838e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.8496e-07 - dense_120_loss: 6.9835e-07 - dense_121_loss: 2.8660e-07 - val_loss: 8.3469e-07 - val_dense_120_loss: 5.6456e-07 - val_dense_121_loss: 2.7013e-07\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.7356e-07 - dense_120_loss: 6.8982e-07 - dense_121_loss: 2.8374e-07 - val_loss: 8.2268e-07 - val_dense_120_loss: 5.5989e-07 - val_dense_121_loss: 2.6280e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.6295e-07 - dense_120_loss: 6.8493e-07 - dense_121_loss: 2.7803e-07 - val_loss: 8.1742e-07 - val_dense_120_loss: 5.5844e-07 - val_dense_121_loss: 2.5898e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5973e-07 - dense_120_loss: 6.8281e-07 - dense_121_loss: 2.7692e-07 - val_loss: 8.0066e-07 - val_dense_120_loss: 5.4697e-07 - val_dense_121_loss: 2.5369e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5192e-07 - dense_120_loss: 6.7826e-07 - dense_121_loss: 2.7366e-07 - val_loss: 8.0351e-07 - val_dense_120_loss: 5.4872e-07 - val_dense_121_loss: 2.5479e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.4682e-07 - dense_120_loss: 6.7443e-07 - dense_121_loss: 2.7239e-07 - val_loss: 7.9030e-07 - val_dense_120_loss: 5.3997e-07 - val_dense_121_loss: 2.5033e-07\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.3505e-07 - dense_120_loss: 6.6912e-07 - dense_121_loss: 2.6593e-07 - val_loss: 7.8625e-07 - val_dense_120_loss: 5.4199e-07 - val_dense_121_loss: 2.4426e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2917e-07 - dense_120_loss: 6.6545e-07 - dense_121_loss: 2.6372e-07 - val_loss: 7.7671e-07 - val_dense_120_loss: 5.3249e-07 - val_dense_121_loss: 2.4423e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2735e-07 - dense_120_loss: 6.6421e-07 - dense_121_loss: 2.6314e-07 - val_loss: 7.9083e-07 - val_dense_120_loss: 5.3914e-07 - val_dense_121_loss: 2.5169e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2485e-07 - dense_120_loss: 6.6081e-07 - dense_121_loss: 2.6404e-07 - val_loss: 7.8691e-07 - val_dense_120_loss: 5.3756e-07 - val_dense_121_loss: 2.4936e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2006e-07 - dense_120_loss: 6.5790e-07 - dense_121_loss: 2.6216e-07 - val_loss: 7.6634e-07 - val_dense_120_loss: 5.2582e-07 - val_dense_121_loss: 2.4052e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.1477e-07 - dense_120_loss: 6.5458e-07 - dense_121_loss: 2.6019e-07 - val_loss: 7.6939e-07 - val_dense_120_loss: 5.2757e-07 - val_dense_121_loss: 2.4182e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0379e-07 - dense_120_loss: 6.4675e-07 - dense_121_loss: 2.5704e-07 - val_loss: 7.6228e-07 - val_dense_120_loss: 5.2185e-07 - val_dense_121_loss: 2.4043e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0109e-07 - dense_120_loss: 6.4477e-07 - dense_121_loss: 2.5632e-07 - val_loss: 7.6659e-07 - val_dense_120_loss: 5.2284e-07 - val_dense_121_loss: 2.4376e-07\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0220e-07 - dense_120_loss: 6.4384e-07 - dense_121_loss: 2.5836e-07 - val_loss: 7.5735e-07 - val_dense_120_loss: 5.1935e-07 - val_dense_121_loss: 2.3800e-07\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0229e-07 - dense_120_loss: 6.4481e-07 - dense_121_loss: 2.5749e-07 - val_loss: 7.5840e-07 - val_dense_120_loss: 5.1649e-07 - val_dense_121_loss: 2.4190e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.9664e-07 - dense_120_loss: 6.3924e-07 - dense_121_loss: 2.5740e-07 - val_loss: 7.5324e-07 - val_dense_120_loss: 5.1387e-07 - val_dense_121_loss: 2.3938e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.8754e-07 - dense_120_loss: 6.3253e-07 - dense_121_loss: 2.5501e-07 - val_loss: 7.5003e-07 - val_dense_120_loss: 5.1142e-07 - val_dense_121_loss: 2.3861e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.8377e-07 - dense_120_loss: 6.2830e-07 - dense_121_loss: 2.5547e-07 - val_loss: 7.6454e-07 - val_dense_120_loss: 5.1993e-07 - val_dense_121_loss: 2.4460e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.8014e-07 - dense_120_loss: 6.2588e-07 - dense_121_loss: 2.5426e-07 - val_loss: 7.4994e-07 - val_dense_120_loss: 5.1130e-07 - val_dense_121_loss: 2.3864e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Now training model 12/12\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 34ms/step - loss: 0.0010 - dense_124_loss: 1.0906e-04 - dense_125_loss: 1.4752e-04 - dense_126_loss: 1.1775e-04 - dense_127_loss: 1.3819e-04 - dense_128_loss: 1.3188e-04 - dense_129_loss: 1.2480e-04 - dense_130_loss: 1.1006e-04 - dense_131_loss: 1.4664e-04 - val_loss: 1.1732e-04 - val_dense_124_loss: 1.3833e-05 - val_dense_125_loss: 1.7750e-05 - val_dense_126_loss: 1.5371e-05 - val_dense_127_loss: 1.2077e-05 - val_dense_128_loss: 1.3027e-05 - val_dense_129_loss: 1.4505e-05 - val_dense_130_loss: 1.3864e-05 - val_dense_131_loss: 1.6896e-05\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.1740e-05 - dense_124_loss: 7.4464e-06 - dense_125_loss: 6.8377e-06 - dense_126_loss: 6.2117e-06 - dense_127_loss: 5.5730e-06 - dense_128_loss: 7.2096e-06 - dense_129_loss: 5.7062e-06 - dense_130_loss: 5.6362e-06 - dense_131_loss: 7.1191e-06 - val_loss: 1.7157e-05 - val_dense_124_loss: 1.9847e-06 - val_dense_125_loss: 2.4249e-06 - val_dense_126_loss: 2.3775e-06 - val_dense_127_loss: 2.0215e-06 - val_dense_128_loss: 2.2806e-06 - val_dense_129_loss: 1.9623e-06 - val_dense_130_loss: 1.8594e-06 - val_dense_131_loss: 2.2464e-06\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 9.6439e-06 - dense_124_loss: 1.0460e-06 - dense_125_loss: 1.5119e-06 - dense_126_loss: 1.1329e-06 - dense_127_loss: 1.2016e-06 - dense_128_loss: 1.2669e-06 - dense_129_loss: 1.1515e-06 - dense_130_loss: 1.0823e-06 - dense_131_loss: 1.2509e-06 - val_loss: 4.9394e-06 - val_dense_124_loss: 4.5272e-07 - val_dense_125_loss: 9.0155e-07 - val_dense_126_loss: 4.5035e-07 - val_dense_127_loss: 7.0635e-07 - val_dense_128_loss: 6.2972e-07 - val_dense_129_loss: 6.1150e-07 - val_dense_130_loss: 5.8940e-07 - val_dense_131_loss: 5.9782e-07\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.5543e-06 - dense_124_loss: 3.7115e-07 - dense_125_loss: 8.5925e-07 - dense_126_loss: 4.0210e-07 - dense_127_loss: 6.6471e-07 - dense_128_loss: 5.3932e-07 - dense_129_loss: 6.0194e-07 - dense_130_loss: 5.4102e-07 - dense_131_loss: 5.7483e-07 - val_loss: 4.5462e-06 - val_dense_124_loss: 3.8301e-07 - val_dense_125_loss: 8.3714e-07 - val_dense_126_loss: 3.8215e-07 - val_dense_127_loss: 6.0131e-07 - val_dense_128_loss: 5.4263e-07 - val_dense_129_loss: 5.8755e-07 - val_dense_130_loss: 5.8878e-07 - val_dense_131_loss: 6.2364e-07\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.1522e-06 - dense_124_loss: 3.2444e-07 - dense_125_loss: 7.8365e-07 - dense_126_loss: 3.5700e-07 - dense_127_loss: 5.9919e-07 - dense_128_loss: 4.7012e-07 - dense_129_loss: 5.5004e-07 - dense_130_loss: 5.1813e-07 - dense_131_loss: 5.4960e-07 - val_loss: 3.8559e-06 - val_dense_124_loss: 3.0219e-07 - val_dense_125_loss: 7.1086e-07 - val_dense_126_loss: 3.0217e-07 - val_dense_127_loss: 5.5521e-07 - val_dense_128_loss: 4.4845e-07 - val_dense_129_loss: 5.2162e-07 - val_dense_130_loss: 4.8125e-07 - val_dense_131_loss: 5.3415e-07\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.6921e-06 - dense_124_loss: 4.1186e-07 - dense_125_loss: 8.4167e-07 - dense_126_loss: 4.1054e-07 - dense_127_loss: 6.6820e-07 - dense_128_loss: 5.4175e-07 - dense_129_loss: 6.1980e-07 - dense_130_loss: 5.8373e-07 - dense_131_loss: 6.1458e-07 - val_loss: 5.8683e-06 - val_dense_124_loss: 6.6252e-07 - val_dense_125_loss: 9.5047e-07 - val_dense_126_loss: 6.1156e-07 - val_dense_127_loss: 8.4880e-07 - val_dense_128_loss: 5.9346e-07 - val_dense_129_loss: 7.8309e-07 - val_dense_130_loss: 6.9554e-07 - val_dense_131_loss: 7.2288e-07\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 6.2305e-06 - dense_124_loss: 6.0152e-07 - dense_125_loss: 1.0604e-06 - dense_126_loss: 6.3672e-07 - dense_127_loss: 8.7034e-07 - dense_128_loss: 7.1880e-07 - dense_129_loss: 7.9858e-07 - dense_130_loss: 7.5348e-07 - dense_131_loss: 7.9063e-07 - val_loss: 5.8591e-06 - val_dense_124_loss: 6.4967e-07 - val_dense_125_loss: 8.5622e-07 - val_dense_126_loss: 5.6314e-07 - val_dense_127_loss: 7.5244e-07 - val_dense_128_loss: 5.7430e-07 - val_dense_129_loss: 8.9005e-07 - val_dense_130_loss: 7.9403e-07 - val_dense_131_loss: 7.7926e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9613e-06 - dense_124_loss: 5.9751e-07 - dense_125_loss: 9.7832e-07 - dense_126_loss: 5.6873e-07 - dense_127_loss: 8.1772e-07 - dense_128_loss: 6.7338e-07 - dense_129_loss: 8.1094e-07 - dense_130_loss: 7.5207e-07 - dense_131_loss: 7.6263e-07 - val_loss: 4.1594e-06 - val_dense_124_loss: 4.1379e-07 - val_dense_125_loss: 7.3645e-07 - val_dense_126_loss: 3.8330e-07 - val_dense_127_loss: 5.7277e-07 - val_dense_128_loss: 4.7733e-07 - val_dense_129_loss: 5.1009e-07 - val_dense_130_loss: 5.4922e-07 - val_dense_131_loss: 5.1644e-07\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 4.9052e-06 - dense_124_loss: 4.4602e-07 - dense_125_loss: 8.4043e-07 - dense_126_loss: 4.4412e-07 - dense_127_loss: 6.8278e-07 - dense_128_loss: 5.9188e-07 - dense_129_loss: 6.3140e-07 - dense_130_loss: 6.3571e-07 - dense_131_loss: 6.3288e-07 - val_loss: 4.5035e-06 - val_dense_124_loss: 4.0224e-07 - val_dense_125_loss: 7.5629e-07 - val_dense_126_loss: 3.9370e-07 - val_dense_127_loss: 6.7897e-07 - val_dense_128_loss: 5.0765e-07 - val_dense_129_loss: 6.2547e-07 - val_dense_130_loss: 5.7005e-07 - val_dense_131_loss: 5.6910e-07\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.9475e-06 - dense_124_loss: 6.4369e-07 - dense_125_loss: 1.1607e-06 - dense_126_loss: 7.1080e-07 - dense_127_loss: 9.6611e-07 - dense_128_loss: 8.5140e-07 - dense_129_loss: 8.6132e-07 - dense_130_loss: 8.9484e-07 - dense_131_loss: 8.5862e-07 - val_loss: 5.7621e-06 - val_dense_124_loss: 5.0875e-07 - val_dense_125_loss: 9.0730e-07 - val_dense_126_loss: 6.9220e-07 - val_dense_127_loss: 7.1585e-07 - val_dense_128_loss: 6.5847e-07 - val_dense_129_loss: 7.5185e-07 - val_dense_130_loss: 8.0815e-07 - val_dense_131_loss: 7.1948e-07\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.4327e-06 - dense_124_loss: 3.7499e-07 - dense_125_loss: 7.6289e-07 - dense_126_loss: 4.2202e-07 - dense_127_loss: 5.9215e-07 - dense_128_loss: 5.0701e-07 - dense_129_loss: 5.9034e-07 - dense_130_loss: 5.8549e-07 - dense_131_loss: 5.9777e-07 - val_loss: 3.8148e-06 - val_dense_124_loss: 2.9014e-07 - val_dense_125_loss: 6.4471e-07 - val_dense_126_loss: 3.3407e-07 - val_dense_127_loss: 5.4855e-07 - val_dense_128_loss: 4.4971e-07 - val_dense_129_loss: 5.2317e-07 - val_dense_130_loss: 5.2915e-07 - val_dense_131_loss: 4.9529e-07\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.5004e-06 - dense_124_loss: 3.9850e-07 - dense_125_loss: 7.5613e-07 - dense_126_loss: 4.0509e-07 - dense_127_loss: 6.3809e-07 - dense_128_loss: 5.2459e-07 - dense_129_loss: 6.0531e-07 - dense_130_loss: 5.7198e-07 - dense_131_loss: 6.0074e-07 - val_loss: 1.0860e-05 - val_dense_124_loss: 1.2752e-06 - val_dense_125_loss: 1.6941e-06 - val_dense_126_loss: 1.0899e-06 - val_dense_127_loss: 1.6481e-06 - val_dense_128_loss: 1.1422e-06 - val_dense_129_loss: 1.4328e-06 - val_dense_130_loss: 1.2541e-06 - val_dense_131_loss: 1.3232e-06\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0681e-05 - dense_124_loss: 1.3816e-06 - dense_125_loss: 1.5974e-06 - dense_126_loss: 1.0932e-06 - dense_127_loss: 1.5046e-06 - dense_128_loss: 1.1579e-06 - dense_129_loss: 1.3455e-06 - dense_130_loss: 1.2999e-06 - dense_131_loss: 1.3010e-06 - val_loss: 4.1390e-06 - val_dense_124_loss: 3.6145e-07 - val_dense_125_loss: 6.9162e-07 - val_dense_126_loss: 3.7450e-07 - val_dense_127_loss: 5.6777e-07 - val_dense_128_loss: 4.9656e-07 - val_dense_129_loss: 5.8958e-07 - val_dense_130_loss: 5.3379e-07 - val_dense_131_loss: 5.2378e-07\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.8370e-06 - dense_124_loss: 3.2432e-07 - dense_125_loss: 6.5996e-07 - dense_126_loss: 3.4051e-07 - dense_127_loss: 5.2684e-07 - dense_128_loss: 4.6578e-07 - dense_129_loss: 5.0440e-07 - dense_130_loss: 5.1527e-07 - dense_131_loss: 4.9990e-07 - val_loss: 3.2665e-06 - val_dense_124_loss: 2.4920e-07 - val_dense_125_loss: 5.6731e-07 - val_dense_126_loss: 2.8222e-07 - val_dense_127_loss: 4.3878e-07 - val_dense_128_loss: 4.1897e-07 - val_dense_129_loss: 4.3694e-07 - val_dense_130_loss: 4.4718e-07 - val_dense_131_loss: 4.2588e-07\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.3795e-06 - dense_124_loss: 3.6822e-07 - dense_125_loss: 7.2839e-07 - dense_126_loss: 4.1148e-07 - dense_127_loss: 5.8959e-07 - dense_128_loss: 5.2981e-07 - dense_129_loss: 5.9093e-07 - dense_130_loss: 5.7039e-07 - dense_131_loss: 5.9069e-07 - val_loss: 5.3476e-06 - val_dense_124_loss: 4.7814e-07 - val_dense_125_loss: 8.0917e-07 - val_dense_126_loss: 4.8370e-07 - val_dense_127_loss: 6.9574e-07 - val_dense_128_loss: 6.7390e-07 - val_dense_129_loss: 7.8191e-07 - val_dense_130_loss: 6.1462e-07 - val_dense_131_loss: 8.1047e-07\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.6112e-06 - dense_124_loss: 4.0123e-07 - dense_125_loss: 7.5266e-07 - dense_126_loss: 4.3446e-07 - dense_127_loss: 6.0848e-07 - dense_128_loss: 5.6996e-07 - dense_129_loss: 6.1346e-07 - dense_130_loss: 6.1743e-07 - dense_131_loss: 6.1346e-07 - val_loss: 6.4014e-06 - val_dense_124_loss: 7.5908e-07 - val_dense_125_loss: 9.4700e-07 - val_dense_126_loss: 6.3615e-07 - val_dense_127_loss: 8.4464e-07 - val_dense_128_loss: 8.3709e-07 - val_dense_129_loss: 8.0049e-07 - val_dense_130_loss: 7.5925e-07 - val_dense_131_loss: 8.1767e-07\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.5651e-06 - dense_124_loss: 5.1638e-07 - dense_125_loss: 9.0805e-07 - dense_126_loss: 5.6551e-07 - dense_127_loss: 7.7098e-07 - dense_128_loss: 6.9707e-07 - dense_129_loss: 7.1530e-07 - dense_130_loss: 6.9129e-07 - dense_131_loss: 7.0047e-07 - val_loss: 4.6925e-06 - val_dense_124_loss: 4.3865e-07 - val_dense_125_loss: 7.4766e-07 - val_dense_126_loss: 4.6639e-07 - val_dense_127_loss: 6.4243e-07 - val_dense_128_loss: 5.1462e-07 - val_dense_129_loss: 5.9737e-07 - val_dense_130_loss: 6.6902e-07 - val_dense_131_loss: 6.1632e-07\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.5592e-06 - dense_124_loss: 4.0600e-07 - dense_125_loss: 7.6550e-07 - dense_126_loss: 4.1631e-07 - dense_127_loss: 6.2456e-07 - dense_128_loss: 5.4224e-07 - dense_129_loss: 6.1024e-07 - dense_130_loss: 6.0901e-07 - dense_131_loss: 5.8534e-07 - val_loss: 4.5084e-06 - val_dense_124_loss: 4.2329e-07 - val_dense_125_loss: 7.2142e-07 - val_dense_126_loss: 4.5385e-07 - val_dense_127_loss: 5.8563e-07 - val_dense_128_loss: 5.7791e-07 - val_dense_129_loss: 5.7867e-07 - val_dense_130_loss: 6.1911e-07 - val_dense_131_loss: 5.4852e-07\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 4.7767e-06 - dense_124_loss: 4.2822e-07 - dense_125_loss: 7.6450e-07 - dense_126_loss: 4.7765e-07 - dense_127_loss: 6.2207e-07 - dense_128_loss: 5.6726e-07 - dense_129_loss: 6.1740e-07 - dense_130_loss: 6.4199e-07 - dense_131_loss: 6.5758e-07 - val_loss: 3.6653e-06 - val_dense_124_loss: 3.1348e-07 - val_dense_125_loss: 6.3851e-07 - val_dense_126_loss: 3.3750e-07 - val_dense_127_loss: 4.9367e-07 - val_dense_128_loss: 4.4909e-07 - val_dense_129_loss: 4.4947e-07 - val_dense_130_loss: 4.9506e-07 - val_dense_131_loss: 4.8852e-07\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.0796e-06 - dense_124_loss: 4.7740e-07 - dense_125_loss: 7.9731e-07 - dense_126_loss: 5.1460e-07 - dense_127_loss: 6.8303e-07 - dense_128_loss: 6.2183e-07 - dense_129_loss: 6.4071e-07 - dense_130_loss: 6.8173e-07 - dense_131_loss: 6.6301e-07 - val_loss: 9.0543e-06 - val_dense_124_loss: 1.1557e-06 - val_dense_125_loss: 1.3086e-06 - val_dense_126_loss: 9.2660e-07 - val_dense_127_loss: 1.2491e-06 - val_dense_128_loss: 1.0492e-06 - val_dense_129_loss: 9.9634e-07 - val_dense_130_loss: 1.3120e-06 - val_dense_131_loss: 1.0567e-06\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.8293e-06 - dense_124_loss: 7.4106e-07 - dense_125_loss: 1.0265e-06 - dense_126_loss: 6.7696e-07 - dense_127_loss: 9.5179e-07 - dense_128_loss: 8.3316e-07 - dense_129_loss: 8.1599e-07 - dense_130_loss: 9.2287e-07 - dense_131_loss: 8.6102e-07 - val_loss: 3.8848e-06 - val_dense_124_loss: 3.6520e-07 - val_dense_125_loss: 6.2986e-07 - val_dense_126_loss: 3.8108e-07 - val_dense_127_loss: 4.9723e-07 - val_dense_128_loss: 4.7713e-07 - val_dense_129_loss: 4.9897e-07 - val_dense_130_loss: 5.1560e-07 - val_dense_131_loss: 5.1969e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.1051e-06 - dense_124_loss: 3.7566e-07 - dense_125_loss: 6.7396e-07 - dense_126_loss: 3.7322e-07 - dense_127_loss: 5.4967e-07 - dense_128_loss: 5.1231e-07 - dense_129_loss: 5.4256e-07 - dense_130_loss: 5.4087e-07 - dense_131_loss: 5.3683e-07 - val_loss: 3.6936e-06 - val_dense_124_loss: 3.0474e-07 - val_dense_125_loss: 6.3608e-07 - val_dense_126_loss: 2.9554e-07 - val_dense_127_loss: 4.9471e-07 - val_dense_128_loss: 4.8225e-07 - val_dense_129_loss: 4.9054e-07 - val_dense_130_loss: 4.9876e-07 - val_dense_131_loss: 4.9098e-07\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.8760e-06 - dense_124_loss: 3.3960e-07 - dense_125_loss: 6.6273e-07 - dense_126_loss: 3.4961e-07 - dense_127_loss: 5.1988e-07 - dense_128_loss: 4.7497e-07 - dense_129_loss: 4.9074e-07 - dense_130_loss: 5.1507e-07 - dense_131_loss: 5.2335e-07 - val_loss: 3.3199e-06 - val_dense_124_loss: 2.8226e-07 - val_dense_125_loss: 5.6646e-07 - val_dense_126_loss: 2.9095e-07 - val_dense_127_loss: 4.4038e-07 - val_dense_128_loss: 4.1491e-07 - val_dense_129_loss: 4.3280e-07 - val_dense_130_loss: 4.6610e-07 - val_dense_131_loss: 4.2607e-07\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.2112e-06 - dense_124_loss: 3.8053e-07 - dense_125_loss: 6.9910e-07 - dense_126_loss: 4.0722e-07 - dense_127_loss: 5.7073e-07 - dense_128_loss: 4.8779e-07 - dense_129_loss: 5.6402e-07 - dense_130_loss: 5.8104e-07 - dense_131_loss: 5.2081e-07 - val_loss: 9.0165e-06 - val_dense_124_loss: 1.0277e-06 - val_dense_125_loss: 1.2989e-06 - val_dense_126_loss: 1.1454e-06 - val_dense_127_loss: 1.1813e-06 - val_dense_128_loss: 1.0622e-06 - val_dense_129_loss: 1.2217e-06 - val_dense_130_loss: 1.1933e-06 - val_dense_131_loss: 8.8605e-07\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 6.6096e-06 - dense_124_loss: 6.4722e-07 - dense_125_loss: 1.0540e-06 - dense_126_loss: 7.5362e-07 - dense_127_loss: 8.9430e-07 - dense_128_loss: 7.7085e-07 - dense_129_loss: 8.7796e-07 - dense_130_loss: 8.6846e-07 - dense_131_loss: 7.4313e-07 - val_loss: 5.8359e-06 - val_dense_124_loss: 5.9813e-07 - val_dense_125_loss: 8.6902e-07 - val_dense_126_loss: 6.3214e-07 - val_dense_127_loss: 9.1540e-07 - val_dense_128_loss: 7.4474e-07 - val_dense_129_loss: 7.0193e-07 - val_dense_130_loss: 6.7474e-07 - val_dense_131_loss: 6.9982e-07\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.6937e-06 - dense_124_loss: 4.5314e-07 - dense_125_loss: 7.1731e-07 - dense_126_loss: 4.7770e-07 - dense_127_loss: 6.1621e-07 - dense_128_loss: 5.7288e-07 - dense_129_loss: 6.2108e-07 - dense_130_loss: 6.3400e-07 - dense_131_loss: 6.0136e-07 - val_loss: 3.4599e-06 - val_dense_124_loss: 2.9728e-07 - val_dense_125_loss: 6.0644e-07 - val_dense_126_loss: 3.2460e-07 - val_dense_127_loss: 4.5838e-07 - val_dense_128_loss: 4.3350e-07 - val_dense_129_loss: 4.2718e-07 - val_dense_130_loss: 4.5951e-07 - val_dense_131_loss: 4.5302e-07\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.6264e-06 - dense_124_loss: 3.0412e-07 - dense_125_loss: 6.2183e-07 - dense_126_loss: 3.3053e-07 - dense_127_loss: 4.7505e-07 - dense_128_loss: 4.5930e-07 - dense_129_loss: 4.7267e-07 - dense_130_loss: 4.8723e-07 - dense_131_loss: 4.7570e-07 - val_loss: 3.5418e-06 - val_dense_124_loss: 3.4287e-07 - val_dense_125_loss: 5.9303e-07 - val_dense_126_loss: 3.0458e-07 - val_dense_127_loss: 4.8150e-07 - val_dense_128_loss: 4.5558e-07 - val_dense_129_loss: 4.4882e-07 - val_dense_130_loss: 4.6199e-07 - val_dense_131_loss: 4.5348e-07\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.6958e-06 - dense_124_loss: 3.2239e-07 - dense_125_loss: 6.2243e-07 - dense_126_loss: 3.2349e-07 - dense_127_loss: 5.1059e-07 - dense_128_loss: 4.5655e-07 - dense_129_loss: 4.7527e-07 - dense_130_loss: 4.9289e-07 - dense_131_loss: 4.9219e-07 - val_loss: 4.1207e-06 - val_dense_124_loss: 3.4546e-07 - val_dense_125_loss: 6.6864e-07 - val_dense_126_loss: 3.3736e-07 - val_dense_127_loss: 5.5260e-07 - val_dense_128_loss: 5.0149e-07 - val_dense_129_loss: 6.0598e-07 - val_dense_130_loss: 5.0056e-07 - val_dense_131_loss: 6.0859e-07\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.9962e-06 - dense_124_loss: 3.4441e-07 - dense_125_loss: 6.7638e-07 - dense_126_loss: 3.7056e-07 - dense_127_loss: 5.3589e-07 - dense_128_loss: 4.9048e-07 - dense_129_loss: 5.2707e-07 - dense_130_loss: 5.2040e-07 - dense_131_loss: 5.3097e-07 - val_loss: 4.8625e-06 - val_dense_124_loss: 4.5912e-07 - val_dense_125_loss: 7.6091e-07 - val_dense_126_loss: 5.1736e-07 - val_dense_127_loss: 6.3758e-07 - val_dense_128_loss: 6.8788e-07 - val_dense_129_loss: 6.3019e-07 - val_dense_130_loss: 5.7467e-07 - val_dense_131_loss: 5.9476e-07\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 6.0425e-06 - dense_124_loss: 5.8773e-07 - dense_125_loss: 9.5140e-07 - dense_126_loss: 6.1967e-07 - dense_127_loss: 7.4442e-07 - dense_128_loss: 8.3119e-07 - dense_129_loss: 7.5109e-07 - dense_130_loss: 7.8027e-07 - dense_131_loss: 7.7671e-07 - val_loss: 4.8244e-06 - val_dense_124_loss: 4.6395e-07 - val_dense_125_loss: 7.8425e-07 - val_dense_126_loss: 5.0026e-07 - val_dense_127_loss: 5.9127e-07 - val_dense_128_loss: 5.7312e-07 - val_dense_129_loss: 6.5811e-07 - val_dense_130_loss: 6.4535e-07 - val_dense_131_loss: 6.0809e-07\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.8843e-06 - dense_124_loss: 3.3865e-07 - dense_125_loss: 6.5575e-07 - dense_126_loss: 3.5963e-07 - dense_127_loss: 5.0416e-07 - dense_128_loss: 4.8742e-07 - dense_129_loss: 5.0268e-07 - dense_130_loss: 5.1864e-07 - dense_131_loss: 5.1737e-07 - val_loss: 4.3207e-06 - val_dense_124_loss: 3.3263e-07 - val_dense_125_loss: 7.0665e-07 - val_dense_126_loss: 4.4923e-07 - val_dense_127_loss: 5.2263e-07 - val_dense_128_loss: 5.6585e-07 - val_dense_129_loss: 5.9066e-07 - val_dense_130_loss: 5.4444e-07 - val_dense_131_loss: 6.0858e-07\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 4.0847e-06 - dense_124_loss: 3.6125e-07 - dense_125_loss: 6.5782e-07 - dense_126_loss: 3.8982e-07 - dense_127_loss: 5.5776e-07 - dense_128_loss: 5.2749e-07 - dense_129_loss: 5.2842e-07 - dense_130_loss: 5.3834e-07 - dense_131_loss: 5.2377e-07 - val_loss: 5.2846e-06 - val_dense_124_loss: 5.3556e-07 - val_dense_125_loss: 7.3117e-07 - val_dense_126_loss: 5.7429e-07 - val_dense_127_loss: 7.5273e-07 - val_dense_128_loss: 6.4893e-07 - val_dense_129_loss: 7.1698e-07 - val_dense_130_loss: 6.5807e-07 - val_dense_131_loss: 6.6684e-07\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.4484e-06 - dense_124_loss: 4.2927e-07 - dense_125_loss: 6.8315e-07 - dense_126_loss: 4.3862e-07 - dense_127_loss: 5.5907e-07 - dense_128_loss: 5.8129e-07 - dense_129_loss: 5.9344e-07 - dense_130_loss: 5.9300e-07 - dense_131_loss: 5.7057e-07 - val_loss: 3.8117e-06 - val_dense_124_loss: 3.6778e-07 - val_dense_125_loss: 6.1518e-07 - val_dense_126_loss: 3.6082e-07 - val_dense_127_loss: 4.7941e-07 - val_dense_128_loss: 4.6285e-07 - val_dense_129_loss: 5.1055e-07 - val_dense_130_loss: 4.9236e-07 - val_dense_131_loss: 5.2271e-07\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 4.3441e-06 - dense_124_loss: 4.0602e-07 - dense_125_loss: 6.7328e-07 - dense_126_loss: 4.2678e-07 - dense_127_loss: 5.6822e-07 - dense_128_loss: 5.3929e-07 - dense_129_loss: 5.5023e-07 - dense_130_loss: 5.8462e-07 - dense_131_loss: 5.9564e-07 - val_loss: 7.0627e-06 - val_dense_124_loss: 7.5533e-07 - val_dense_125_loss: 1.0230e-06 - val_dense_126_loss: 7.5061e-07 - val_dense_127_loss: 9.1135e-07 - val_dense_128_loss: 8.1483e-07 - val_dense_129_loss: 9.2227e-07 - val_dense_130_loss: 8.7331e-07 - val_dense_131_loss: 1.0120e-06\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "88.42196615599096\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders)\n",
    "stop = time.perf_counter()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1167afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        print('evaluating model for '+histgroup[0])\n",
    "        print(histstruct.evaluate_classifier(histgroup)[0].shape)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    print('Found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "            thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "            mse_good.append( thismse )\n",
    "            print(run)\n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    print('Found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        print('Found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f34546ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model for NormalizedHitResiduals_TIB__Layer__1\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_1\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_2\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_3\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_4\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+1\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-1\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+2\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-2\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+3\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-3\n",
      "(2831,)\n",
      "evaluating model for NormalizedHitResiduals_TOB__Layer__1\n",
      "(2831,)\n",
      "Found mse array for training set of following shape: (1651, 44)\n",
      "Found mse array for good set of following shape: (1509, 44)\n",
      "Found mse array for bad set of following shape: (43, 44)\n",
      "Found mse array for bad set of following shape: (34, 44)\n",
      "Found mse array for bad set of following shape: (45, 44)\n",
      "Found mse array for bad set of following shape: (8, 44)\n",
      "Found mse array for bad set of following shape: (21, 44)\n",
      "Found mse array for bad set of following shape: (28, 44)\n",
      "Found mse array for bad set of following shape: (12, 44)\n",
      "Found mse array for bad set of following shape: (32, 44)\n"
     ]
    }
   ],
   "source": [
    "(mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7105b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct, mse_train):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    #for dims in dimslist:\n",
    "    #    thismse = mse_train[:,dims]\n",
    "    #    if training_mode=='global': \n",
    "    #        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "    #        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "    #        #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "    #        #                                                    'up')\n",
    "    #    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    #    #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "    #    #                onlycontour=False, xlims=30, ylims=30, \n",
    "    #    #                onlypositive=True, transparency=0.5,\n",
    "    #    #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "    #    #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "    #    #                title='density fit of lumisection MSE')\n",
    "    #    ##plt.close('all') # release plot memory\n",
    "    #    fitfunclist.append(fitfunc)\n",
    "    # \n",
    "    #    \n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "    else: \n",
    "        fitfunc = GaussianKdeFitter.GaussianKdeFitter()\n",
    "        fitfunc.fit(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4988fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = fit_mse_distribution(histstruct, mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7437c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    print('--- good lumesections ---')\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    print('length of log prob array: '+str(len(logprob_good)))\n",
    "    print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "    #print(sorted(logprob_good))\n",
    "    \n",
    "    print('--- bad lumisections ---')\n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "    \n",
    "    print('length of log prob array: '+str(len(logprob_bad)))\n",
    "    print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "    #print(sorted(logprob_good))\n",
    "    #print(sorted(logprob_bad))\n",
    "    #print(logprob_bad)\n",
    "    \n",
    "    return [logprob_good, logprob_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a8ed5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- good lumesections ---\n",
      "length of log prob array: 1509\n",
      "minimum of log prob: 446.4882232220617\n",
      "--- bad lumisections ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22600/688802665.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of log prob array: 223\n",
      "maximum of log prob: 461.5070628433653\n"
     ]
    }
   ],
   "source": [
    "(logprob_good, logprob_bad) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09b777c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoder_individual(histstruct):\n",
    "    \n",
    "    msewps = []\n",
    "    for histname in histstruct.histnames:\n",
    "        \n",
    "        # Get histograms from histstruct\n",
    "        X_test_good = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'good']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        X_test_bad = X_test_bad = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'bad']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        # Get each model from the histstruct\n",
    "        autoencoder = histstruct.get_classifier(histname)\n",
    "        \n",
    "        # Getting evaluation criteria\n",
    "        prediction_test_good = autoencoder.reconstruct(X_test_good)\n",
    "        mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "        prediction_test_bad = autoencoder.reconstruct(X_test_bad)\n",
    "        mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "        \n",
    "        if userfriendly:\n",
    "            print('Average MSE on good set: ' + str(np.mean(mse_test_good)))\n",
    "            print('Average MSE on bad set: ' + str(np.mean(mse_test_bad)))\n",
    "        \n",
    "        if createPlots:\n",
    "            # Number of plots of each type to generate per model (so nplot * 2 * len(model))\n",
    "            nplot = 3\n",
    "            \n",
    "            # Good examples\n",
    "            print('Examples of good histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "            for i in randint: \n",
    "                histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "            \n",
    "            # Bad examples\n",
    "            print('Examples of bad histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "            for i in randint:\n",
    "                histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "        \n",
    "        # Attaching the bad histograms as a new set of rows under the good histograms\n",
    "        validation_data = np.vstack((X_test_good, X_test_bad))\n",
    "        validation_preds = np.vstack((prediction_test_good, prediction_test_bad))\n",
    "        # Creating labels to differentiate the data when we go to compare predictions\n",
    "        #     with actual label\n",
    "        labels = np.hstack((np.zeros(len(X_test_good)), np.ones(len(X_test_bad))))\n",
    "        \n",
    "        # Pick a working point to see \n",
    "        msewp = 0.5*(np.mean(mse_test_bad) - np.mean(mse_test_good))\n",
    "        print(\"Selected working point: \" + str(msewp))\n",
    "        \n",
    "        # Get data to pick a good working point for future evaluation\n",
    "        scores = aeu.mseTop10Raw(validation_data, validation_preds)\n",
    "        nsig = np.sum(labels)\n",
    "        nback = np.sum(1-labels)\n",
    "        \n",
    "        # Get some metrics for the user\n",
    "        tp = np.sum(np.where((labels==1) & (scores>msewp),1,0))/nsig\n",
    "        fp = np.sum(np.where((labels==0) & (scores>msewp),1,0))/nback\n",
    "        tn = 1-fp\n",
    "        fn = 1-tp\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2*precision*recall) / (precision + recall)\n",
    "        \n",
    "        if userfriendly:\n",
    "            print(accuracy)\n",
    "            print(precision)\n",
    "            print(recall)\n",
    "            print(f1)\n",
    "        \n",
    "    return msewps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "891a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad, biasFactor):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    badMin = min(np.where(logprob_bad != -np.inf, logprob_bad, np.inf))\n",
    "    goodMax = max(np.where(logprob_good != np.inf, logprob_good, -np.inf))\n",
    "    \n",
    "    # Getting rid of infinities\n",
    "    logprob_good[logprob_good > 500] = goodMax\n",
    "    logprob_bad[logprob_bad < 0] = badMin\n",
    "    # These only take effect if a histogram is grossly misclassified\n",
    "    logprob_good[logprob_good < badMin] = badMin\n",
    "    logprob_bad[logprob_bad > goodMax] = goodMax\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                       bcklabel='good', bckcolor='g', \n",
    "                       nbins=200, normalize=True,\n",
    "                       xaxtitle='negative logarithmic probability',\n",
    "                       yaxtitle='number of lumisections (normalized)')\n",
    "      \n",
    "    # Plot ROC curve for analysis\n",
    "    auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    # Average is biased towards better recall per user specifications\n",
    "    logprob_threshold = (1/(wpBiasFactor + 1)) * (wpBiasFactor*np.mean(logprob_good) + np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "    # logprob_threshold = 424\n",
    "    (_, _, _, tp, fp, tn, fn) = aeu.get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    print('Selected logprob threshold of ' + str(logprob_threshold))\n",
    "    \n",
    "    # Get metrics for analysis\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = (1 + fmBiasFactor * fmBiasFactor) * ((precision * recall) / ((fmBiasFactor * fmBiasFactor * precision) + recall)) \n",
    "    \n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('F-Measure: ' + str(f_measure))\n",
    "    \n",
    "    return logprob_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bbddf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected logprob threshold of 452.9219947622614\n",
      "Accuracy: 0.9772471300745601\n",
      "Precision: 0.9993066782738466\n",
      "Recall: 0.9551569506726457\n",
      "F-Measure: 0.9636720258468713\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logprob_threshold = evaluate_autoencoders_combined(logprob_good, logprob_bad, biasFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4e3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "356f7ddc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
