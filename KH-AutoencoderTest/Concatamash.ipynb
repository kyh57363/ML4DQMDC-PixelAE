{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba412492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import SubHistStruct\n",
    "importlib.reload(SubHistStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed Controls and Run Mode\n",
    "\n",
    "# Disables all plots for large datasets where speed is more important\n",
    "createPlots = False\n",
    "\n",
    "# Control for the notebook - turn off user-friendly mode to enable faster runtimes\n",
    "userfriendly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2020c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation Parameters\n",
    "\n",
    "# Select the bias towards recall against precision, treated as a factor (so < 1 biases towards precision, 1 is equal importance, and > 1 biases towards recall)\n",
    "biasFactor = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4590f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = '../data/'\n",
    "\n",
    "# Select a list of good runs to train on in development training_mode\n",
    "# Should be validated by eye\n",
    "trainrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                   \"297598\":[[-1]],\n",
    "#                   \"297604\":[[-1]],   # A decently clean histogram\n",
    "                   \"297620\":[[-1]],   # A decently clean histogram\n",
    "                   \"297659\":[[-1]],   # An okay histogram\n",
    "                   \"297670\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                   \"299065\":[[-1]],   # A decently clean histogram\n",
    "                   \"299067\":[[-1]],   # A decently clean histogram\n",
    "                   \"299096\":[[-1]],\n",
    "                   \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "#                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "                   '2017C': {\n",
    "                      \"299370\":[[-1]],\n",
    "                      \"299394\":[[-1]],\n",
    "                      \"299420\":[[-1]],\n",
    "                      \"299477\":[[-1]],\n",
    "                      \"299593\":[[-1]],\n",
    "                      \"299597\":[[-1]],\n",
    "                      \"299617\":[[-1]],\n",
    "                      \"300018\":[[-1]],\n",
    "                      \"300105\":[[-1]],\n",
    "                      \"300117\":[[-1]],\n",
    "                      \"300124\":[[-1]],\n",
    "                      \"300234\":[[-1]],\n",
    "                      \"300237\":[[-1]],\n",
    "                      \"300240\":[[-1]],\n",
    "                      \"300370\":[[-1]],\n",
    "                      \"300157\":[[-1]],\n",
    "                      \"300373\":[[-1]],\n",
    "                      \"300392\":[[-1]],\n",
    "                      \"300395\":[[-1]],\n",
    "                      \"300401\":[[-1]],\n",
    "                      \"300462\":[[-1]],\n",
    "                      \"300466\":[[-1]],\n",
    "                      \"300514\":[[-1]],\n",
    "                      \"300517\":[[-1]],\n",
    "                      \"300538\":[[-1]],\n",
    "                      \"300539\":[[-1]],\n",
    "                      \"300364\":[[-1]],\n",
    "                 },'2017F':{\n",
    "                      \"305310\":[[-1]],\n",
    "                      \"305040\":[[-1]],\n",
    "                      \"305043\":[[-1]],\n",
    "                      \"305185\":[[-1]],\n",
    "                      \"305204\":[[-1]],\n",
    "                      \"305234\":[[-1]],\n",
    "                      \"305247\":[[-1]],\n",
    "                      \"305313\":[[-1]],\n",
    "                      \"305338\":[[-1]],\n",
    "                      \"305350\":[[-1]],\n",
    "                      \"305364\":[[-1]],\n",
    "                      \"305376\":[[-1]],\n",
    "                      \"306042\":[[-1]],\n",
    "                      \"306051\":[[-1]],\n",
    "                      \"305406\":[[-1]],\n",
    "                      \"306122\":[[-1]],\n",
    "                      \"306134\":[[-1]],\n",
    "                      \"306137\":[[-1]],\n",
    "                      \"306154\":[[-1]],\n",
    "                      \"306170\":[[-1]],\n",
    "                      \"306417\":[[-1]],\n",
    "                      \"306432\":[[-1]],\n",
    "                      \"306456\":[[-1]],\n",
    "                      \"305516\":[[-1]],\n",
    "                      \"305586\":[[-1]],\n",
    "                      \"305588\":[[-1]],\n",
    "                      \"305590\":[[-1]],\n",
    "                      \"305809\":[[-1]],\n",
    "                      \"305832\":[[-1]],\n",
    "                      \"305840\":[[-1]],\n",
    "                      \"305898\":[[-1]],\n",
    "                      \"306029\":[[-1]],\n",
    "                      \"306037\":[[-1]],\n",
    "                      \"306095\":[[-1]],\n",
    "                },\n",
    "                '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "# Select a list of good runs to test on in development training_mode\n",
    "# Should be validated by eye\n",
    "goodrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                    \"297598\":[[-1]],\n",
    "#                    \"297604\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297620\":[[-1]],   # A decently clean histogram\n",
    "                    \"297659\":[[-1]],   # An okay histogram\n",
    "                    \"297670\":[[-1]],   # A decently clean histogram\n",
    "                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                    \"299065\":[[-1]],   # A decently clean histogram\n",
    "                    \"299067\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299096\":[[-1]],\n",
    "#                    \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "                '2017C':{\n",
    "                      \"299370\":[[-1]],\n",
    "                      \"299394\":[[-1]],\n",
    "                      \"299420\":[[-1]],\n",
    "                      \"299477\":[[-1]],\n",
    "                      \"299593\":[[-1]],\n",
    "                      \"299597\":[[-1]],\n",
    "                      \"299617\":[[-1]],\n",
    "                      \"300018\":[[-1]],\n",
    "                      \"300105\":[[-1]],\n",
    "                      \"300117\":[[-1]],\n",
    "                      \"300124\":[[-1]],\n",
    "                      \"300234\":[[-1]],\n",
    "                      \"300237\":[[-1]],\n",
    "                      \"300240\":[[-1]],\n",
    "                      \"300370\":[[-1]],\n",
    "                      \"300157\":[[-1]],\n",
    "                      \"300373\":[[-1]],\n",
    "                      \"300392\":[[-1]],\n",
    "                      \"300395\":[[-1]],\n",
    "                      \"300401\":[[-1]],\n",
    "                      \"300462\":[[-1]],\n",
    "                      \"300466\":[[-1]],\n",
    "                      \"300514\":[[-1]],\n",
    "                      \"300517\":[[-1]],\n",
    "                      \"300538\":[[-1]],\n",
    "                      \"300539\":[[-1]],\n",
    "                      \"300364\":[[-1]],\n",
    "                },'2017F':{\n",
    "                      \"305310\":[[-1]],\n",
    "                      \"305040\":[[-1]],\n",
    "                      \"305043\":[[-1]],\n",
    "                      \"305185\":[[-1]],\n",
    "                      \"305204\":[[-1]],\n",
    "                      \"305234\":[[-1]],\n",
    "                      \"305247\":[[-1]],\n",
    "                      \"305313\":[[-1]],\n",
    "                      \"305338\":[[-1]],\n",
    "                      \"305350\":[[-1]],\n",
    "                      \"305364\":[[-1]],\n",
    "                      \"305376\":[[-1]],\n",
    "                      \"306042\":[[-1]],\n",
    "                      \"306051\":[[-1]],\n",
    "                      \"305406\":[[-1]],\n",
    "                      \"306122\":[[-1]],\n",
    "                      \"306134\":[[-1]],\n",
    "                      \"306137\":[[-1]],\n",
    "                      \"306154\":[[-1]],\n",
    "                      \"306170\":[[-1]],\n",
    "                      \"306417\":[[-1]],\n",
    "                      \"306432\":[[-1]],\n",
    "                      \"306456\":[[-1]],\n",
    "                      \"305516\":[[-1]],\n",
    "                      \"305586\":[[-1]],\n",
    "                      \"305588\":[[-1]],\n",
    "                      \"305590\":[[-1]],\n",
    "                      \"305809\":[[-1]],\n",
    "                      \"305832\":[[-1]],\n",
    "                      \"305840\":[[-1]],\n",
    "                      \"305898\":[[-1]],\n",
    "                      \"306029\":[[-1]],\n",
    "                      \"306037\":[[-1]],\n",
    "                      \"306095\":[[-1]],\n",
    "                },\n",
    "                '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "\n",
    "badrunsls = {'2017B':\n",
    "                {\n",
    "                    #\"297048\":[[-1]],\n",
    "                    #\"297282\":[[-1]],\n",
    "                    #\"297283\":[[-1]],\n",
    "                    #\"297284\":[[-1]],\n",
    "                    #\"297287\":[[-1]],\n",
    "                    #\"297288\":[[-1]],\n",
    "                    #\"297289\":[[-1]],\n",
    "                    \"299316\":[[-1]],\n",
    "                    \"299317\":[[-1]],\n",
    "                    \"299318\":[[-1]],\n",
    "                    \"299324\":[[-1]],\n",
    "                    \"299326\":[[-1]],\n",
    "                    #\"301086\":[[88,126]],\n",
    "                    #\"301086\":[[89,89]],\n",
    "                    #\"303948\":[[1710,1710]],\n",
    "                    \"297047\":[[-1]], #close but, true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297211\":[[-1]], #Reconstructs well\n",
    "#                   \"299325\":[[-1]], #Reconstructs well\n",
    "                    \"297664\":[[-1]], #true bad for all 8\n",
    "                    \"299317\":[[-1]], #true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297502\":[[-1]]\n",
    "                },\n",
    "             '2017C':{\n",
    "#                 \"300781\":[[-1]], # bad for tracking (pixels were excluded.\n",
    "                 \"300079\":[[-1]], # is bad for strips and then also for tracking\n",
    "#                 \"302029\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good \n",
    "#                 \"300576\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"300574\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"300282\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"301912\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "#                 \"301086\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "#                 \"300283\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300282\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "#                 \"300281\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "#                 \"300239\":[[-1]], # Half bad for pixels (lost HV or readout card)\n",
    "#                 \"301394\":[[-1]], # Marginal for pixels\n",
    "#                 \"301183\":[[-1]], # Marginal for pixels\n",
    "                 \"300398\":[[-1]], # Marginal for pixels\n",
    "                 \"300389\":[[-1]], # Marginal for pixels\n",
    "#                 \"300365\":[[-1]]  # Marginal for pixels\n",
    "              },\n",
    "             '2017E':{\n",
    "                 \"304740\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304776\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304506\":[[-1]], # Portcard problem for pixels\n",
    "                 \"304507\":[[-1]], # Portcard problem for pixels \n",
    "                 \"303989\":[[-1]], # Bad for pixels, power supply died\n",
    "                 \"303824\":[[-1]]  # Partly bad for strips due to a test\n",
    "             },\n",
    "             '2017F':{\n",
    "                 \"306422\":[[-1]], # Partly bad for strips - 2 data readouts failed \n",
    "#                 \"306423\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "#                 \"306425\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "#                 \"305440\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "#                 \"305441\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "                 \"305249\":[[-1]], # Bad for pixels - half of disk failed \n",
    "                 \"305250\":[[-1]], # Bad for pixels - half of disk failed\n",
    "#                 \"305064\":[[-1]], # Marginal for pixels - some readout failed\n",
    "             },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "\n",
    "# The year and era being used\n",
    "year = '2017'\n",
    "era = 'B'\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = [\n",
    "    ['NormalizedHitResiduals_TIB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1', 'NormalizedHitResiduals_TIB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2',\n",
    "     'NormalizedHitResiduals_TIB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3' , 'NormalizedHitResiduals_TIB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4'],\n",
    "    ['chargeInner_PXLayer_1', 'chargeOuter_PXLayer_1', 'adc_PXLayer_1'],\n",
    "    ['chargeInner_PXLayer_2', 'chargeOuter_PXLayer_2', 'adc_PXLayer_2'],\n",
    "    ['chargeInner_PXLayer_3', 'chargeOuter_PXLayer_3', 'adc_PXLayer_3'],\n",
    "    ['chargeInner_PXLayer_4', 'chargeOuter_PXLayer_4', 'adc_PXLayer_4'],\n",
    "    ['charge_PXDisk_+1', 'adc_PXDisk_+1'],\n",
    "    ['charge_PXDisk_-1', 'adc_PXDisk_-1'],\n",
    "    ['charge_PXDisk_+2', 'adc_PXDisk_+2'],\n",
    "    ['charge_PXDisk_-2', 'adc_PXDisk_-2'],\n",
    "    ['charge_PXDisk_+3', 'adc_PXDisk_+3'],\n",
    "    ['charge_PXDisk_-3', 'adc_PXDisk_-3'],\n",
    "    ['NormalizedHitResiduals_TOB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__1', 'NormalizedHitResiduals_TOB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__2',\n",
    "     'NormalizedHitResiduals_TOB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__3' , 'NormalizedHitResiduals_TOB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__4']\n",
    "]\n",
    "\n",
    "# Read new data or use previously saved data & should data be saved\n",
    "readnew = True\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ffebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Set whether to train globally or locally or in a development/testing mode\n",
    "training_mode = 'development'\n",
    "\n",
    "# Selects whether to create a new histstruct or use a saved one\n",
    "readnew = True\n",
    "\n",
    "# Select whether to save a new histstruct\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6394238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames\n",
    "\n",
    "# Evaluate models seperately, as an ensemble, both, or neither\n",
    "individualEval = True\n",
    "ensembleEval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4051dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected runs/lumisections for training: \n",
      "{'297175': [[-1]], '297620': [[-1]], '297659': [[-1]], '297670': [[-1]], '299065': [[-1]], '299067': [[-1]], '299096': [[-1]], '299149': [[-1]]}\n",
      "selected runs/lumisections as good test set:\n",
      "{'297175': [[-1]], '297659': [[-1]], '297670': [[-1]], '297674': [[-1]], '297722': [[-1]], '299065': [[-1]], '299067': [[-1]], '299185': [[-1]], '299327': [[-1]], '299480': [[-1]]}\n",
      "selected runs/lumisections as bad test set:\n",
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n"
     ]
    }
   ],
   "source": [
    "### Define Training Mode Parameters - Combined Autoencoder\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use averages of training set)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    # - this only works for a single era\n",
    "    \n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+era+'_'+histnames[0][0]+'.csv') ) )\n",
    "    # Cherry picked really bad run\n",
    "    run_application = 299316\n",
    "    #run_application = 299317\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5\n",
    "        offset = 0 # normal case: offset = 0 (just use 5 previous runs)\n",
    "        \n",
    "        # Selects the 5 previous runs for training\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    #runsls_bad = badrunsls[year]\n",
    "    #runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_good = runsls_training\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)\n",
    "        \n",
    "elif training_mode == 'development':\n",
    "    # train on a user-defined subset of runs\n",
    "    \n",
    "    # Select runs to be used in training from the user-defined list\n",
    "    runsls_training = trainrunsls[year + era]\n",
    "    # Select bad runs to test on in the user-defined list\n",
    "    runsls_bad = badrunsls[year + era]\n",
    "    # Select good runs to test on in the user-defined list\n",
    "    runsls_good = goodrunsls[year + era]\n",
    "    \n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54180f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Classifiers cleared to preserve consistency\n",
      "Adding NormalizedHitResiduals_TIB__Layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4...\n",
      "Adding chargeInner_PXLayer_1...\n",
      "Adding chargeOuter_PXLayer_1...\n",
      "Adding adc_PXLayer_1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_2...\n",
      "Adding chargeOuter_PXLayer_2...\n",
      "Adding adc_PXLayer_2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_3...\n",
      "Adding chargeOuter_PXLayer_3...\n",
      "Adding adc_PXLayer_3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_4...\n",
      "Adding chargeOuter_PXLayer_4...\n",
      "Adding adc_PXLayer_4...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+1...\n",
      "Adding adc_PXDisk_+1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-1...\n",
      "Adding adc_PXDisk_-1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+2...\n",
      "Adding adc_PXDisk_+2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-2...\n",
      "Adding adc_PXDisk_-2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+3...\n",
      "Adding adc_PXDisk_+3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-3...\n",
      "Adding adc_PXDisk_-3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding NormalizedHitResiduals_TOB__Layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4...\n",
      "Found 2831 histograms\n",
      "Created a histstruct with the following properties:\n",
      "- number of histogram types: 40\n",
      "- number of lumisections: 2831\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "\n",
    "# Create a new HistStruct from the data\n",
    "if readnew:\n",
    "    # Initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = SubHistStruct.SubHistStruct()\n",
    "    histstruct.reset_histlist(histnames)\n",
    "    \n",
    "    # Unpack histnames and add every histogram individually\n",
    "    for histnamegroup in histnames:\n",
    "        for histname in histnamegroup:\n",
    "            print('Adding {}...'.format(histname))\n",
    "            \n",
    "            # Bring the histograms into memory from storage for later use\n",
    "            filename = datadir + year + era + '/DF' + year + era + '_' + histname + '.csv'\n",
    "            df = dloader.get_dataframe_from_file( filename )\n",
    "            \n",
    "            # In case of local training, we can remove most of the histograms\n",
    "            if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "                runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "                df = dfu.select_runsls( df, runsls_total )\n",
    "                \n",
    "            # Store the data in the histstruct object managing this whole thing\n",
    "            histstruct.add_dataframe( df, rebinningfactor = 3 )\n",
    "        \n",
    "    print('Found {} histograms'.format(len(histstruct.runnbs)))\n",
    "\n",
    "# Load a previously saved HistStruct\n",
    "else:\n",
    "    # Load histstruct from storage\n",
    "    histstruct = HistStruct.HistStruct.load('test.pk1')\n",
    "    \n",
    "    # Count of bad runs, presumably for later use\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "if userfriendly:\n",
    "    print('Created a histstruct with the following properties:')\n",
    "    print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "    print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45931fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n",
      "Assigned masks: ['dcson', 'golden', 'highstat', 'lowstat', 'training', 'good', 'bad', 'bad0', 'bad1', 'bad2', 'bad3', 'bad4', 'bad5', 'bad6', 'bad7']\n"
     ]
    }
   ],
   "source": [
    "### Add Masks to Data\n",
    "\n",
    "if readnew:\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat' )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=100 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        print(runsls_bad)\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    if save:\n",
    "        histstruct.save('test.pk1')\n",
    "if userfriendly: print('Assigned masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30d6a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the input data for analysis\n",
    "\n",
    "if((training_mode=='local' or training_mode == 'development') and createPlots):\n",
    "\n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )\n",
    "    \n",
    "elif( training_mode=='global' and createPlots):\n",
    "    \n",
    "    # bad test runs\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "                                labellist = ['typical good histograms','bad'],\n",
    "                                colorlist = ['blue','red'],\n",
    "                                transparencylist = [0.01,1.]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dc93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_concatamash_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            if userfriendly:\n",
    "                print('\\nNow Defining model {}/'.format(i + 1) \n",
    "                      + str(len(histnames)))\n",
    "                print(' - Size of training set: {}'.format(X_train.shape))\n",
    "            \n",
    "            # Half the total bin count\n",
    "            arch = 51 * len(histnamegroup)\n",
    "            \n",
    "            ## Model parameters\n",
    "            print(X_train.shape)\n",
    "            \n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(arch * 2, activation=\"tanh\")(conc_layer)\n",
    "            #encoder = Dense(128, activation='relu')(encoder)\n",
    "            #\n",
    "            #encoder = Dense(32, activation='relu')(encoder)\n",
    "            \n",
    "            decoder = Dense(arch, activation=\"relu\")(encoder)\n",
    "            #decoder = Dense(256, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoder.summary()\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c76ea4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now Defining model 1/12\n",
      " - Size of training set: (1006, 8, 34)\n",
      "(1006, 8, 34)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_66 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_67 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_68 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_69 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_70 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_71 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_72 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 272)          0           input_65[0][0]                   \n",
      "                                                                 input_66[0][0]                   \n",
      "                                                                 input_67[0][0]                   \n",
      "                                                                 input_68[0][0]                   \n",
      "                                                                 input_69[0][0]                   \n",
      "                                                                 input_70[0][0]                   \n",
      "                                                                 input_71[0][0]                   \n",
      "                                                                 input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 816)          222768      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 408)          333336      dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 34)           13906       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 34)           13906       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 34)           13906       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 34)           13906       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 34)           13906       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 34)           13906       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 34)           13906       dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 34)           13906       dense_98[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 667,352\n",
      "Trainable params: 667,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 2/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_73 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_74 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_75 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 102)          0           input_73[0][0]                   \n",
      "                                                                 input_74[0][0]                   \n",
      "                                                                 input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 306)          31518       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 153)          46971       dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 34)           5236        dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 34)           5236        dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 34)           5236        dense_108[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 94,197\n",
      "Trainable params: 94,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 3/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_76 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_77 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 102)          0           input_76[0][0]                   \n",
      "                                                                 input_77[0][0]                   \n",
      "                                                                 input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 306)          31518       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 153)          46971       dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 34)           5236        dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 34)           5236        dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 34)           5236        dense_113[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 94,197\n",
      "Trainable params: 94,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 4/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_79 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_81 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 102)          0           input_79[0][0]                   \n",
      "                                                                 input_80[0][0]                   \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 306)          31518       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 153)          46971       dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 34)           5236        dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 34)           5236        dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 34)           5236        dense_118[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 94,197\n",
      "Trainable params: 94,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 5/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_82 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_83 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 102)          0           input_82[0][0]                   \n",
      "                                                                 input_83[0][0]                   \n",
      "                                                                 input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 306)          31518       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 153)          46971       dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 34)           5236        dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_125 (Dense)               (None, 34)           5236        dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 34)           5236        dense_123[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 94,197\n",
      "Trainable params: 94,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 6/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_85 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_86 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 68)           0           input_85[0][0]                   \n",
      "                                                                 input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 204)          14076       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_128 (Dense)               (None, 102)          20910       dense_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 34)           3502        dense_128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 34)           3502        dense_128[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,990\n",
      "Trainable params: 41,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 7/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_87 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_88 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 68)           0           input_87[0][0]                   \n",
      "                                                                 input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 204)          14076       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 102)          20910       dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 34)           3502        dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 34)           3502        dense_132[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,990\n",
      "Trainable params: 41,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 8/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_89 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_90 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 68)           0           input_89[0][0]                   \n",
      "                                                                 input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 204)          14076       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_136 (Dense)               (None, 102)          20910       dense_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 34)           3502        dense_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 34)           3502        dense_136[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,990\n",
      "Trainable params: 41,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 9/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_91 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_92 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 68)           0           input_91[0][0]                   \n",
      "                                                                 input_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 204)          14076       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 102)          20910       dense_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 34)           3502        dense_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 34)           3502        dense_140[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,990\n",
      "Trainable params: 41,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 10/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_93 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_94 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 68)           0           input_93[0][0]                   \n",
      "                                                                 input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_143 (Dense)               (None, 204)          14076       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 102)          20910       dense_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 34)           3502        dense_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_146 (Dense)               (None, 34)           3502        dense_144[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,990\n",
      "Trainable params: 41,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 11/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_95 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_96 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 68)           0           input_95[0][0]                   \n",
      "                                                                 input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_147 (Dense)               (None, 204)          14076       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 102)          20910       dense_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 34)           3502        dense_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 34)           3502        dense_148[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,990\n",
      "Trainable params: 41,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 12/12\n",
      " - Size of training set: (1006, 8, 34)\n",
      "(1006, 8, 34)\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_97 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_98 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_99 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_100 (InputLayer)          [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_101 (InputLayer)          [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_102 (InputLayer)          [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_103 (InputLayer)          [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_104 (InputLayer)          [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 272)          0           input_97[0][0]                   \n",
      "                                                                 input_98[0][0]                   \n",
      "                                                                 input_99[0][0]                   \n",
      "                                                                 input_100[0][0]                  \n",
      "                                                                 input_101[0][0]                  \n",
      "                                                                 input_102[0][0]                  \n",
      "                                                                 input_103[0][0]                  \n",
      "                                                                 input_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 816)          222768      concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 408)          333336      dense_151[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_153 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 34)           13906       dense_152[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 667,352\n",
      "Trainable params: 667,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(histslist, vallist, autoencoders, train_normhist) = define_concatamash_autoencoder(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a44e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders):\n",
    "    \n",
    "    # Iterate through the training data to train corresponding autoencoders\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        if userfriendly: print('\\nNow training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 500\n",
    "        batch_size = 50\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                            epochs=nb_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                            verbose=1,\n",
    "                            callbacks= [earlystop],    \n",
    "                            )\n",
    "        \n",
    "        # Create a plot of the model\n",
    "        \n",
    "        tf.keras.utils.plot_model(\n",
    "            autoencoder,\n",
    "            to_file=\"models/modelConcatamash{}.png\".format(i),\n",
    "            show_shapes=True,\n",
    "            show_dtype=False,\n",
    "            show_layer_names=False,\n",
    "            rankdir=\"TB\")\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52397fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now training model 1/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 2s 23ms/step - loss: 7.7848e-04 - dense_99_loss: 1.0051e-04 - dense_100_loss: 9.9550e-05 - dense_101_loss: 1.1147e-04 - dense_102_loss: 9.1561e-05 - dense_103_loss: 9.1641e-05 - dense_104_loss: 9.7742e-05 - dense_105_loss: 9.0888e-05 - dense_106_loss: 9.5123e-05 - val_loss: 1.6482e-04 - val_dense_99_loss: 2.0207e-05 - val_dense_100_loss: 2.6196e-05 - val_dense_101_loss: 1.4375e-05 - val_dense_102_loss: 3.4918e-05 - val_dense_103_loss: 1.9823e-05 - val_dense_104_loss: 2.0088e-05 - val_dense_105_loss: 1.6580e-05 - val_dense_106_loss: 1.2638e-05\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9044e-05 - dense_99_loss: 7.7916e-06 - dense_100_loss: 1.0513e-05 - dense_101_loss: 7.0906e-06 - dense_102_loss: 9.6417e-06 - dense_103_loss: 8.6378e-06 - dense_104_loss: 9.6944e-06 - dense_105_loss: 7.6311e-06 - dense_106_loss: 8.0435e-06 - val_loss: 2.3462e-05 - val_dense_99_loss: 2.2142e-06 - val_dense_100_loss: 5.0332e-06 - val_dense_101_loss: 2.1513e-06 - val_dense_102_loss: 3.0737e-06 - val_dense_103_loss: 2.7017e-06 - val_dense_104_loss: 2.7777e-06 - val_dense_105_loss: 3.2079e-06 - val_dense_106_loss: 2.3027e-06\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7634e-05 - dense_99_loss: 1.7132e-06 - dense_100_loss: 4.1659e-06 - dense_101_loss: 1.4717e-06 - dense_102_loss: 2.5612e-06 - dense_103_loss: 1.8371e-06 - dense_104_loss: 2.0515e-06 - dense_105_loss: 2.0462e-06 - dense_106_loss: 1.7875e-06 - val_loss: 1.2001e-05 - val_dense_99_loss: 8.9038e-07 - val_dense_100_loss: 3.2039e-06 - val_dense_101_loss: 7.0508e-07 - val_dense_102_loss: 1.8235e-06 - val_dense_103_loss: 1.2862e-06 - val_dense_104_loss: 1.4089e-06 - val_dense_105_loss: 1.3358e-06 - val_dense_106_loss: 1.3470e-06\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1393e-05 - dense_99_loss: 8.3166e-07 - dense_100_loss: 3.2899e-06 - dense_101_loss: 6.6160e-07 - dense_102_loss: 1.7790e-06 - dense_103_loss: 1.0879e-06 - dense_104_loss: 1.3081e-06 - dense_105_loss: 1.2729e-06 - dense_106_loss: 1.1621e-06 - val_loss: 1.0361e-05 - val_dense_99_loss: 7.5781e-07 - val_dense_100_loss: 3.0257e-06 - val_dense_101_loss: 5.5002e-07 - val_dense_102_loss: 1.6225e-06 - val_dense_103_loss: 1.0080e-06 - val_dense_104_loss: 1.1855e-06 - val_dense_105_loss: 1.2176e-06 - val_dense_106_loss: 9.9378e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0372e-05 - dense_99_loss: 6.9277e-07 - dense_100_loss: 3.1324e-06 - dense_101_loss: 5.4361e-07 - dense_102_loss: 1.6351e-06 - dense_103_loss: 9.7184e-07 - dense_104_loss: 1.1885e-06 - dense_105_loss: 1.1696e-06 - dense_106_loss: 1.0385e-06 - val_loss: 1.0206e-05 - val_dense_99_loss: 7.1526e-07 - val_dense_100_loss: 2.9573e-06 - val_dense_101_loss: 5.7612e-07 - val_dense_102_loss: 1.6002e-06 - val_dense_103_loss: 1.0502e-06 - val_dense_104_loss: 1.1606e-06 - val_dense_105_loss: 1.1187e-06 - val_dense_106_loss: 1.0279e-06\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0343e-05 - dense_99_loss: 6.8857e-07 - dense_100_loss: 3.1221e-06 - dense_101_loss: 5.5697e-07 - dense_102_loss: 1.6325e-06 - dense_103_loss: 9.7927e-07 - dense_104_loss: 1.1789e-06 - dense_105_loss: 1.1456e-06 - dense_106_loss: 1.0393e-06 - val_loss: 1.0078e-05 - val_dense_99_loss: 6.8612e-07 - val_dense_100_loss: 2.9990e-06 - val_dense_101_loss: 5.3526e-07 - val_dense_102_loss: 1.5584e-06 - val_dense_103_loss: 1.0104e-06 - val_dense_104_loss: 1.1521e-06 - val_dense_105_loss: 1.1286e-06 - val_dense_106_loss: 1.0086e-06\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0255e-05 - dense_99_loss: 6.9098e-07 - dense_100_loss: 3.1139e-06 - dense_101_loss: 5.5113e-07 - dense_102_loss: 1.5992e-06 - dense_103_loss: 9.7439e-07 - dense_104_loss: 1.1614e-06 - dense_105_loss: 1.1346e-06 - dense_106_loss: 1.0297e-06 - val_loss: 1.0029e-05 - val_dense_99_loss: 7.3017e-07 - val_dense_100_loss: 2.9158e-06 - val_dense_101_loss: 5.7746e-07 - val_dense_102_loss: 1.6300e-06 - val_dense_103_loss: 9.8191e-07 - val_dense_104_loss: 1.0945e-06 - val_dense_105_loss: 1.1231e-06 - val_dense_106_loss: 9.7576e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0216e-05 - dense_99_loss: 6.8073e-07 - dense_100_loss: 3.0854e-06 - dense_101_loss: 5.6528e-07 - dense_102_loss: 1.5962e-06 - dense_103_loss: 9.6948e-07 - dense_104_loss: 1.1526e-06 - dense_105_loss: 1.1322e-06 - dense_106_loss: 1.0341e-06 - val_loss: 1.0498e-05 - val_dense_99_loss: 7.6450e-07 - val_dense_100_loss: 2.9743e-06 - val_dense_101_loss: 6.1178e-07 - val_dense_102_loss: 1.6058e-06 - val_dense_103_loss: 1.0184e-06 - val_dense_104_loss: 1.1399e-06 - val_dense_105_loss: 1.2430e-06 - val_dense_106_loss: 1.1407e-06\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0377e-05 - dense_99_loss: 7.2737e-07 - dense_100_loss: 3.0731e-06 - dense_101_loss: 5.8835e-07 - dense_102_loss: 1.6164e-06 - dense_103_loss: 9.8531e-07 - dense_104_loss: 1.1521e-06 - dense_105_loss: 1.1867e-06 - dense_106_loss: 1.0481e-06 - val_loss: 1.1249e-05 - val_dense_99_loss: 7.9229e-07 - val_dense_100_loss: 3.1839e-06 - val_dense_101_loss: 7.2315e-07 - val_dense_102_loss: 1.9731e-06 - val_dense_103_loss: 1.0826e-06 - val_dense_104_loss: 1.2134e-06 - val_dense_105_loss: 1.1805e-06 - val_dense_106_loss: 1.0998e-06\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0669e-05 - dense_99_loss: 7.4855e-07 - dense_100_loss: 3.1407e-06 - dense_101_loss: 6.2302e-07 - dense_102_loss: 1.6452e-06 - dense_103_loss: 1.0393e-06 - dense_104_loss: 1.1930e-06 - dense_105_loss: 1.2054e-06 - dense_106_loss: 1.0739e-06 - val_loss: 1.0218e-05 - val_dense_99_loss: 7.4789e-07 - val_dense_100_loss: 3.0232e-06 - val_dense_101_loss: 5.9673e-07 - val_dense_102_loss: 1.5089e-06 - val_dense_103_loss: 1.0391e-06 - val_dense_104_loss: 1.1580e-06 - val_dense_105_loss: 1.1141e-06 - val_dense_106_loss: 1.0297e-06\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0449e-05 - dense_99_loss: 7.3978e-07 - dense_100_loss: 3.0497e-06 - dense_101_loss: 6.3348e-07 - dense_102_loss: 1.5689e-06 - dense_103_loss: 1.0335e-06 - dense_104_loss: 1.1727e-06 - dense_105_loss: 1.1867e-06 - dense_106_loss: 1.0647e-06 - val_loss: 9.7983e-06 - val_dense_99_loss: 7.0653e-07 - val_dense_100_loss: 2.7642e-06 - val_dense_101_loss: 5.7291e-07 - val_dense_102_loss: 1.4393e-06 - val_dense_103_loss: 1.0075e-06 - val_dense_104_loss: 1.1292e-06 - val_dense_105_loss: 1.1962e-06 - val_dense_106_loss: 9.8255e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0291e-05 - dense_99_loss: 7.4919e-07 - dense_100_loss: 2.9491e-06 - dense_101_loss: 6.2232e-07 - dense_102_loss: 1.5460e-06 - dense_103_loss: 1.0164e-06 - dense_104_loss: 1.1451e-06 - dense_105_loss: 1.2242e-06 - dense_106_loss: 1.0390e-06 - val_loss: 9.6155e-06 - val_dense_99_loss: 6.5990e-07 - val_dense_100_loss: 2.7495e-06 - val_dense_101_loss: 6.1213e-07 - val_dense_102_loss: 1.4060e-06 - val_dense_103_loss: 1.0021e-06 - val_dense_104_loss: 1.0833e-06 - val_dense_105_loss: 1.1369e-06 - val_dense_106_loss: 9.6573e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0065e-05 - dense_99_loss: 7.2851e-07 - dense_100_loss: 2.8909e-06 - dense_101_loss: 6.1259e-07 - dense_102_loss: 1.4957e-06 - dense_103_loss: 1.0060e-06 - dense_104_loss: 1.1294e-06 - dense_105_loss: 1.1782e-06 - dense_106_loss: 1.0235e-06 - val_loss: 1.0338e-05 - val_dense_99_loss: 7.5240e-07 - val_dense_100_loss: 2.8782e-06 - val_dense_101_loss: 7.0604e-07 - val_dense_102_loss: 1.4348e-06 - val_dense_103_loss: 1.1113e-06 - val_dense_104_loss: 1.1983e-06 - val_dense_105_loss: 1.2258e-06 - val_dense_106_loss: 1.0312e-06\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0697e-05 - dense_99_loss: 8.1753e-07 - dense_100_loss: 2.9580e-06 - dense_101_loss: 7.0958e-07 - dense_102_loss: 1.5544e-06 - dense_103_loss: 1.0634e-06 - dense_104_loss: 1.2213e-06 - dense_105_loss: 1.2822e-06 - dense_106_loss: 1.0902e-06 - val_loss: 1.4378e-05 - val_dense_99_loss: 1.3237e-06 - val_dense_100_loss: 3.3728e-06 - val_dense_101_loss: 1.2653e-06 - val_dense_102_loss: 2.0034e-06 - val_dense_103_loss: 1.5285e-06 - val_dense_104_loss: 1.5705e-06 - val_dense_105_loss: 1.8461e-06 - val_dense_106_loss: 1.4677e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4429e-05 - dense_99_loss: 1.2891e-06 - dense_100_loss: 3.4864e-06 - dense_101_loss: 1.2843e-06 - dense_102_loss: 2.0087e-06 - dense_103_loss: 1.5287e-06 - dense_104_loss: 1.5921e-06 - dense_105_loss: 1.8101e-06 - dense_106_loss: 1.4292e-06 - val_loss: 1.1670e-05 - val_dense_99_loss: 8.9719e-07 - val_dense_100_loss: 2.7898e-06 - val_dense_101_loss: 8.7783e-07 - val_dense_102_loss: 1.7505e-06 - val_dense_103_loss: 1.4300e-06 - val_dense_104_loss: 1.2163e-06 - val_dense_105_loss: 1.4927e-06 - val_dense_106_loss: 1.2155e-06\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1740e-05 - dense_99_loss: 9.4107e-07 - dense_100_loss: 2.9911e-06 - dense_101_loss: 9.4649e-07 - dense_102_loss: 1.6938e-06 - dense_103_loss: 1.1912e-06 - dense_104_loss: 1.3013e-06 - dense_105_loss: 1.4819e-06 - dense_106_loss: 1.1931e-06 - val_loss: 1.1393e-05 - val_dense_99_loss: 9.6158e-07 - val_dense_100_loss: 2.7342e-06 - val_dense_101_loss: 7.8987e-07 - val_dense_102_loss: 1.5456e-06 - val_dense_103_loss: 1.2123e-06 - val_dense_104_loss: 1.4508e-06 - val_dense_105_loss: 1.4925e-06 - val_dense_106_loss: 1.2057e-06\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1226e-05 - dense_99_loss: 8.7951e-07 - dense_100_loss: 2.8239e-06 - dense_101_loss: 8.1708e-07 - dense_102_loss: 1.6377e-06 - dense_103_loss: 1.1457e-06 - dense_104_loss: 1.3345e-06 - dense_105_loss: 1.4678e-06 - dense_106_loss: 1.1203e-06 - val_loss: 1.1403e-05 - val_dense_99_loss: 8.8522e-07 - val_dense_100_loss: 2.7236e-06 - val_dense_101_loss: 8.9229e-07 - val_dense_102_loss: 1.9235e-06 - val_dense_103_loss: 1.2142e-06 - val_dense_104_loss: 1.2003e-06 - val_dense_105_loss: 1.5365e-06 - val_dense_106_loss: 1.0278e-06\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2554e-05 - dense_99_loss: 1.0685e-06 - dense_100_loss: 2.8394e-06 - dense_101_loss: 1.0422e-06 - dense_102_loss: 2.0078e-06 - dense_103_loss: 1.3421e-06 - dense_104_loss: 1.4255e-06 - dense_105_loss: 1.5921e-06 - dense_106_loss: 1.2365e-06 - val_loss: 1.0838e-05 - val_dense_99_loss: 8.1631e-07 - val_dense_100_loss: 2.5267e-06 - val_dense_101_loss: 9.4585e-07 - val_dense_102_loss: 1.5479e-06 - val_dense_103_loss: 1.3308e-06 - val_dense_104_loss: 1.1899e-06 - val_dense_105_loss: 1.3273e-06 - val_dense_106_loss: 1.1533e-06\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6880e-05 - dense_99_loss: 1.4980e-06 - dense_100_loss: 3.5479e-06 - dense_101_loss: 1.8143e-06 - dense_102_loss: 2.4110e-06 - dense_103_loss: 1.9017e-06 - dense_104_loss: 1.8681e-06 - dense_105_loss: 2.2028e-06 - dense_106_loss: 1.6363e-06 - val_loss: 1.0824e-05 - val_dense_99_loss: 9.8731e-07 - val_dense_100_loss: 2.7355e-06 - val_dense_101_loss: 8.5566e-07 - val_dense_102_loss: 1.3333e-06 - val_dense_103_loss: 1.1702e-06 - val_dense_104_loss: 1.2138e-06 - val_dense_105_loss: 1.4430e-06 - val_dense_106_loss: 1.0853e-06\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2470e-05 - dense_99_loss: 1.1086e-06 - dense_100_loss: 2.8872e-06 - dense_101_loss: 1.1006e-06 - dense_102_loss: 1.7131e-06 - dense_103_loss: 1.3592e-06 - dense_104_loss: 1.4205e-06 - dense_105_loss: 1.6065e-06 - dense_106_loss: 1.2744e-06 - val_loss: 1.2467e-05 - val_dense_99_loss: 1.1456e-06 - val_dense_100_loss: 2.5501e-06 - val_dense_101_loss: 1.2488e-06 - val_dense_102_loss: 1.7538e-06 - val_dense_103_loss: 1.5944e-06 - val_dense_104_loss: 1.5015e-06 - val_dense_105_loss: 1.3942e-06 - val_dense_106_loss: 1.2782e-06\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1516e-05 - dense_99_loss: 1.0013e-06 - dense_100_loss: 2.5494e-06 - dense_101_loss: 9.9012e-07 - dense_102_loss: 1.6983e-06 - dense_103_loss: 1.2708e-06 - dense_104_loss: 1.3293e-06 - dense_105_loss: 1.5092e-06 - dense_106_loss: 1.1676e-06 - val_loss: 1.1644e-05 - val_dense_99_loss: 1.0792e-06 - val_dense_100_loss: 2.6207e-06 - val_dense_101_loss: 1.0549e-06 - val_dense_102_loss: 1.4800e-06 - val_dense_103_loss: 1.2862e-06 - val_dense_104_loss: 1.2833e-06 - val_dense_105_loss: 1.6513e-06 - val_dense_106_loss: 1.1888e-06\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0642e-05 - dense_99_loss: 9.7962e-07 - dense_100_loss: 2.4473e-06 - dense_101_loss: 9.1418e-07 - dense_102_loss: 1.4230e-06 - dense_103_loss: 1.1768e-06 - dense_104_loss: 1.1891e-06 - dense_105_loss: 1.3914e-06 - dense_106_loss: 1.1203e-06 - val_loss: 9.2343e-06 - val_dense_99_loss: 8.6034e-07 - val_dense_100_loss: 2.1825e-06 - val_dense_101_loss: 6.5494e-07 - val_dense_102_loss: 1.2461e-06 - val_dense_103_loss: 1.0126e-06 - val_dense_104_loss: 9.6006e-07 - val_dense_105_loss: 1.2962e-06 - val_dense_106_loss: 1.0215e-06\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0291e-05 - dense_99_loss: 8.8835e-07 - dense_100_loss: 2.3316e-06 - dense_101_loss: 8.7305e-07 - dense_102_loss: 1.4193e-06 - dense_103_loss: 1.1321e-06 - dense_104_loss: 1.2221e-06 - dense_105_loss: 1.3738e-06 - dense_106_loss: 1.0509e-06 - val_loss: 1.4329e-05 - val_dense_99_loss: 1.2313e-06 - val_dense_100_loss: 2.7386e-06 - val_dense_101_loss: 1.5774e-06 - val_dense_102_loss: 2.0434e-06 - val_dense_103_loss: 1.5300e-06 - val_dense_104_loss: 1.5591e-06 - val_dense_105_loss: 2.1644e-06 - val_dense_106_loss: 1.4847e-06\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.0866e-05 - dense_99_loss: 2.7542e-06 - dense_100_loss: 4.7643e-06 - dense_101_loss: 3.8905e-06 - dense_102_loss: 4.7607e-06 - dense_103_loss: 3.5157e-06 - dense_104_loss: 3.3023e-06 - dense_105_loss: 4.4538e-06 - dense_106_loss: 3.4249e-06 - val_loss: 1.3633e-05 - val_dense_99_loss: 1.3761e-06 - val_dense_100_loss: 2.6010e-06 - val_dense_101_loss: 1.6580e-06 - val_dense_102_loss: 1.4530e-06 - val_dense_103_loss: 1.9984e-06 - val_dense_104_loss: 1.5435e-06 - val_dense_105_loss: 1.7348e-06 - val_dense_106_loss: 1.2681e-06\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2008e-05 - dense_99_loss: 1.2058e-06 - dense_100_loss: 2.4090e-06 - dense_101_loss: 1.2624e-06 - dense_102_loss: 1.6196e-06 - dense_103_loss: 1.4235e-06 - dense_104_loss: 1.2955e-06 - dense_105_loss: 1.5794e-06 - dense_106_loss: 1.2131e-06 - val_loss: 1.0065e-05 - val_dense_99_loss: 1.0034e-06 - val_dense_100_loss: 2.2562e-06 - val_dense_101_loss: 7.6509e-07 - val_dense_102_loss: 1.2589e-06 - val_dense_103_loss: 1.3127e-06 - val_dense_104_loss: 1.2271e-06 - val_dense_105_loss: 1.2917e-06 - val_dense_106_loss: 9.4991e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0069e-05 - dense_99_loss: 8.9898e-07 - dense_100_loss: 2.1196e-06 - dense_101_loss: 8.9050e-07 - dense_102_loss: 1.2889e-06 - dense_103_loss: 1.1690e-06 - dense_104_loss: 1.2156e-06 - dense_105_loss: 1.4180e-06 - dense_106_loss: 1.0681e-06 - val_loss: 1.0363e-05 - val_dense_99_loss: 9.6592e-07 - val_dense_100_loss: 2.0734e-06 - val_dense_101_loss: 1.1260e-06 - val_dense_102_loss: 1.1522e-06 - val_dense_103_loss: 1.3508e-06 - val_dense_104_loss: 1.2196e-06 - val_dense_105_loss: 1.4532e-06 - val_dense_106_loss: 1.0219e-06\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6869e-06 - dense_99_loss: 9.6987e-07 - dense_100_loss: 1.9694e-06 - dense_101_loss: 8.3438e-07 - dense_102_loss: 1.2675e-06 - dense_103_loss: 1.1196e-06 - dense_104_loss: 1.0769e-06 - dense_105_loss: 1.3968e-06 - dense_106_loss: 1.0525e-06 - val_loss: 9.5524e-06 - val_dense_99_loss: 1.0195e-06 - val_dense_100_loss: 1.6223e-06 - val_dense_101_loss: 7.8842e-07 - val_dense_102_loss: 1.3508e-06 - val_dense_103_loss: 1.1025e-06 - val_dense_104_loss: 1.2289e-06 - val_dense_105_loss: 1.4084e-06 - val_dense_106_loss: 1.0316e-06\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2167e-06 - dense_99_loss: 7.7979e-07 - dense_100_loss: 1.7252e-06 - dense_101_loss: 6.9455e-07 - dense_102_loss: 1.0428e-06 - dense_103_loss: 1.0229e-06 - dense_104_loss: 9.3527e-07 - dense_105_loss: 1.1839e-06 - dense_106_loss: 8.3230e-07 - val_loss: 8.0626e-06 - val_dense_99_loss: 7.4506e-07 - val_dense_100_loss: 1.5237e-06 - val_dense_101_loss: 7.2538e-07 - val_dense_102_loss: 1.0155e-06 - val_dense_103_loss: 1.0438e-06 - val_dense_104_loss: 9.0092e-07 - val_dense_105_loss: 1.1975e-06 - val_dense_106_loss: 9.1069e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2876e-06 - dense_99_loss: 7.6137e-07 - dense_100_loss: 1.6161e-06 - dense_101_loss: 7.6106e-07 - dense_102_loss: 1.0143e-06 - dense_103_loss: 1.0233e-06 - dense_104_loss: 9.9106e-07 - dense_105_loss: 1.2393e-06 - dense_106_loss: 8.8115e-07 - val_loss: 9.6711e-06 - val_dense_99_loss: 7.9786e-07 - val_dense_100_loss: 1.7781e-06 - val_dense_101_loss: 9.4928e-07 - val_dense_102_loss: 1.4681e-06 - val_dense_103_loss: 1.2775e-06 - val_dense_104_loss: 1.1965e-06 - val_dense_105_loss: 1.2945e-06 - val_dense_106_loss: 9.0931e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4921e-05 - dense_99_loss: 1.6458e-06 - dense_100_loss: 2.2010e-06 - dense_101_loss: 1.4546e-06 - dense_102_loss: 2.0351e-06 - dense_103_loss: 1.6696e-06 - dense_104_loss: 2.0287e-06 - dense_105_loss: 2.1600e-06 - dense_106_loss: 1.7267e-06 - val_loss: 8.2079e-06 - val_dense_99_loss: 8.5684e-07 - val_dense_100_loss: 1.4116e-06 - val_dense_101_loss: 7.3915e-07 - val_dense_102_loss: 1.0877e-06 - val_dense_103_loss: 1.0376e-06 - val_dense_104_loss: 9.6070e-07 - val_dense_105_loss: 1.2739e-06 - val_dense_106_loss: 8.4040e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2714e-06 - dense_99_loss: 8.2809e-07 - dense_100_loss: 1.4346e-06 - dense_101_loss: 7.9416e-07 - dense_102_loss: 1.0245e-06 - dense_103_loss: 1.0387e-06 - dense_104_loss: 9.5920e-07 - dense_105_loss: 1.2356e-06 - dense_106_loss: 9.5651e-07 - val_loss: 8.8076e-06 - val_dense_99_loss: 6.8725e-07 - val_dense_100_loss: 1.4460e-06 - val_dense_101_loss: 8.1293e-07 - val_dense_102_loss: 1.0423e-06 - val_dense_103_loss: 1.2708e-06 - val_dense_104_loss: 9.0642e-07 - val_dense_105_loss: 1.5079e-06 - val_dense_106_loss: 1.1340e-06\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0948e-06 - dense_99_loss: 7.8408e-07 - dense_100_loss: 1.4569e-06 - dense_101_loss: 7.7615e-07 - dense_102_loss: 9.7415e-07 - dense_103_loss: 1.0396e-06 - dense_104_loss: 8.9717e-07 - dense_105_loss: 1.2675e-06 - dense_106_loss: 8.9931e-07 - val_loss: 9.8412e-06 - val_dense_99_loss: 1.1282e-06 - val_dense_100_loss: 1.4349e-06 - val_dense_101_loss: 1.0548e-06 - val_dense_102_loss: 1.1557e-06 - val_dense_103_loss: 1.2502e-06 - val_dense_104_loss: 9.6396e-07 - val_dense_105_loss: 1.7380e-06 - val_dense_106_loss: 1.1155e-06\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2438e-05 - dense_99_loss: 1.2920e-06 - dense_100_loss: 1.9261e-06 - dense_101_loss: 1.4673e-06 - dense_102_loss: 1.5898e-06 - dense_103_loss: 1.4665e-06 - dense_104_loss: 1.5024e-06 - dense_105_loss: 1.9017e-06 - dense_106_loss: 1.2920e-06 - val_loss: 2.1420e-05 - val_dense_99_loss: 2.7082e-06 - val_dense_100_loss: 2.7459e-06 - val_dense_101_loss: 3.1222e-06 - val_dense_102_loss: 2.0974e-06 - val_dense_103_loss: 3.2458e-06 - val_dense_104_loss: 3.3937e-06 - val_dense_105_loss: 2.1134e-06 - val_dense_106_loss: 1.9938e-06\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1502e-05 - dense_99_loss: 1.2670e-06 - dense_100_loss: 1.7439e-06 - dense_101_loss: 1.2772e-06 - dense_102_loss: 1.3327e-06 - dense_103_loss: 1.5937e-06 - dense_104_loss: 1.4777e-06 - dense_105_loss: 1.5571e-06 - dense_106_loss: 1.2526e-06 - val_loss: 8.4293e-06 - val_dense_99_loss: 9.1555e-07 - val_dense_100_loss: 1.1912e-06 - val_dense_101_loss: 8.2772e-07 - val_dense_102_loss: 1.1214e-06 - val_dense_103_loss: 1.1255e-06 - val_dense_104_loss: 9.6946e-07 - val_dense_105_loss: 1.2720e-06 - val_dense_106_loss: 1.0065e-06\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5308e-06 - dense_99_loss: 7.2635e-07 - dense_100_loss: 1.2521e-06 - dense_101_loss: 7.0700e-07 - dense_102_loss: 9.6788e-07 - dense_103_loss: 1.0066e-06 - dense_104_loss: 8.5185e-07 - dense_105_loss: 1.1720e-06 - dense_106_loss: 8.4699e-07 - val_loss: 7.5390e-06 - val_dense_99_loss: 6.4070e-07 - val_dense_100_loss: 1.0452e-06 - val_dense_101_loss: 7.5496e-07 - val_dense_102_loss: 1.0250e-06 - val_dense_103_loss: 1.1566e-06 - val_dense_104_loss: 8.4293e-07 - val_dense_105_loss: 1.1819e-06 - val_dense_106_loss: 8.9168e-07\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9522e-06 - dense_99_loss: 6.6772e-07 - dense_100_loss: 1.1314e-06 - dense_101_loss: 6.6165e-07 - dense_102_loss: 9.0005e-07 - dense_103_loss: 9.1189e-07 - dense_104_loss: 7.9907e-07 - dense_105_loss: 1.0955e-06 - dense_106_loss: 7.8484e-07 - val_loss: 6.4630e-06 - val_dense_99_loss: 5.1119e-07 - val_dense_100_loss: 1.0075e-06 - val_dense_101_loss: 6.2031e-07 - val_dense_102_loss: 8.8297e-07 - val_dense_103_loss: 1.0057e-06 - val_dense_104_loss: 7.2149e-07 - val_dense_105_loss: 1.0463e-06 - val_dense_106_loss: 6.6751e-07\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8836e-06 - dense_99_loss: 6.4524e-07 - dense_100_loss: 1.0373e-06 - dense_101_loss: 6.5955e-07 - dense_102_loss: 8.3598e-07 - dense_103_loss: 9.8091e-07 - dense_104_loss: 8.0342e-07 - dense_105_loss: 1.1076e-06 - dense_106_loss: 8.1358e-07 - val_loss: 8.7588e-06 - val_dense_99_loss: 8.8693e-07 - val_dense_100_loss: 1.1448e-06 - val_dense_101_loss: 9.6413e-07 - val_dense_102_loss: 9.5419e-07 - val_dense_103_loss: 1.1257e-06 - val_dense_104_loss: 9.9645e-07 - val_dense_105_loss: 1.6651e-06 - val_dense_106_loss: 1.0215e-06\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0867e-06 - dense_99_loss: 9.0933e-07 - dense_100_loss: 1.3502e-06 - dense_101_loss: 1.0811e-06 - dense_102_loss: 1.1332e-06 - dense_103_loss: 1.2309e-06 - dense_104_loss: 9.9814e-07 - dense_105_loss: 1.3594e-06 - dense_106_loss: 1.0245e-06 - val_loss: 1.1500e-05 - val_dense_99_loss: 1.0674e-06 - val_dense_100_loss: 1.7568e-06 - val_dense_101_loss: 1.1818e-06 - val_dense_102_loss: 1.5548e-06 - val_dense_103_loss: 1.6899e-06 - val_dense_104_loss: 1.3976e-06 - val_dense_105_loss: 1.6154e-06 - val_dense_106_loss: 1.2365e-06\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4735e-05 - dense_99_loss: 1.6265e-06 - dense_100_loss: 1.9482e-06 - dense_101_loss: 1.7596e-06 - dense_102_loss: 1.9829e-06 - dense_103_loss: 1.8772e-06 - dense_104_loss: 1.8458e-06 - dense_105_loss: 1.8770e-06 - dense_106_loss: 1.8175e-06 - val_loss: 6.3922e-06 - val_dense_99_loss: 5.4738e-07 - val_dense_100_loss: 9.2533e-07 - val_dense_101_loss: 7.2982e-07 - val_dense_102_loss: 6.5266e-07 - val_dense_103_loss: 9.0784e-07 - val_dense_104_loss: 6.9921e-07 - val_dense_105_loss: 1.1633e-06 - val_dense_106_loss: 7.6666e-07\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0319e-06 - dense_99_loss: 7.0019e-07 - dense_100_loss: 1.0630e-06 - dense_101_loss: 7.6284e-07 - dense_102_loss: 8.8059e-07 - dense_103_loss: 9.3420e-07 - dense_104_loss: 7.6439e-07 - dense_105_loss: 1.1097e-06 - dense_106_loss: 8.1698e-07 - val_loss: 6.4152e-06 - val_dense_99_loss: 5.4398e-07 - val_dense_100_loss: 9.2184e-07 - val_dense_101_loss: 6.3265e-07 - val_dense_102_loss: 7.6166e-07 - val_dense_103_loss: 8.6384e-07 - val_dense_104_loss: 7.3470e-07 - val_dense_105_loss: 1.0576e-06 - val_dense_106_loss: 8.9892e-07\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.4242e-06 - dense_99_loss: 6.1657e-07 - dense_100_loss: 9.2792e-07 - dense_101_loss: 6.6303e-07 - dense_102_loss: 7.5558e-07 - dense_103_loss: 9.4545e-07 - dense_104_loss: 7.1817e-07 - dense_105_loss: 1.0437e-06 - dense_106_loss: 7.5380e-07 - val_loss: 8.1069e-06 - val_dense_99_loss: 7.8778e-07 - val_dense_100_loss: 1.2658e-06 - val_dense_101_loss: 6.5282e-07 - val_dense_102_loss: 1.0004e-06 - val_dense_103_loss: 1.3214e-06 - val_dense_104_loss: 9.9494e-07 - val_dense_105_loss: 1.1702e-06 - val_dense_106_loss: 9.1339e-07\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7949e-06 - dense_99_loss: 6.9517e-07 - dense_100_loss: 9.6331e-07 - dense_101_loss: 6.6664e-07 - dense_102_loss: 8.2132e-07 - dense_103_loss: 9.5744e-07 - dense_104_loss: 7.9096e-07 - dense_105_loss: 1.1172e-06 - dense_106_loss: 7.8287e-07 - val_loss: 7.3799e-06 - val_dense_99_loss: 6.7945e-07 - val_dense_100_loss: 1.0972e-06 - val_dense_101_loss: 7.8769e-07 - val_dense_102_loss: 8.5157e-07 - val_dense_103_loss: 9.6294e-07 - val_dense_104_loss: 8.6994e-07 - val_dense_105_loss: 1.1305e-06 - val_dense_106_loss: 1.0006e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5285e-06 - dense_99_loss: 6.3593e-07 - dense_100_loss: 9.5514e-07 - dense_101_loss: 7.0073e-07 - dense_102_loss: 7.5714e-07 - dense_103_loss: 9.0745e-07 - dense_104_loss: 7.5244e-07 - dense_105_loss: 1.0416e-06 - dense_106_loss: 7.7810e-07 - val_loss: 7.5228e-06 - val_dense_99_loss: 7.3812e-07 - val_dense_100_loss: 1.2121e-06 - val_dense_101_loss: 8.8139e-07 - val_dense_102_loss: 8.6909e-07 - val_dense_103_loss: 9.9426e-07 - val_dense_104_loss: 8.7500e-07 - val_dense_105_loss: 1.0875e-06 - val_dense_106_loss: 8.6537e-07\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9216e-06 - dense_99_loss: 6.7956e-07 - dense_100_loss: 9.8612e-07 - dense_101_loss: 6.7079e-07 - dense_102_loss: 8.3750e-07 - dense_103_loss: 9.8046e-07 - dense_104_loss: 8.1260e-07 - dense_105_loss: 1.1386e-06 - dense_106_loss: 8.1603e-07 - val_loss: 6.6575e-06 - val_dense_99_loss: 6.1222e-07 - val_dense_100_loss: 9.4466e-07 - val_dense_101_loss: 6.2864e-07 - val_dense_102_loss: 7.3908e-07 - val_dense_103_loss: 1.0203e-06 - val_dense_104_loss: 8.6441e-07 - val_dense_105_loss: 9.2054e-07 - val_dense_106_loss: 9.2766e-07\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1532e-06 - dense_99_loss: 8.2536e-07 - dense_100_loss: 1.0574e-06 - dense_101_loss: 8.1619e-07 - dense_102_loss: 9.9342e-07 - dense_103_loss: 1.0712e-06 - dense_104_loss: 1.0209e-06 - dense_105_loss: 1.3267e-06 - dense_106_loss: 1.0421e-06 - val_loss: 1.0870e-05 - val_dense_99_loss: 1.3519e-06 - val_dense_100_loss: 1.1432e-06 - val_dense_101_loss: 1.1827e-06 - val_dense_102_loss: 1.2266e-06 - val_dense_103_loss: 1.6166e-06 - val_dense_104_loss: 1.3565e-06 - val_dense_105_loss: 1.6038e-06 - val_dense_106_loss: 1.3890e-06\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8393e-05 - dense_99_loss: 2.3587e-06 - dense_100_loss: 1.9926e-06 - dense_101_loss: 1.9945e-06 - dense_102_loss: 2.2569e-06 - dense_103_loss: 2.4282e-06 - dense_104_loss: 2.3267e-06 - dense_105_loss: 2.7715e-06 - dense_106_loss: 2.2637e-06 - val_loss: 1.1186e-05 - val_dense_99_loss: 9.1227e-07 - val_dense_100_loss: 1.2027e-06 - val_dense_101_loss: 1.0866e-06 - val_dense_102_loss: 1.4138e-06 - val_dense_103_loss: 1.7622e-06 - val_dense_104_loss: 1.5752e-06 - val_dense_105_loss: 1.6703e-06 - val_dense_106_loss: 1.5626e-06\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5426e-06 - dense_99_loss: 7.5795e-07 - dense_100_loss: 1.0427e-06 - dense_101_loss: 7.9964e-07 - dense_102_loss: 8.6920e-07 - dense_103_loss: 1.1298e-06 - dense_104_loss: 8.7244e-07 - dense_105_loss: 1.1339e-06 - dense_106_loss: 9.3695e-07 - val_loss: 6.2102e-06 - val_dense_99_loss: 6.2772e-07 - val_dense_100_loss: 9.1109e-07 - val_dense_101_loss: 6.6024e-07 - val_dense_102_loss: 6.8638e-07 - val_dense_103_loss: 9.8667e-07 - val_dense_104_loss: 7.3030e-07 - val_dense_105_loss: 1.0280e-06 - val_dense_106_loss: 5.7976e-07\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.8782e-06 - dense_99_loss: 5.7678e-07 - dense_100_loss: 8.1225e-07 - dense_101_loss: 6.2927e-07 - dense_102_loss: 6.4286e-07 - dense_103_loss: 8.6881e-07 - dense_104_loss: 6.6124e-07 - dense_105_loss: 9.6888e-07 - dense_106_loss: 7.1816e-07 - val_loss: 6.2760e-06 - val_dense_99_loss: 7.8878e-07 - val_dense_100_loss: 7.6451e-07 - val_dense_101_loss: 5.3385e-07 - val_dense_102_loss: 6.8947e-07 - val_dense_103_loss: 1.0279e-06 - val_dense_104_loss: 7.7845e-07 - val_dense_105_loss: 9.5258e-07 - val_dense_106_loss: 7.4042e-07\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1903e-06 - dense_99_loss: 6.0908e-07 - dense_100_loss: 7.6670e-07 - dense_101_loss: 6.2157e-07 - dense_102_loss: 7.0502e-07 - dense_103_loss: 9.7296e-07 - dense_104_loss: 7.3502e-07 - dense_105_loss: 1.0258e-06 - dense_106_loss: 7.5424e-07 - val_loss: 5.6946e-06 - val_dense_99_loss: 4.2478e-07 - val_dense_100_loss: 6.8099e-07 - val_dense_101_loss: 6.1635e-07 - val_dense_102_loss: 6.5468e-07 - val_dense_103_loss: 9.6883e-07 - val_dense_104_loss: 7.3702e-07 - val_dense_105_loss: 9.1651e-07 - val_dense_106_loss: 6.9541e-07\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.7565e-06 - dense_99_loss: 5.4912e-07 - dense_100_loss: 7.4491e-07 - dense_101_loss: 5.7028e-07 - dense_102_loss: 6.5568e-07 - dense_103_loss: 9.0666e-07 - dense_104_loss: 6.6419e-07 - dense_105_loss: 9.9057e-07 - dense_106_loss: 6.7507e-07 - val_loss: 6.7194e-06 - val_dense_99_loss: 7.2855e-07 - val_dense_100_loss: 8.5988e-07 - val_dense_101_loss: 6.5472e-07 - val_dense_102_loss: 6.7410e-07 - val_dense_103_loss: 1.0450e-06 - val_dense_104_loss: 9.1427e-07 - val_dense_105_loss: 1.1474e-06 - val_dense_106_loss: 6.9548e-07\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3448e-06 - dense_99_loss: 8.9398e-07 - dense_100_loss: 1.1115e-06 - dense_101_loss: 7.7081e-07 - dense_102_loss: 1.0185e-06 - dense_103_loss: 1.2409e-06 - dense_104_loss: 9.1801e-07 - dense_105_loss: 1.3637e-06 - dense_106_loss: 1.0274e-06 - val_loss: 6.8144e-06 - val_dense_99_loss: 7.3131e-07 - val_dense_100_loss: 9.9800e-07 - val_dense_101_loss: 7.0366e-07 - val_dense_102_loss: 7.6552e-07 - val_dense_103_loss: 9.5785e-07 - val_dense_104_loss: 7.7526e-07 - val_dense_105_loss: 1.0410e-06 - val_dense_106_loss: 8.4176e-07\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.2762e-06 - dense_99_loss: 7.6391e-07 - dense_100_loss: 1.0112e-06 - dense_101_loss: 7.7108e-07 - dense_102_loss: 7.8807e-07 - dense_103_loss: 1.0782e-06 - dense_104_loss: 8.0028e-07 - dense_105_loss: 1.1631e-06 - dense_106_loss: 9.0036e-07 - val_loss: 5.9485e-06 - val_dense_99_loss: 6.1644e-07 - val_dense_100_loss: 6.8710e-07 - val_dense_101_loss: 5.7058e-07 - val_dense_102_loss: 7.0718e-07 - val_dense_103_loss: 9.4702e-07 - val_dense_104_loss: 6.7346e-07 - val_dense_105_loss: 1.0732e-06 - val_dense_106_loss: 6.7346e-07\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3539e-06 - dense_99_loss: 6.4417e-07 - dense_100_loss: 7.8456e-07 - dense_101_loss: 7.2095e-07 - dense_102_loss: 7.2270e-07 - dense_103_loss: 9.4745e-07 - dense_104_loss: 7.4334e-07 - dense_105_loss: 1.0370e-06 - dense_106_loss: 7.5374e-07 - val_loss: 6.3374e-06 - val_dense_99_loss: 4.6821e-07 - val_dense_100_loss: 7.7493e-07 - val_dense_101_loss: 7.1478e-07 - val_dense_102_loss: 7.3333e-07 - val_dense_103_loss: 9.5545e-07 - val_dense_104_loss: 7.1807e-07 - val_dense_105_loss: 1.1216e-06 - val_dense_106_loss: 8.5095e-07\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0295e-05 - dense_99_loss: 9.0732e-07 - dense_100_loss: 1.2556e-06 - dense_101_loss: 1.3499e-06 - dense_102_loss: 1.4410e-06 - dense_103_loss: 1.3274e-06 - dense_104_loss: 1.2894e-06 - dense_105_loss: 1.5523e-06 - dense_106_loss: 1.1722e-06 - val_loss: 8.2898e-06 - val_dense_99_loss: 9.7102e-07 - val_dense_100_loss: 9.4369e-07 - val_dense_101_loss: 8.7618e-07 - val_dense_102_loss: 6.5055e-07 - val_dense_103_loss: 1.2590e-06 - val_dense_104_loss: 1.0491e-06 - val_dense_105_loss: 1.5002e-06 - val_dense_106_loss: 1.0402e-06\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1077e-06 - dense_99_loss: 8.7960e-07 - dense_100_loss: 1.0946e-06 - dense_101_loss: 7.8668e-07 - dense_102_loss: 1.0073e-06 - dense_103_loss: 1.1455e-06 - dense_104_loss: 9.4473e-07 - dense_105_loss: 1.3032e-06 - dense_106_loss: 9.4608e-07 - val_loss: 6.9532e-06 - val_dense_99_loss: 7.6404e-07 - val_dense_100_loss: 8.1029e-07 - val_dense_101_loss: 7.5571e-07 - val_dense_102_loss: 8.8288e-07 - val_dense_103_loss: 1.2704e-06 - val_dense_104_loss: 6.5017e-07 - val_dense_105_loss: 1.0320e-06 - val_dense_106_loss: 7.8772e-07\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1893e-06 - dense_99_loss: 6.4555e-07 - dense_100_loss: 7.4019e-07 - dense_101_loss: 6.7676e-07 - dense_102_loss: 6.6556e-07 - dense_103_loss: 9.8397e-07 - dense_104_loss: 7.0277e-07 - dense_105_loss: 1.0137e-06 - dense_106_loss: 7.6084e-07 - val_loss: 8.2010e-06 - val_dense_99_loss: 9.0182e-07 - val_dense_100_loss: 7.6399e-07 - val_dense_101_loss: 1.1853e-06 - val_dense_102_loss: 9.3755e-07 - val_dense_103_loss: 1.4367e-06 - val_dense_104_loss: 7.8058e-07 - val_dense_105_loss: 1.1218e-06 - val_dense_106_loss: 1.0733e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3502e-06 - dense_99_loss: 9.4127e-07 - dense_100_loss: 9.3511e-07 - dense_101_loss: 9.6598e-07 - dense_102_loss: 9.0677e-07 - dense_103_loss: 1.2282e-06 - dense_104_loss: 9.7221e-07 - dense_105_loss: 1.2779e-06 - dense_106_loss: 1.1227e-06 - val_loss: 8.1327e-06 - val_dense_99_loss: 9.4699e-07 - val_dense_100_loss: 1.0615e-06 - val_dense_101_loss: 8.1340e-07 - val_dense_102_loss: 8.8668e-07 - val_dense_103_loss: 1.1340e-06 - val_dense_104_loss: 8.7728e-07 - val_dense_105_loss: 1.2422e-06 - val_dense_106_loss: 1.1706e-06\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3081e-06 - dense_99_loss: 7.3605e-07 - dense_100_loss: 7.4460e-07 - dense_101_loss: 7.0768e-07 - dense_102_loss: 6.2249e-07 - dense_103_loss: 9.7010e-07 - dense_104_loss: 6.8764e-07 - dense_105_loss: 1.0335e-06 - dense_106_loss: 8.0597e-07 - val_loss: 7.4994e-06 - val_dense_99_loss: 7.2468e-07 - val_dense_100_loss: 1.0679e-06 - val_dense_101_loss: 9.2062e-07 - val_dense_102_loss: 9.0087e-07 - val_dense_103_loss: 1.0817e-06 - val_dense_104_loss: 9.3190e-07 - val_dense_105_loss: 1.2073e-06 - val_dense_106_loss: 6.6445e-07\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2032e-06 - dense_99_loss: 7.7711e-07 - dense_100_loss: 8.9873e-07 - dense_101_loss: 7.7792e-07 - dense_102_loss: 8.2733e-07 - dense_103_loss: 1.0047e-06 - dense_104_loss: 8.3042e-07 - dense_105_loss: 1.2364e-06 - dense_106_loss: 8.5058e-07 - val_loss: 7.3257e-06 - val_dense_99_loss: 8.2792e-07 - val_dense_100_loss: 9.8928e-07 - val_dense_101_loss: 8.3698e-07 - val_dense_102_loss: 8.1514e-07 - val_dense_103_loss: 1.0297e-06 - val_dense_104_loss: 7.8045e-07 - val_dense_105_loss: 1.1009e-06 - val_dense_106_loss: 9.4529e-07\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6315e-06 - dense_99_loss: 7.6041e-07 - dense_100_loss: 8.1556e-07 - dense_101_loss: 7.0340e-07 - dense_102_loss: 6.7476e-07 - dense_103_loss: 1.0135e-06 - dense_104_loss: 7.2418e-07 - dense_105_loss: 1.0877e-06 - dense_106_loss: 8.5208e-07 - val_loss: 7.1677e-06 - val_dense_99_loss: 8.5486e-07 - val_dense_100_loss: 9.7639e-07 - val_dense_101_loss: 6.0958e-07 - val_dense_102_loss: 7.9866e-07 - val_dense_103_loss: 1.2401e-06 - val_dense_104_loss: 6.3440e-07 - val_dense_105_loss: 1.1432e-06 - val_dense_106_loss: 9.1061e-07\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.0380e-06 - dense_99_loss: 6.5033e-07 - dense_100_loss: 6.7996e-07 - dense_101_loss: 6.3592e-07 - dense_102_loss: 6.6960e-07 - dense_103_loss: 9.5765e-07 - dense_104_loss: 6.7040e-07 - dense_105_loss: 1.0389e-06 - dense_106_loss: 7.3523e-07 - val_loss: 7.1266e-06 - val_dense_99_loss: 7.5443e-07 - val_dense_100_loss: 9.8077e-07 - val_dense_101_loss: 8.5608e-07 - val_dense_102_loss: 7.4788e-07 - val_dense_103_loss: 9.7977e-07 - val_dense_104_loss: 7.1111e-07 - val_dense_105_loss: 1.2542e-06 - val_dense_106_loss: 8.4235e-07\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0232e-06 - dense_99_loss: 9.2287e-07 - dense_100_loss: 9.2880e-07 - dense_101_loss: 9.0857e-07 - dense_102_loss: 8.6998e-07 - dense_103_loss: 1.0928e-06 - dense_104_loss: 8.9043e-07 - dense_105_loss: 1.3951e-06 - dense_106_loss: 1.0147e-06 - val_loss: 7.9281e-06 - val_dense_99_loss: 9.2038e-07 - val_dense_100_loss: 9.3388e-07 - val_dense_101_loss: 1.0959e-06 - val_dense_102_loss: 7.7511e-07 - val_dense_103_loss: 1.2408e-06 - val_dense_104_loss: 8.9180e-07 - val_dense_105_loss: 1.2007e-06 - val_dense_106_loss: 8.6940e-07\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.2334e-06 - dense_99_loss: 6.8028e-07 - dense_100_loss: 6.5475e-07 - dense_101_loss: 7.9397e-07 - dense_102_loss: 6.5407e-07 - dense_103_loss: 9.9158e-07 - dense_104_loss: 7.4367e-07 - dense_105_loss: 9.9476e-07 - dense_106_loss: 7.2031e-07 - val_loss: 5.6011e-06 - val_dense_99_loss: 5.3410e-07 - val_dense_100_loss: 6.4963e-07 - val_dense_101_loss: 5.6940e-07 - val_dense_102_loss: 5.8139e-07 - val_dense_103_loss: 9.8306e-07 - val_dense_104_loss: 6.6731e-07 - val_dense_105_loss: 1.0053e-06 - val_dense_106_loss: 6.1090e-07\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1863e-05 - dense_99_loss: 1.3424e-06 - dense_100_loss: 1.2599e-06 - dense_101_loss: 1.4481e-06 - dense_102_loss: 1.7180e-06 - dense_103_loss: 1.6061e-06 - dense_104_loss: 1.3551e-06 - dense_105_loss: 1.7811e-06 - dense_106_loss: 1.3521e-06 - val_loss: 1.0604e-05 - val_dense_99_loss: 1.3523e-06 - val_dense_100_loss: 8.7000e-07 - val_dense_101_loss: 1.1988e-06 - val_dense_102_loss: 1.5615e-06 - val_dense_103_loss: 1.7330e-06 - val_dense_104_loss: 1.1090e-06 - val_dense_105_loss: 1.6353e-06 - val_dense_106_loss: 1.1439e-06\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3998e-06 - dense_99_loss: 7.5888e-07 - dense_100_loss: 8.0278e-07 - dense_101_loss: 7.8501e-07 - dense_102_loss: 8.7917e-07 - dense_103_loss: 1.1456e-06 - dense_104_loss: 8.4867e-07 - dense_105_loss: 1.2986e-06 - dense_106_loss: 8.8104e-07 - val_loss: 7.7157e-06 - val_dense_99_loss: 7.9261e-07 - val_dense_100_loss: 1.1186e-06 - val_dense_101_loss: 9.8310e-07 - val_dense_102_loss: 6.0613e-07 - val_dense_103_loss: 1.2825e-06 - val_dense_104_loss: 9.6360e-07 - val_dense_105_loss: 1.2564e-06 - val_dense_106_loss: 7.1282e-07\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6171e-06 - dense_99_loss: 1.0528e-06 - dense_100_loss: 1.1246e-06 - dense_101_loss: 1.1684e-06 - dense_102_loss: 1.0302e-06 - dense_103_loss: 1.4379e-06 - dense_104_loss: 1.0747e-06 - dense_105_loss: 1.5764e-06 - dense_106_loss: 1.1520e-06 - val_loss: 5.3767e-06 - val_dense_99_loss: 5.4424e-07 - val_dense_100_loss: 6.7834e-07 - val_dense_101_loss: 6.3738e-07 - val_dense_102_loss: 4.4066e-07 - val_dense_103_loss: 9.3660e-07 - val_dense_104_loss: 5.5505e-07 - val_dense_105_loss: 9.9761e-07 - val_dense_106_loss: 5.8679e-07\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5851e-06 - dense_99_loss: 5.5692e-07 - dense_100_loss: 5.9511e-07 - dense_101_loss: 6.3274e-07 - dense_102_loss: 5.5290e-07 - dense_103_loss: 9.3671e-07 - dense_104_loss: 6.3680e-07 - dense_105_loss: 9.9260e-07 - dense_106_loss: 6.8128e-07 - val_loss: 6.1443e-06 - val_dense_99_loss: 8.5621e-07 - val_dense_100_loss: 7.3247e-07 - val_dense_101_loss: 4.7019e-07 - val_dense_102_loss: 4.9395e-07 - val_dense_103_loss: 9.7456e-07 - val_dense_104_loss: 7.1947e-07 - val_dense_105_loss: 1.0981e-06 - val_dense_106_loss: 7.9929e-07\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3115e-06 - dense_99_loss: 6.8919e-07 - dense_100_loss: 6.5632e-07 - dense_101_loss: 7.2597e-07 - dense_102_loss: 7.2971e-07 - dense_103_loss: 9.7789e-07 - dense_104_loss: 7.4374e-07 - dense_105_loss: 1.0605e-06 - dense_106_loss: 7.2819e-07 - val_loss: 5.3849e-06 - val_dense_99_loss: 5.2890e-07 - val_dense_100_loss: 6.6006e-07 - val_dense_101_loss: 5.4863e-07 - val_dense_102_loss: 5.6127e-07 - val_dense_103_loss: 9.2553e-07 - val_dense_104_loss: 6.8354e-07 - val_dense_105_loss: 8.8882e-07 - val_dense_106_loss: 5.8818e-07\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6537e-06 - dense_99_loss: 6.6015e-07 - dense_100_loss: 7.1430e-07 - dense_101_loss: 7.4874e-07 - dense_102_loss: 8.1033e-07 - dense_103_loss: 1.0198e-06 - dense_104_loss: 8.0825e-07 - dense_105_loss: 1.0712e-06 - dense_106_loss: 8.2091e-07 - val_loss: 7.7991e-06 - val_dense_99_loss: 8.0977e-07 - val_dense_100_loss: 1.1058e-06 - val_dense_101_loss: 6.3626e-07 - val_dense_102_loss: 9.3749e-07 - val_dense_103_loss: 1.2741e-06 - val_dense_104_loss: 7.8175e-07 - val_dense_105_loss: 1.1734e-06 - val_dense_106_loss: 1.0805e-06\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.0935e-06 - dense_99_loss: 6.9673e-07 - dense_100_loss: 8.6559e-07 - dense_101_loss: 7.4892e-07 - dense_102_loss: 8.1793e-07 - dense_103_loss: 1.1176e-06 - dense_104_loss: 8.5074e-07 - dense_105_loss: 1.1676e-06 - dense_106_loss: 8.2848e-07 - val_loss: 6.7485e-06 - val_dense_99_loss: 6.5746e-07 - val_dense_100_loss: 7.3393e-07 - val_dense_101_loss: 7.3972e-07 - val_dense_102_loss: 7.1652e-07 - val_dense_103_loss: 1.0735e-06 - val_dense_104_loss: 6.7999e-07 - val_dense_105_loss: 1.2022e-06 - val_dense_106_loss: 9.4515e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1800e-06 - dense_99_loss: 6.7065e-07 - dense_100_loss: 6.5536e-07 - dense_101_loss: 6.9356e-07 - dense_102_loss: 6.3969e-07 - dense_103_loss: 9.7891e-07 - dense_104_loss: 6.9128e-07 - dense_105_loss: 1.0717e-06 - dense_106_loss: 7.7879e-07 - val_loss: 7.8626e-06 - val_dense_99_loss: 7.1923e-07 - val_dense_100_loss: 1.0849e-06 - val_dense_101_loss: 8.8408e-07 - val_dense_102_loss: 1.0160e-06 - val_dense_103_loss: 1.2670e-06 - val_dense_104_loss: 7.0547e-07 - val_dense_105_loss: 1.1549e-06 - val_dense_106_loss: 1.0310e-06\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.2639e-06 - dense_99_loss: 6.1533e-07 - dense_100_loss: 6.1618e-07 - dense_101_loss: 6.9572e-07 - dense_102_loss: 7.3023e-07 - dense_103_loss: 9.7866e-07 - dense_104_loss: 7.3529e-07 - dense_105_loss: 1.0798e-06 - dense_106_loss: 8.1267e-07 - val_loss: 7.6432e-06 - val_dense_99_loss: 6.6546e-07 - val_dense_100_loss: 8.9275e-07 - val_dense_101_loss: 7.9592e-07 - val_dense_102_loss: 1.0986e-06 - val_dense_103_loss: 1.0901e-06 - val_dense_104_loss: 9.6406e-07 - val_dense_105_loss: 1.3578e-06 - val_dense_106_loss: 7.7837e-07\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8415e-06 - dense_99_loss: 6.9760e-07 - dense_100_loss: 7.3145e-07 - dense_101_loss: 7.6351e-07 - dense_102_loss: 8.3138e-07 - dense_103_loss: 1.0503e-06 - dense_104_loss: 8.2990e-07 - dense_105_loss: 1.1290e-06 - dense_106_loss: 8.0828e-07 - val_loss: 6.4583e-06 - val_dense_99_loss: 8.8143e-07 - val_dense_100_loss: 5.8318e-07 - val_dense_101_loss: 6.6215e-07 - val_dense_102_loss: 5.6050e-07 - val_dense_103_loss: 1.0155e-06 - val_dense_104_loss: 6.3366e-07 - val_dense_105_loss: 1.1358e-06 - val_dense_106_loss: 9.8621e-07\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.7831e-06 - dense_99_loss: 6.3667e-07 - dense_100_loss: 5.7684e-07 - dense_101_loss: 6.5739e-07 - dense_102_loss: 5.9058e-07 - dense_103_loss: 9.1151e-07 - dense_104_loss: 6.8456e-07 - dense_105_loss: 1.0263e-06 - dense_106_loss: 6.9929e-07 - val_loss: 5.7437e-06 - val_dense_99_loss: 6.4954e-07 - val_dense_100_loss: 5.8645e-07 - val_dense_101_loss: 7.0934e-07 - val_dense_102_loss: 5.6448e-07 - val_dense_103_loss: 8.1374e-07 - val_dense_104_loss: 6.6803e-07 - val_dense_105_loss: 1.0760e-06 - val_dense_106_loss: 6.7611e-07\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0540e-05 - dense_99_loss: 1.0980e-06 - dense_100_loss: 1.3487e-06 - dense_101_loss: 1.1476e-06 - dense_102_loss: 1.1513e-06 - dense_103_loss: 1.5134e-06 - dense_104_loss: 1.1849e-06 - dense_105_loss: 1.6925e-06 - dense_106_loss: 1.4036e-06 - val_loss: 1.2695e-05 - val_dense_99_loss: 1.3122e-06 - val_dense_100_loss: 1.7510e-06 - val_dense_101_loss: 1.3937e-06 - val_dense_102_loss: 1.7735e-06 - val_dense_103_loss: 1.5705e-06 - val_dense_104_loss: 1.0876e-06 - val_dense_105_loss: 2.0324e-06 - val_dense_106_loss: 1.7740e-06\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3443e-06 - dense_99_loss: 9.1413e-07 - dense_100_loss: 1.0950e-06 - dense_101_loss: 9.7534e-07 - dense_102_loss: 1.1209e-06 - dense_103_loss: 1.4278e-06 - dense_104_loss: 9.9908e-07 - dense_105_loss: 1.5435e-06 - dense_106_loss: 1.2686e-06 - val_loss: 6.6282e-06 - val_dense_99_loss: 5.8463e-07 - val_dense_100_loss: 5.7542e-07 - val_dense_101_loss: 7.1856e-07 - val_dense_102_loss: 7.0374e-07 - val_dense_103_loss: 1.0564e-06 - val_dense_104_loss: 8.0855e-07 - val_dense_105_loss: 1.2996e-06 - val_dense_106_loss: 8.8133e-07\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5821e-06 - dense_99_loss: 6.0248e-07 - dense_100_loss: 4.9625e-07 - dense_101_loss: 6.1930e-07 - dense_102_loss: 5.6628e-07 - dense_103_loss: 9.3891e-07 - dense_104_loss: 5.9002e-07 - dense_105_loss: 1.0594e-06 - dense_106_loss: 7.0945e-07 - val_loss: 6.3054e-06 - val_dense_99_loss: 7.0823e-07 - val_dense_100_loss: 5.7405e-07 - val_dense_101_loss: 6.1931e-07 - val_dense_102_loss: 5.7151e-07 - val_dense_103_loss: 9.8321e-07 - val_dense_104_loss: 7.4857e-07 - val_dense_105_loss: 1.2005e-06 - val_dense_106_loss: 8.9999e-07\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5058e-06 - dense_99_loss: 4.9189e-07 - dense_100_loss: 3.7744e-07 - dense_101_loss: 5.0672e-07 - dense_102_loss: 4.0499e-07 - dense_103_loss: 7.5784e-07 - dense_104_loss: 5.1847e-07 - dense_105_loss: 8.9969e-07 - dense_106_loss: 5.4880e-07 - val_loss: 4.7322e-06 - val_dense_99_loss: 4.3273e-07 - val_dense_100_loss: 4.4773e-07 - val_dense_101_loss: 5.5140e-07 - val_dense_102_loss: 4.6721e-07 - val_dense_103_loss: 8.2171e-07 - val_dense_104_loss: 5.2468e-07 - val_dense_105_loss: 8.4250e-07 - val_dense_106_loss: 6.4421e-07\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0342e-06 - dense_99_loss: 5.4252e-07 - dense_100_loss: 4.7810e-07 - dense_101_loss: 5.6271e-07 - dense_102_loss: 4.8933e-07 - dense_103_loss: 8.4125e-07 - dense_104_loss: 5.5382e-07 - dense_105_loss: 8.8975e-07 - dense_106_loss: 6.7672e-07 - val_loss: 4.8772e-06 - val_dense_99_loss: 4.8156e-07 - val_dense_100_loss: 3.3709e-07 - val_dense_101_loss: 5.8257e-07 - val_dense_102_loss: 4.1296e-07 - val_dense_103_loss: 8.8486e-07 - val_dense_104_loss: 5.4391e-07 - val_dense_105_loss: 8.8888e-07 - val_dense_106_loss: 7.4535e-07\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7724e-06 - dense_99_loss: 8.7525e-07 - dense_100_loss: 8.7043e-07 - dense_101_loss: 9.3355e-07 - dense_102_loss: 9.1676e-07 - dense_103_loss: 1.1713e-06 - dense_104_loss: 9.1236e-07 - dense_105_loss: 1.0921e-06 - dense_106_loss: 1.0006e-06 - val_loss: 7.0939e-06 - val_dense_99_loss: 8.0266e-07 - val_dense_100_loss: 6.9459e-07 - val_dense_101_loss: 7.9277e-07 - val_dense_102_loss: 6.7123e-07 - val_dense_103_loss: 1.2478e-06 - val_dense_104_loss: 9.0413e-07 - val_dense_105_loss: 1.0986e-06 - val_dense_106_loss: 8.8206e-07\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3837e-06 - dense_99_loss: 6.1849e-07 - dense_100_loss: 4.6556e-07 - dense_101_loss: 6.3041e-07 - dense_102_loss: 4.7409e-07 - dense_103_loss: 9.3994e-07 - dense_104_loss: 6.2562e-07 - dense_105_loss: 9.7063e-07 - dense_106_loss: 6.5901e-07 - val_loss: 5.3706e-06 - val_dense_99_loss: 5.0812e-07 - val_dense_100_loss: 4.0584e-07 - val_dense_101_loss: 5.5655e-07 - val_dense_102_loss: 5.1767e-07 - val_dense_103_loss: 1.1248e-06 - val_dense_104_loss: 6.7401e-07 - val_dense_105_loss: 1.0602e-06 - val_dense_106_loss: 5.2339e-07\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0940e-06 - dense_99_loss: 5.3362e-07 - dense_100_loss: 4.3683e-07 - dense_101_loss: 5.7454e-07 - dense_102_loss: 4.7886e-07 - dense_103_loss: 8.5246e-07 - dense_104_loss: 5.8735e-07 - dense_105_loss: 1.0205e-06 - dense_106_loss: 6.0989e-07 - val_loss: 5.7278e-06 - val_dense_99_loss: 5.7032e-07 - val_dense_100_loss: 5.9555e-07 - val_dense_101_loss: 7.8060e-07 - val_dense_102_loss: 5.4856e-07 - val_dense_103_loss: 9.7015e-07 - val_dense_104_loss: 5.5679e-07 - val_dense_105_loss: 1.0579e-06 - val_dense_106_loss: 6.4792e-07\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.1767e-06 - dense_99_loss: 5.1737e-07 - dense_100_loss: 5.3193e-07 - dense_101_loss: 6.2928e-07 - dense_102_loss: 4.7147e-07 - dense_103_loss: 8.7908e-07 - dense_104_loss: 6.0247e-07 - dense_105_loss: 9.3038e-07 - dense_106_loss: 6.1476e-07 - val_loss: 6.9917e-06 - val_dense_99_loss: 8.1353e-07 - val_dense_100_loss: 6.0884e-07 - val_dense_101_loss: 7.7747e-07 - val_dense_102_loss: 7.0045e-07 - val_dense_103_loss: 1.3677e-06 - val_dense_104_loss: 9.0414e-07 - val_dense_105_loss: 1.0854e-06 - val_dense_106_loss: 7.3418e-07\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7731e-06 - dense_99_loss: 7.4211e-07 - dense_100_loss: 5.8759e-07 - dense_101_loss: 7.4788e-07 - dense_102_loss: 7.6851e-07 - dense_103_loss: 1.1007e-06 - dense_104_loss: 8.6571e-07 - dense_105_loss: 1.1683e-06 - dense_106_loss: 7.9230e-07 - val_loss: 5.5639e-06 - val_dense_99_loss: 6.1296e-07 - val_dense_100_loss: 6.0799e-07 - val_dense_101_loss: 6.7774e-07 - val_dense_102_loss: 4.9963e-07 - val_dense_103_loss: 8.0666e-07 - val_dense_104_loss: 5.5103e-07 - val_dense_105_loss: 1.0224e-06 - val_dense_106_loss: 7.8545e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.1978e-06 - dense_99_loss: 5.7395e-07 - dense_100_loss: 4.5797e-07 - dense_101_loss: 6.0806e-07 - dense_102_loss: 4.7505e-07 - dense_103_loss: 9.1992e-07 - dense_104_loss: 5.6879e-07 - dense_105_loss: 9.8358e-07 - dense_106_loss: 6.1049e-07 - val_loss: 5.9653e-06 - val_dense_99_loss: 7.9010e-07 - val_dense_100_loss: 6.2399e-07 - val_dense_101_loss: 5.3467e-07 - val_dense_102_loss: 5.0954e-07 - val_dense_103_loss: 1.0951e-06 - val_dense_104_loss: 6.8204e-07 - val_dense_105_loss: 1.0851e-06 - val_dense_106_loss: 6.4482e-07\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3138e-06 - dense_99_loss: 7.5822e-07 - dense_100_loss: 5.7134e-07 - dense_101_loss: 6.9587e-07 - dense_102_loss: 6.2122e-07 - dense_103_loss: 1.0046e-06 - dense_104_loss: 7.9201e-07 - dense_105_loss: 1.1409e-06 - dense_106_loss: 7.2967e-07 - val_loss: 6.5329e-06 - val_dense_99_loss: 8.2089e-07 - val_dense_100_loss: 7.7274e-07 - val_dense_101_loss: 5.9121e-07 - val_dense_102_loss: 5.4218e-07 - val_dense_103_loss: 1.0185e-06 - val_dense_104_loss: 6.5682e-07 - val_dense_105_loss: 1.1447e-06 - val_dense_106_loss: 9.8579e-07\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1516e-06 - dense_99_loss: 6.6088e-07 - dense_100_loss: 6.1738e-07 - dense_101_loss: 6.3149e-07 - dense_102_loss: 6.5565e-07 - dense_103_loss: 9.3441e-07 - dense_104_loss: 7.3798e-07 - dense_105_loss: 1.1009e-06 - dense_106_loss: 8.1290e-07 - val_loss: 5.0586e-06 - val_dense_99_loss: 5.1373e-07 - val_dense_100_loss: 3.5086e-07 - val_dense_101_loss: 5.7489e-07 - val_dense_102_loss: 5.8355e-07 - val_dense_103_loss: 9.3029e-07 - val_dense_104_loss: 4.5081e-07 - val_dense_105_loss: 1.0063e-06 - val_dense_106_loss: 6.4815e-07\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.6912e-06 - dense_99_loss: 4.7491e-07 - dense_100_loss: 3.9234e-07 - dense_101_loss: 5.7456e-07 - dense_102_loss: 4.2754e-07 - dense_103_loss: 8.1719e-07 - dense_104_loss: 5.0956e-07 - dense_105_loss: 9.1935e-07 - dense_106_loss: 5.7579e-07 - val_loss: 5.5142e-06 - val_dense_99_loss: 6.6006e-07 - val_dense_100_loss: 4.7671e-07 - val_dense_101_loss: 7.8915e-07 - val_dense_102_loss: 5.4221e-07 - val_dense_103_loss: 8.4121e-07 - val_dense_104_loss: 6.3232e-07 - val_dense_105_loss: 8.8534e-07 - val_dense_106_loss: 6.8723e-07\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.4890e-06 - dense_99_loss: 9.7530e-07 - dense_100_loss: 8.7779e-07 - dense_101_loss: 9.6982e-07 - dense_102_loss: 1.0337e-06 - dense_103_loss: 1.2216e-06 - dense_104_loss: 1.0641e-06 - dense_105_loss: 1.3399e-06 - dense_106_loss: 1.0069e-06 - val_loss: 1.0126e-05 - val_dense_99_loss: 9.6348e-07 - val_dense_100_loss: 1.0072e-06 - val_dense_101_loss: 1.1107e-06 - val_dense_102_loss: 1.3694e-06 - val_dense_103_loss: 1.1346e-06 - val_dense_104_loss: 1.6413e-06 - val_dense_105_loss: 1.5015e-06 - val_dense_106_loss: 1.3980e-06\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.9427e-06 - dense_99_loss: 5.9547e-07 - dense_100_loss: 5.9518e-07 - dense_101_loss: 6.5613e-07 - dense_102_loss: 5.8365e-07 - dense_103_loss: 9.9055e-07 - dense_104_loss: 6.8125e-07 - dense_105_loss: 1.0502e-06 - dense_106_loss: 7.9027e-07 - val_loss: 6.5248e-06 - val_dense_99_loss: 8.7825e-07 - val_dense_100_loss: 6.8107e-07 - val_dense_101_loss: 5.3699e-07 - val_dense_102_loss: 5.4064e-07 - val_dense_103_loss: 1.0883e-06 - val_dense_104_loss: 9.2472e-07 - val_dense_105_loss: 1.0180e-06 - val_dense_106_loss: 8.5686e-07\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.4347e-06 - dense_99_loss: 5.5182e-07 - dense_100_loss: 5.3507e-07 - dense_101_loss: 5.6622e-07 - dense_102_loss: 5.8029e-07 - dense_103_loss: 9.1646e-07 - dense_104_loss: 6.4319e-07 - dense_105_loss: 9.5521e-07 - dense_106_loss: 6.8644e-07 - val_loss: 5.7511e-06 - val_dense_99_loss: 8.1072e-07 - val_dense_100_loss: 6.0104e-07 - val_dense_101_loss: 5.4785e-07 - val_dense_102_loss: 3.4546e-07 - val_dense_103_loss: 1.0316e-06 - val_dense_104_loss: 6.7202e-07 - val_dense_105_loss: 1.1345e-06 - val_dense_106_loss: 6.0795e-07\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3367e-06 - dense_99_loss: 5.7177e-07 - dense_100_loss: 5.3895e-07 - dense_101_loss: 6.2269e-07 - dense_102_loss: 4.7659e-07 - dense_103_loss: 8.8998e-07 - dense_104_loss: 5.7933e-07 - dense_105_loss: 9.9712e-07 - dense_106_loss: 6.6030e-07 - val_loss: 5.1439e-06 - val_dense_99_loss: 5.3117e-07 - val_dense_100_loss: 4.9089e-07 - val_dense_101_loss: 6.5367e-07 - val_dense_102_loss: 3.8026e-07 - val_dense_103_loss: 9.2334e-07 - val_dense_104_loss: 6.5443e-07 - val_dense_105_loss: 9.3397e-07 - val_dense_106_loss: 5.7619e-07\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0920e-06 - dense_99_loss: 5.3919e-07 - dense_100_loss: 4.5967e-07 - dense_101_loss: 6.1541e-07 - dense_102_loss: 4.5191e-07 - dense_103_loss: 9.1591e-07 - dense_104_loss: 5.4544e-07 - dense_105_loss: 9.4487e-07 - dense_106_loss: 6.1964e-07 - val_loss: 4.8555e-06 - val_dense_99_loss: 4.4126e-07 - val_dense_100_loss: 3.4041e-07 - val_dense_101_loss: 5.5338e-07 - val_dense_102_loss: 3.8371e-07 - val_dense_103_loss: 9.2256e-07 - val_dense_104_loss: 5.5720e-07 - val_dense_105_loss: 1.0117e-06 - val_dense_106_loss: 6.4528e-07\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2753e-06 - dense_99_loss: 5.7167e-07 - dense_100_loss: 4.3303e-07 - dense_101_loss: 6.4861e-07 - dense_102_loss: 4.4233e-07 - dense_103_loss: 8.9187e-07 - dense_104_loss: 6.0162e-07 - dense_105_loss: 1.0205e-06 - dense_106_loss: 6.6566e-07 - val_loss: 5.6877e-06 - val_dense_99_loss: 6.5265e-07 - val_dense_100_loss: 4.7095e-07 - val_dense_101_loss: 6.7095e-07 - val_dense_102_loss: 4.0969e-07 - val_dense_103_loss: 1.0806e-06 - val_dense_104_loss: 7.4365e-07 - val_dense_105_loss: 9.5748e-07 - val_dense_106_loss: 7.0174e-07\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0731e-06 - dense_99_loss: 7.4294e-07 - dense_100_loss: 6.7478e-07 - dense_101_loss: 8.3149e-07 - dense_102_loss: 7.3697e-07 - dense_103_loss: 1.0507e-06 - dense_104_loss: 8.6280e-07 - dense_105_loss: 1.2545e-06 - dense_106_loss: 9.1893e-07 - val_loss: 5.9745e-06 - val_dense_99_loss: 6.1503e-07 - val_dense_100_loss: 5.4062e-07 - val_dense_101_loss: 6.5529e-07 - val_dense_102_loss: 4.9082e-07 - val_dense_103_loss: 8.1680e-07 - val_dense_104_loss: 7.4200e-07 - val_dense_105_loss: 1.0830e-06 - val_dense_106_loss: 1.0309e-06\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.4792e-06 - dense_99_loss: 5.9766e-07 - dense_100_loss: 4.5245e-07 - dense_101_loss: 6.8663e-07 - dense_102_loss: 5.0967e-07 - dense_103_loss: 8.5533e-07 - dense_104_loss: 6.8096e-07 - dense_105_loss: 1.0074e-06 - dense_106_loss: 6.8910e-07 - val_loss: 5.4946e-06 - val_dense_99_loss: 7.1522e-07 - val_dense_100_loss: 3.6761e-07 - val_dense_101_loss: 6.6808e-07 - val_dense_102_loss: 5.2361e-07 - val_dense_103_loss: 1.0081e-06 - val_dense_104_loss: 5.5770e-07 - val_dense_105_loss: 1.0200e-06 - val_dense_106_loss: 6.3431e-07\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7439e-06 - dense_99_loss: 7.7290e-07 - dense_100_loss: 6.1582e-07 - dense_101_loss: 7.8559e-07 - dense_102_loss: 6.5527e-07 - dense_103_loss: 1.1088e-06 - dense_104_loss: 8.0539e-07 - dense_105_loss: 1.1477e-06 - dense_106_loss: 8.5248e-07 - val_loss: 9.2124e-06 - val_dense_99_loss: 1.1463e-06 - val_dense_100_loss: 6.7847e-07 - val_dense_101_loss: 1.3239e-06 - val_dense_102_loss: 9.6475e-07 - val_dense_103_loss: 1.3669e-06 - val_dense_104_loss: 1.0701e-06 - val_dense_105_loss: 1.4510e-06 - val_dense_106_loss: 1.2110e-06\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.1545e-06 - dense_99_loss: 9.2550e-07 - dense_100_loss: 1.0134e-06 - dense_101_loss: 9.9498e-07 - dense_102_loss: 1.2768e-06 - dense_103_loss: 1.3440e-06 - dense_104_loss: 1.0728e-06 - dense_105_loss: 1.4988e-06 - dense_106_loss: 1.0282e-06 - val_loss: 6.2742e-06 - val_dense_99_loss: 6.6695e-07 - val_dense_100_loss: 6.1147e-07 - val_dense_101_loss: 7.3614e-07 - val_dense_102_loss: 9.1385e-07 - val_dense_103_loss: 9.7532e-07 - val_dense_104_loss: 7.1480e-07 - val_dense_105_loss: 1.0777e-06 - val_dense_106_loss: 5.7796e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00098: early stopping\n",
      "\n",
      "Now training model 2/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 4.5025e-05 - dense_109_loss: 1.5105e-05 - dense_110_loss: 1.7211e-05 - dense_111_loss: 1.2709e-05 - val_loss: 1.3702e-05 - val_dense_109_loss: 4.2329e-06 - val_dense_110_loss: 4.8784e-06 - val_dense_111_loss: 4.5911e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.2145e-06 - dense_109_loss: 2.0200e-06 - dense_110_loss: 2.3349e-06 - dense_111_loss: 1.8597e-06 - val_loss: 3.2585e-06 - val_dense_109_loss: 1.0598e-06 - val_dense_110_loss: 1.5072e-06 - val_dense_111_loss: 6.9153e-07\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3146e-06 - dense_109_loss: 7.4047e-07 - dense_110_loss: 1.0339e-06 - dense_111_loss: 5.4026e-07 - val_loss: 2.0424e-06 - val_dense_109_loss: 6.1091e-07 - val_dense_110_loss: 1.0185e-06 - val_dense_111_loss: 4.1292e-07\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7252e-06 - dense_109_loss: 5.3140e-07 - dense_110_loss: 8.4667e-07 - dense_111_loss: 3.4708e-07 - val_loss: 1.8709e-06 - val_dense_109_loss: 5.2234e-07 - val_dense_110_loss: 9.7069e-07 - val_dense_111_loss: 3.7787e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6121e-06 - dense_109_loss: 4.9428e-07 - dense_110_loss: 8.0172e-07 - dense_111_loss: 3.1612e-07 - val_loss: 1.7641e-06 - val_dense_109_loss: 5.1521e-07 - val_dense_110_loss: 9.0290e-07 - val_dense_111_loss: 3.4600e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5589e-06 - dense_109_loss: 4.8350e-07 - dense_110_loss: 7.7145e-07 - dense_111_loss: 3.0395e-07 - val_loss: 2.0185e-06 - val_dense_109_loss: 6.4999e-07 - val_dense_110_loss: 9.5544e-07 - val_dense_111_loss: 4.1311e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6217e-06 - dense_109_loss: 5.1681e-07 - dense_110_loss: 7.7926e-07 - dense_111_loss: 3.2567e-07 - val_loss: 1.7210e-06 - val_dense_109_loss: 4.9965e-07 - val_dense_110_loss: 8.5190e-07 - val_dense_111_loss: 3.6941e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5175e-06 - dense_109_loss: 4.8083e-07 - dense_110_loss: 7.2827e-07 - dense_111_loss: 3.0837e-07 - val_loss: 1.9918e-06 - val_dense_109_loss: 6.2043e-07 - val_dense_110_loss: 9.1511e-07 - val_dense_111_loss: 4.5626e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5396e-06 - dense_109_loss: 4.9484e-07 - dense_110_loss: 7.3459e-07 - dense_111_loss: 3.1013e-07 - val_loss: 1.8545e-06 - val_dense_109_loss: 5.7455e-07 - val_dense_110_loss: 8.7393e-07 - val_dense_111_loss: 4.0597e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4539e-06 - dense_109_loss: 4.6706e-07 - dense_110_loss: 6.9465e-07 - dense_111_loss: 2.9221e-07 - val_loss: 1.5809e-06 - val_dense_109_loss: 5.0343e-07 - val_dense_110_loss: 7.6702e-07 - val_dense_111_loss: 3.1047e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3967e-06 - dense_109_loss: 4.6158e-07 - dense_110_loss: 6.5565e-07 - dense_111_loss: 2.7944e-07 - val_loss: 1.6017e-06 - val_dense_109_loss: 5.0668e-07 - val_dense_110_loss: 7.7225e-07 - val_dense_111_loss: 3.2277e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3594e-06 - dense_109_loss: 4.5486e-07 - dense_110_loss: 6.3381e-07 - dense_111_loss: 2.7076e-07 - val_loss: 1.5477e-06 - val_dense_109_loss: 4.7524e-07 - val_dense_110_loss: 7.3447e-07 - val_dense_111_loss: 3.3802e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3959e-06 - dense_109_loss: 4.6448e-07 - dense_110_loss: 6.3681e-07 - dense_111_loss: 2.9465e-07 - val_loss: 1.4416e-06 - val_dense_109_loss: 4.6680e-07 - val_dense_110_loss: 6.9273e-07 - val_dense_111_loss: 2.8208e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3142e-06 - dense_109_loss: 4.4629e-07 - dense_110_loss: 5.9889e-07 - dense_111_loss: 2.6903e-07 - val_loss: 1.7189e-06 - val_dense_109_loss: 5.7172e-07 - val_dense_110_loss: 7.3712e-07 - val_dense_111_loss: 4.1002e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3679e-06 - dense_109_loss: 4.6487e-07 - dense_110_loss: 6.1281e-07 - dense_111_loss: 2.9023e-07 - val_loss: 1.3971e-06 - val_dense_109_loss: 4.6051e-07 - val_dense_110_loss: 6.5559e-07 - val_dense_111_loss: 2.8095e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3069e-06 - dense_109_loss: 4.4856e-07 - dense_110_loss: 5.8463e-07 - dense_111_loss: 2.7368e-07 - val_loss: 1.5543e-06 - val_dense_109_loss: 5.1590e-07 - val_dense_110_loss: 6.8105e-07 - val_dense_111_loss: 3.5730e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4210e-06 - dense_109_loss: 4.9209e-07 - dense_110_loss: 6.0838e-07 - dense_111_loss: 3.2057e-07 - val_loss: 1.7513e-06 - val_dense_109_loss: 5.2835e-07 - val_dense_110_loss: 8.6581e-07 - val_dense_111_loss: 3.5710e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6903e-06 - dense_109_loss: 5.8012e-07 - dense_110_loss: 7.0092e-07 - dense_111_loss: 4.0924e-07 - val_loss: 1.6040e-06 - val_dense_109_loss: 5.3546e-07 - val_dense_110_loss: 7.3958e-07 - val_dense_111_loss: 3.2892e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4352e-06 - dense_109_loss: 4.9946e-07 - dense_110_loss: 6.1666e-07 - dense_111_loss: 3.1909e-07 - val_loss: 1.4579e-06 - val_dense_109_loss: 5.1809e-07 - val_dense_110_loss: 6.5053e-07 - val_dense_111_loss: 2.8928e-07\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2999e-06 - dense_109_loss: 4.5939e-07 - dense_110_loss: 5.6304e-07 - dense_111_loss: 2.7748e-07 - val_loss: 1.6127e-06 - val_dense_109_loss: 5.6154e-07 - val_dense_110_loss: 6.0297e-07 - val_dense_111_loss: 4.4824e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3710e-06 - dense_109_loss: 4.7388e-07 - dense_110_loss: 5.8713e-07 - dense_111_loss: 3.1003e-07 - val_loss: 1.7388e-06 - val_dense_109_loss: 5.2831e-07 - val_dense_110_loss: 8.1250e-07 - val_dense_111_loss: 3.9802e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5709e-06 - dense_109_loss: 5.4759e-07 - dense_110_loss: 6.5404e-07 - dense_111_loss: 3.6931e-07 - val_loss: 1.3754e-06 - val_dense_109_loss: 4.7337e-07 - val_dense_110_loss: 6.1506e-07 - val_dense_111_loss: 2.8698e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6024e-06 - dense_109_loss: 5.2005e-07 - dense_110_loss: 6.6194e-07 - dense_111_loss: 4.2040e-07 - val_loss: 2.7431e-06 - val_dense_109_loss: 6.5846e-07 - val_dense_110_loss: 1.0684e-06 - val_dense_111_loss: 1.0162e-06\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6807e-06 - dense_109_loss: 5.4765e-07 - dense_110_loss: 6.6238e-07 - dense_111_loss: 4.7065e-07 - val_loss: 1.9281e-06 - val_dense_109_loss: 7.1291e-07 - val_dense_110_loss: 7.7206e-07 - val_dense_111_loss: 4.4314e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6018e-06 - dense_109_loss: 5.8687e-07 - dense_110_loss: 6.2167e-07 - dense_111_loss: 3.9330e-07 - val_loss: 1.8029e-06 - val_dense_109_loss: 5.5410e-07 - val_dense_110_loss: 8.3596e-07 - val_dense_111_loss: 4.1285e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6744e-06 - dense_109_loss: 5.6936e-07 - dense_110_loss: 7.0804e-07 - dense_111_loss: 3.9703e-07 - val_loss: 1.9440e-06 - val_dense_109_loss: 7.0650e-07 - val_dense_110_loss: 7.7521e-07 - val_dense_111_loss: 4.6232e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4009e-06 - dense_109_loss: 4.8970e-07 - dense_110_loss: 5.8384e-07 - dense_111_loss: 3.2733e-07 - val_loss: 1.4783e-06 - val_dense_109_loss: 5.6789e-07 - val_dense_110_loss: 5.5104e-07 - val_dense_111_loss: 3.5934e-07\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4528e-06 - dense_109_loss: 4.8958e-07 - dense_110_loss: 5.9384e-07 - dense_111_loss: 3.6938e-07 - val_loss: 1.7001e-06 - val_dense_109_loss: 6.2241e-07 - val_dense_110_loss: 6.2025e-07 - val_dense_111_loss: 4.5742e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4823e-06 - dense_109_loss: 5.0944e-07 - dense_110_loss: 5.9151e-07 - dense_111_loss: 3.8131e-07 - val_loss: 1.9454e-06 - val_dense_109_loss: 5.1887e-07 - val_dense_110_loss: 8.4200e-07 - val_dense_111_loss: 5.8451e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5763e-06 - dense_109_loss: 5.4818e-07 - dense_110_loss: 6.1724e-07 - dense_111_loss: 4.1085e-07 - val_loss: 2.7816e-06 - val_dense_109_loss: 7.6907e-07 - val_dense_110_loss: 1.2580e-06 - val_dense_111_loss: 7.5448e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8797e-06 - dense_109_loss: 5.7345e-07 - dense_110_loss: 8.0347e-07 - dense_111_loss: 5.0278e-07 - val_loss: 1.1470e-06 - val_dense_109_loss: 4.0121e-07 - val_dense_110_loss: 5.2856e-07 - val_dense_111_loss: 2.1724e-07\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4673e-06 - dense_109_loss: 4.7275e-07 - dense_110_loss: 6.4178e-07 - dense_111_loss: 3.5276e-07 - val_loss: 1.9915e-06 - val_dense_109_loss: 4.7184e-07 - val_dense_110_loss: 1.0448e-06 - val_dense_111_loss: 4.7482e-07\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3577e-06 - dense_109_loss: 4.7130e-07 - dense_110_loss: 5.7253e-07 - dense_111_loss: 3.1386e-07 - val_loss: 1.3046e-06 - val_dense_109_loss: 4.2888e-07 - val_dense_110_loss: 5.3661e-07 - val_dense_111_loss: 3.3913e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1207e-06 - dense_109_loss: 4.0929e-07 - dense_110_loss: 4.7622e-07 - dense_111_loss: 2.3523e-07 - val_loss: 1.3434e-06 - val_dense_109_loss: 5.0207e-07 - val_dense_110_loss: 5.5854e-07 - val_dense_111_loss: 2.8283e-07\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4577e-06 - dense_109_loss: 4.7035e-07 - dense_110_loss: 6.2517e-07 - dense_111_loss: 3.6217e-07 - val_loss: 1.3130e-06 - val_dense_109_loss: 4.6780e-07 - val_dense_110_loss: 5.7535e-07 - val_dense_111_loss: 2.6990e-07\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5176e-06 - dense_109_loss: 5.2448e-07 - dense_110_loss: 6.2070e-07 - dense_111_loss: 3.7244e-07 - val_loss: 1.9238e-06 - val_dense_109_loss: 7.7753e-07 - val_dense_110_loss: 6.7579e-07 - val_dense_111_loss: 4.7045e-07\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3130e-06 - dense_109_loss: 4.6027e-07 - dense_110_loss: 5.4471e-07 - dense_111_loss: 3.0801e-07 - val_loss: 1.4510e-06 - val_dense_109_loss: 5.1122e-07 - val_dense_110_loss: 6.0632e-07 - val_dense_111_loss: 3.3341e-07\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4653e-06 - dense_109_loss: 4.8283e-07 - dense_110_loss: 5.9285e-07 - dense_111_loss: 3.8967e-07 - val_loss: 1.8279e-06 - val_dense_109_loss: 5.7420e-07 - val_dense_110_loss: 7.6500e-07 - val_dense_111_loss: 4.8866e-07\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8304e-06 - dense_109_loss: 5.7082e-07 - dense_110_loss: 7.5517e-07 - dense_111_loss: 5.0440e-07 - val_loss: 1.8897e-06 - val_dense_109_loss: 6.1739e-07 - val_dense_110_loss: 7.5381e-07 - val_dense_111_loss: 5.1845e-07\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2838e-06 - dense_109_loss: 4.4429e-07 - dense_110_loss: 5.4588e-07 - dense_111_loss: 2.9360e-07 - val_loss: 1.5562e-06 - val_dense_109_loss: 5.7937e-07 - val_dense_110_loss: 5.7285e-07 - val_dense_111_loss: 4.0394e-07\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1203e-06 - dense_109_loss: 4.1730e-07 - dense_110_loss: 4.7506e-07 - dense_111_loss: 2.2790e-07 - val_loss: 1.6017e-06 - val_dense_109_loss: 6.7181e-07 - val_dense_110_loss: 6.3422e-07 - val_dense_111_loss: 2.9569e-07\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.9221e-06 - dense_109_loss: 5.8317e-07 - dense_110_loss: 8.0587e-07 - dense_111_loss: 5.3303e-07 - val_loss: 2.3975e-06 - val_dense_109_loss: 6.9964e-07 - val_dense_110_loss: 8.1314e-07 - val_dense_111_loss: 8.8471e-07\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1379e-06 - dense_109_loss: 7.3864e-07 - dense_110_loss: 8.3368e-07 - dense_111_loss: 5.6559e-07 - val_loss: 1.5579e-06 - val_dense_109_loss: 5.4297e-07 - val_dense_110_loss: 5.5405e-07 - val_dense_111_loss: 4.6091e-07\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4989e-06 - dense_109_loss: 5.1921e-07 - dense_110_loss: 5.7163e-07 - dense_111_loss: 4.0804e-07 - val_loss: 1.4477e-06 - val_dense_109_loss: 5.2996e-07 - val_dense_110_loss: 5.7505e-07 - val_dense_111_loss: 3.4268e-07\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1788e-06 - dense_109_loss: 4.2209e-07 - dense_110_loss: 4.9130e-07 - dense_111_loss: 2.6539e-07 - val_loss: 1.3779e-06 - val_dense_109_loss: 4.6198e-07 - val_dense_110_loss: 6.1432e-07 - val_dense_111_loss: 3.0158e-07\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0929e-06 - dense_109_loss: 4.0979e-07 - dense_110_loss: 4.6262e-07 - dense_111_loss: 2.2048e-07 - val_loss: 1.4587e-06 - val_dense_109_loss: 5.3213e-07 - val_dense_110_loss: 6.0287e-07 - val_dense_111_loss: 3.2369e-07\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4704e-06 - dense_109_loss: 5.1823e-07 - dense_110_loss: 6.1324e-07 - dense_111_loss: 3.3894e-07 - val_loss: 1.2657e-06 - val_dense_109_loss: 4.3444e-07 - val_dense_110_loss: 6.0742e-07 - val_dense_111_loss: 2.2380e-07\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0883e-06 - dense_109_loss: 3.9233e-07 - dense_110_loss: 4.6494e-07 - dense_111_loss: 2.3108e-07 - val_loss: 1.0810e-06 - val_dense_109_loss: 4.1902e-07 - val_dense_110_loss: 4.6457e-07 - val_dense_111_loss: 1.9744e-07\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3435e-06 - dense_109_loss: 4.7841e-07 - dense_110_loss: 5.6220e-07 - dense_111_loss: 3.0287e-07 - val_loss: 1.5131e-06 - val_dense_109_loss: 4.9296e-07 - val_dense_110_loss: 5.8556e-07 - val_dense_111_loss: 4.3455e-07\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3347e-06 - dense_109_loss: 4.9027e-07 - dense_110_loss: 5.2757e-07 - dense_111_loss: 3.1691e-07 - val_loss: 1.8391e-06 - val_dense_109_loss: 5.4918e-07 - val_dense_110_loss: 7.8730e-07 - val_dense_111_loss: 5.0259e-07\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3499e-06 - dense_109_loss: 4.6954e-07 - dense_110_loss: 5.8197e-07 - dense_111_loss: 2.9839e-07 - val_loss: 1.5007e-06 - val_dense_109_loss: 4.8359e-07 - val_dense_110_loss: 6.2649e-07 - val_dense_111_loss: 3.9066e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00051: early stopping\n",
      "\n",
      "Now training model 3/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 4.2781e-05 - dense_114_loss: 1.4536e-05 - dense_115_loss: 1.1233e-05 - dense_116_loss: 1.7012e-05 - val_loss: 8.4111e-06 - val_dense_114_loss: 3.1885e-06 - val_dense_115_loss: 2.6766e-06 - val_dense_116_loss: 2.5460e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4204e-06 - dense_114_loss: 1.9468e-06 - dense_115_loss: 1.7423e-06 - dense_116_loss: 1.7313e-06 - val_loss: 3.3217e-06 - val_dense_114_loss: 1.2814e-06 - val_dense_115_loss: 1.0658e-06 - val_dense_116_loss: 9.7461e-07\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2858e-06 - dense_114_loss: 8.5729e-07 - dense_115_loss: 7.1169e-07 - dense_116_loss: 7.1678e-07 - val_loss: 1.8520e-06 - val_dense_114_loss: 6.7960e-07 - val_dense_115_loss: 5.8907e-07 - val_dense_116_loss: 5.8334e-07\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7853e-06 - dense_114_loss: 6.6511e-07 - dense_115_loss: 5.6903e-07 - dense_116_loss: 5.5114e-07 - val_loss: 1.7952e-06 - val_dense_114_loss: 6.5656e-07 - val_dense_115_loss: 5.8831e-07 - val_dense_116_loss: 5.5029e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7408e-06 - dense_114_loss: 6.4114e-07 - dense_115_loss: 5.5992e-07 - dense_116_loss: 5.3975e-07 - val_loss: 1.7560e-06 - val_dense_114_loss: 6.3021e-07 - val_dense_115_loss: 5.3841e-07 - val_dense_116_loss: 5.8738e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6840e-06 - dense_114_loss: 6.2746e-07 - dense_115_loss: 5.3573e-07 - dense_116_loss: 5.2082e-07 - val_loss: 1.7037e-06 - val_dense_114_loss: 6.4251e-07 - val_dense_115_loss: 5.4395e-07 - val_dense_116_loss: 5.1726e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7249e-06 - dense_114_loss: 6.4468e-07 - dense_115_loss: 5.4736e-07 - dense_116_loss: 5.3286e-07 - val_loss: 1.6609e-06 - val_dense_114_loss: 6.3067e-07 - val_dense_115_loss: 5.4851e-07 - val_dense_116_loss: 4.8168e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6408e-06 - dense_114_loss: 6.0903e-07 - dense_115_loss: 5.3870e-07 - dense_116_loss: 4.9305e-07 - val_loss: 1.8232e-06 - val_dense_114_loss: 6.6881e-07 - val_dense_115_loss: 5.8995e-07 - val_dense_116_loss: 5.6446e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7595e-06 - dense_114_loss: 6.4551e-07 - dense_115_loss: 5.5602e-07 - dense_116_loss: 5.5797e-07 - val_loss: 2.0706e-06 - val_dense_114_loss: 7.8180e-07 - val_dense_115_loss: 6.6150e-07 - val_dense_116_loss: 6.2732e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7481e-06 - dense_114_loss: 6.2979e-07 - dense_115_loss: 5.6416e-07 - dense_116_loss: 5.5412e-07 - val_loss: 1.6998e-06 - val_dense_114_loss: 7.2128e-07 - val_dense_115_loss: 5.0394e-07 - val_dense_116_loss: 4.7459e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6251e-06 - dense_114_loss: 6.1443e-07 - dense_115_loss: 5.3929e-07 - dense_116_loss: 4.7137e-07 - val_loss: 1.7686e-06 - val_dense_114_loss: 6.6838e-07 - val_dense_115_loss: 5.6759e-07 - val_dense_116_loss: 5.3262e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7121e-06 - dense_114_loss: 6.4187e-07 - dense_115_loss: 5.6701e-07 - dense_116_loss: 5.0319e-07 - val_loss: 2.8445e-06 - val_dense_114_loss: 9.5264e-07 - val_dense_115_loss: 9.1099e-07 - val_dense_116_loss: 9.8088e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.9073e-06 - dense_114_loss: 6.8163e-07 - dense_115_loss: 6.1110e-07 - dense_116_loss: 6.1454e-07 - val_loss: 2.1228e-06 - val_dense_114_loss: 7.5223e-07 - val_dense_115_loss: 6.4286e-07 - val_dense_116_loss: 7.2768e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.9537e-06 - dense_114_loss: 7.3104e-07 - dense_115_loss: 6.0921e-07 - dense_116_loss: 6.1349e-07 - val_loss: 1.8815e-06 - val_dense_114_loss: 7.0308e-07 - val_dense_115_loss: 6.4067e-07 - val_dense_116_loss: 5.3774e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6823e-06 - dense_114_loss: 6.3126e-07 - dense_115_loss: 5.6685e-07 - dense_116_loss: 4.8421e-07 - val_loss: 1.5694e-06 - val_dense_114_loss: 5.7024e-07 - val_dense_115_loss: 5.2197e-07 - val_dense_116_loss: 4.7720e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6660e-06 - dense_114_loss: 6.3695e-07 - dense_115_loss: 5.5578e-07 - dense_116_loss: 4.7326e-07 - val_loss: 2.7562e-06 - val_dense_114_loss: 9.9620e-07 - val_dense_115_loss: 9.2369e-07 - val_dense_116_loss: 8.3629e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4215e-06 - dense_114_loss: 8.5186e-07 - dense_115_loss: 7.8562e-07 - dense_116_loss: 7.8407e-07 - val_loss: 1.9032e-06 - val_dense_114_loss: 7.7172e-07 - val_dense_115_loss: 5.5720e-07 - val_dense_116_loss: 5.7424e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7580e-06 - dense_114_loss: 6.6672e-07 - dense_115_loss: 5.9781e-07 - dense_116_loss: 4.9348e-07 - val_loss: 2.2411e-06 - val_dense_114_loss: 7.1886e-07 - val_dense_115_loss: 6.6495e-07 - val_dense_116_loss: 8.5731e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6465e-06 - dense_114_loss: 6.1861e-07 - dense_115_loss: 5.4490e-07 - dense_116_loss: 4.8303e-07 - val_loss: 2.6876e-06 - val_dense_114_loss: 9.7082e-07 - val_dense_115_loss: 8.3452e-07 - val_dense_116_loss: 8.8221e-07\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.0073e-06 - dense_114_loss: 7.5847e-07 - dense_115_loss: 6.3457e-07 - dense_116_loss: 6.1424e-07 - val_loss: 2.0070e-06 - val_dense_114_loss: 6.9587e-07 - val_dense_115_loss: 7.3495e-07 - val_dense_116_loss: 5.7617e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6508e-06 - dense_114_loss: 6.2467e-07 - dense_115_loss: 5.9229e-07 - dense_116_loss: 4.3385e-07 - val_loss: 1.6794e-06 - val_dense_114_loss: 5.9478e-07 - val_dense_115_loss: 6.4583e-07 - val_dense_116_loss: 4.3879e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4128e-06 - dense_114_loss: 5.3863e-07 - dense_115_loss: 4.8220e-07 - dense_116_loss: 3.9199e-07 - val_loss: 1.5284e-06 - val_dense_114_loss: 5.4465e-07 - val_dense_115_loss: 5.6672e-07 - val_dense_116_loss: 4.1704e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5995e-06 - dense_114_loss: 6.0148e-07 - dense_115_loss: 5.5599e-07 - dense_116_loss: 4.4198e-07 - val_loss: 1.7723e-06 - val_dense_114_loss: 6.8697e-07 - val_dense_115_loss: 6.1872e-07 - val_dense_116_loss: 4.6658e-07\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5613e-06 - dense_114_loss: 5.7358e-07 - dense_115_loss: 5.2838e-07 - dense_116_loss: 4.5931e-07 - val_loss: 1.9118e-06 - val_dense_114_loss: 6.1594e-07 - val_dense_115_loss: 6.1033e-07 - val_dense_116_loss: 6.8557e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8661e-06 - dense_114_loss: 6.7760e-07 - dense_115_loss: 6.8538e-07 - dense_116_loss: 5.0316e-07 - val_loss: 2.9192e-06 - val_dense_114_loss: 1.2442e-06 - val_dense_115_loss: 8.2561e-07 - val_dense_116_loss: 8.4938e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7746e-06 - dense_114_loss: 7.0101e-07 - dense_115_loss: 5.9126e-07 - dense_116_loss: 4.8235e-07 - val_loss: 1.7770e-06 - val_dense_114_loss: 7.1413e-07 - val_dense_115_loss: 6.3910e-07 - val_dense_116_loss: 4.2373e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7824e-06 - dense_114_loss: 6.4846e-07 - dense_115_loss: 6.2466e-07 - dense_116_loss: 5.0929e-07 - val_loss: 1.3223e-06 - val_dense_114_loss: 5.3867e-07 - val_dense_115_loss: 4.9669e-07 - val_dense_116_loss: 2.8698e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4597e-06 - dense_114_loss: 5.6072e-07 - dense_115_loss: 5.2450e-07 - dense_116_loss: 3.7450e-07 - val_loss: 2.5237e-06 - val_dense_114_loss: 1.0409e-06 - val_dense_115_loss: 8.2901e-07 - val_dense_116_loss: 6.5381e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7270e-06 - dense_114_loss: 6.4856e-07 - dense_115_loss: 5.7684e-07 - dense_116_loss: 5.0163e-07 - val_loss: 1.4851e-06 - val_dense_114_loss: 5.2067e-07 - val_dense_115_loss: 5.5500e-07 - val_dense_116_loss: 4.0945e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5066e-06 - dense_114_loss: 5.7261e-07 - dense_115_loss: 5.3678e-07 - dense_116_loss: 3.9723e-07 - val_loss: 1.9300e-06 - val_dense_114_loss: 7.9654e-07 - val_dense_115_loss: 6.9665e-07 - val_dense_116_loss: 4.3684e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.9678e-06 - dense_114_loss: 7.2823e-07 - dense_115_loss: 6.6719e-07 - dense_116_loss: 5.7234e-07 - val_loss: 2.4723e-06 - val_dense_114_loss: 8.6062e-07 - val_dense_115_loss: 8.9801e-07 - val_dense_116_loss: 7.1367e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4191e-06 - dense_114_loss: 5.5517e-07 - dense_115_loss: 5.1593e-07 - dense_116_loss: 3.4804e-07 - val_loss: 1.1404e-06 - val_dense_114_loss: 4.9156e-07 - val_dense_115_loss: 4.2129e-07 - val_dense_116_loss: 2.2759e-07\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2547e-06 - dense_114_loss: 4.8718e-07 - dense_115_loss: 4.7859e-07 - dense_116_loss: 2.8897e-07 - val_loss: 1.3017e-06 - val_dense_114_loss: 5.3980e-07 - val_dense_115_loss: 4.6588e-07 - val_dense_116_loss: 2.9598e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2302e-06 - dense_114_loss: 4.8854e-07 - dense_115_loss: 4.5159e-07 - dense_116_loss: 2.9011e-07 - val_loss: 2.2280e-06 - val_dense_114_loss: 7.0648e-07 - val_dense_115_loss: 9.3683e-07 - val_dense_116_loss: 5.8468e-07\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6374e-06 - dense_114_loss: 5.6179e-07 - dense_115_loss: 5.8240e-07 - dense_116_loss: 4.9319e-07 - val_loss: 1.4800e-06 - val_dense_114_loss: 5.1503e-07 - val_dense_115_loss: 5.9247e-07 - val_dense_116_loss: 3.7246e-07\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2581e-06 - dense_114_loss: 4.7672e-07 - dense_115_loss: 4.7727e-07 - dense_116_loss: 3.0415e-07 - val_loss: 1.1348e-06 - val_dense_114_loss: 4.9585e-07 - val_dense_115_loss: 4.1189e-07 - val_dense_116_loss: 2.2710e-07\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0933e-06 - dense_114_loss: 4.3255e-07 - dense_115_loss: 4.3014e-07 - dense_116_loss: 2.3064e-07 - val_loss: 1.6796e-06 - val_dense_114_loss: 6.0374e-07 - val_dense_115_loss: 6.2745e-07 - val_dense_116_loss: 4.4840e-07\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3114e-06 - dense_114_loss: 4.9631e-07 - dense_115_loss: 4.7439e-07 - dense_116_loss: 3.4069e-07 - val_loss: 1.3712e-06 - val_dense_114_loss: 5.2793e-07 - val_dense_115_loss: 4.6199e-07 - val_dense_116_loss: 3.8130e-07\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5882e-06 - dense_114_loss: 5.8063e-07 - dense_115_loss: 5.6452e-07 - dense_116_loss: 4.4306e-07 - val_loss: 2.0727e-06 - val_dense_114_loss: 6.1458e-07 - val_dense_115_loss: 7.9674e-07 - val_dense_116_loss: 6.6140e-07\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8381e-06 - dense_114_loss: 6.8615e-07 - dense_115_loss: 6.5032e-07 - dense_116_loss: 5.0167e-07 - val_loss: 1.9068e-06 - val_dense_114_loss: 7.5937e-07 - val_dense_115_loss: 6.7379e-07 - val_dense_116_loss: 4.7367e-07\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3460e-06 - dense_114_loss: 5.3803e-07 - dense_115_loss: 5.0992e-07 - dense_116_loss: 2.9809e-07 - val_loss: 1.4584e-06 - val_dense_114_loss: 5.5353e-07 - val_dense_115_loss: 5.5490e-07 - val_dense_116_loss: 3.4998e-07\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4350e-06 - dense_114_loss: 5.3603e-07 - dense_115_loss: 5.0083e-07 - dense_116_loss: 3.9810e-07 - val_loss: 1.7354e-06 - val_dense_114_loss: 6.5677e-07 - val_dense_115_loss: 6.4625e-07 - val_dense_116_loss: 4.3240e-07\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3437e-06 - dense_114_loss: 4.9741e-07 - dense_115_loss: 4.7197e-07 - dense_116_loss: 3.7437e-07 - val_loss: 1.2423e-06 - val_dense_114_loss: 4.7849e-07 - val_dense_115_loss: 5.1664e-07 - val_dense_116_loss: 2.4715e-07\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4173e-06 - dense_114_loss: 5.3943e-07 - dense_115_loss: 5.3784e-07 - dense_116_loss: 3.4003e-07 - val_loss: 1.4611e-06 - val_dense_114_loss: 6.0390e-07 - val_dense_115_loss: 4.8223e-07 - val_dense_116_loss: 3.7500e-07\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0805e-06 - dense_114_loss: 4.2848e-07 - dense_115_loss: 4.1512e-07 - dense_116_loss: 2.3692e-07 - val_loss: 1.2435e-06 - val_dense_114_loss: 5.1852e-07 - val_dense_115_loss: 4.9571e-07 - val_dense_116_loss: 2.2932e-07\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2056e-06 - dense_114_loss: 4.8850e-07 - dense_115_loss: 4.7804e-07 - dense_116_loss: 2.3903e-07 - val_loss: 1.4137e-06 - val_dense_114_loss: 5.5986e-07 - val_dense_115_loss: 5.6243e-07 - val_dense_116_loss: 2.9136e-07\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5193e-06 - dense_114_loss: 5.6023e-07 - dense_115_loss: 5.5529e-07 - dense_116_loss: 4.0374e-07 - val_loss: 1.2915e-06 - val_dense_114_loss: 4.8326e-07 - val_dense_115_loss: 5.2522e-07 - val_dense_116_loss: 2.8301e-07\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2094e-06 - dense_114_loss: 4.6814e-07 - dense_115_loss: 4.7884e-07 - dense_116_loss: 2.6242e-07 - val_loss: 1.1317e-06 - val_dense_114_loss: 4.9638e-07 - val_dense_115_loss: 4.1381e-07 - val_dense_116_loss: 2.2149e-07\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3577e-06 - dense_114_loss: 5.1815e-07 - dense_115_loss: 4.8897e-07 - dense_116_loss: 3.5059e-07 - val_loss: 1.6248e-06 - val_dense_114_loss: 6.5803e-07 - val_dense_115_loss: 5.3287e-07 - val_dense_116_loss: 4.3386e-07\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1872e-06 - dense_114_loss: 4.6980e-07 - dense_115_loss: 4.3100e-07 - dense_116_loss: 2.8637e-07 - val_loss: 1.5896e-06 - val_dense_114_loss: 5.8595e-07 - val_dense_115_loss: 5.1549e-07 - val_dense_116_loss: 4.8811e-07\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5124e-06 - dense_114_loss: 5.6369e-07 - dense_115_loss: 5.0802e-07 - dense_116_loss: 4.4071e-07 - val_loss: 1.1173e-06 - val_dense_114_loss: 4.7322e-07 - val_dense_115_loss: 4.4596e-07 - val_dense_116_loss: 1.9812e-07\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0058e-06 - dense_114_loss: 4.0041e-07 - dense_115_loss: 3.8913e-07 - dense_116_loss: 2.1623e-07 - val_loss: 1.3454e-06 - val_dense_114_loss: 5.3823e-07 - val_dense_115_loss: 4.4866e-07 - val_dense_116_loss: 3.5853e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "\n",
      "Now training model 4/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 4.9331e-05 - dense_119_loss: 1.6248e-05 - dense_120_loss: 1.6958e-05 - dense_121_loss: 1.6125e-05 - val_loss: 1.3854e-05 - val_dense_119_loss: 4.4339e-06 - val_dense_120_loss: 5.3269e-06 - val_dense_121_loss: 4.0935e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.9872e-06 - dense_119_loss: 2.5052e-06 - dense_120_loss: 2.4593e-06 - dense_121_loss: 2.0227e-06 - val_loss: 3.9554e-06 - val_dense_119_loss: 1.4162e-06 - val_dense_120_loss: 1.5026e-06 - val_dense_121_loss: 1.0366e-06\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.9452e-06 - dense_119_loss: 1.0551e-06 - dense_120_loss: 1.0619e-06 - dense_121_loss: 8.2829e-07 - val_loss: 2.5270e-06 - val_dense_119_loss: 9.7200e-07 - val_dense_120_loss: 9.2850e-07 - val_dense_121_loss: 6.2655e-07\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3302e-06 - dense_119_loss: 8.5725e-07 - dense_120_loss: 8.0091e-07 - dense_121_loss: 6.7206e-07 - val_loss: 2.2724e-06 - val_dense_119_loss: 8.4282e-07 - val_dense_120_loss: 7.8530e-07 - val_dense_121_loss: 6.4429e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2117e-06 - dense_119_loss: 8.0927e-07 - dense_120_loss: 7.5737e-07 - dense_121_loss: 6.4511e-07 - val_loss: 2.2583e-06 - val_dense_119_loss: 8.3902e-07 - val_dense_120_loss: 7.7520e-07 - val_dense_121_loss: 6.4405e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2269e-06 - dense_119_loss: 8.1265e-07 - dense_120_loss: 7.7084e-07 - dense_121_loss: 6.4341e-07 - val_loss: 2.2026e-06 - val_dense_119_loss: 8.1414e-07 - val_dense_120_loss: 7.7332e-07 - val_dense_121_loss: 6.1518e-07\n",
      "Epoch 7/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 2.2301e-06 - dense_119_loss: 8.0993e-07 - dense_120_loss: 7.6685e-07 - dense_121_loss: 6.5333e-07 - val_loss: 2.1620e-06 - val_dense_119_loss: 7.7286e-07 - val_dense_120_loss: 7.5099e-07 - val_dense_121_loss: 6.3818e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1640e-06 - dense_119_loss: 7.8199e-07 - dense_120_loss: 7.4611e-07 - dense_121_loss: 6.3589e-07 - val_loss: 2.4028e-06 - val_dense_119_loss: 8.6886e-07 - val_dense_120_loss: 8.4572e-07 - val_dense_121_loss: 6.8820e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2086e-06 - dense_119_loss: 7.9459e-07 - dense_120_loss: 7.5806e-07 - dense_121_loss: 6.5596e-07 - val_loss: 2.4305e-06 - val_dense_119_loss: 8.8475e-07 - val_dense_120_loss: 8.3590e-07 - val_dense_121_loss: 7.0988e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3819e-06 - dense_119_loss: 8.7859e-07 - dense_120_loss: 8.1503e-07 - dense_121_loss: 6.8827e-07 - val_loss: 2.8767e-06 - val_dense_119_loss: 9.9564e-07 - val_dense_120_loss: 9.2325e-07 - val_dense_121_loss: 9.5782e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4372e-06 - dense_119_loss: 8.5724e-07 - dense_120_loss: 8.2968e-07 - dense_121_loss: 7.5026e-07 - val_loss: 2.8832e-06 - val_dense_119_loss: 1.0244e-06 - val_dense_120_loss: 1.0760e-06 - val_dense_121_loss: 7.8272e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2379e-06 - dense_119_loss: 8.0971e-07 - dense_120_loss: 7.7127e-07 - dense_121_loss: 6.5696e-07 - val_loss: 2.5067e-06 - val_dense_119_loss: 8.6797e-07 - val_dense_120_loss: 9.0520e-07 - val_dense_121_loss: 7.3349e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1952e-06 - dense_119_loss: 7.7809e-07 - dense_120_loss: 7.6043e-07 - dense_121_loss: 6.5672e-07 - val_loss: 4.2570e-06 - val_dense_119_loss: 1.2125e-06 - val_dense_120_loss: 1.4400e-06 - val_dense_121_loss: 1.6045e-06\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.8585e-06 - dense_119_loss: 9.8945e-07 - dense_120_loss: 9.4785e-07 - dense_121_loss: 9.2115e-07 - val_loss: 2.4517e-06 - val_dense_119_loss: 7.9622e-07 - val_dense_120_loss: 9.1404e-07 - val_dense_121_loss: 7.4139e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2596e-06 - dense_119_loss: 7.9463e-07 - dense_120_loss: 7.7830e-07 - dense_121_loss: 6.8666e-07 - val_loss: 2.4266e-06 - val_dense_119_loss: 8.5625e-07 - val_dense_120_loss: 8.8832e-07 - val_dense_121_loss: 6.8204e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3125e-06 - dense_119_loss: 8.0706e-07 - dense_120_loss: 8.0147e-07 - dense_121_loss: 7.0399e-07 - val_loss: 2.0459e-06 - val_dense_119_loss: 7.7486e-07 - val_dense_120_loss: 6.9570e-07 - val_dense_121_loss: 5.7533e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1414e-06 - dense_119_loss: 7.5322e-07 - dense_120_loss: 7.5240e-07 - dense_121_loss: 6.3581e-07 - val_loss: 2.2792e-06 - val_dense_119_loss: 7.7093e-07 - val_dense_120_loss: 8.2984e-07 - val_dense_121_loss: 6.7847e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4254e-06 - dense_119_loss: 8.5164e-07 - dense_120_loss: 8.1942e-07 - dense_121_loss: 7.5438e-07 - val_loss: 2.4357e-06 - val_dense_119_loss: 7.8736e-07 - val_dense_120_loss: 8.3150e-07 - val_dense_121_loss: 8.1686e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2018e-06 - dense_119_loss: 7.7113e-07 - dense_120_loss: 7.6331e-07 - dense_121_loss: 6.6739e-07 - val_loss: 2.1162e-06 - val_dense_119_loss: 7.4098e-07 - val_dense_120_loss: 7.8808e-07 - val_dense_121_loss: 5.8717e-07\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2369e-06 - dense_119_loss: 7.8899e-07 - dense_120_loss: 7.5199e-07 - dense_121_loss: 6.9589e-07 - val_loss: 3.6585e-06 - val_dense_119_loss: 1.4095e-06 - val_dense_120_loss: 1.0057e-06 - val_dense_121_loss: 1.2434e-06\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.7369e-06 - dense_119_loss: 9.6211e-07 - dense_120_loss: 8.6870e-07 - dense_121_loss: 9.0609e-07 - val_loss: 2.6555e-06 - val_dense_119_loss: 9.8518e-07 - val_dense_120_loss: 9.7762e-07 - val_dense_121_loss: 6.9268e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.5715e-06 - dense_119_loss: 9.2757e-07 - dense_120_loss: 8.4540e-07 - dense_121_loss: 7.9856e-07 - val_loss: 2.5190e-06 - val_dense_119_loss: 9.0859e-07 - val_dense_120_loss: 8.0457e-07 - val_dense_121_loss: 8.0584e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1967e-06 - dense_119_loss: 7.7688e-07 - dense_120_loss: 7.5893e-07 - dense_121_loss: 6.6088e-07 - val_loss: 2.5829e-06 - val_dense_119_loss: 7.6400e-07 - val_dense_120_loss: 9.6593e-07 - val_dense_121_loss: 8.5303e-07\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.0887e-06 - dense_119_loss: 6.9994e-07 - dense_120_loss: 7.2664e-07 - dense_121_loss: 6.6216e-07 - val_loss: 2.4188e-06 - val_dense_119_loss: 8.5346e-07 - val_dense_120_loss: 8.2777e-07 - val_dense_121_loss: 7.3755e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4456e-06 - dense_119_loss: 8.3728e-07 - dense_120_loss: 8.2914e-07 - dense_121_loss: 7.7916e-07 - val_loss: 3.0755e-06 - val_dense_119_loss: 9.7689e-07 - val_dense_120_loss: 1.0035e-06 - val_dense_121_loss: 1.0951e-06\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1498e-06 - dense_119_loss: 7.2736e-07 - dense_120_loss: 7.3895e-07 - dense_121_loss: 6.8348e-07 - val_loss: 2.3267e-06 - val_dense_119_loss: 8.5454e-07 - val_dense_120_loss: 8.4152e-07 - val_dense_121_loss: 6.3062e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2359e-06 - dense_119_loss: 7.7633e-07 - dense_120_loss: 7.9687e-07 - dense_121_loss: 6.6269e-07 - val_loss: 2.7507e-06 - val_dense_119_loss: 9.6738e-07 - val_dense_120_loss: 8.9130e-07 - val_dense_121_loss: 8.9207e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.5639e-06 - dense_119_loss: 9.0044e-07 - dense_120_loss: 8.6773e-07 - dense_121_loss: 7.9569e-07 - val_loss: 2.6718e-06 - val_dense_119_loss: 8.3788e-07 - val_dense_120_loss: 9.4784e-07 - val_dense_121_loss: 8.8606e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4173e-06 - dense_119_loss: 8.2422e-07 - dense_120_loss: 8.5008e-07 - dense_121_loss: 7.4299e-07 - val_loss: 2.5595e-06 - val_dense_119_loss: 8.2359e-07 - val_dense_120_loss: 9.6594e-07 - val_dense_121_loss: 7.7000e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.0230e-06 - dense_119_loss: 6.8906e-07 - dense_120_loss: 7.1334e-07 - dense_121_loss: 6.2056e-07 - val_loss: 2.4713e-06 - val_dense_119_loss: 9.7723e-07 - val_dense_120_loss: 7.7058e-07 - val_dense_121_loss: 7.2345e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2908e-06 - dense_119_loss: 7.9707e-07 - dense_120_loss: 7.8832e-07 - dense_121_loss: 7.0543e-07 - val_loss: 2.3303e-06 - val_dense_119_loss: 7.8505e-07 - val_dense_120_loss: 8.3285e-07 - val_dense_121_loss: 7.1238e-07\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3437e-06 - dense_119_loss: 8.0131e-07 - dense_120_loss: 8.4786e-07 - dense_121_loss: 6.9449e-07 - val_loss: 3.4079e-06 - val_dense_119_loss: 1.1675e-06 - val_dense_120_loss: 1.1522e-06 - val_dense_121_loss: 1.0882e-06\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.5654e-06 - dense_119_loss: 8.8957e-07 - dense_120_loss: 9.1834e-07 - dense_121_loss: 7.5753e-07 - val_loss: 2.3347e-06 - val_dense_119_loss: 7.7729e-07 - val_dense_120_loss: 9.3304e-07 - val_dense_121_loss: 6.2432e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.0687e-06 - dense_119_loss: 6.9756e-07 - dense_120_loss: 7.2886e-07 - dense_121_loss: 6.4228e-07 - val_loss: 2.2509e-06 - val_dense_119_loss: 6.8671e-07 - val_dense_120_loss: 9.9244e-07 - val_dense_121_loss: 5.7179e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4506e-06 - dense_119_loss: 8.7851e-07 - dense_120_loss: 8.5424e-07 - dense_121_loss: 7.1788e-07 - val_loss: 3.2656e-06 - val_dense_119_loss: 1.1835e-06 - val_dense_120_loss: 1.0453e-06 - val_dense_121_loss: 1.0369e-06\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2431e-06 - dense_119_loss: 7.7637e-07 - dense_120_loss: 7.8068e-07 - dense_121_loss: 6.8608e-07 - val_loss: 2.1780e-06 - val_dense_119_loss: 7.7879e-07 - val_dense_120_loss: 8.5448e-07 - val_dense_121_loss: 5.4478e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "\n",
      "Now training model 5/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 4.6594e-05 - dense_124_loss: 1.6204e-05 - dense_125_loss: 1.5687e-05 - dense_126_loss: 1.4703e-05 - val_loss: 1.1411e-05 - val_dense_124_loss: 4.5656e-06 - val_dense_125_loss: 4.1519e-06 - val_dense_126_loss: 2.6931e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.2399e-06 - dense_124_loss: 2.6890e-06 - dense_125_loss: 2.5047e-06 - dense_126_loss: 2.0462e-06 - val_loss: 4.1501e-06 - val_dense_124_loss: 1.4078e-06 - val_dense_125_loss: 1.6851e-06 - val_dense_126_loss: 1.0572e-06\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.9576e-06 - dense_124_loss: 1.1371e-06 - dense_125_loss: 1.1672e-06 - dense_126_loss: 6.5326e-07 - val_loss: 2.2490e-06 - val_dense_124_loss: 8.8934e-07 - val_dense_125_loss: 9.5144e-07 - val_dense_126_loss: 4.0825e-07\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3348e-06 - dense_124_loss: 9.4325e-07 - dense_125_loss: 9.5162e-07 - dense_126_loss: 4.3996e-07 - val_loss: 2.1737e-06 - val_dense_124_loss: 9.1428e-07 - val_dense_125_loss: 8.8168e-07 - val_dense_126_loss: 3.7775e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2686e-06 - dense_124_loss: 9.2911e-07 - dense_125_loss: 9.1068e-07 - dense_126_loss: 4.2879e-07 - val_loss: 2.3303e-06 - val_dense_124_loss: 9.7647e-07 - val_dense_125_loss: 9.3549e-07 - val_dense_126_loss: 4.1833e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3392e-06 - dense_124_loss: 9.5436e-07 - dense_125_loss: 9.2389e-07 - dense_126_loss: 4.6095e-07 - val_loss: 2.2011e-06 - val_dense_124_loss: 8.6832e-07 - val_dense_125_loss: 8.9814e-07 - val_dense_126_loss: 4.3461e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2483e-06 - dense_124_loss: 9.0139e-07 - dense_125_loss: 9.1145e-07 - dense_126_loss: 4.3545e-07 - val_loss: 2.7323e-06 - val_dense_124_loss: 1.1905e-06 - val_dense_125_loss: 9.6716e-07 - val_dense_126_loss: 5.7469e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3925e-06 - dense_124_loss: 9.3809e-07 - dense_125_loss: 9.5283e-07 - dense_126_loss: 5.0161e-07 - val_loss: 2.4120e-06 - val_dense_124_loss: 9.0188e-07 - val_dense_125_loss: 1.0210e-06 - val_dense_126_loss: 4.8908e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3023e-06 - dense_124_loss: 9.1391e-07 - dense_125_loss: 9.2243e-07 - dense_126_loss: 4.6595e-07 - val_loss: 2.1436e-06 - val_dense_124_loss: 8.3886e-07 - val_dense_125_loss: 8.7012e-07 - val_dense_126_loss: 4.3466e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2499e-06 - dense_124_loss: 8.8700e-07 - dense_125_loss: 8.9531e-07 - dense_126_loss: 4.6764e-07 - val_loss: 2.4092e-06 - val_dense_124_loss: 1.0108e-06 - val_dense_125_loss: 8.8593e-07 - val_dense_126_loss: 5.1245e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2507e-06 - dense_124_loss: 8.8548e-07 - dense_125_loss: 9.0150e-07 - dense_126_loss: 4.6375e-07 - val_loss: 2.3914e-06 - val_dense_124_loss: 9.6212e-07 - val_dense_125_loss: 9.4993e-07 - val_dense_126_loss: 4.7934e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2463e-06 - dense_124_loss: 8.6782e-07 - dense_125_loss: 9.0268e-07 - dense_126_loss: 4.7580e-07 - val_loss: 2.1818e-06 - val_dense_124_loss: 8.5053e-07 - val_dense_125_loss: 9.3700e-07 - val_dense_126_loss: 3.9430e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1947e-06 - dense_124_loss: 8.4675e-07 - dense_125_loss: 8.8660e-07 - dense_126_loss: 4.6140e-07 - val_loss: 2.3360e-06 - val_dense_124_loss: 9.2981e-07 - val_dense_125_loss: 9.2889e-07 - val_dense_126_loss: 4.7733e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2095e-06 - dense_124_loss: 8.4736e-07 - dense_125_loss: 8.8610e-07 - dense_126_loss: 4.7600e-07 - val_loss: 2.5044e-06 - val_dense_124_loss: 9.1824e-07 - val_dense_125_loss: 1.0513e-06 - val_dense_126_loss: 5.3482e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2681e-06 - dense_124_loss: 8.6598e-07 - dense_125_loss: 9.0730e-07 - dense_126_loss: 4.9481e-07 - val_loss: 2.4702e-06 - val_dense_124_loss: 9.6297e-07 - val_dense_125_loss: 9.3013e-07 - val_dense_126_loss: 5.7707e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3452e-06 - dense_124_loss: 8.9464e-07 - dense_125_loss: 9.2877e-07 - dense_126_loss: 5.2177e-07 - val_loss: 2.4666e-06 - val_dense_124_loss: 1.0457e-06 - val_dense_125_loss: 8.9836e-07 - val_dense_126_loss: 5.2252e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.5064e-06 - dense_124_loss: 9.4829e-07 - dense_125_loss: 9.6946e-07 - dense_126_loss: 5.8863e-07 - val_loss: 2.2722e-06 - val_dense_124_loss: 9.5708e-07 - val_dense_125_loss: 8.6512e-07 - val_dense_126_loss: 4.5002e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2760e-06 - dense_124_loss: 8.6820e-07 - dense_125_loss: 9.0330e-07 - dense_126_loss: 5.0446e-07 - val_loss: 2.9837e-06 - val_dense_124_loss: 1.0866e-06 - val_dense_125_loss: 1.2253e-06 - val_dense_126_loss: 6.7177e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.0147e-06 - dense_124_loss: 1.1009e-06 - dense_125_loss: 1.1281e-06 - dense_126_loss: 7.8575e-07 - val_loss: 3.8653e-06 - val_dense_124_loss: 1.2431e-06 - val_dense_125_loss: 1.5860e-06 - val_dense_126_loss: 1.0361e-06\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.0245e-06 - dense_124_loss: 1.1431e-06 - dense_125_loss: 1.1413e-06 - dense_126_loss: 7.4012e-07 - val_loss: 2.4872e-06 - val_dense_124_loss: 9.5295e-07 - val_dense_125_loss: 9.5371e-07 - val_dense_126_loss: 5.8056e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4392e-06 - dense_124_loss: 9.3300e-07 - dense_125_loss: 9.5889e-07 - dense_126_loss: 5.4728e-07 - val_loss: 2.2479e-06 - val_dense_124_loss: 8.1644e-07 - val_dense_125_loss: 9.0196e-07 - val_dense_126_loss: 5.2952e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2528e-06 - dense_124_loss: 8.5307e-07 - dense_125_loss: 8.8768e-07 - dense_126_loss: 5.1208e-07 - val_loss: 2.3506e-06 - val_dense_124_loss: 8.0387e-07 - val_dense_125_loss: 9.5279e-07 - val_dense_126_loss: 5.9398e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3191e-06 - dense_124_loss: 8.5499e-07 - dense_125_loss: 9.0443e-07 - dense_126_loss: 5.5966e-07 - val_loss: 2.7475e-06 - val_dense_124_loss: 8.7762e-07 - val_dense_125_loss: 1.2360e-06 - val_dense_126_loss: 6.3389e-07\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.4098e-06 - dense_124_loss: 8.6615e-07 - dense_125_loss: 9.6421e-07 - dense_126_loss: 5.7947e-07 - val_loss: 2.4834e-06 - val_dense_124_loss: 9.4235e-07 - val_dense_125_loss: 9.2917e-07 - val_dense_126_loss: 6.1190e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3312e-06 - dense_124_loss: 8.5179e-07 - dense_125_loss: 9.1844e-07 - dense_126_loss: 5.6098e-07 - val_loss: 2.2018e-06 - val_dense_124_loss: 7.1681e-07 - val_dense_125_loss: 9.8739e-07 - val_dense_126_loss: 4.9763e-07\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2223e-06 - dense_124_loss: 8.3180e-07 - dense_125_loss: 8.7243e-07 - dense_126_loss: 5.1805e-07 - val_loss: 2.9584e-06 - val_dense_124_loss: 1.0688e-06 - val_dense_125_loss: 1.0070e-06 - val_dense_126_loss: 8.8261e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.6305e-06 - dense_124_loss: 9.7736e-07 - dense_125_loss: 1.0146e-06 - dense_126_loss: 6.3849e-07 - val_loss: 3.0015e-06 - val_dense_124_loss: 1.1646e-06 - val_dense_125_loss: 1.2109e-06 - val_dense_126_loss: 6.2607e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.6162e-06 - dense_124_loss: 9.4855e-07 - dense_125_loss: 1.0174e-06 - dense_126_loss: 6.5017e-07 - val_loss: 2.4054e-06 - val_dense_124_loss: 8.1823e-07 - val_dense_125_loss: 1.1148e-06 - val_dense_126_loss: 4.7236e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3725e-06 - dense_124_loss: 8.5301e-07 - dense_125_loss: 9.3601e-07 - dense_126_loss: 5.8351e-07 - val_loss: 2.8506e-06 - val_dense_124_loss: 1.1680e-06 - val_dense_125_loss: 1.0853e-06 - val_dense_126_loss: 5.9737e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "\n",
      "Now training model 6/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 9ms/step - loss: 1.7071e-05 - dense_129_loss: 1.0479e-05 - dense_130_loss: 6.5924e-06 - val_loss: 7.1753e-06 - val_dense_129_loss: 4.9087e-06 - val_dense_130_loss: 2.2665e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 7.5219e-06 - dense_129_loss: 5.4759e-06 - dense_130_loss: 2.0460e-06 - val_loss: 5.2053e-06 - val_dense_129_loss: 3.8080e-06 - val_dense_130_loss: 1.3974e-06\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 6.1777e-06 - dense_129_loss: 4.6116e-06 - dense_130_loss: 1.5661e-06 - val_loss: 4.8704e-06 - val_dense_129_loss: 3.5806e-06 - val_dense_130_loss: 1.2898e-06\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 5.7551e-06 - dense_129_loss: 4.2735e-06 - dense_130_loss: 1.4816e-06 - val_loss: 4.3595e-06 - val_dense_129_loss: 3.1127e-06 - val_dense_130_loss: 1.2468e-06\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 5.2651e-06 - dense_129_loss: 3.8412e-06 - dense_130_loss: 1.4239e-06 - val_loss: 4.0405e-06 - val_dense_129_loss: 2.7991e-06 - val_dense_130_loss: 1.2414e-06\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.8665e-06 - dense_129_loss: 3.4608e-06 - dense_130_loss: 1.4056e-06 - val_loss: 3.7241e-06 - val_dense_129_loss: 2.5390e-06 - val_dense_130_loss: 1.1851e-06\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.2267e-06 - dense_129_loss: 2.9132e-06 - dense_130_loss: 1.3135e-06 - val_loss: 3.4068e-06 - val_dense_129_loss: 2.1458e-06 - val_dense_130_loss: 1.2610e-06\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.6294e-06 - dense_129_loss: 2.3902e-06 - dense_130_loss: 1.2392e-06 - val_loss: 2.6648e-06 - val_dense_129_loss: 1.6619e-06 - val_dense_130_loss: 1.0029e-06\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.8580e-06 - dense_129_loss: 1.8121e-06 - dense_130_loss: 1.0460e-06 - val_loss: 2.1310e-06 - val_dense_129_loss: 1.2855e-06 - val_dense_130_loss: 8.4542e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.2239e-06 - dense_129_loss: 1.3422e-06 - dense_130_loss: 8.8168e-07 - val_loss: 1.8830e-06 - val_dense_129_loss: 1.0679e-06 - val_dense_130_loss: 8.1509e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.8534e-06 - dense_129_loss: 1.0436e-06 - dense_130_loss: 8.0983e-07 - val_loss: 1.7016e-06 - val_dense_129_loss: 9.0346e-07 - val_dense_130_loss: 7.9815e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.4369e-06 - dense_129_loss: 7.5951e-07 - dense_130_loss: 6.7735e-07 - val_loss: 1.3715e-06 - val_dense_129_loss: 6.6895e-07 - val_dense_130_loss: 7.0258e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2074e-06 - dense_129_loss: 5.9754e-07 - dense_130_loss: 6.0983e-07 - val_loss: 1.2464e-06 - val_dense_129_loss: 6.3204e-07 - val_dense_130_loss: 6.1433e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0701e-06 - dense_129_loss: 5.2117e-07 - dense_130_loss: 5.4889e-07 - val_loss: 9.9602e-07 - val_dense_129_loss: 4.3690e-07 - val_dense_130_loss: 5.5912e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.0770e-07 - dense_129_loss: 4.2380e-07 - dense_130_loss: 4.8390e-07 - val_loss: 9.5235e-07 - val_dense_129_loss: 4.4903e-07 - val_dense_130_loss: 5.0331e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9725e-07 - dense_129_loss: 4.2666e-07 - dense_130_loss: 4.7059e-07 - val_loss: 1.1594e-06 - val_dense_129_loss: 4.8250e-07 - val_dense_130_loss: 6.7693e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.4489e-07 - dense_129_loss: 4.4074e-07 - dense_130_loss: 5.0415e-07 - val_loss: 8.8190e-07 - val_dense_129_loss: 3.8714e-07 - val_dense_130_loss: 4.9476e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9884e-07 - dense_129_loss: 4.7613e-07 - dense_130_loss: 5.2270e-07 - val_loss: 1.4142e-06 - val_dense_129_loss: 6.1596e-07 - val_dense_130_loss: 7.9825e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0487e-06 - dense_129_loss: 5.0058e-07 - dense_130_loss: 5.4811e-07 - val_loss: 1.0789e-06 - val_dense_129_loss: 5.0058e-07 - val_dense_130_loss: 5.7835e-07\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0786e-06 - dense_129_loss: 5.2304e-07 - dense_130_loss: 5.5552e-07 - val_loss: 1.2381e-06 - val_dense_129_loss: 5.6202e-07 - val_dense_130_loss: 6.7607e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0772e-06 - dense_129_loss: 5.0490e-07 - dense_130_loss: 5.7228e-07 - val_loss: 1.0511e-06 - val_dense_129_loss: 4.4943e-07 - val_dense_130_loss: 6.0171e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.4692e-07 - dense_129_loss: 4.6023e-07 - dense_130_loss: 4.8669e-07 - val_loss: 9.1968e-07 - val_dense_129_loss: 4.4744e-07 - val_dense_130_loss: 4.7224e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.8979e-07 - dense_129_loss: 4.4254e-07 - dense_130_loss: 4.4725e-07 - val_loss: 9.3010e-07 - val_dense_129_loss: 4.6734e-07 - val_dense_130_loss: 4.6276e-07\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.4613e-07 - dense_129_loss: 4.1889e-07 - dense_130_loss: 4.2724e-07 - val_loss: 9.6772e-07 - val_dense_129_loss: 4.8676e-07 - val_dense_130_loss: 4.8096e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.5211e-07 - dense_129_loss: 4.7192e-07 - dense_130_loss: 4.8019e-07 - val_loss: 1.0494e-06 - val_dense_129_loss: 5.3720e-07 - val_dense_130_loss: 5.1217e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.2845e-07 - dense_129_loss: 4.6552e-07 - dense_130_loss: 4.6293e-07 - val_loss: 9.7999e-07 - val_dense_129_loss: 4.6884e-07 - val_dense_130_loss: 5.1114e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0809e-06 - dense_129_loss: 5.5364e-07 - dense_130_loss: 5.2724e-07 - val_loss: 8.6704e-07 - val_dense_129_loss: 4.1494e-07 - val_dense_130_loss: 4.5210e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0553e-06 - dense_129_loss: 5.2483e-07 - dense_130_loss: 5.3043e-07 - val_loss: 9.4035e-07 - val_dense_129_loss: 4.8999e-07 - val_dense_130_loss: 4.5037e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9171e-07 - dense_129_loss: 4.6135e-07 - dense_130_loss: 4.3036e-07 - val_loss: 1.1594e-06 - val_dense_129_loss: 5.3223e-07 - val_dense_130_loss: 6.2717e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.3493e-07 - dense_129_loss: 4.7064e-07 - dense_130_loss: 4.6429e-07 - val_loss: 9.9347e-07 - val_dense_129_loss: 4.9922e-07 - val_dense_130_loss: 4.9425e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.6219e-07 - dense_129_loss: 4.4608e-07 - dense_130_loss: 4.1611e-07 - val_loss: 1.1745e-06 - val_dense_129_loss: 5.9112e-07 - val_dense_130_loss: 5.8333e-07\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.8340e-07 - dense_129_loss: 4.6428e-07 - dense_130_loss: 4.1912e-07 - val_loss: 8.8468e-07 - val_dense_129_loss: 4.6512e-07 - val_dense_130_loss: 4.1955e-07\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.6127e-07 - dense_129_loss: 4.5350e-07 - dense_130_loss: 4.0777e-07 - val_loss: 9.2449e-07 - val_dense_129_loss: 4.8924e-07 - val_dense_130_loss: 4.3525e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.0702e-07 - dense_129_loss: 4.6891e-07 - dense_130_loss: 4.3811e-07 - val_loss: 8.9984e-07 - val_dense_129_loss: 4.7522e-07 - val_dense_130_loss: 4.2462e-07\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.7553e-07 - dense_129_loss: 4.6528e-07 - dense_130_loss: 4.1024e-07 - val_loss: 9.3787e-07 - val_dense_129_loss: 4.8483e-07 - val_dense_130_loss: 4.5304e-07\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 7.8288e-07 - dense_129_loss: 4.1416e-07 - dense_130_loss: 3.6872e-07 - val_loss: 9.0898e-07 - val_dense_129_loss: 4.5140e-07 - val_dense_130_loss: 4.5758e-07\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.1047e-07 - dense_129_loss: 4.8431e-07 - dense_130_loss: 4.2617e-07 - val_loss: 1.1566e-06 - val_dense_129_loss: 5.2032e-07 - val_dense_130_loss: 6.3626e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "\n",
      "Now training model 7/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 9ms/step - loss: 1.2441e-05 - dense_133_loss: 7.0759e-06 - dense_134_loss: 5.3654e-06 - val_loss: 4.0528e-06 - val_dense_133_loss: 2.3301e-06 - val_dense_134_loss: 1.7227e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1875e-06 - dense_133_loss: 1.1348e-06 - dense_134_loss: 1.0527e-06 - val_loss: 1.5687e-06 - val_dense_133_loss: 7.6149e-07 - val_dense_134_loss: 8.0718e-07\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1698e-06 - dense_133_loss: 5.3033e-07 - dense_134_loss: 6.3943e-07 - val_loss: 1.1427e-06 - val_dense_133_loss: 5.2713e-07 - val_dense_134_loss: 6.1554e-07\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0287e-06 - dense_133_loss: 4.5507e-07 - dense_134_loss: 5.7364e-07 - val_loss: 1.0539e-06 - val_dense_133_loss: 4.5345e-07 - val_dense_134_loss: 6.0043e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0209e-06 - dense_133_loss: 4.5564e-07 - dense_134_loss: 5.6530e-07 - val_loss: 1.1064e-06 - val_dense_133_loss: 4.9580e-07 - val_dense_134_loss: 6.1059e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0269e-06 - dense_133_loss: 4.6770e-07 - dense_134_loss: 5.5921e-07 - val_loss: 1.2548e-06 - val_dense_133_loss: 5.8764e-07 - val_dense_134_loss: 6.6719e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.7268e-07 - dense_133_loss: 4.3289e-07 - dense_134_loss: 5.3979e-07 - val_loss: 1.0652e-06 - val_dense_133_loss: 4.8664e-07 - val_dense_134_loss: 5.7859e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0129e-06 - dense_133_loss: 4.6595e-07 - dense_134_loss: 5.4691e-07 - val_loss: 1.2850e-06 - val_dense_133_loss: 5.6473e-07 - val_dense_134_loss: 7.2024e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1220e-06 - dense_133_loss: 5.2996e-07 - dense_134_loss: 5.9209e-07 - val_loss: 1.3361e-06 - val_dense_133_loss: 6.0168e-07 - val_dense_134_loss: 7.3445e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1116e-06 - dense_133_loss: 5.2485e-07 - dense_134_loss: 5.8673e-07 - val_loss: 1.1702e-06 - val_dense_133_loss: 5.4880e-07 - val_dense_134_loss: 6.2141e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.9903e-07 - dense_133_loss: 4.6127e-07 - dense_134_loss: 5.3776e-07 - val_loss: 1.1413e-06 - val_dense_133_loss: 5.2830e-07 - val_dense_134_loss: 6.1295e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0407e-06 - dense_133_loss: 4.8206e-07 - dense_134_loss: 5.5861e-07 - val_loss: 1.2546e-06 - val_dense_133_loss: 6.0019e-07 - val_dense_134_loss: 6.5440e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9338e-07 - dense_133_loss: 4.6393e-07 - dense_134_loss: 5.2944e-07 - val_loss: 1.5157e-06 - val_dense_133_loss: 6.8988e-07 - val_dense_134_loss: 8.2584e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0410e-06 - dense_133_loss: 4.9890e-07 - dense_134_loss: 5.4206e-07 - val_loss: 1.1100e-06 - val_dense_133_loss: 5.3252e-07 - val_dense_134_loss: 5.7753e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.5818e-07 - dense_133_loss: 4.6552e-07 - dense_134_loss: 4.9267e-07 - val_loss: 1.0210e-06 - val_dense_133_loss: 4.6175e-07 - val_dense_134_loss: 5.5922e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0022e-06 - dense_133_loss: 4.7507e-07 - dense_134_loss: 5.2714e-07 - val_loss: 1.1968e-06 - val_dense_133_loss: 6.2145e-07 - val_dense_134_loss: 5.7530e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.5958e-07 - dense_133_loss: 4.6735e-07 - dense_134_loss: 4.9223e-07 - val_loss: 1.1017e-06 - val_dense_133_loss: 4.9554e-07 - val_dense_134_loss: 6.0613e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.0209e-07 - dense_133_loss: 4.2276e-07 - dense_134_loss: 4.7933e-07 - val_loss: 9.5052e-07 - val_dense_133_loss: 4.7562e-07 - val_dense_134_loss: 4.7490e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.8365e-07 - dense_133_loss: 4.2518e-07 - dense_134_loss: 4.5847e-07 - val_loss: 1.1420e-06 - val_dense_133_loss: 5.4351e-07 - val_dense_134_loss: 5.9853e-07\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.1227e-07 - dense_133_loss: 4.3651e-07 - dense_134_loss: 4.7576e-07 - val_loss: 1.1471e-06 - val_dense_133_loss: 5.8343e-07 - val_dense_134_loss: 5.6372e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.7104e-07 - dense_133_loss: 4.7402e-07 - dense_134_loss: 4.9702e-07 - val_loss: 1.1231e-06 - val_dense_133_loss: 5.2192e-07 - val_dense_134_loss: 6.0118e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0063e-06 - dense_133_loss: 4.8821e-07 - dense_134_loss: 5.1812e-07 - val_loss: 9.4607e-07 - val_dense_133_loss: 4.8140e-07 - val_dense_134_loss: 4.6467e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9118e-07 - dense_133_loss: 4.2754e-07 - dense_134_loss: 4.6365e-07 - val_loss: 1.0047e-06 - val_dense_133_loss: 4.2021e-07 - val_dense_134_loss: 5.8452e-07\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.3103e-07 - dense_133_loss: 4.5981e-07 - dense_134_loss: 4.7122e-07 - val_loss: 1.2163e-06 - val_dense_133_loss: 5.5836e-07 - val_dense_134_loss: 6.5793e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1405e-06 - dense_133_loss: 5.6721e-07 - dense_134_loss: 5.7327e-07 - val_loss: 1.5843e-06 - val_dense_133_loss: 8.7150e-07 - val_dense_134_loss: 7.1284e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0081e-06 - dense_133_loss: 5.0682e-07 - dense_134_loss: 5.0132e-07 - val_loss: 1.1554e-06 - val_dense_133_loss: 5.9459e-07 - val_dense_134_loss: 5.6080e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0092e-06 - dense_133_loss: 5.1628e-07 - dense_134_loss: 4.9291e-07 - val_loss: 8.5387e-07 - val_dense_133_loss: 4.1728e-07 - val_dense_134_loss: 4.3659e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8391e-07 - dense_133_loss: 4.8864e-07 - dense_134_loss: 4.9526e-07 - val_loss: 1.7156e-06 - val_dense_133_loss: 8.6029e-07 - val_dense_134_loss: 8.5526e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3974e-06 - dense_133_loss: 7.6396e-07 - dense_134_loss: 6.3348e-07 - val_loss: 1.1328e-06 - val_dense_133_loss: 5.5344e-07 - val_dense_134_loss: 5.7941e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.3872e-07 - dense_133_loss: 4.6937e-07 - dense_134_loss: 4.6936e-07 - val_loss: 1.1007e-06 - val_dense_133_loss: 5.6828e-07 - val_dense_134_loss: 5.3242e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0084e-06 - dense_133_loss: 5.0067e-07 - dense_134_loss: 5.0770e-07 - val_loss: 1.1154e-06 - val_dense_133_loss: 5.8714e-07 - val_dense_134_loss: 5.2827e-07\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0026e-06 - dense_133_loss: 5.3075e-07 - dense_134_loss: 4.7185e-07 - val_loss: 1.1903e-06 - val_dense_133_loss: 5.4598e-07 - val_dense_134_loss: 6.4436e-07\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.6197e-07 - dense_133_loss: 4.9217e-07 - dense_134_loss: 4.6980e-07 - val_loss: 1.0068e-06 - val_dense_133_loss: 5.2115e-07 - val_dense_134_loss: 4.8562e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.4346e-07 - dense_133_loss: 5.0023e-07 - dense_134_loss: 4.4323e-07 - val_loss: 9.7452e-07 - val_dense_133_loss: 5.4042e-07 - val_dense_134_loss: 4.3410e-07\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.4363e-07 - dense_133_loss: 5.0120e-07 - dense_134_loss: 4.4244e-07 - val_loss: 1.0170e-06 - val_dense_133_loss: 5.5661e-07 - val_dense_134_loss: 4.6044e-07\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9383e-07 - dense_133_loss: 4.6436e-07 - dense_134_loss: 4.2947e-07 - val_loss: 9.2458e-07 - val_dense_133_loss: 4.7660e-07 - val_dense_134_loss: 4.4799e-07\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0642e-06 - dense_133_loss: 5.5371e-07 - dense_134_loss: 5.1048e-07 - val_loss: 1.1355e-06 - val_dense_133_loss: 5.6942e-07 - val_dense_134_loss: 5.6611e-07\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.2942e-07 - dense_133_loss: 4.6546e-07 - dense_134_loss: 4.6397e-07 - val_loss: 1.0837e-06 - val_dense_133_loss: 5.6831e-07 - val_dense_134_loss: 5.1540e-07\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9855e-07 - dense_133_loss: 5.1610e-07 - dense_134_loss: 4.8245e-07 - val_loss: 1.1483e-06 - val_dense_133_loss: 6.1935e-07 - val_dense_134_loss: 5.2893e-07\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.3472e-07 - dense_133_loss: 4.9715e-07 - dense_134_loss: 4.3757e-07 - val_loss: 1.2495e-06 - val_dense_133_loss: 6.7967e-07 - val_dense_134_loss: 5.6987e-07\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8863e-07 - dense_133_loss: 5.3749e-07 - dense_134_loss: 4.5114e-07 - val_loss: 9.9910e-07 - val_dense_133_loss: 5.3322e-07 - val_dense_134_loss: 4.6588e-07\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.7722e-07 - dense_133_loss: 5.1814e-07 - dense_134_loss: 4.5908e-07 - val_loss: 1.3547e-06 - val_dense_133_loss: 6.6357e-07 - val_dense_134_loss: 6.9112e-07\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0685e-06 - dense_133_loss: 5.7279e-07 - dense_134_loss: 4.9571e-07 - val_loss: 1.6047e-06 - val_dense_133_loss: 7.5756e-07 - val_dense_134_loss: 8.4711e-07\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0595e-06 - dense_133_loss: 5.5245e-07 - dense_134_loss: 5.0701e-07 - val_loss: 1.1997e-06 - val_dense_133_loss: 6.7187e-07 - val_dense_134_loss: 5.2783e-07\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9292e-07 - dense_133_loss: 4.6794e-07 - dense_134_loss: 4.2498e-07 - val_loss: 8.2295e-07 - val_dense_133_loss: 4.1579e-07 - val_dense_134_loss: 4.0716e-07\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.3608e-07 - dense_133_loss: 4.3436e-07 - dense_134_loss: 4.0173e-07 - val_loss: 1.0183e-06 - val_dense_133_loss: 5.8204e-07 - val_dense_134_loss: 4.3623e-07\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9245e-07 - dense_133_loss: 4.6805e-07 - dense_134_loss: 4.2440e-07 - val_loss: 1.1164e-06 - val_dense_133_loss: 5.9578e-07 - val_dense_134_loss: 5.2060e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "\n",
      "Now training model 8/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 9ms/step - loss: 1.5431e-05 - dense_137_loss: 7.3682e-06 - dense_138_loss: 8.0633e-06 - val_loss: 3.4252e-06 - val_dense_137_loss: 1.6844e-06 - val_dense_138_loss: 1.7409e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.5777e-06 - dense_137_loss: 1.2090e-06 - dense_138_loss: 1.3687e-06 - val_loss: 1.6530e-06 - val_dense_137_loss: 7.6344e-07 - val_dense_138_loss: 8.8954e-07\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4026e-06 - dense_137_loss: 6.5099e-07 - dense_138_loss: 7.5157e-07 - val_loss: 1.4271e-06 - val_dense_137_loss: 7.0220e-07 - val_dense_138_loss: 7.2491e-07\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2792e-06 - dense_137_loss: 5.7693e-07 - dense_138_loss: 7.0223e-07 - val_loss: 1.4854e-06 - val_dense_137_loss: 6.3679e-07 - val_dense_138_loss: 8.4864e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2069e-06 - dense_137_loss: 5.3848e-07 - dense_138_loss: 6.6839e-07 - val_loss: 1.3002e-06 - val_dense_137_loss: 6.2367e-07 - val_dense_138_loss: 6.7653e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1790e-06 - dense_137_loss: 5.3228e-07 - dense_138_loss: 6.4673e-07 - val_loss: 1.2553e-06 - val_dense_137_loss: 5.6326e-07 - val_dense_138_loss: 6.9208e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1115e-06 - dense_137_loss: 4.8933e-07 - dense_138_loss: 6.2213e-07 - val_loss: 1.1503e-06 - val_dense_137_loss: 5.2235e-07 - val_dense_138_loss: 6.2794e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1141e-06 - dense_137_loss: 5.1024e-07 - dense_138_loss: 6.0389e-07 - val_loss: 1.1059e-06 - val_dense_137_loss: 5.0487e-07 - val_dense_138_loss: 6.0105e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0911e-06 - dense_137_loss: 4.9841e-07 - dense_138_loss: 5.9267e-07 - val_loss: 1.7305e-06 - val_dense_137_loss: 6.5219e-07 - val_dense_138_loss: 1.0783e-06\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2788e-06 - dense_137_loss: 5.6076e-07 - dense_138_loss: 7.1809e-07 - val_loss: 1.3589e-06 - val_dense_137_loss: 6.1038e-07 - val_dense_138_loss: 7.4857e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1281e-06 - dense_137_loss: 5.2197e-07 - dense_138_loss: 6.0615e-07 - val_loss: 1.2598e-06 - val_dense_137_loss: 6.1489e-07 - val_dense_138_loss: 6.4494e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0741e-06 - dense_137_loss: 5.0537e-07 - dense_138_loss: 5.6874e-07 - val_loss: 1.2607e-06 - val_dense_137_loss: 5.8505e-07 - val_dense_138_loss: 6.7568e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1057e-06 - dense_137_loss: 5.1826e-07 - dense_138_loss: 5.8747e-07 - val_loss: 1.2971e-06 - val_dense_137_loss: 5.8548e-07 - val_dense_138_loss: 7.1162e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1562e-06 - dense_137_loss: 5.3077e-07 - dense_138_loss: 6.2544e-07 - val_loss: 1.4271e-06 - val_dense_137_loss: 6.3772e-07 - val_dense_138_loss: 7.8935e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1030e-06 - dense_137_loss: 5.2565e-07 - dense_138_loss: 5.7736e-07 - val_loss: 1.2295e-06 - val_dense_137_loss: 5.7280e-07 - val_dense_138_loss: 6.5666e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1720e-06 - dense_137_loss: 5.5559e-07 - dense_138_loss: 6.1640e-07 - val_loss: 1.0955e-06 - val_dense_137_loss: 4.9786e-07 - val_dense_138_loss: 5.9766e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8103e-07 - dense_137_loss: 4.7443e-07 - dense_138_loss: 5.0660e-07 - val_loss: 1.1438e-06 - val_dense_137_loss: 5.0234e-07 - val_dense_138_loss: 6.4142e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0147e-06 - dense_137_loss: 4.8683e-07 - dense_138_loss: 5.2788e-07 - val_loss: 1.0943e-06 - val_dense_137_loss: 5.2045e-07 - val_dense_138_loss: 5.7381e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0186e-06 - dense_137_loss: 4.9162e-07 - dense_138_loss: 5.2702e-07 - val_loss: 1.3529e-06 - val_dense_137_loss: 6.3726e-07 - val_dense_138_loss: 7.1562e-07\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0786e-06 - dense_137_loss: 5.2845e-07 - dense_138_loss: 5.5017e-07 - val_loss: 9.7374e-07 - val_dense_137_loss: 4.8487e-07 - val_dense_138_loss: 4.8887e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8034e-07 - dense_137_loss: 4.6913e-07 - dense_138_loss: 5.1121e-07 - val_loss: 1.1304e-06 - val_dense_137_loss: 5.8795e-07 - val_dense_138_loss: 5.4245e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0107e-06 - dense_137_loss: 5.0678e-07 - dense_138_loss: 5.0392e-07 - val_loss: 9.8641e-07 - val_dense_137_loss: 5.0357e-07 - val_dense_138_loss: 4.8284e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8208e-07 - dense_137_loss: 4.7796e-07 - dense_138_loss: 5.0412e-07 - val_loss: 1.0536e-06 - val_dense_137_loss: 5.4267e-07 - val_dense_138_loss: 5.1096e-07\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.5363e-07 - dense_137_loss: 4.8133e-07 - dense_138_loss: 4.7231e-07 - val_loss: 1.5700e-06 - val_dense_137_loss: 7.8770e-07 - val_dense_138_loss: 7.8232e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0385e-06 - dense_137_loss: 5.3310e-07 - dense_138_loss: 5.0541e-07 - val_loss: 9.7816e-07 - val_dense_137_loss: 5.2933e-07 - val_dense_138_loss: 4.4883e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0396e-06 - dense_137_loss: 5.2940e-07 - dense_138_loss: 5.1017e-07 - val_loss: 1.3550e-06 - val_dense_137_loss: 7.2852e-07 - val_dense_138_loss: 6.2648e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2175e-06 - dense_137_loss: 6.1886e-07 - dense_138_loss: 5.9862e-07 - val_loss: 1.6005e-06 - val_dense_137_loss: 9.3663e-07 - val_dense_138_loss: 6.6383e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2194e-06 - dense_137_loss: 6.1937e-07 - dense_138_loss: 5.9999e-07 - val_loss: 1.4255e-06 - val_dense_137_loss: 8.0336e-07 - val_dense_138_loss: 6.2210e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0376e-06 - dense_137_loss: 5.3646e-07 - dense_138_loss: 5.0112e-07 - val_loss: 1.0136e-06 - val_dense_137_loss: 5.6935e-07 - val_dense_138_loss: 4.4428e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2915e-06 - dense_137_loss: 6.3436e-07 - dense_138_loss: 6.5711e-07 - val_loss: 1.7304e-06 - val_dense_137_loss: 7.9584e-07 - val_dense_138_loss: 9.3458e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2452e-06 - dense_137_loss: 6.2726e-07 - dense_138_loss: 6.1794e-07 - val_loss: 1.2046e-06 - val_dense_137_loss: 5.5903e-07 - val_dense_138_loss: 6.4556e-07\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0529e-06 - dense_137_loss: 5.4239e-07 - dense_138_loss: 5.1051e-07 - val_loss: 1.4544e-06 - val_dense_137_loss: 7.3456e-07 - val_dense_138_loss: 7.1986e-07\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0519e-06 - dense_137_loss: 5.6258e-07 - dense_138_loss: 4.8935e-07 - val_loss: 9.4616e-07 - val_dense_137_loss: 4.8793e-07 - val_dense_138_loss: 4.5823e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.4362e-07 - dense_137_loss: 4.8959e-07 - dense_138_loss: 4.5403e-07 - val_loss: 1.4517e-06 - val_dense_137_loss: 7.2530e-07 - val_dense_138_loss: 7.2640e-07\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1224e-06 - dense_137_loss: 5.9824e-07 - dense_138_loss: 5.2415e-07 - val_loss: 1.1343e-06 - val_dense_137_loss: 5.8661e-07 - val_dense_138_loss: 5.4768e-07\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0715e-06 - dense_137_loss: 5.7615e-07 - dense_138_loss: 4.9534e-07 - val_loss: 1.1340e-06 - val_dense_137_loss: 5.8017e-07 - val_dense_138_loss: 5.5387e-07\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0758e-06 - dense_137_loss: 5.7370e-07 - dense_138_loss: 5.0214e-07 - val_loss: 1.1510e-06 - val_dense_137_loss: 5.9196e-07 - val_dense_138_loss: 5.5905e-07\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8399e-07 - dense_137_loss: 5.3347e-07 - dense_138_loss: 4.5052e-07 - val_loss: 1.2555e-06 - val_dense_137_loss: 6.9221e-07 - val_dense_138_loss: 5.6327e-07\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0115e-06 - dense_137_loss: 5.4571e-07 - dense_138_loss: 4.6576e-07 - val_loss: 1.2367e-06 - val_dense_137_loss: 5.9739e-07 - val_dense_138_loss: 6.3926e-07\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0654e-06 - dense_137_loss: 5.5246e-07 - dense_138_loss: 5.1295e-07 - val_loss: 9.4001e-07 - val_dense_137_loss: 5.5017e-07 - val_dense_138_loss: 3.8984e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "\n",
      "Now training model 9/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 9ms/step - loss: 1.1730e-05 - dense_141_loss: 6.5283e-06 - dense_142_loss: 5.2020e-06 - val_loss: 3.4422e-06 - val_dense_141_loss: 1.5387e-06 - val_dense_142_loss: 1.9035e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.1722e-06 - dense_141_loss: 1.0924e-06 - dense_142_loss: 1.0798e-06 - val_loss: 1.1697e-06 - val_dense_141_loss: 5.7708e-07 - val_dense_142_loss: 5.9261e-07\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1617e-06 - dense_141_loss: 5.8086e-07 - dense_142_loss: 5.8084e-07 - val_loss: 1.0426e-06 - val_dense_141_loss: 5.0718e-07 - val_dense_142_loss: 5.3542e-07\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0274e-06 - dense_141_loss: 5.0754e-07 - dense_142_loss: 5.1990e-07 - val_loss: 1.0219e-06 - val_dense_141_loss: 4.7798e-07 - val_dense_142_loss: 5.4388e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0169e-06 - dense_141_loss: 4.9297e-07 - dense_142_loss: 5.2391e-07 - val_loss: 1.0391e-06 - val_dense_141_loss: 4.9716e-07 - val_dense_142_loss: 5.4191e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0101e-06 - dense_141_loss: 4.9287e-07 - dense_142_loss: 5.1718e-07 - val_loss: 1.0543e-06 - val_dense_141_loss: 4.9220e-07 - val_dense_142_loss: 5.6212e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9154e-07 - dense_141_loss: 4.7530e-07 - dense_142_loss: 5.1624e-07 - val_loss: 1.0667e-06 - val_dense_141_loss: 5.0725e-07 - val_dense_142_loss: 5.5943e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0092e-06 - dense_141_loss: 4.9365e-07 - dense_142_loss: 5.1558e-07 - val_loss: 1.1533e-06 - val_dense_141_loss: 5.8850e-07 - val_dense_142_loss: 5.6484e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0169e-06 - dense_141_loss: 4.9583e-07 - dense_142_loss: 5.2104e-07 - val_loss: 1.1255e-06 - val_dense_141_loss: 5.4985e-07 - val_dense_142_loss: 5.7560e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0417e-06 - dense_141_loss: 5.0490e-07 - dense_142_loss: 5.3676e-07 - val_loss: 1.0745e-06 - val_dense_141_loss: 5.6039e-07 - val_dense_142_loss: 5.1415e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8743e-07 - dense_141_loss: 4.8501e-07 - dense_142_loss: 5.0241e-07 - val_loss: 1.0653e-06 - val_dense_141_loss: 5.0916e-07 - val_dense_142_loss: 5.5619e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.7877e-07 - dense_141_loss: 4.7803e-07 - dense_142_loss: 5.0074e-07 - val_loss: 1.0733e-06 - val_dense_141_loss: 5.0839e-07 - val_dense_142_loss: 5.6494e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.4397e-07 - dense_141_loss: 4.6353e-07 - dense_142_loss: 4.8045e-07 - val_loss: 1.0907e-06 - val_dense_141_loss: 5.1293e-07 - val_dense_142_loss: 5.7778e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.5463e-07 - dense_141_loss: 4.5628e-07 - dense_142_loss: 4.9835e-07 - val_loss: 9.5254e-07 - val_dense_141_loss: 4.4597e-07 - val_dense_142_loss: 5.0657e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.5440e-07 - dense_141_loss: 4.7351e-07 - dense_142_loss: 4.8088e-07 - val_loss: 1.1135e-06 - val_dense_141_loss: 5.5610e-07 - val_dense_142_loss: 5.5744e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0497e-06 - dense_141_loss: 5.1572e-07 - dense_142_loss: 5.3398e-07 - val_loss: 9.8764e-07 - val_dense_141_loss: 4.4029e-07 - val_dense_142_loss: 5.4735e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0177e-06 - dense_141_loss: 5.0984e-07 - dense_142_loss: 5.0786e-07 - val_loss: 1.0823e-06 - val_dense_141_loss: 5.4695e-07 - val_dense_142_loss: 5.3538e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.6198e-07 - dense_141_loss: 4.7527e-07 - dense_142_loss: 4.8671e-07 - val_loss: 1.0228e-06 - val_dense_141_loss: 4.9779e-07 - val_dense_142_loss: 5.2498e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0138e-06 - dense_141_loss: 4.9077e-07 - dense_142_loss: 5.2301e-07 - val_loss: 1.0561e-06 - val_dense_141_loss: 5.2420e-07 - val_dense_142_loss: 5.3192e-07\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9670e-07 - dense_141_loss: 4.9029e-07 - dense_142_loss: 5.0640e-07 - val_loss: 1.1122e-06 - val_dense_141_loss: 5.4274e-07 - val_dense_142_loss: 5.6949e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0657e-06 - dense_141_loss: 5.3654e-07 - dense_142_loss: 5.2918e-07 - val_loss: 1.0677e-06 - val_dense_141_loss: 5.4833e-07 - val_dense_142_loss: 5.1938e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0662e-06 - dense_141_loss: 5.3512e-07 - dense_142_loss: 5.3111e-07 - val_loss: 1.2432e-06 - val_dense_141_loss: 6.4858e-07 - val_dense_142_loss: 5.9464e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1110e-06 - dense_141_loss: 5.4797e-07 - dense_142_loss: 5.6300e-07 - val_loss: 1.6699e-06 - val_dense_141_loss: 8.5565e-07 - val_dense_142_loss: 8.1421e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "\n",
      "Now training model 10/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 9ms/step - loss: 1.6124e-05 - dense_145_loss: 8.6436e-06 - dense_146_loss: 7.4805e-06 - val_loss: 6.9101e-06 - val_dense_145_loss: 3.8710e-06 - val_dense_146_loss: 3.0391e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.7044e-06 - dense_145_loss: 4.0138e-06 - dense_146_loss: 1.6906e-06 - val_loss: 3.9749e-06 - val_dense_145_loss: 2.8233e-06 - val_dense_146_loss: 1.1516e-06\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.6393e-06 - dense_145_loss: 3.5532e-06 - dense_146_loss: 1.0862e-06 - val_loss: 4.4676e-06 - val_dense_145_loss: 3.3588e-06 - val_dense_146_loss: 1.1088e-06\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.6923e-06 - dense_145_loss: 3.5798e-06 - dense_146_loss: 1.1125e-06 - val_loss: 3.7919e-06 - val_dense_145_loss: 2.7927e-06 - val_dense_146_loss: 9.9927e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4385e-06 - dense_145_loss: 3.3505e-06 - dense_146_loss: 1.0880e-06 - val_loss: 3.6158e-06 - val_dense_145_loss: 2.5938e-06 - val_dense_146_loss: 1.0220e-06\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3327e-06 - dense_145_loss: 3.2519e-06 - dense_146_loss: 1.0808e-06 - val_loss: 3.5108e-06 - val_dense_145_loss: 2.5300e-06 - val_dense_146_loss: 9.8081e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.3533e-06 - dense_145_loss: 3.2347e-06 - dense_146_loss: 1.1186e-06 - val_loss: 3.7986e-06 - val_dense_145_loss: 2.6272e-06 - val_dense_146_loss: 1.1714e-06\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.2393e-06 - dense_145_loss: 3.1052e-06 - dense_146_loss: 1.1341e-06 - val_loss: 3.4852e-06 - val_dense_145_loss: 2.4711e-06 - val_dense_146_loss: 1.0142e-06\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.0833e-06 - dense_145_loss: 2.9720e-06 - dense_146_loss: 1.1113e-06 - val_loss: 3.4265e-06 - val_dense_145_loss: 2.4082e-06 - val_dense_146_loss: 1.0182e-06\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 4.1081e-06 - dense_145_loss: 2.9808e-06 - dense_146_loss: 1.1273e-06 - val_loss: 3.7765e-06 - val_dense_145_loss: 2.5982e-06 - val_dense_146_loss: 1.1783e-06\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.0305e-06 - dense_145_loss: 2.8868e-06 - dense_146_loss: 1.1437e-06 - val_loss: 3.2916e-06 - val_dense_145_loss: 2.2124e-06 - val_dense_146_loss: 1.0792e-06\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.8624e-06 - dense_145_loss: 2.7204e-06 - dense_146_loss: 1.1420e-06 - val_loss: 3.3076e-06 - val_dense_145_loss: 2.2980e-06 - val_dense_146_loss: 1.0095e-06\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.8118e-06 - dense_145_loss: 2.6579e-06 - dense_146_loss: 1.1540e-06 - val_loss: 3.1741e-06 - val_dense_145_loss: 2.1423e-06 - val_dense_146_loss: 1.0319e-06\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.6533e-06 - dense_145_loss: 2.5340e-06 - dense_146_loss: 1.1193e-06 - val_loss: 3.0307e-06 - val_dense_145_loss: 2.0153e-06 - val_dense_146_loss: 1.0153e-06\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.5635e-06 - dense_145_loss: 2.4318e-06 - dense_146_loss: 1.1317e-06 - val_loss: 2.9581e-06 - val_dense_145_loss: 1.9304e-06 - val_dense_146_loss: 1.0277e-06\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.4765e-06 - dense_145_loss: 2.3620e-06 - dense_146_loss: 1.1145e-06 - val_loss: 2.8695e-06 - val_dense_145_loss: 1.8744e-06 - val_dense_146_loss: 9.9510e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.2721e-06 - dense_145_loss: 2.2050e-06 - dense_146_loss: 1.0671e-06 - val_loss: 3.3352e-06 - val_dense_145_loss: 2.1091e-06 - val_dense_146_loss: 1.2261e-06\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.3264e-06 - dense_145_loss: 2.2146e-06 - dense_146_loss: 1.1118e-06 - val_loss: 2.5071e-06 - val_dense_145_loss: 1.6066e-06 - val_dense_146_loss: 9.0049e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 3.0059e-06 - dense_145_loss: 1.9686e-06 - dense_146_loss: 1.0373e-06 - val_loss: 2.8286e-06 - val_dense_145_loss: 1.7356e-06 - val_dense_146_loss: 1.0931e-06\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.9295e-06 - dense_145_loss: 1.8728e-06 - dense_146_loss: 1.0567e-06 - val_loss: 2.8181e-06 - val_dense_145_loss: 1.7973e-06 - val_dense_146_loss: 1.0208e-06\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.8346e-06 - dense_145_loss: 1.7886e-06 - dense_146_loss: 1.0460e-06 - val_loss: 2.3490e-06 - val_dense_145_loss: 1.4415e-06 - val_dense_146_loss: 9.0749e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.4864e-06 - dense_145_loss: 1.5535e-06 - dense_146_loss: 9.3293e-07 - val_loss: 2.1371e-06 - val_dense_145_loss: 1.2780e-06 - val_dense_146_loss: 8.5916e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.3413e-06 - dense_145_loss: 1.4387e-06 - dense_146_loss: 9.0257e-07 - val_loss: 2.6573e-06 - val_dense_145_loss: 1.5615e-06 - val_dense_146_loss: 1.0958e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.6991e-06 - dense_145_loss: 1.6128e-06 - dense_146_loss: 1.0862e-06 - val_loss: 2.3557e-06 - val_dense_145_loss: 1.4241e-06 - val_dense_146_loss: 9.3164e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.2476e-06 - dense_145_loss: 1.3398e-06 - dense_146_loss: 9.0776e-07 - val_loss: 2.4791e-06 - val_dense_145_loss: 1.5108e-06 - val_dense_146_loss: 9.6831e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.2245e-06 - dense_145_loss: 1.3198e-06 - dense_146_loss: 9.0473e-07 - val_loss: 2.0494e-06 - val_dense_145_loss: 1.2418e-06 - val_dense_146_loss: 8.0766e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.9487e-06 - dense_145_loss: 1.1676e-06 - dense_146_loss: 7.8109e-07 - val_loss: 2.2346e-06 - val_dense_145_loss: 1.3629e-06 - val_dense_146_loss: 8.7172e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.8580e-06 - dense_145_loss: 1.0873e-06 - dense_146_loss: 7.7078e-07 - val_loss: 1.7747e-06 - val_dense_145_loss: 1.0140e-06 - val_dense_146_loss: 7.6064e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5270e-06 - dense_145_loss: 8.9124e-07 - dense_146_loss: 6.3576e-07 - val_loss: 1.4679e-06 - val_dense_145_loss: 8.6385e-07 - val_dense_146_loss: 6.0403e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4021e-06 - dense_145_loss: 8.0546e-07 - dense_146_loss: 5.9663e-07 - val_loss: 1.5898e-06 - val_dense_145_loss: 9.5969e-07 - val_dense_146_loss: 6.3014e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3757e-06 - dense_145_loss: 8.0373e-07 - dense_146_loss: 5.7199e-07 - val_loss: 1.1709e-06 - val_dense_145_loss: 6.6094e-07 - val_dense_146_loss: 5.0992e-07\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2167e-06 - dense_145_loss: 7.0377e-07 - dense_146_loss: 5.1289e-07 - val_loss: 1.5680e-06 - val_dense_145_loss: 8.6001e-07 - val_dense_146_loss: 7.0799e-07\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2919e-06 - dense_145_loss: 7.4361e-07 - dense_146_loss: 5.4828e-07 - val_loss: 1.3304e-06 - val_dense_145_loss: 7.3452e-07 - val_dense_146_loss: 5.9592e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1257e-06 - dense_145_loss: 6.4982e-07 - dense_146_loss: 4.7589e-07 - val_loss: 1.2703e-06 - val_dense_145_loss: 7.9268e-07 - val_dense_146_loss: 4.7762e-07\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0658e-06 - dense_145_loss: 6.3591e-07 - dense_146_loss: 4.2984e-07 - val_loss: 1.2202e-06 - val_dense_145_loss: 6.7632e-07 - val_dense_146_loss: 5.4386e-07\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3760e-06 - dense_145_loss: 7.7519e-07 - dense_146_loss: 6.0080e-07 - val_loss: 1.2951e-06 - val_dense_145_loss: 7.7170e-07 - val_dense_146_loss: 5.2341e-07\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1706e-06 - dense_145_loss: 6.8418e-07 - dense_146_loss: 4.8638e-07 - val_loss: 1.2081e-06 - val_dense_145_loss: 6.6957e-07 - val_dense_146_loss: 5.3856e-07\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1029e-06 - dense_145_loss: 6.4978e-07 - dense_146_loss: 4.5313e-07 - val_loss: 1.1377e-06 - val_dense_145_loss: 6.3992e-07 - val_dense_146_loss: 4.9777e-07\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8933e-07 - dense_145_loss: 5.8949e-07 - dense_146_loss: 3.9984e-07 - val_loss: 1.2130e-06 - val_dense_145_loss: 7.1292e-07 - val_dense_146_loss: 5.0008e-07\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9480e-07 - dense_145_loss: 5.8632e-07 - dense_146_loss: 4.0847e-07 - val_loss: 1.1570e-06 - val_dense_145_loss: 7.0124e-07 - val_dense_146_loss: 4.5575e-07\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1174e-06 - dense_145_loss: 6.6334e-07 - dense_146_loss: 4.5405e-07 - val_loss: 1.4006e-06 - val_dense_145_loss: 7.7618e-07 - val_dense_146_loss: 6.2437e-07\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0940e-06 - dense_145_loss: 6.4810e-07 - dense_146_loss: 4.4588e-07 - val_loss: 1.0656e-06 - val_dense_145_loss: 6.5074e-07 - val_dense_146_loss: 4.1488e-07\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1319e-06 - dense_145_loss: 6.7285e-07 - dense_146_loss: 4.5905e-07 - val_loss: 1.1452e-06 - val_dense_145_loss: 6.7071e-07 - val_dense_146_loss: 4.7454e-07\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0732e-06 - dense_145_loss: 6.3423e-07 - dense_146_loss: 4.3892e-07 - val_loss: 1.0675e-06 - val_dense_145_loss: 6.2933e-07 - val_dense_146_loss: 4.3821e-07\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0368e-06 - dense_145_loss: 6.0830e-07 - dense_146_loss: 4.2848e-07 - val_loss: 1.2099e-06 - val_dense_145_loss: 7.1514e-07 - val_dense_146_loss: 4.9481e-07\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0219e-06 - dense_145_loss: 6.0705e-07 - dense_146_loss: 4.1487e-07 - val_loss: 1.0711e-06 - val_dense_145_loss: 6.5948e-07 - val_dense_146_loss: 4.1162e-07\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.6137e-07 - dense_145_loss: 5.8535e-07 - dense_146_loss: 3.7602e-07 - val_loss: 1.1268e-06 - val_dense_145_loss: 6.4598e-07 - val_dense_146_loss: 4.8083e-07\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8681e-07 - dense_145_loss: 5.9821e-07 - dense_146_loss: 3.8860e-07 - val_loss: 1.0750e-06 - val_dense_145_loss: 6.1678e-07 - val_dense_146_loss: 4.5818e-07\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.0110e-07 - dense_145_loss: 5.4925e-07 - dense_146_loss: 3.5185e-07 - val_loss: 1.0026e-06 - val_dense_145_loss: 6.2103e-07 - val_dense_146_loss: 3.8158e-07\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0068e-06 - dense_145_loss: 6.1897e-07 - dense_146_loss: 3.8784e-07 - val_loss: 1.2931e-06 - val_dense_145_loss: 7.4804e-07 - val_dense_146_loss: 5.4507e-07\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0735e-06 - dense_145_loss: 6.3737e-07 - dense_146_loss: 4.3609e-07 - val_loss: 1.2205e-06 - val_dense_145_loss: 6.8726e-07 - val_dense_146_loss: 5.3322e-07\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1167e-06 - dense_145_loss: 6.5841e-07 - dense_146_loss: 4.5830e-07 - val_loss: 9.9233e-07 - val_dense_145_loss: 5.8316e-07 - val_dense_146_loss: 4.0917e-07\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.0873e-07 - dense_145_loss: 5.5635e-07 - dense_146_loss: 3.5238e-07 - val_loss: 1.0963e-06 - val_dense_145_loss: 6.6192e-07 - val_dense_146_loss: 4.3436e-07\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.7535e-07 - dense_145_loss: 5.9207e-07 - dense_146_loss: 3.8328e-07 - val_loss: 8.9465e-07 - val_dense_145_loss: 5.7258e-07 - val_dense_146_loss: 3.2207e-07\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9984e-07 - dense_145_loss: 5.5436e-07 - dense_146_loss: 3.4548e-07 - val_loss: 8.5586e-07 - val_dense_145_loss: 5.2731e-07 - val_dense_146_loss: 3.2855e-07\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.9259e-07 - dense_145_loss: 5.5262e-07 - dense_146_loss: 3.3997e-07 - val_loss: 1.1469e-06 - val_dense_145_loss: 6.2487e-07 - val_dense_146_loss: 5.2200e-07\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8758e-07 - dense_145_loss: 5.9503e-07 - dense_146_loss: 3.9256e-07 - val_loss: 1.1203e-06 - val_dense_145_loss: 6.8704e-07 - val_dense_146_loss: 4.3321e-07\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0325e-06 - dense_145_loss: 6.1675e-07 - dense_146_loss: 4.1579e-07 - val_loss: 1.2791e-06 - val_dense_145_loss: 7.8935e-07 - val_dense_146_loss: 4.8975e-07\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 9.9754e-07 - dense_145_loss: 6.0615e-07 - dense_146_loss: 3.9139e-07 - val_loss: 9.3043e-07 - val_dense_145_loss: 5.7529e-07 - val_dense_146_loss: 3.5514e-07\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.3369e-07 - dense_145_loss: 5.2774e-07 - dense_146_loss: 3.0595e-07 - val_loss: 1.0889e-06 - val_dense_145_loss: 6.7446e-07 - val_dense_146_loss: 4.1443e-07\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.7477e-07 - dense_145_loss: 6.1204e-07 - dense_146_loss: 3.6273e-07 - val_loss: 1.5313e-06 - val_dense_145_loss: 9.6294e-07 - val_dense_146_loss: 5.6834e-07\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0295e-06 - dense_145_loss: 6.2270e-07 - dense_146_loss: 4.0677e-07 - val_loss: 1.0425e-06 - val_dense_145_loss: 6.5503e-07 - val_dense_146_loss: 3.8743e-07\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0226e-06 - dense_145_loss: 6.4969e-07 - dense_146_loss: 3.7293e-07 - val_loss: 9.8058e-07 - val_dense_145_loss: 6.5575e-07 - val_dense_146_loss: 3.2483e-07\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.5833e-07 - dense_145_loss: 5.4520e-07 - dense_146_loss: 3.1313e-07 - val_loss: 8.9463e-07 - val_dense_145_loss: 5.6768e-07 - val_dense_146_loss: 3.2695e-07\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.1234e-07 - dense_145_loss: 5.0847e-07 - dense_146_loss: 3.0387e-07 - val_loss: 9.5218e-07 - val_dense_145_loss: 5.9171e-07 - val_dense_146_loss: 3.6047e-07\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.6761e-07 - dense_145_loss: 6.0145e-07 - dense_146_loss: 3.6616e-07 - val_loss: 8.8278e-07 - val_dense_145_loss: 5.7100e-07 - val_dense_146_loss: 3.1178e-07\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.8297e-07 - dense_145_loss: 5.5847e-07 - dense_146_loss: 3.2451e-07 - val_loss: 1.1658e-06 - val_dense_145_loss: 7.6412e-07 - val_dense_146_loss: 4.0168e-07\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.4361e-07 - dense_145_loss: 5.9262e-07 - dense_146_loss: 3.5100e-07 - val_loss: 9.3401e-07 - val_dense_145_loss: 6.0285e-07 - val_dense_146_loss: 3.3116e-07\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.5071e-07 - dense_145_loss: 5.5164e-07 - dense_146_loss: 2.9907e-07 - val_loss: 8.3594e-07 - val_dense_145_loss: 5.5007e-07 - val_dense_146_loss: 2.8587e-07\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.8782e-07 - dense_145_loss: 5.0629e-07 - dense_146_loss: 2.8153e-07 - val_loss: 8.1999e-07 - val_dense_145_loss: 5.3821e-07 - val_dense_146_loss: 2.8178e-07\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 7.8471e-07 - dense_145_loss: 5.1343e-07 - dense_146_loss: 2.7128e-07 - val_loss: 1.0110e-06 - val_dense_145_loss: 5.8858e-07 - val_dense_146_loss: 4.2238e-07\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 9.8988e-07 - dense_145_loss: 6.1242e-07 - dense_146_loss: 3.7746e-07 - val_loss: 1.1110e-06 - val_dense_145_loss: 6.2584e-07 - val_dense_146_loss: 4.8517e-07\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.3358e-07 - dense_145_loss: 5.3090e-07 - dense_146_loss: 3.0268e-07 - val_loss: 8.6816e-07 - val_dense_145_loss: 5.8211e-07 - val_dense_146_loss: 2.8605e-07\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 8.4009e-07 - dense_145_loss: 5.3804e-07 - dense_146_loss: 3.0205e-07 - val_loss: 1.0447e-06 - val_dense_145_loss: 6.5526e-07 - val_dense_146_loss: 3.8944e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00074: early stopping\n",
      "\n",
      "Now training model 11/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 2.2326e-05 - dense_149_loss: 1.1156e-05 - dense_150_loss: 1.1170e-05 - val_loss: 4.7888e-06 - val_dense_149_loss: 3.2223e-06 - val_dense_150_loss: 1.5665e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.3721e-06 - dense_149_loss: 1.9793e-06 - dense_150_loss: 1.3928e-06 - val_loss: 1.8576e-06 - val_dense_149_loss: 1.0586e-06 - val_dense_150_loss: 7.9906e-07\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.4575e-06 - dense_149_loss: 8.3911e-07 - dense_150_loss: 6.1844e-07 - val_loss: 1.2377e-06 - val_dense_149_loss: 6.8124e-07 - val_dense_150_loss: 5.5644e-07\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2006e-06 - dense_149_loss: 6.8085e-07 - dense_150_loss: 5.1976e-07 - val_loss: 1.2281e-06 - val_dense_149_loss: 6.5126e-07 - val_dense_150_loss: 5.7689e-07\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1768e-06 - dense_149_loss: 6.5698e-07 - dense_150_loss: 5.1983e-07 - val_loss: 1.2175e-06 - val_dense_149_loss: 6.8223e-07 - val_dense_150_loss: 5.3525e-07\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2092e-06 - dense_149_loss: 6.7990e-07 - dense_150_loss: 5.2933e-07 - val_loss: 1.3879e-06 - val_dense_149_loss: 7.8575e-07 - val_dense_150_loss: 6.0218e-07\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1744e-06 - dense_149_loss: 6.6592e-07 - dense_150_loss: 5.0852e-07 - val_loss: 1.2299e-06 - val_dense_149_loss: 6.6293e-07 - val_dense_150_loss: 5.6697e-07\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1403e-06 - dense_149_loss: 6.3634e-07 - dense_150_loss: 5.0399e-07 - val_loss: 1.1908e-06 - val_dense_149_loss: 6.7077e-07 - val_dense_150_loss: 5.2008e-07\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1210e-06 - dense_149_loss: 6.2770e-07 - dense_150_loss: 4.9334e-07 - val_loss: 1.1707e-06 - val_dense_149_loss: 6.5041e-07 - val_dense_150_loss: 5.2030e-07\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0987e-06 - dense_149_loss: 6.1861e-07 - dense_150_loss: 4.8006e-07 - val_loss: 1.2472e-06 - val_dense_149_loss: 7.1620e-07 - val_dense_150_loss: 5.3096e-07\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1209e-06 - dense_149_loss: 6.2971e-07 - dense_150_loss: 4.9120e-07 - val_loss: 1.2722e-06 - val_dense_149_loss: 7.2569e-07 - val_dense_150_loss: 5.4652e-07\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1115e-06 - dense_149_loss: 6.3175e-07 - dense_150_loss: 4.7970e-07 - val_loss: 1.3719e-06 - val_dense_149_loss: 7.5811e-07 - val_dense_150_loss: 6.1382e-07\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1330e-06 - dense_149_loss: 6.4588e-07 - dense_150_loss: 4.8710e-07 - val_loss: 1.2176e-06 - val_dense_149_loss: 6.9034e-07 - val_dense_150_loss: 5.2729e-07\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1205e-06 - dense_149_loss: 6.3712e-07 - dense_150_loss: 4.8338e-07 - val_loss: 1.2297e-06 - val_dense_149_loss: 7.0425e-07 - val_dense_150_loss: 5.2549e-07\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0857e-06 - dense_149_loss: 6.1881e-07 - dense_150_loss: 4.6690e-07 - val_loss: 1.0345e-06 - val_dense_149_loss: 5.8484e-07 - val_dense_150_loss: 4.4969e-07\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0440e-06 - dense_149_loss: 5.9770e-07 - dense_150_loss: 4.4631e-07 - val_loss: 1.1308e-06 - val_dense_149_loss: 6.4328e-07 - val_dense_150_loss: 4.8749e-07\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0947e-06 - dense_149_loss: 6.1803e-07 - dense_150_loss: 4.7670e-07 - val_loss: 1.2028e-06 - val_dense_149_loss: 6.6038e-07 - val_dense_150_loss: 5.4237e-07\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0876e-06 - dense_149_loss: 6.2135e-07 - dense_150_loss: 4.6627e-07 - val_loss: 1.2703e-06 - val_dense_149_loss: 7.0998e-07 - val_dense_150_loss: 5.6033e-07\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1370e-06 - dense_149_loss: 6.5424e-07 - dense_150_loss: 4.8280e-07 - val_loss: 1.1605e-06 - val_dense_149_loss: 6.7152e-07 - val_dense_150_loss: 4.8898e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0517e-06 - dense_149_loss: 6.0203e-07 - dense_150_loss: 4.4971e-07 - val_loss: 1.3249e-06 - val_dense_149_loss: 7.6017e-07 - val_dense_150_loss: 5.6468e-07\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1386e-06 - dense_149_loss: 6.5306e-07 - dense_150_loss: 4.8550e-07 - val_loss: 1.3427e-06 - val_dense_149_loss: 7.3044e-07 - val_dense_150_loss: 6.1225e-07\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2791e-06 - dense_149_loss: 7.2830e-07 - dense_150_loss: 5.5076e-07 - val_loss: 1.5967e-06 - val_dense_149_loss: 9.1959e-07 - val_dense_150_loss: 6.7713e-07\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3199e-06 - dense_149_loss: 7.3009e-07 - dense_150_loss: 5.8983e-07 - val_loss: 1.2915e-06 - val_dense_149_loss: 6.9576e-07 - val_dense_150_loss: 5.9577e-07\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0484e-06 - dense_149_loss: 5.8487e-07 - dense_150_loss: 4.6357e-07 - val_loss: 1.0509e-06 - val_dense_149_loss: 5.9431e-07 - val_dense_150_loss: 4.5657e-07\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0398e-06 - dense_149_loss: 5.9494e-07 - dense_150_loss: 4.4482e-07 - val_loss: 1.1153e-06 - val_dense_149_loss: 6.3053e-07 - val_dense_150_loss: 4.8481e-07\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0436e-06 - dense_149_loss: 6.0195e-07 - dense_150_loss: 4.4164e-07 - val_loss: 1.5626e-06 - val_dense_149_loss: 9.0676e-07 - val_dense_150_loss: 6.5582e-07\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1306e-06 - dense_149_loss: 6.5149e-07 - dense_150_loss: 4.7910e-07 - val_loss: 1.5131e-06 - val_dense_149_loss: 7.7051e-07 - val_dense_150_loss: 7.4261e-07\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1134e-06 - dense_149_loss: 6.3482e-07 - dense_150_loss: 4.7860e-07 - val_loss: 1.2028e-06 - val_dense_149_loss: 7.0588e-07 - val_dense_150_loss: 4.9694e-07\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1136e-06 - dense_149_loss: 6.4555e-07 - dense_150_loss: 4.6808e-07 - val_loss: 1.1382e-06 - val_dense_149_loss: 5.8667e-07 - val_dense_150_loss: 5.5153e-07\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1347e-06 - dense_149_loss: 6.4787e-07 - dense_150_loss: 4.8685e-07 - val_loss: 1.2104e-06 - val_dense_149_loss: 7.1314e-07 - val_dense_150_loss: 4.9723e-07\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0704e-06 - dense_149_loss: 6.2926e-07 - dense_150_loss: 4.4114e-07 - val_loss: 1.0452e-06 - val_dense_149_loss: 6.3358e-07 - val_dense_150_loss: 4.1163e-07\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0270e-06 - dense_149_loss: 6.0665e-07 - dense_150_loss: 4.2038e-07 - val_loss: 1.0431e-06 - val_dense_149_loss: 5.8682e-07 - val_dense_150_loss: 4.5632e-07\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0440e-06 - dense_149_loss: 6.0707e-07 - dense_150_loss: 4.3691e-07 - val_loss: 1.4100e-06 - val_dense_149_loss: 7.9414e-07 - val_dense_150_loss: 6.1587e-07\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4079e-06 - dense_149_loss: 8.1096e-07 - dense_150_loss: 5.9690e-07 - val_loss: 1.3937e-06 - val_dense_149_loss: 8.1381e-07 - val_dense_150_loss: 5.7991e-07\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1204e-06 - dense_149_loss: 6.4738e-07 - dense_150_loss: 4.7298e-07 - val_loss: 1.4565e-06 - val_dense_149_loss: 8.6789e-07 - val_dense_150_loss: 5.8856e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "\n",
      "Now training model 12/12\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 2s 22ms/step - loss: 7.0147e-04 - dense_153_loss: 7.9635e-05 - dense_154_loss: 1.1194e-04 - dense_155_loss: 9.1583e-05 - dense_156_loss: 7.8648e-05 - dense_157_loss: 8.5364e-05 - dense_158_loss: 8.5266e-05 - dense_159_loss: 9.8676e-05 - dense_160_loss: 7.0358e-05 - val_loss: 9.2581e-05 - val_dense_153_loss: 9.5213e-06 - val_dense_154_loss: 1.6092e-05 - val_dense_155_loss: 8.4998e-06 - val_dense_156_loss: 1.3793e-05 - val_dense_157_loss: 1.1472e-05 - val_dense_158_loss: 1.5089e-05 - val_dense_159_loss: 8.7205e-06 - val_dense_160_loss: 9.3924e-06\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1704e-05 - dense_153_loss: 7.7919e-06 - dense_154_loss: 9.0081e-06 - dense_155_loss: 7.0419e-06 - dense_156_loss: 8.8960e-06 - dense_157_loss: 6.9261e-06 - dense_158_loss: 8.4828e-06 - dense_159_loss: 7.0308e-06 - dense_160_loss: 6.5261e-06 - val_loss: 2.4001e-05 - val_dense_153_loss: 2.2250e-06 - val_dense_154_loss: 4.5290e-06 - val_dense_155_loss: 2.8813e-06 - val_dense_156_loss: 3.2439e-06 - val_dense_157_loss: 2.7775e-06 - val_dense_158_loss: 2.5492e-06 - val_dense_159_loss: 2.7227e-06 - val_dense_160_loss: 3.0728e-06\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7553e-05 - dense_153_loss: 1.3970e-06 - dense_154_loss: 3.3559e-06 - dense_155_loss: 1.5663e-06 - dense_156_loss: 2.8138e-06 - dense_157_loss: 1.8024e-06 - dense_158_loss: 2.1403e-06 - dense_159_loss: 2.1141e-06 - dense_160_loss: 2.3637e-06 - val_loss: 1.3212e-05 - val_dense_153_loss: 8.5977e-07 - val_dense_154_loss: 2.8066e-06 - val_dense_155_loss: 8.2027e-07 - val_dense_156_loss: 2.4129e-06 - val_dense_157_loss: 1.2560e-06 - val_dense_158_loss: 1.6708e-06 - val_dense_159_loss: 1.5709e-06 - val_dense_160_loss: 1.8142e-06\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2218e-05 - dense_153_loss: 7.2497e-07 - dense_154_loss: 2.7037e-06 - dense_155_loss: 8.1624e-07 - dense_156_loss: 2.1886e-06 - dense_157_loss: 1.1680e-06 - dense_158_loss: 1.5777e-06 - dense_159_loss: 1.3770e-06 - dense_160_loss: 1.6619e-06 - val_loss: 1.1986e-05 - val_dense_153_loss: 7.4046e-07 - val_dense_154_loss: 2.5793e-06 - val_dense_155_loss: 8.5480e-07 - val_dense_156_loss: 2.0328e-06 - val_dense_157_loss: 1.1612e-06 - val_dense_158_loss: 1.5655e-06 - val_dense_159_loss: 1.3708e-06 - val_dense_160_loss: 1.6811e-06\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1529e-05 - dense_153_loss: 6.4232e-07 - dense_154_loss: 2.6152e-06 - dense_155_loss: 7.2910e-07 - dense_156_loss: 2.1129e-06 - dense_157_loss: 1.0831e-06 - dense_158_loss: 1.4846e-06 - dense_159_loss: 1.3050e-06 - dense_160_loss: 1.5566e-06 - val_loss: 1.1622e-05 - val_dense_153_loss: 6.2604e-07 - val_dense_154_loss: 2.7006e-06 - val_dense_155_loss: 7.3207e-07 - val_dense_156_loss: 2.0269e-06 - val_dense_157_loss: 1.1570e-06 - val_dense_158_loss: 1.5123e-06 - val_dense_159_loss: 1.3138e-06 - val_dense_160_loss: 1.5530e-06\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1625e-05 - dense_153_loss: 6.4628e-07 - dense_154_loss: 2.6413e-06 - dense_155_loss: 7.2820e-07 - dense_156_loss: 2.1190e-06 - dense_157_loss: 1.0927e-06 - dense_158_loss: 1.5128e-06 - dense_159_loss: 1.3020e-06 - dense_160_loss: 1.5830e-06 - val_loss: 1.2452e-05 - val_dense_153_loss: 7.6702e-07 - val_dense_154_loss: 2.7857e-06 - val_dense_155_loss: 8.0332e-07 - val_dense_156_loss: 2.2184e-06 - val_dense_157_loss: 1.1983e-06 - val_dense_158_loss: 1.7410e-06 - val_dense_159_loss: 1.3229e-06 - val_dense_160_loss: 1.6150e-06\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1475e-05 - dense_153_loss: 6.4819e-07 - dense_154_loss: 2.6084e-06 - dense_155_loss: 7.1713e-07 - dense_156_loss: 2.0869e-06 - dense_157_loss: 1.0674e-06 - dense_158_loss: 1.5018e-06 - dense_159_loss: 1.2845e-06 - dense_160_loss: 1.5604e-06 - val_loss: 1.1887e-05 - val_dense_153_loss: 7.0954e-07 - val_dense_154_loss: 2.8003e-06 - val_dense_155_loss: 8.0644e-07 - val_dense_156_loss: 2.0850e-06 - val_dense_157_loss: 1.1313e-06 - val_dense_158_loss: 1.4546e-06 - val_dense_159_loss: 1.3686e-06 - val_dense_160_loss: 1.5308e-06\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1584e-05 - dense_153_loss: 6.6597e-07 - dense_154_loss: 2.5883e-06 - dense_155_loss: 7.2997e-07 - dense_156_loss: 2.0984e-06 - dense_157_loss: 1.0893e-06 - dense_158_loss: 1.5130e-06 - dense_159_loss: 1.3111e-06 - dense_160_loss: 1.5874e-06 - val_loss: 1.1618e-05 - val_dense_153_loss: 6.9210e-07 - val_dense_154_loss: 2.6267e-06 - val_dense_155_loss: 7.7389e-07 - val_dense_156_loss: 2.0431e-06 - val_dense_157_loss: 1.0781e-06 - val_dense_158_loss: 1.5033e-06 - val_dense_159_loss: 1.3873e-06 - val_dense_160_loss: 1.5133e-06\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1391e-05 - dense_153_loss: 6.7074e-07 - dense_154_loss: 2.5252e-06 - dense_155_loss: 7.1958e-07 - dense_156_loss: 2.0424e-06 - dense_157_loss: 1.0790e-06 - dense_158_loss: 1.4803e-06 - dense_159_loss: 1.3106e-06 - dense_160_loss: 1.5628e-06 - val_loss: 1.1189e-05 - val_dense_153_loss: 6.6851e-07 - val_dense_154_loss: 2.3668e-06 - val_dense_155_loss: 7.8848e-07 - val_dense_156_loss: 1.8681e-06 - val_dense_157_loss: 1.1137e-06 - val_dense_158_loss: 1.5084e-06 - val_dense_159_loss: 1.3359e-06 - val_dense_160_loss: 1.5394e-06\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1241e-05 - dense_153_loss: 6.7111e-07 - dense_154_loss: 2.4470e-06 - dense_155_loss: 7.2642e-07 - dense_156_loss: 1.9777e-06 - dense_157_loss: 1.0799e-06 - dense_158_loss: 1.4636e-06 - dense_159_loss: 1.3197e-06 - dense_160_loss: 1.5560e-06 - val_loss: 1.1425e-05 - val_dense_153_loss: 7.3530e-07 - val_dense_154_loss: 2.4712e-06 - val_dense_155_loss: 8.2938e-07 - val_dense_156_loss: 1.8856e-06 - val_dense_157_loss: 1.1594e-06 - val_dense_158_loss: 1.4592e-06 - val_dense_159_loss: 1.3250e-06 - val_dense_160_loss: 1.5600e-06\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1244e-05 - dense_153_loss: 7.1172e-07 - dense_154_loss: 2.4251e-06 - dense_155_loss: 7.4353e-07 - dense_156_loss: 1.9496e-06 - dense_157_loss: 1.0898e-06 - dense_158_loss: 1.4567e-06 - dense_159_loss: 1.3122e-06 - dense_160_loss: 1.5553e-06 - val_loss: 1.1973e-05 - val_dense_153_loss: 7.7761e-07 - val_dense_154_loss: 2.5346e-06 - val_dense_155_loss: 7.7609e-07 - val_dense_156_loss: 1.9493e-06 - val_dense_157_loss: 1.2742e-06 - val_dense_158_loss: 1.4797e-06 - val_dense_159_loss: 1.5247e-06 - val_dense_160_loss: 1.6574e-06\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2286e-05 - dense_153_loss: 8.1116e-07 - dense_154_loss: 2.6152e-06 - dense_155_loss: 8.3520e-07 - dense_156_loss: 2.0821e-06 - dense_157_loss: 1.2039e-06 - dense_158_loss: 1.6178e-06 - dense_159_loss: 1.4271e-06 - dense_160_loss: 1.6936e-06 - val_loss: 1.1477e-05 - val_dense_153_loss: 7.6749e-07 - val_dense_154_loss: 2.2817e-06 - val_dense_155_loss: 8.0722e-07 - val_dense_156_loss: 1.8689e-06 - val_dense_157_loss: 1.2851e-06 - val_dense_158_loss: 1.4448e-06 - val_dense_159_loss: 1.4459e-06 - val_dense_160_loss: 1.5761e-06\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5409e-05 - dense_153_loss: 1.2494e-06 - dense_154_loss: 3.1456e-06 - dense_155_loss: 1.2212e-06 - dense_156_loss: 2.4676e-06 - dense_157_loss: 1.4564e-06 - dense_158_loss: 2.0215e-06 - dense_159_loss: 1.7434e-06 - dense_160_loss: 2.1038e-06 - val_loss: 1.2247e-05 - val_dense_153_loss: 7.1026e-07 - val_dense_154_loss: 2.3643e-06 - val_dense_155_loss: 8.0764e-07 - val_dense_156_loss: 1.9168e-06 - val_dense_157_loss: 1.3286e-06 - val_dense_158_loss: 1.6697e-06 - val_dense_159_loss: 1.6085e-06 - val_dense_160_loss: 1.8411e-06\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2588e-05 - dense_153_loss: 9.0152e-07 - dense_154_loss: 2.5967e-06 - dense_155_loss: 9.0972e-07 - dense_156_loss: 2.0742e-06 - dense_157_loss: 1.2247e-06 - dense_158_loss: 1.6536e-06 - dense_159_loss: 1.4797e-06 - dense_160_loss: 1.7476e-06 - val_loss: 1.5653e-05 - val_dense_153_loss: 1.1885e-06 - val_dense_154_loss: 3.0647e-06 - val_dense_155_loss: 1.2590e-06 - val_dense_156_loss: 2.4456e-06 - val_dense_157_loss: 1.5899e-06 - val_dense_158_loss: 1.9660e-06 - val_dense_159_loss: 1.8887e-06 - val_dense_160_loss: 2.2507e-06\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3959e-05 - dense_153_loss: 1.0809e-06 - dense_154_loss: 2.7990e-06 - dense_155_loss: 1.0865e-06 - dense_156_loss: 2.2473e-06 - dense_157_loss: 1.3831e-06 - dense_158_loss: 1.8187e-06 - dense_159_loss: 1.6036e-06 - dense_160_loss: 1.9405e-06 - val_loss: 1.2739e-05 - val_dense_153_loss: 9.4536e-07 - val_dense_154_loss: 2.3730e-06 - val_dense_155_loss: 9.5383e-07 - val_dense_156_loss: 1.8780e-06 - val_dense_157_loss: 1.3885e-06 - val_dense_158_loss: 1.5952e-06 - val_dense_159_loss: 1.7143e-06 - val_dense_160_loss: 1.8907e-06\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2428e-05 - dense_153_loss: 9.1613e-07 - dense_154_loss: 2.4886e-06 - dense_155_loss: 9.1941e-07 - dense_156_loss: 1.9898e-06 - dense_157_loss: 1.3010e-06 - dense_158_loss: 1.6051e-06 - dense_159_loss: 1.5076e-06 - dense_160_loss: 1.7000e-06 - val_loss: 1.2032e-05 - val_dense_153_loss: 9.4753e-07 - val_dense_154_loss: 2.3686e-06 - val_dense_155_loss: 8.3178e-07 - val_dense_156_loss: 1.8335e-06 - val_dense_157_loss: 1.3817e-06 - val_dense_158_loss: 1.4826e-06 - val_dense_159_loss: 1.4601e-06 - val_dense_160_loss: 1.7262e-06\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4119e-05 - dense_153_loss: 1.1634e-06 - dense_154_loss: 2.7585e-06 - dense_155_loss: 1.1218e-06 - dense_156_loss: 2.1958e-06 - dense_157_loss: 1.4405e-06 - dense_158_loss: 1.8370e-06 - dense_159_loss: 1.6700e-06 - dense_160_loss: 1.9322e-06 - val_loss: 2.3813e-05 - val_dense_153_loss: 2.1691e-06 - val_dense_154_loss: 4.2939e-06 - val_dense_155_loss: 2.3488e-06 - val_dense_156_loss: 3.1088e-06 - val_dense_157_loss: 2.7002e-06 - val_dense_158_loss: 3.0854e-06 - val_dense_159_loss: 2.7574e-06 - val_dense_160_loss: 3.3498e-06\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3262e-05 - dense_153_loss: 1.0389e-06 - dense_154_loss: 2.7301e-06 - dense_155_loss: 1.0074e-06 - dense_156_loss: 2.0714e-06 - dense_157_loss: 1.3337e-06 - dense_158_loss: 1.7032e-06 - dense_159_loss: 1.5648e-06 - dense_160_loss: 1.8127e-06 - val_loss: 1.2145e-05 - val_dense_153_loss: 8.7996e-07 - val_dense_154_loss: 2.2415e-06 - val_dense_155_loss: 9.2041e-07 - val_dense_156_loss: 1.8198e-06 - val_dense_157_loss: 1.3837e-06 - val_dense_158_loss: 1.6348e-06 - val_dense_159_loss: 1.5507e-06 - val_dense_160_loss: 1.7140e-06\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2577e-05 - dense_153_loss: 9.8246e-07 - dense_154_loss: 2.4630e-06 - dense_155_loss: 9.6405e-07 - dense_156_loss: 1.9312e-06 - dense_157_loss: 1.3094e-06 - dense_158_loss: 1.6252e-06 - dense_159_loss: 1.5586e-06 - dense_160_loss: 1.7433e-06 - val_loss: 1.2111e-05 - val_dense_153_loss: 7.7679e-07 - val_dense_154_loss: 2.3539e-06 - val_dense_155_loss: 1.0550e-06 - val_dense_156_loss: 1.8644e-06 - val_dense_157_loss: 1.2255e-06 - val_dense_158_loss: 1.5746e-06 - val_dense_159_loss: 1.6237e-06 - val_dense_160_loss: 1.6368e-06\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1788e-05 - dense_153_loss: 8.9170e-07 - dense_154_loss: 2.3029e-06 - dense_155_loss: 9.3074e-07 - dense_156_loss: 1.7808e-06 - dense_157_loss: 1.2209e-06 - dense_158_loss: 1.5074e-06 - dense_159_loss: 1.5065e-06 - dense_160_loss: 1.6471e-06 - val_loss: 1.4061e-05 - val_dense_153_loss: 1.2841e-06 - val_dense_154_loss: 2.7855e-06 - val_dense_155_loss: 1.3035e-06 - val_dense_156_loss: 2.0399e-06 - val_dense_157_loss: 1.4123e-06 - val_dense_158_loss: 1.7191e-06 - val_dense_159_loss: 1.7002e-06 - val_dense_160_loss: 1.8164e-06\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1940e-05 - dense_153_loss: 9.8548e-07 - dense_154_loss: 2.2321e-06 - dense_155_loss: 9.0950e-07 - dense_156_loss: 1.8169e-06 - dense_157_loss: 1.2742e-06 - dense_158_loss: 1.5777e-06 - dense_159_loss: 1.5358e-06 - dense_160_loss: 1.6083e-06 - val_loss: 1.3301e-05 - val_dense_153_loss: 1.1068e-06 - val_dense_154_loss: 2.2348e-06 - val_dense_155_loss: 1.1048e-06 - val_dense_156_loss: 1.9402e-06 - val_dense_157_loss: 1.5982e-06 - val_dense_158_loss: 1.8126e-06 - val_dense_159_loss: 1.7205e-06 - val_dense_160_loss: 1.7832e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3864e-05 - dense_153_loss: 1.2364e-06 - dense_154_loss: 2.4424e-06 - dense_155_loss: 1.1093e-06 - dense_156_loss: 2.0957e-06 - dense_157_loss: 1.4856e-06 - dense_158_loss: 1.8616e-06 - dense_159_loss: 1.7509e-06 - dense_160_loss: 1.8821e-06 - val_loss: 1.2782e-05 - val_dense_153_loss: 1.0181e-06 - val_dense_154_loss: 2.4388e-06 - val_dense_155_loss: 9.7703e-07 - val_dense_156_loss: 1.8788e-06 - val_dense_157_loss: 1.4540e-06 - val_dense_158_loss: 1.5547e-06 - val_dense_159_loss: 1.7173e-06 - val_dense_160_loss: 1.7434e-06\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7459e-05 - dense_153_loss: 1.6127e-06 - dense_154_loss: 3.0048e-06 - dense_155_loss: 1.5338e-06 - dense_156_loss: 2.4318e-06 - dense_157_loss: 1.9438e-06 - dense_158_loss: 2.0754e-06 - dense_159_loss: 2.4202e-06 - dense_160_loss: 2.4368e-06 - val_loss: 1.3403e-05 - val_dense_153_loss: 1.3306e-06 - val_dense_154_loss: 2.5806e-06 - val_dense_155_loss: 1.1540e-06 - val_dense_156_loss: 1.5972e-06 - val_dense_157_loss: 1.5723e-06 - val_dense_158_loss: 1.5824e-06 - val_dense_159_loss: 1.6607e-06 - val_dense_160_loss: 1.9247e-06\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1197e-05 - dense_153_loss: 9.4726e-07 - dense_154_loss: 2.0253e-06 - dense_155_loss: 9.5745e-07 - dense_156_loss: 1.5553e-06 - dense_157_loss: 1.3081e-06 - dense_158_loss: 1.3769e-06 - dense_159_loss: 1.4821e-06 - dense_160_loss: 1.5450e-06 - val_loss: 1.1368e-05 - val_dense_153_loss: 9.8455e-07 - val_dense_154_loss: 1.9409e-06 - val_dense_155_loss: 1.0026e-06 - val_dense_156_loss: 1.4890e-06 - val_dense_157_loss: 1.5205e-06 - val_dense_158_loss: 1.3842e-06 - val_dense_159_loss: 1.4741e-06 - val_dense_160_loss: 1.5721e-06\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2120e-05 - dense_153_loss: 1.1195e-06 - dense_154_loss: 2.0420e-06 - dense_155_loss: 1.0149e-06 - dense_156_loss: 1.6944e-06 - dense_157_loss: 1.4439e-06 - dense_158_loss: 1.5350e-06 - dense_159_loss: 1.6290e-06 - dense_160_loss: 1.6411e-06 - val_loss: 1.5875e-05 - val_dense_153_loss: 1.8813e-06 - val_dense_154_loss: 2.2117e-06 - val_dense_155_loss: 1.2444e-06 - val_dense_156_loss: 2.0158e-06 - val_dense_157_loss: 1.7752e-06 - val_dense_158_loss: 2.3852e-06 - val_dense_159_loss: 2.4941e-06 - val_dense_160_loss: 1.8668e-06\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1981e-05 - dense_153_loss: 1.0101e-06 - dense_154_loss: 2.0042e-06 - dense_155_loss: 1.0184e-06 - dense_156_loss: 1.6392e-06 - dense_157_loss: 1.4237e-06 - dense_158_loss: 1.5552e-06 - dense_159_loss: 1.6527e-06 - dense_160_loss: 1.6777e-06 - val_loss: 1.0221e-05 - val_dense_153_loss: 7.3739e-07 - val_dense_154_loss: 1.7917e-06 - val_dense_155_loss: 9.4050e-07 - val_dense_156_loss: 1.3875e-06 - val_dense_157_loss: 1.3171e-06 - val_dense_158_loss: 1.2360e-06 - val_dense_159_loss: 1.2894e-06 - val_dense_160_loss: 1.5209e-06\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0671e-05 - dense_153_loss: 9.4548e-07 - dense_154_loss: 1.7723e-06 - dense_155_loss: 9.2184e-07 - dense_156_loss: 1.4831e-06 - dense_157_loss: 1.2520e-06 - dense_158_loss: 1.3721e-06 - dense_159_loss: 1.4500e-06 - dense_160_loss: 1.4740e-06 - val_loss: 1.2320e-05 - val_dense_153_loss: 1.0848e-06 - val_dense_154_loss: 2.2840e-06 - val_dense_155_loss: 1.2652e-06 - val_dense_156_loss: 1.5742e-06 - val_dense_157_loss: 1.3295e-06 - val_dense_158_loss: 1.3871e-06 - val_dense_159_loss: 1.7514e-06 - val_dense_160_loss: 1.6437e-06\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6512e-05 - dense_153_loss: 1.6879e-06 - dense_154_loss: 2.7775e-06 - dense_155_loss: 1.5385e-06 - dense_156_loss: 2.1969e-06 - dense_157_loss: 1.8533e-06 - dense_158_loss: 2.2067e-06 - dense_159_loss: 2.1215e-06 - dense_160_loss: 2.1299e-06 - val_loss: 1.4773e-05 - val_dense_153_loss: 1.2239e-06 - val_dense_154_loss: 2.1671e-06 - val_dense_155_loss: 1.5515e-06 - val_dense_156_loss: 1.9498e-06 - val_dense_157_loss: 2.0103e-06 - val_dense_158_loss: 1.6473e-06 - val_dense_159_loss: 2.3078e-06 - val_dense_160_loss: 1.9157e-06\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1823e-05 - dense_153_loss: 1.0491e-06 - dense_154_loss: 1.8430e-06 - dense_155_loss: 1.0776e-06 - dense_156_loss: 1.5753e-06 - dense_157_loss: 1.5577e-06 - dense_158_loss: 1.4564e-06 - dense_159_loss: 1.6885e-06 - dense_160_loss: 1.5759e-06 - val_loss: 1.1430e-05 - val_dense_153_loss: 1.0635e-06 - val_dense_154_loss: 1.8121e-06 - val_dense_155_loss: 8.8113e-07 - val_dense_156_loss: 1.4156e-06 - val_dense_157_loss: 1.4997e-06 - val_dense_158_loss: 1.4006e-06 - val_dense_159_loss: 1.7253e-06 - val_dense_160_loss: 1.6318e-06\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1091e-05 - dense_153_loss: 1.0138e-06 - dense_154_loss: 1.7453e-06 - dense_155_loss: 1.0082e-06 - dense_156_loss: 1.4754e-06 - dense_157_loss: 1.4094e-06 - dense_158_loss: 1.3625e-06 - dense_159_loss: 1.5095e-06 - dense_160_loss: 1.5669e-06 - val_loss: 1.0665e-05 - val_dense_153_loss: 9.0297e-07 - val_dense_154_loss: 1.6049e-06 - val_dense_155_loss: 1.0541e-06 - val_dense_156_loss: 1.3486e-06 - val_dense_157_loss: 1.4766e-06 - val_dense_158_loss: 1.5063e-06 - val_dense_159_loss: 1.4615e-06 - val_dense_160_loss: 1.3099e-06\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0440e-05 - dense_153_loss: 1.0005e-06 - dense_154_loss: 1.6006e-06 - dense_155_loss: 9.5743e-07 - dense_156_loss: 1.3544e-06 - dense_157_loss: 1.3010e-06 - dense_158_loss: 1.3201e-06 - dense_159_loss: 1.5076e-06 - dense_160_loss: 1.3979e-06 - val_loss: 1.1073e-05 - val_dense_153_loss: 1.0660e-06 - val_dense_154_loss: 1.4429e-06 - val_dense_155_loss: 9.1273e-07 - val_dense_156_loss: 1.4283e-06 - val_dense_157_loss: 1.5965e-06 - val_dense_158_loss: 1.5377e-06 - val_dense_159_loss: 1.4480e-06 - val_dense_160_loss: 1.6405e-06\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2546e-05 - dense_153_loss: 1.1614e-06 - dense_154_loss: 1.7711e-06 - dense_155_loss: 1.1764e-06 - dense_156_loss: 1.6153e-06 - dense_157_loss: 1.6504e-06 - dense_158_loss: 1.6088e-06 - dense_159_loss: 1.7383e-06 - dense_160_loss: 1.8240e-06 - val_loss: 1.6060e-05 - val_dense_153_loss: 1.7043e-06 - val_dense_154_loss: 1.7075e-06 - val_dense_155_loss: 1.5485e-06 - val_dense_156_loss: 1.8774e-06 - val_dense_157_loss: 2.0991e-06 - val_dense_158_loss: 2.6524e-06 - val_dense_159_loss: 2.1853e-06 - val_dense_160_loss: 2.2852e-06\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1143e-05 - dense_153_loss: 1.1031e-06 - dense_154_loss: 1.5616e-06 - dense_155_loss: 9.9181e-07 - dense_156_loss: 1.4081e-06 - dense_157_loss: 1.4210e-06 - dense_158_loss: 1.4987e-06 - dense_159_loss: 1.5845e-06 - dense_160_loss: 1.5746e-06 - val_loss: 1.0678e-05 - val_dense_153_loss: 1.0692e-06 - val_dense_154_loss: 1.4438e-06 - val_dense_155_loss: 1.0911e-06 - val_dense_156_loss: 1.1518e-06 - val_dense_157_loss: 1.3437e-06 - val_dense_158_loss: 1.5580e-06 - val_dense_159_loss: 1.6541e-06 - val_dense_160_loss: 1.3662e-06\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0136e-05 - dense_153_loss: 1.0011e-06 - dense_154_loss: 1.4442e-06 - dense_155_loss: 9.4879e-07 - dense_156_loss: 1.2129e-06 - dense_157_loss: 1.3695e-06 - dense_158_loss: 1.3072e-06 - dense_159_loss: 1.4845e-06 - dense_160_loss: 1.3681e-06 - val_loss: 1.1441e-05 - val_dense_153_loss: 1.1103e-06 - val_dense_154_loss: 1.8524e-06 - val_dense_155_loss: 9.2782e-07 - val_dense_156_loss: 1.2472e-06 - val_dense_157_loss: 1.3812e-06 - val_dense_158_loss: 1.5391e-06 - val_dense_159_loss: 1.7160e-06 - val_dense_160_loss: 1.6674e-06\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4874e-06 - dense_153_loss: 9.5031e-07 - dense_154_loss: 1.2936e-06 - dense_155_loss: 8.4886e-07 - dense_156_loss: 1.0911e-06 - dense_157_loss: 1.3087e-06 - dense_158_loss: 1.2484e-06 - dense_159_loss: 1.3789e-06 - dense_160_loss: 1.3675e-06 - val_loss: 9.7888e-06 - val_dense_153_loss: 9.0443e-07 - val_dense_154_loss: 1.1867e-06 - val_dense_155_loss: 8.1604e-07 - val_dense_156_loss: 1.1813e-06 - val_dense_157_loss: 1.4998e-06 - val_dense_158_loss: 1.3038e-06 - val_dense_159_loss: 1.3114e-06 - val_dense_160_loss: 1.5854e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2293e-05 - dense_153_loss: 1.2750e-06 - dense_154_loss: 1.5682e-06 - dense_155_loss: 1.2082e-06 - dense_156_loss: 1.4047e-06 - dense_157_loss: 1.6250e-06 - dense_158_loss: 1.6214e-06 - dense_159_loss: 1.8072e-06 - dense_160_loss: 1.7831e-06 - val_loss: 1.2257e-05 - val_dense_153_loss: 1.0155e-06 - val_dense_154_loss: 1.7590e-06 - val_dense_155_loss: 1.1699e-06 - val_dense_156_loss: 1.6709e-06 - val_dense_157_loss: 1.7523e-06 - val_dense_158_loss: 1.4638e-06 - val_dense_159_loss: 1.6346e-06 - val_dense_160_loss: 1.7911e-06\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0589e-05 - dense_153_loss: 9.7728e-07 - dense_154_loss: 1.4725e-06 - dense_155_loss: 1.0473e-06 - dense_156_loss: 1.3000e-06 - dense_157_loss: 1.4915e-06 - dense_158_loss: 1.2898e-06 - dense_159_loss: 1.5611e-06 - dense_160_loss: 1.4500e-06 - val_loss: 1.2762e-05 - val_dense_153_loss: 1.1946e-06 - val_dense_154_loss: 1.6670e-06 - val_dense_155_loss: 1.5355e-06 - val_dense_156_loss: 1.3240e-06 - val_dense_157_loss: 1.5432e-06 - val_dense_158_loss: 1.8849e-06 - val_dense_159_loss: 1.7892e-06 - val_dense_160_loss: 1.8233e-06\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1275e-05 - dense_153_loss: 1.0870e-06 - dense_154_loss: 1.4343e-06 - dense_155_loss: 1.1986e-06 - dense_156_loss: 1.4050e-06 - dense_157_loss: 1.5461e-06 - dense_158_loss: 1.4921e-06 - dense_159_loss: 1.6346e-06 - dense_160_loss: 1.4774e-06 - val_loss: 1.0006e-05 - val_dense_153_loss: 9.0402e-07 - val_dense_154_loss: 1.2026e-06 - val_dense_155_loss: 1.0452e-06 - val_dense_156_loss: 1.3487e-06 - val_dense_157_loss: 1.5314e-06 - val_dense_158_loss: 1.3451e-06 - val_dense_159_loss: 1.3474e-06 - val_dense_160_loss: 1.2821e-06\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4376e-06 - dense_153_loss: 8.9789e-07 - dense_154_loss: 1.1745e-06 - dense_155_loss: 9.4356e-07 - dense_156_loss: 1.1955e-06 - dense_157_loss: 1.3928e-06 - dense_158_loss: 1.2491e-06 - dense_159_loss: 1.3185e-06 - dense_160_loss: 1.2657e-06 - val_loss: 8.3015e-06 - val_dense_153_loss: 7.8190e-07 - val_dense_154_loss: 9.4811e-07 - val_dense_155_loss: 7.6418e-07 - val_dense_156_loss: 9.0466e-07 - val_dense_157_loss: 1.2029e-06 - val_dense_158_loss: 1.1155e-06 - val_dense_159_loss: 1.3665e-06 - val_dense_160_loss: 1.2177e-06\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0268e-06 - dense_153_loss: 8.6620e-07 - dense_154_loss: 1.0759e-06 - dense_155_loss: 8.1331e-07 - dense_156_loss: 1.1575e-06 - dense_157_loss: 1.2658e-06 - dense_158_loss: 1.2402e-06 - dense_159_loss: 1.3598e-06 - dense_160_loss: 1.2479e-06 - val_loss: 1.9638e-05 - val_dense_153_loss: 1.8313e-06 - val_dense_154_loss: 2.4208e-06 - val_dense_155_loss: 2.1764e-06 - val_dense_156_loss: 2.6650e-06 - val_dense_157_loss: 2.3296e-06 - val_dense_158_loss: 2.5056e-06 - val_dense_159_loss: 3.2725e-06 - val_dense_160_loss: 2.4365e-06\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2519e-05 - dense_153_loss: 1.2233e-06 - dense_154_loss: 1.5835e-06 - dense_155_loss: 1.2205e-06 - dense_156_loss: 1.5561e-06 - dense_157_loss: 1.7437e-06 - dense_158_loss: 1.4886e-06 - dense_159_loss: 1.8906e-06 - dense_160_loss: 1.8124e-06 - val_loss: 1.2336e-05 - val_dense_153_loss: 1.2106e-06 - val_dense_154_loss: 1.5060e-06 - val_dense_155_loss: 1.0300e-06 - val_dense_156_loss: 1.7218e-06 - val_dense_157_loss: 1.9866e-06 - val_dense_158_loss: 1.5231e-06 - val_dense_159_loss: 1.5827e-06 - val_dense_160_loss: 1.7751e-06\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.7164e-06 - dense_153_loss: 1.0269e-06 - dense_154_loss: 1.1405e-06 - dense_155_loss: 9.2615e-07 - dense_156_loss: 1.2291e-06 - dense_157_loss: 1.3377e-06 - dense_158_loss: 1.2476e-06 - dense_159_loss: 1.4324e-06 - dense_160_loss: 1.3760e-06 - val_loss: 1.0100e-05 - val_dense_153_loss: 1.1178e-06 - val_dense_154_loss: 1.3035e-06 - val_dense_155_loss: 1.0551e-06 - val_dense_156_loss: 1.0644e-06 - val_dense_157_loss: 1.1948e-06 - val_dense_158_loss: 1.6079e-06 - val_dense_159_loss: 1.4871e-06 - val_dense_160_loss: 1.2693e-06\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8624e-06 - dense_153_loss: 8.8939e-07 - dense_154_loss: 1.0368e-06 - dense_155_loss: 8.8008e-07 - dense_156_loss: 1.0389e-06 - dense_157_loss: 1.2777e-06 - dense_158_loss: 1.1901e-06 - dense_159_loss: 1.2912e-06 - dense_160_loss: 1.2583e-06 - val_loss: 9.8461e-06 - val_dense_153_loss: 1.1179e-06 - val_dense_154_loss: 1.2302e-06 - val_dense_155_loss: 1.0841e-06 - val_dense_156_loss: 1.0693e-06 - val_dense_157_loss: 1.2346e-06 - val_dense_158_loss: 1.3002e-06 - val_dense_159_loss: 1.3653e-06 - val_dense_160_loss: 1.4445e-06\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.9372e-06 - dense_153_loss: 9.1629e-07 - dense_154_loss: 1.1216e-06 - dense_155_loss: 8.6224e-07 - dense_156_loss: 1.0351e-06 - dense_157_loss: 1.2319e-06 - dense_158_loss: 1.2202e-06 - dense_159_loss: 1.3367e-06 - dense_160_loss: 1.2133e-06 - val_loss: 9.0587e-06 - val_dense_153_loss: 9.2766e-07 - val_dense_154_loss: 9.8116e-07 - val_dense_155_loss: 8.0418e-07 - val_dense_156_loss: 1.1555e-06 - val_dense_157_loss: 1.2693e-06 - val_dense_158_loss: 1.1070e-06 - val_dense_159_loss: 1.4461e-06 - val_dense_160_loss: 1.3678e-06\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2025e-06 - dense_153_loss: 7.8788e-07 - dense_154_loss: 9.5811e-07 - dense_155_loss: 7.5989e-07 - dense_156_loss: 9.4651e-07 - dense_157_loss: 1.1760e-06 - dense_158_loss: 1.0838e-06 - dense_159_loss: 1.2817e-06 - dense_160_loss: 1.2087e-06 - val_loss: 9.1177e-06 - val_dense_153_loss: 8.1232e-07 - val_dense_154_loss: 1.1521e-06 - val_dense_155_loss: 6.6983e-07 - val_dense_156_loss: 1.2982e-06 - val_dense_157_loss: 1.4044e-06 - val_dense_158_loss: 1.1933e-06 - val_dense_159_loss: 1.2953e-06 - val_dense_160_loss: 1.2922e-06\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1389e-06 - dense_153_loss: 7.2721e-07 - dense_154_loss: 9.4649e-07 - dense_155_loss: 7.2300e-07 - dense_156_loss: 1.0298e-06 - dense_157_loss: 1.1702e-06 - dense_158_loss: 1.0863e-06 - dense_159_loss: 1.2653e-06 - dense_160_loss: 1.1906e-06 - val_loss: 1.0365e-05 - val_dense_153_loss: 1.1781e-06 - val_dense_154_loss: 1.4489e-06 - val_dense_155_loss: 1.0770e-06 - val_dense_156_loss: 1.2716e-06 - val_dense_157_loss: 1.2749e-06 - val_dense_158_loss: 1.1176e-06 - val_dense_159_loss: 1.6512e-06 - val_dense_160_loss: 1.3455e-06\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9537e-06 - dense_153_loss: 8.0475e-07 - dense_154_loss: 9.1407e-07 - dense_155_loss: 7.3850e-07 - dense_156_loss: 9.2153e-07 - dense_157_loss: 1.1476e-06 - dense_158_loss: 1.0385e-06 - dense_159_loss: 1.2544e-06 - dense_160_loss: 1.1343e-06 - val_loss: 8.8294e-06 - val_dense_153_loss: 1.0996e-06 - val_dense_154_loss: 1.0827e-06 - val_dense_155_loss: 9.8115e-07 - val_dense_156_loss: 1.0018e-06 - val_dense_157_loss: 1.1638e-06 - val_dense_158_loss: 1.1195e-06 - val_dense_159_loss: 1.2620e-06 - val_dense_160_loss: 1.1189e-06\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6911e-05 - dense_153_loss: 1.9049e-06 - dense_154_loss: 2.2711e-06 - dense_155_loss: 1.6233e-06 - dense_156_loss: 2.1715e-06 - dense_157_loss: 2.0783e-06 - dense_158_loss: 2.4706e-06 - dense_159_loss: 2.1375e-06 - dense_160_loss: 2.2534e-06 - val_loss: 1.4202e-05 - val_dense_153_loss: 1.7175e-06 - val_dense_154_loss: 1.4129e-06 - val_dense_155_loss: 1.4045e-06 - val_dense_156_loss: 1.7598e-06 - val_dense_157_loss: 2.0910e-06 - val_dense_158_loss: 2.0623e-06 - val_dense_159_loss: 2.1130e-06 - val_dense_160_loss: 1.6409e-06\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5954e-06 - dense_153_loss: 1.0218e-06 - dense_154_loss: 1.1076e-06 - dense_155_loss: 9.3207e-07 - dense_156_loss: 1.1436e-06 - dense_157_loss: 1.3984e-06 - dense_158_loss: 1.2382e-06 - dense_159_loss: 1.4794e-06 - dense_160_loss: 1.2743e-06 - val_loss: 8.1811e-06 - val_dense_153_loss: 7.5221e-07 - val_dense_154_loss: 9.0526e-07 - val_dense_155_loss: 6.8967e-07 - val_dense_156_loss: 8.8764e-07 - val_dense_157_loss: 1.3270e-06 - val_dense_158_loss: 1.1158e-06 - val_dense_159_loss: 1.3457e-06 - val_dense_160_loss: 1.1578e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7957e-06 - dense_153_loss: 7.2648e-07 - dense_154_loss: 8.6762e-07 - dense_155_loss: 7.2584e-07 - dense_156_loss: 9.0529e-07 - dense_157_loss: 1.1586e-06 - dense_158_loss: 1.0319e-06 - dense_159_loss: 1.2466e-06 - dense_160_loss: 1.1335e-06 - val_loss: 8.0889e-06 - val_dense_153_loss: 7.4120e-07 - val_dense_154_loss: 9.6018e-07 - val_dense_155_loss: 8.8808e-07 - val_dense_156_loss: 9.5624e-07 - val_dense_157_loss: 1.3002e-06 - val_dense_158_loss: 1.0065e-06 - val_dense_159_loss: 1.1987e-06 - val_dense_160_loss: 1.0377e-06\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1796e-06 - dense_153_loss: 7.9883e-07 - dense_154_loss: 8.8382e-07 - dense_155_loss: 8.2780e-07 - dense_156_loss: 9.4720e-07 - dense_157_loss: 1.2247e-06 - dense_158_loss: 1.0932e-06 - dense_159_loss: 1.2846e-06 - dense_160_loss: 1.1194e-06 - val_loss: 7.4757e-06 - val_dense_153_loss: 6.8657e-07 - val_dense_154_loss: 8.4261e-07 - val_dense_155_loss: 7.6096e-07 - val_dense_156_loss: 8.6607e-07 - val_dense_157_loss: 1.0770e-06 - val_dense_158_loss: 8.8887e-07 - val_dense_159_loss: 1.2027e-06 - val_dense_160_loss: 1.1508e-06\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3951e-06 - dense_153_loss: 7.1128e-07 - dense_154_loss: 8.2209e-07 - dense_155_loss: 7.4919e-07 - dense_156_loss: 8.4811e-07 - dense_157_loss: 1.0904e-06 - dense_158_loss: 9.5114e-07 - dense_159_loss: 1.1714e-06 - dense_160_loss: 1.0515e-06 - val_loss: 1.0691e-05 - val_dense_153_loss: 8.0014e-07 - val_dense_154_loss: 1.5893e-06 - val_dense_155_loss: 9.7844e-07 - val_dense_156_loss: 1.2388e-06 - val_dense_157_loss: 1.7724e-06 - val_dense_158_loss: 1.2785e-06 - val_dense_159_loss: 1.5011e-06 - val_dense_160_loss: 1.5328e-06\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0718e-05 - dense_153_loss: 1.1623e-06 - dense_154_loss: 1.2451e-06 - dense_155_loss: 1.0946e-06 - dense_156_loss: 1.2369e-06 - dense_157_loss: 1.5544e-06 - dense_158_loss: 1.3972e-06 - dense_159_loss: 1.4981e-06 - dense_160_loss: 1.5295e-06 - val_loss: 1.0004e-05 - val_dense_153_loss: 1.0310e-06 - val_dense_154_loss: 1.1185e-06 - val_dense_155_loss: 9.5350e-07 - val_dense_156_loss: 1.2131e-06 - val_dense_157_loss: 1.5548e-06 - val_dense_158_loss: 1.2113e-06 - val_dense_159_loss: 1.4364e-06 - val_dense_160_loss: 1.4858e-06\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3823e-06 - dense_153_loss: 7.8491e-07 - dense_154_loss: 9.0228e-07 - dense_155_loss: 8.9226e-07 - dense_156_loss: 9.6933e-07 - dense_157_loss: 1.1895e-06 - dense_158_loss: 1.1054e-06 - dense_159_loss: 1.3395e-06 - dense_160_loss: 1.1991e-06 - val_loss: 8.7452e-06 - val_dense_153_loss: 8.0441e-07 - val_dense_154_loss: 1.2829e-06 - val_dense_155_loss: 7.4107e-07 - val_dense_156_loss: 8.7921e-07 - val_dense_157_loss: 1.2988e-06 - val_dense_158_loss: 1.0417e-06 - val_dense_159_loss: 1.5602e-06 - val_dense_160_loss: 1.1370e-06\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3861e-06 - dense_153_loss: 6.8245e-07 - dense_154_loss: 8.2307e-07 - dense_155_loss: 7.0311e-07 - dense_156_loss: 8.4215e-07 - dense_157_loss: 1.1198e-06 - dense_158_loss: 9.8775e-07 - dense_159_loss: 1.1725e-06 - dense_160_loss: 1.0553e-06 - val_loss: 8.0794e-06 - val_dense_153_loss: 7.0801e-07 - val_dense_154_loss: 7.7789e-07 - val_dense_155_loss: 7.2645e-07 - val_dense_156_loss: 8.8830e-07 - val_dense_157_loss: 1.4017e-06 - val_dense_158_loss: 1.1149e-06 - val_dense_159_loss: 1.3439e-06 - val_dense_160_loss: 1.1181e-06\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5523e-06 - dense_153_loss: 7.3336e-07 - dense_154_loss: 8.3138e-07 - dense_155_loss: 7.2530e-07 - dense_156_loss: 8.5333e-07 - dense_157_loss: 1.1439e-06 - dense_158_loss: 9.9616e-07 - dense_159_loss: 1.1991e-06 - dense_160_loss: 1.0697e-06 - val_loss: 9.4181e-06 - val_dense_153_loss: 1.0664e-06 - val_dense_154_loss: 9.2178e-07 - val_dense_155_loss: 9.4497e-07 - val_dense_156_loss: 9.1958e-07 - val_dense_157_loss: 1.2374e-06 - val_dense_158_loss: 1.2842e-06 - val_dense_159_loss: 1.6072e-06 - val_dense_160_loss: 1.4365e-06\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7917e-06 - dense_153_loss: 8.4017e-07 - dense_154_loss: 9.7301e-07 - dense_155_loss: 9.0810e-07 - dense_156_loss: 9.7390e-07 - dense_157_loss: 1.3462e-06 - dense_158_loss: 1.1186e-06 - dense_159_loss: 1.4013e-06 - dense_160_loss: 1.2304e-06 - val_loss: 7.3706e-06 - val_dense_153_loss: 7.0375e-07 - val_dense_154_loss: 7.8583e-07 - val_dense_155_loss: 6.8785e-07 - val_dense_156_loss: 8.8847e-07 - val_dense_157_loss: 1.1750e-06 - val_dense_158_loss: 1.0477e-06 - val_dense_159_loss: 1.1069e-06 - val_dense_160_loss: 9.7515e-07\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.7631e-06 - dense_153_loss: 1.0461e-06 - dense_154_loss: 1.0819e-06 - dense_155_loss: 1.0656e-06 - dense_156_loss: 1.1450e-06 - dense_157_loss: 1.3606e-06 - dense_158_loss: 1.2402e-06 - dense_159_loss: 1.4835e-06 - dense_160_loss: 1.3403e-06 - val_loss: 8.0935e-06 - val_dense_153_loss: 7.4396e-07 - val_dense_154_loss: 8.8341e-07 - val_dense_155_loss: 9.1566e-07 - val_dense_156_loss: 8.5221e-07 - val_dense_157_loss: 1.1940e-06 - val_dense_158_loss: 9.3700e-07 - val_dense_159_loss: 1.3359e-06 - val_dense_160_loss: 1.2313e-06\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4061e-06 - dense_153_loss: 7.3353e-07 - dense_154_loss: 7.9863e-07 - dense_155_loss: 7.2909e-07 - dense_156_loss: 8.1971e-07 - dense_157_loss: 1.0808e-06 - dense_158_loss: 9.8816e-07 - dense_159_loss: 1.2118e-06 - dense_160_loss: 1.0444e-06 - val_loss: 7.0430e-06 - val_dense_153_loss: 6.2894e-07 - val_dense_154_loss: 6.7557e-07 - val_dense_155_loss: 6.7598e-07 - val_dense_156_loss: 7.3966e-07 - val_dense_157_loss: 1.1284e-06 - val_dense_158_loss: 1.0372e-06 - val_dense_159_loss: 1.2181e-06 - val_dense_160_loss: 9.3914e-07\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6945e-06 - dense_153_loss: 8.3773e-07 - dense_154_loss: 1.0033e-06 - dense_155_loss: 8.5116e-07 - dense_156_loss: 1.0067e-06 - dense_157_loss: 1.2547e-06 - dense_158_loss: 1.1232e-06 - dense_159_loss: 1.3341e-06 - dense_160_loss: 1.2836e-06 - val_loss: 8.6488e-06 - val_dense_153_loss: 8.3653e-07 - val_dense_154_loss: 9.6074e-07 - val_dense_155_loss: 7.6376e-07 - val_dense_156_loss: 8.9272e-07 - val_dense_157_loss: 1.2145e-06 - val_dense_158_loss: 1.3731e-06 - val_dense_159_loss: 1.4051e-06 - val_dense_160_loss: 1.2023e-06\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3689e-06 - dense_153_loss: 7.8404e-07 - dense_154_loss: 9.6873e-07 - dense_155_loss: 8.2452e-07 - dense_156_loss: 9.9913e-07 - dense_157_loss: 1.2075e-06 - dense_158_loss: 1.0804e-06 - dense_159_loss: 1.2836e-06 - dense_160_loss: 1.2210e-06 - val_loss: 7.1338e-06 - val_dense_153_loss: 6.0403e-07 - val_dense_154_loss: 8.1250e-07 - val_dense_155_loss: 6.9234e-07 - val_dense_156_loss: 9.2979e-07 - val_dense_157_loss: 1.1094e-06 - val_dense_158_loss: 9.0594e-07 - val_dense_159_loss: 1.0898e-06 - val_dense_160_loss: 9.9009e-07\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8374e-06 - dense_153_loss: 7.7397e-07 - dense_154_loss: 8.4292e-07 - dense_155_loss: 7.6575e-07 - dense_156_loss: 9.1145e-07 - dense_157_loss: 1.1645e-06 - dense_158_loss: 1.0416e-06 - dense_159_loss: 1.2288e-06 - dense_160_loss: 1.1084e-06 - val_loss: 8.9857e-06 - val_dense_153_loss: 1.1109e-06 - val_dense_154_loss: 1.1279e-06 - val_dense_155_loss: 9.1355e-07 - val_dense_156_loss: 7.5876e-07 - val_dense_157_loss: 1.3131e-06 - val_dense_158_loss: 1.0421e-06 - val_dense_159_loss: 1.5829e-06 - val_dense_160_loss: 1.1364e-06\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1759e-06 - dense_153_loss: 8.4333e-07 - dense_154_loss: 8.6041e-07 - dense_155_loss: 8.6149e-07 - dense_156_loss: 9.2093e-07 - dense_157_loss: 1.1807e-06 - dense_158_loss: 1.0384e-06 - dense_159_loss: 1.3268e-06 - dense_160_loss: 1.1438e-06 - val_loss: 9.6631e-06 - val_dense_153_loss: 1.2096e-06 - val_dense_154_loss: 8.1957e-07 - val_dense_155_loss: 1.0611e-06 - val_dense_156_loss: 1.0360e-06 - val_dense_157_loss: 1.4127e-06 - val_dense_158_loss: 1.2859e-06 - val_dense_159_loss: 1.4749e-06 - val_dense_160_loss: 1.3633e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0456e-06 - dense_153_loss: 8.3093e-07 - dense_154_loss: 8.2144e-07 - dense_155_loss: 8.6020e-07 - dense_156_loss: 8.8433e-07 - dense_157_loss: 1.2501e-06 - dense_158_loss: 1.0801e-06 - dense_159_loss: 1.2347e-06 - dense_160_loss: 1.0838e-06 - val_loss: 8.3389e-06 - val_dense_153_loss: 7.2970e-07 - val_dense_154_loss: 9.0584e-07 - val_dense_155_loss: 8.2763e-07 - val_dense_156_loss: 8.7502e-07 - val_dense_157_loss: 1.2790e-06 - val_dense_158_loss: 1.1489e-06 - val_dense_159_loss: 1.5080e-06 - val_dense_160_loss: 1.0649e-06\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1136e-05 - dense_153_loss: 1.1102e-06 - dense_154_loss: 1.3350e-06 - dense_155_loss: 1.0539e-06 - dense_156_loss: 1.2734e-06 - dense_157_loss: 1.6154e-06 - dense_158_loss: 1.5338e-06 - dense_159_loss: 1.7131e-06 - dense_160_loss: 1.5016e-06 - val_loss: 1.5384e-05 - val_dense_153_loss: 2.1000e-06 - val_dense_154_loss: 1.6066e-06 - val_dense_155_loss: 1.3638e-06 - val_dense_156_loss: 2.0803e-06 - val_dense_157_loss: 2.0065e-06 - val_dense_158_loss: 2.1413e-06 - val_dense_159_loss: 1.7564e-06 - val_dense_160_loss: 2.3294e-06\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0207e-05 - dense_153_loss: 1.1642e-06 - dense_154_loss: 1.0987e-06 - dense_155_loss: 1.0607e-06 - dense_156_loss: 1.1832e-06 - dense_157_loss: 1.4982e-06 - dense_158_loss: 1.3345e-06 - dense_159_loss: 1.3620e-06 - dense_160_loss: 1.5054e-06 - val_loss: 8.8812e-06 - val_dense_153_loss: 9.1545e-07 - val_dense_154_loss: 9.8092e-07 - val_dense_155_loss: 9.0374e-07 - val_dense_156_loss: 9.3020e-07 - val_dense_157_loss: 1.3117e-06 - val_dense_158_loss: 1.3614e-06 - val_dense_159_loss: 1.3866e-06 - val_dense_160_loss: 1.0912e-06\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5911e-06 - dense_153_loss: 8.3819e-07 - dense_154_loss: 7.7931e-07 - dense_155_loss: 7.9918e-07 - dense_156_loss: 8.1893e-07 - dense_157_loss: 1.1471e-06 - dense_158_loss: 9.7553e-07 - dense_159_loss: 1.2064e-06 - dense_160_loss: 1.0264e-06 - val_loss: 9.8819e-06 - val_dense_153_loss: 1.0733e-06 - val_dense_154_loss: 8.5657e-07 - val_dense_155_loss: 1.0071e-06 - val_dense_156_loss: 1.0222e-06 - val_dense_157_loss: 1.4931e-06 - val_dense_158_loss: 1.4710e-06 - val_dense_159_loss: 1.7288e-06 - val_dense_160_loss: 1.2298e-06\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7015e-06 - dense_153_loss: 8.1121e-07 - dense_154_loss: 8.0325e-07 - dense_155_loss: 7.8013e-07 - dense_156_loss: 8.7483e-07 - dense_157_loss: 1.1683e-06 - dense_158_loss: 1.0238e-06 - dense_159_loss: 1.2078e-06 - dense_160_loss: 1.0322e-06 - val_loss: 8.2458e-06 - val_dense_153_loss: 9.4646e-07 - val_dense_154_loss: 7.6618e-07 - val_dense_155_loss: 7.8049e-07 - val_dense_156_loss: 1.0054e-06 - val_dense_157_loss: 1.1818e-06 - val_dense_158_loss: 9.1729e-07 - val_dense_159_loss: 1.3881e-06 - val_dense_160_loss: 1.2601e-06\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9978e-06 - dense_153_loss: 8.6814e-07 - dense_154_loss: 8.9618e-07 - dense_155_loss: 8.2586e-07 - dense_156_loss: 8.2551e-07 - dense_157_loss: 1.1585e-06 - dense_158_loss: 1.0097e-06 - dense_159_loss: 1.3202e-06 - dense_160_loss: 1.0936e-06 - val_loss: 7.3888e-06 - val_dense_153_loss: 8.0696e-07 - val_dense_154_loss: 7.4842e-07 - val_dense_155_loss: 7.1468e-07 - val_dense_156_loss: 7.5827e-07 - val_dense_157_loss: 1.0861e-06 - val_dense_158_loss: 9.3579e-07 - val_dense_159_loss: 1.2939e-06 - val_dense_160_loss: 1.0447e-06\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1787e-06 - dense_153_loss: 7.0687e-07 - dense_154_loss: 7.5492e-07 - dense_155_loss: 7.4307e-07 - dense_156_loss: 7.3860e-07 - dense_157_loss: 1.1052e-06 - dense_158_loss: 9.4125e-07 - dense_159_loss: 1.1846e-06 - dense_160_loss: 1.0041e-06 - val_loss: 9.8007e-06 - val_dense_153_loss: 8.7698e-07 - val_dense_154_loss: 1.2427e-06 - val_dense_155_loss: 1.1931e-06 - val_dense_156_loss: 8.5916e-07 - val_dense_157_loss: 1.4544e-06 - val_dense_158_loss: 1.1076e-06 - val_dense_159_loss: 1.5942e-06 - val_dense_160_loss: 1.4725e-06\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0042e-06 - dense_153_loss: 8.4810e-07 - dense_154_loss: 8.5356e-07 - dense_155_loss: 8.3779e-07 - dense_156_loss: 9.2537e-07 - dense_157_loss: 1.1741e-06 - dense_158_loss: 1.0168e-06 - dense_159_loss: 1.2523e-06 - dense_160_loss: 1.0962e-06 - val_loss: 7.2058e-06 - val_dense_153_loss: 7.9036e-07 - val_dense_154_loss: 6.3566e-07 - val_dense_155_loss: 7.2113e-07 - val_dense_156_loss: 7.8810e-07 - val_dense_157_loss: 1.1508e-06 - val_dense_158_loss: 8.8973e-07 - val_dense_159_loss: 1.2594e-06 - val_dense_160_loss: 9.7055e-07\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8365e-06 - dense_153_loss: 8.1306e-07 - dense_154_loss: 8.3088e-07 - dense_155_loss: 8.0637e-07 - dense_156_loss: 8.4065e-07 - dense_157_loss: 1.1551e-06 - dense_158_loss: 1.0494e-06 - dense_159_loss: 1.2253e-06 - dense_160_loss: 1.1156e-06 - val_loss: 9.0190e-06 - val_dense_153_loss: 1.0472e-06 - val_dense_154_loss: 7.2827e-07 - val_dense_155_loss: 1.0473e-06 - val_dense_156_loss: 9.2956e-07 - val_dense_157_loss: 1.3049e-06 - val_dense_158_loss: 1.2652e-06 - val_dense_159_loss: 1.5601e-06 - val_dense_160_loss: 1.1365e-06\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8495e-06 - dense_153_loss: 1.0771e-06 - dense_154_loss: 8.4662e-07 - dense_155_loss: 9.3379e-07 - dense_156_loss: 9.5434e-07 - dense_157_loss: 1.2679e-06 - dense_158_loss: 1.1750e-06 - dense_159_loss: 1.3512e-06 - dense_160_loss: 1.2435e-06 - val_loss: 9.9128e-06 - val_dense_153_loss: 1.0250e-06 - val_dense_154_loss: 1.1145e-06 - val_dense_155_loss: 1.0632e-06 - val_dense_156_loss: 1.2479e-06 - val_dense_157_loss: 1.3702e-06 - val_dense_158_loss: 1.3353e-06 - val_dense_159_loss: 1.4184e-06 - val_dense_160_loss: 1.3383e-06\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2291e-06 - dense_153_loss: 9.3536e-07 - dense_154_loss: 9.8352e-07 - dense_155_loss: 9.8330e-07 - dense_156_loss: 1.0695e-06 - dense_157_loss: 1.3071e-06 - dense_158_loss: 1.2308e-06 - dense_159_loss: 1.3910e-06 - dense_160_loss: 1.3285e-06 - val_loss: 9.0679e-06 - val_dense_153_loss: 8.0783e-07 - val_dense_154_loss: 8.7782e-07 - val_dense_155_loss: 1.2162e-06 - val_dense_156_loss: 1.0793e-06 - val_dense_157_loss: 1.6292e-06 - val_dense_158_loss: 1.0725e-06 - val_dense_159_loss: 1.3381e-06 - val_dense_160_loss: 1.0470e-06\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6482e-06 - dense_153_loss: 7.9930e-07 - dense_154_loss: 7.5858e-07 - dense_155_loss: 8.0446e-07 - dense_156_loss: 8.2199e-07 - dense_157_loss: 1.1624e-06 - dense_158_loss: 9.9343e-07 - dense_159_loss: 1.2612e-06 - dense_160_loss: 1.0469e-06 - val_loss: 7.2657e-06 - val_dense_153_loss: 7.1463e-07 - val_dense_154_loss: 6.0272e-07 - val_dense_155_loss: 6.6579e-07 - val_dense_156_loss: 7.4185e-07 - val_dense_157_loss: 1.1546e-06 - val_dense_158_loss: 9.6967e-07 - val_dense_159_loss: 1.3744e-06 - val_dense_160_loss: 1.0421e-06\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.9103e-06 - dense_153_loss: 9.2623e-07 - dense_154_loss: 9.8298e-07 - dense_155_loss: 8.6034e-07 - dense_156_loss: 9.6211e-07 - dense_157_loss: 1.3547e-06 - dense_158_loss: 1.1665e-06 - dense_159_loss: 1.4077e-06 - dense_160_loss: 1.2498e-06 - val_loss: 8.3233e-06 - val_dense_153_loss: 7.7087e-07 - val_dense_154_loss: 6.9535e-07 - val_dense_155_loss: 8.0301e-07 - val_dense_156_loss: 8.1549e-07 - val_dense_157_loss: 1.3383e-06 - val_dense_158_loss: 9.8225e-07 - val_dense_159_loss: 1.7994e-06 - val_dense_160_loss: 1.1187e-06\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3221e-06 - dense_153_loss: 7.4617e-07 - dense_154_loss: 7.0727e-07 - dense_155_loss: 7.5930e-07 - dense_156_loss: 7.8352e-07 - dense_157_loss: 1.1172e-06 - dense_158_loss: 9.6706e-07 - dense_159_loss: 1.2306e-06 - dense_160_loss: 1.0110e-06 - val_loss: 7.4693e-06 - val_dense_153_loss: 7.6653e-07 - val_dense_154_loss: 8.2860e-07 - val_dense_155_loss: 7.3427e-07 - val_dense_156_loss: 8.3481e-07 - val_dense_157_loss: 1.1278e-06 - val_dense_158_loss: 9.5216e-07 - val_dense_159_loss: 1.1422e-06 - val_dense_160_loss: 1.0830e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1846e-06 - dense_153_loss: 7.2718e-07 - dense_154_loss: 6.9091e-07 - dense_155_loss: 7.3777e-07 - dense_156_loss: 8.5146e-07 - dense_157_loss: 1.0732e-06 - dense_158_loss: 9.3298e-07 - dense_159_loss: 1.2158e-06 - dense_160_loss: 9.5527e-07 - val_loss: 9.3527e-06 - val_dense_153_loss: 9.2990e-07 - val_dense_154_loss: 1.0491e-06 - val_dense_155_loss: 8.4933e-07 - val_dense_156_loss: 1.0762e-06 - val_dense_157_loss: 1.4510e-06 - val_dense_158_loss: 1.2466e-06 - val_dense_159_loss: 1.4346e-06 - val_dense_160_loss: 1.3161e-06\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0656e-06 - dense_153_loss: 7.0797e-07 - dense_154_loss: 6.9955e-07 - dense_155_loss: 7.4839e-07 - dense_156_loss: 7.3146e-07 - dense_157_loss: 1.1002e-06 - dense_158_loss: 8.9761e-07 - dense_159_loss: 1.1844e-06 - dense_160_loss: 9.9600e-07 - val_loss: 8.0123e-06 - val_dense_153_loss: 7.9498e-07 - val_dense_154_loss: 9.6052e-07 - val_dense_155_loss: 6.8395e-07 - val_dense_156_loss: 7.6576e-07 - val_dense_157_loss: 1.3674e-06 - val_dense_158_loss: 1.1991e-06 - val_dense_159_loss: 1.3319e-06 - val_dense_160_loss: 9.0863e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "61.38265958894044\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders)\n",
    "stop = time.perf_counter()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1167afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        print('evaluating model for '+histgroup[0])\n",
    "        print(histstruct.evaluate_classifier(histgroup)[0].shape)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    print('Found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "            thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "            mse_good.append( thismse )\n",
    "            print(run)\n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    print('Found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        print('Found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34546ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct, mse_train):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    #for dims in dimslist:\n",
    "    #    thismse = mse_train[:,dims]\n",
    "    #    if training_mode=='global': \n",
    "    #        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "    #        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "    #        #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "    #        #                                                    'up')\n",
    "    #    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    #    #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "    #    #                onlycontour=False, xlims=30, ylims=30, \n",
    "    #    #                onlypositive=True, transparency=0.5,\n",
    "    #    #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "    #    #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "    #    #                title='density fit of lumisection MSE')\n",
    "    #    ##plt.close('all') # release plot memory\n",
    "    #    fitfunclist.append(fitfunc)\n",
    "    # \n",
    "    #    \n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "    else: \n",
    "        fitfunc = GaussianKdeFitter.GaussianKdeFitter()\n",
    "        fitfunc.fit(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4988fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = fit_mse_distribution(histstruct, mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    print('--- good lumesections ---')\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    print('length of log prob array: '+str(len(logprob_good)))\n",
    "    print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "    #print(sorted(logprob_good))\n",
    "    \n",
    "    print('--- bad lumisections ---')\n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "    \n",
    "    print('length of log prob array: '+str(len(logprob_bad)))\n",
    "    print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "    #print(sorted(logprob_good))\n",
    "    #print(sorted(logprob_bad))\n",
    "    #print(logprob_bad)\n",
    "    \n",
    "    return [logprob_good, logprob_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ed5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(logprob_good, logprob_bad) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b777c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoder_individual(histstruct):\n",
    "    \n",
    "    msewps = []\n",
    "    for histname in histstruct.histnames:\n",
    "        \n",
    "        # Get histograms from histstruct\n",
    "        X_test_good = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'good']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        X_test_bad = X_test_bad = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'bad']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        # Get each model from the histstruct\n",
    "        autoencoder = histstruct.get_classifier(histname)\n",
    "        \n",
    "        # Getting evaluation criteria\n",
    "        prediction_test_good = autoencoder.reconstruct(X_test_good)\n",
    "        mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "        prediction_test_bad = autoencoder.reconstruct(X_test_bad)\n",
    "        mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "        \n",
    "        if userfriendly:\n",
    "            print('Average MSE on good set: ' + str(np.mean(mse_test_good)))\n",
    "            print('Average MSE on bad set: ' + str(np.mean(mse_test_bad)))\n",
    "        \n",
    "        if createPlots:\n",
    "            # Number of plots of each type to generate per model (so nplot * 2 * len(model))\n",
    "            nplot = 3\n",
    "            \n",
    "            # Good examples\n",
    "            print('Examples of good histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "            for i in randint: \n",
    "                histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "            \n",
    "            # Bad examples\n",
    "            print('Examples of bad histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "            for i in randint:\n",
    "                histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "        \n",
    "        # Attaching the bad histograms as a new set of rows under the good histograms\n",
    "        validation_data = np.vstack((X_test_good, X_test_bad))\n",
    "        validation_preds = np.vstack((prediction_test_good, prediction_test_bad))\n",
    "        # Creating labels to differentiate the data when we go to compare predictions\n",
    "        #     with actual label\n",
    "        labels = np.hstack((np.zeros(len(X_test_good)), np.ones(len(X_test_bad))))\n",
    "        \n",
    "        # Pick a working point to see \n",
    "        msewp = 0.5*(np.mean(mse_test_bad) - np.mean(mse_test_good))\n",
    "        print(\"Selected working point: \" + str(msewp))\n",
    "        \n",
    "        # Get data to pick a good working point for future evaluation\n",
    "        scores = aeu.mseTop10Raw(validation_data, validation_preds)\n",
    "        nsig = np.sum(labels)\n",
    "        nback = np.sum(1-labels)\n",
    "        \n",
    "        # Get some metrics for the user\n",
    "        tp = np.sum(np.where((labels==1) & (scores>msewp),1,0))/nsig\n",
    "        fp = np.sum(np.where((labels==0) & (scores>msewp),1,0))/nback\n",
    "        tn = 1-fp\n",
    "        fn = 1-tp\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2*precision*recall) / (precision + recall)\n",
    "        \n",
    "        if userfriendly:\n",
    "            print(accuracy)\n",
    "            print(precision)\n",
    "            print(recall)\n",
    "            print(f1)\n",
    "        \n",
    "    return msewps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad, biasFactor):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    badMin = min(np.where(logprob_bad != -np.inf, logprob_bad, np.inf))\n",
    "    goodMax = max(np.where(logprob_good != np.inf, logprob_good, -np.inf))\n",
    "    \n",
    "    # Getting rid of infinities\n",
    "    logprob_good[logprob_good > 500] = goodMax\n",
    "    logprob_bad[logprob_bad < 0] = badMin\n",
    "    # These only take effect if a histogram is grossly misclassified\n",
    "    logprob_good[logprob_good < badMin] = badMin\n",
    "    logprob_bad[logprob_bad > goodMax] = goodMax\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                       bcklabel='good', bckcolor='g', \n",
    "                       nbins=200, normalize=True,\n",
    "                       xaxtitle='negative logarithmic probability',\n",
    "                       yaxtitle='number of lumisections (normalized)')\n",
    "      \n",
    "    # Plot ROC curve for analysis\n",
    "    auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    # Average is biased towards better recall per user specifications\n",
    "    logprob_threshold = (1/(biasFactor + 1)) * (biasFactor*np.mean(logprob_good) + np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "    # logprob_threshold = 424\n",
    "    (_, _, _, tp, fp, tn, fn) = aeu.get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    print('Selected logprob threshold of ' + str(logprob_threshold))\n",
    "    \n",
    "    # Get metrics for analysis\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = (1 + biasFactor * biasFactor) * ((precision * recall) / ((biasFactor * biasFactor * precision) + recall)) \n",
    "    \n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('F-Measure: ' + str(f_measure))\n",
    "    \n",
    "    return logprob_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbddf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_threshold = evaluate_autoencoders_combined(logprob_good, logprob_bad, biasFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4e3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "356f7ddc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
