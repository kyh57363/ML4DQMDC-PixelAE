{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba412492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import SubHistStruct\n",
    "importlib.reload(SubHistStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed Controls and Run Mode\n",
    "\n",
    "# Disables all plots for large datasets where speed is more important\n",
    "createPlots = False\n",
    "\n",
    "# Control for the notebook - turn off user-friendly mode to enable faster runtimes\n",
    "userfriendly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2020c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation Parameters\n",
    "\n",
    "# Select the bias towards recall against precision, treated as a factor (so < 1 biases towards precision, 1 is equal importance, and > 1 biases towards recall)\n",
    "biasFactor = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4590f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = '../data/'\n",
    "\n",
    "# Select a list of good runs to train on in development training_mode\n",
    "# Should be validated by eye\n",
    "trainrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                   \"297598\":[[-1]],\n",
    "#                   \"297604\":[[-1]],   # A decently clean histogram\n",
    "                   \"297620\":[[-1]],   # A decently clean histogram\n",
    "                   \"297659\":[[-1]],   # An okay histogram\n",
    "                   \"297670\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                   \"299065\":[[-1]],   # A decently clean histogram\n",
    "                   \"299067\":[[-1]],   # A decently clean histogram\n",
    "                   \"299096\":[[-1]],\n",
    "                   \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "#                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "               '2017C':{\n",
    "                   \"299369\":[[-1]]\n",
    "               },\n",
    "              '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "# Select a list of good runs to test on in development training_mode\n",
    "# Should be validated by eye\n",
    "goodrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                    \"297598\":[[-1]],\n",
    "#                    \"297604\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297620\":[[-1]],   # A decently clean histogram\n",
    "                    \"297659\":[[-1]],   # An okay histogram\n",
    "                    \"297670\":[[-1]],   # A decently clean histogram\n",
    "                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                    \"299065\":[[-1]],   # A decently clean histogram\n",
    "                    \"299067\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299096\":[[-1]],\n",
    "#                    \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "              '2017C':{\n",
    "                  \"299368\":[[-1]]\n",
    "              },\n",
    "              '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "\n",
    "badrunsls = {'2017B':\n",
    "                {\n",
    "                    #\"297048\":[[-1]],\n",
    "                    #\"297282\":[[-1]],\n",
    "                    #\"297283\":[[-1]],\n",
    "                    #\"297284\":[[-1]],\n",
    "                    #\"297287\":[[-1]],\n",
    "                    #\"297288\":[[-1]],\n",
    "                    #\"297289\":[[-1]],\n",
    "                    \"299316\":[[-1]],\n",
    "                    \"299317\":[[-1]],\n",
    "                    \"299318\":[[-1]],\n",
    "                    \"299324\":[[-1]],\n",
    "                    \"299326\":[[-1]],\n",
    "                    #\"301086\":[[88,126]],\n",
    "                    #\"301086\":[[89,89]],\n",
    "                    #\"303948\":[[1710,1710]],\n",
    "                    \"297047\":[[-1]], #close but, true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297211\":[[-1]], #Reconstructs well\n",
    "#                   \"299325\":[[-1]], #Reconstructs well\n",
    "                    \"297664\":[[-1]], #true bad for all 8\n",
    "                    \"299317\":[[-1]], #true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297502\":[[-1]]\n",
    "                },\n",
    "             '2017C':{\n",
    "                 \"300781\":[[-1]], # bad for tracking (pixels were excluded.\n",
    "                 \"300079\":[[-1]], # is bad for strips and then also for tracking\n",
    "                 \"302029\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good \n",
    "                 \"300576\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                 \"300574\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                 \"300282\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                 \"301912\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "                 \"301086\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "                 \"300283\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300282\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300281\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300239\":[[-1]], # Half bad for pixels (lost HV or readout card)\n",
    "                 \"301394\":[[-1]], # Marginal for pixels\n",
    "                 \"301183\":[[-1]], # Marginal for pixels\n",
    "                 \"300398\":[[-1]], # Marginal for pixels\n",
    "                 \"300389\":[[-1]], # Marginal for pixels\n",
    "                 \"300365\":[[-1]]  # Marginal for pixels\n",
    "              },\n",
    "             '2017E':{\n",
    "                 \"304740\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304776\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304506\":[[-1]], # Portcard problem for pixels\n",
    "                 \"304507\":[[-1]], # Portcard problem for pixels \n",
    "                 \"303989\":[[-1]], # Bad for pixels, power supply died\n",
    "                 \"303824\":[[-1]]  # Partly bad for strips due to a test\n",
    "             },\n",
    "             '2017F':{\n",
    "                 \"306422\":[[-1]], # Partly bad for strips - 2 data readouts failed \n",
    "                 \"306423\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "                 \"306425\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "                 \"305440\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "                 \"305441\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "                 \"305249\":[[-1]], # Bad for pixels - half of disk failed \n",
    "                 \"305250\":[[-1]], # Bad for pixels - half of disk failed\n",
    "                 \"305064\":[[-1]], # Marginal for pixels - some readout failed\n",
    "             },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "\n",
    "# The year and era being used\n",
    "year = '2017'\n",
    "era = 'B'\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = [\n",
    "    ['NormalizedHitResiduals_TIB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1', 'NormalizedHitResiduals_TIB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2',\n",
    "     'NormalizedHitResiduals_TIB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3' , 'NormalizedHitResiduals_TIB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4'],\n",
    "    ['chargeInner_PXLayer_1', 'chargeOuter_PXLayer_1', 'adc_PXLayer_1'],\n",
    "    ['chargeInner_PXLayer_2', 'chargeOuter_PXLayer_2', 'adc_PXLayer_2'],\n",
    "    ['chargeInner_PXLayer_3', 'chargeOuter_PXLayer_3', 'adc_PXLayer_3'],\n",
    "    ['chargeInner_PXLayer_4', 'chargeOuter_PXLayer_4', 'adc_PXLayer_4'],\n",
    "    ['charge_PXDisk_+1', 'adc_PXDisk_+1'],\n",
    "    ['charge_PXDisk_-1', 'adc_PXDisk_-1'],\n",
    "    ['charge_PXDisk_+2', 'adc_PXDisk_+2'],\n",
    "    ['charge_PXDisk_-2', 'adc_PXDisk_-2'],\n",
    "    ['charge_PXDisk_+3', 'adc_PXDisk_+3'],\n",
    "    ['charge_PXDisk_-3', 'adc_PXDisk_-3'],\n",
    "    ['NormalizedHitResiduals_TOB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__1', 'NormalizedHitResiduals_TOB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__2',\n",
    "     'NormalizedHitResiduals_TOB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__3' , 'NormalizedHitResiduals_TOB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__4']\n",
    "]\n",
    "\n",
    "# Read new data or use previously saved data & should data be saved\n",
    "readnew = True\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ffebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Set whether to train globally or locally or in a development/testing mode\n",
    "training_mode = 'development'\n",
    "\n",
    "# Selects whether to create a new histstruct or use a saved one\n",
    "readnew = True\n",
    "\n",
    "# Select whether to save a new histstruct\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6394238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames\n",
    "\n",
    "# Evaluate models seperately, as an ensemble, both, or neither\n",
    "individualEval = True\n",
    "ensembleEval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4051dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected runs/lumisections for training: \n",
      "{'297175': [[-1]], '297620': [[-1]], '297659': [[-1]], '297670': [[-1]], '299065': [[-1]], '299067': [[-1]], '299096': [[-1]], '299149': [[-1]]}\n",
      "selected runs/lumisections as good test set:\n",
      "{'297175': [[-1]], '297659': [[-1]], '297670': [[-1]], '297674': [[-1]], '297722': [[-1]], '299065': [[-1]], '299067': [[-1]], '299185': [[-1]], '299327': [[-1]], '299480': [[-1]]}\n",
      "selected runs/lumisections as bad test set:\n",
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n"
     ]
    }
   ],
   "source": [
    "### Define Training Mode Parameters - Combined Autoencoder\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use averages of training set)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    # - this only works for a single era\n",
    "    \n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+era+'_'+histnames[0][0]+'.csv') ) )\n",
    "    # Cherry picked really bad run\n",
    "    run_application = 299316\n",
    "    #run_application = 299317\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5\n",
    "        offset = 0 # normal case: offset = 0 (just use 5 previous runs)\n",
    "        \n",
    "        # Selects the 5 previous runs for training\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    #runsls_bad = badrunsls[year]\n",
    "    #runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_good = runsls_training\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)\n",
    "        \n",
    "elif training_mode == 'development':\n",
    "    # train on a user-defined subset of runs\n",
    "    \n",
    "    # Select runs to be used in training from the user-defined list\n",
    "    runsls_training = trainrunsls[year + era]\n",
    "    # Select bad runs to test on in the user-defined list\n",
    "    runsls_bad = badrunsls[year + era]\n",
    "    # Select good runs to test on in the user-defined list\n",
    "    runsls_good = goodrunsls[year + era]\n",
    "    \n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54180f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Classifiers cleared to preserve consistency\n",
      "Adding NormalizedHitResiduals_TIB__Layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4...\n",
      "Adding chargeInner_PXLayer_1...\n",
      "Adding chargeOuter_PXLayer_1...\n",
      "Adding adc_PXLayer_1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_2...\n",
      "Adding chargeOuter_PXLayer_2...\n",
      "Adding adc_PXLayer_2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_3...\n",
      "Adding chargeOuter_PXLayer_3...\n",
      "Adding adc_PXLayer_3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_4...\n",
      "Adding chargeOuter_PXLayer_4...\n",
      "Adding adc_PXLayer_4...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+1...\n",
      "Adding adc_PXDisk_+1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-1...\n",
      "Adding adc_PXDisk_-1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+2...\n",
      "Adding adc_PXDisk_+2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-2...\n",
      "Adding adc_PXDisk_-2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+3...\n",
      "Adding adc_PXDisk_+3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-3...\n",
      "Adding adc_PXDisk_-3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding NormalizedHitResiduals_TOB__Layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4...\n",
      "Found 2831 histograms\n",
      "Created a histstruct with the following properties:\n",
      "- number of histogram types: 40\n",
      "- number of lumisections: 2831\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "\n",
    "# Create a new HistStruct from the data\n",
    "if readnew:\n",
    "    # Initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = SubHistStruct.SubHistStruct()\n",
    "    histstruct.reset_histlist(histnames)\n",
    "    \n",
    "    # Unpack histnames and add every histogram individually\n",
    "    for histnamegroup in histnames:\n",
    "        for histname in histnamegroup:\n",
    "            print('Adding {}...'.format(histname))\n",
    "            \n",
    "            # Bring the histograms into memory from storage for later use\n",
    "            filename = datadir + year + era + '/DF' + year + era + '_' + histname + '.csv'\n",
    "            df = dloader.get_dataframe_from_file( filename )\n",
    "            \n",
    "            # In case of local training, we can remove most of the histograms\n",
    "            if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "                runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "                df = dfu.select_runsls( df, runsls_total )\n",
    "                \n",
    "            # Store the data in the histstruct object managing this whole thing\n",
    "            histstruct.add_dataframe( df, rebinningfactor = 3 )\n",
    "        \n",
    "    print('Found {} histograms'.format(len(histstruct.runnbs)))\n",
    "\n",
    "# Load a previously saved HistStruct\n",
    "else:\n",
    "    # Load histstruct from storage\n",
    "    histstruct = HistStruct.HistStruct.load('test.pk1')\n",
    "    \n",
    "    # Count of bad runs, presumably for later use\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "if userfriendly:\n",
    "    print('Created a histstruct with the following properties:')\n",
    "    print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "    print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45931fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n",
      "Assigned masks: ['dcson', 'golden', 'highstat', 'lowstat', 'training', 'good', 'bad', 'bad0', 'bad1', 'bad2', 'bad3', 'bad4', 'bad5', 'bad6', 'bad7']\n"
     ]
    }
   ],
   "source": [
    "### Add Masks to Data\n",
    "\n",
    "if readnew:\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat' )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=100 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        print(runsls_bad)\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    if save:\n",
    "        histstruct.save('test.pk1')\n",
    "if userfriendly: print('Assigned masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d6a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the input data for analysis\n",
    "\n",
    "if((training_mode=='local' or training_mode == 'development') and createPlots):\n",
    "\n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )\n",
    "    \n",
    "elif( training_mode=='global' and createPlots):\n",
    "    \n",
    "    # bad test runs\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "                                labellist = ['typical good histograms','bad'],\n",
    "                                colorlist = ['blue','red'],\n",
    "                                transparencylist = [0.01,1.]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_concatamash_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            if userfriendly:\n",
    "                print('\\nNow Defining model {}/'.format(i + 1) \n",
    "                      + str(len(histnames)))\n",
    "                print(' - Size of training set: {}'.format(X_train.shape))\n",
    "            \n",
    "            ## Model parameters\n",
    "            print(X_train.shape)\n",
    "            \n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(256, activation=\"tanh\")(conc_layer)\n",
    "            encoder = Dense(128, activation='relu')(encoder)\n",
    "            \n",
    "            encoder = Dense(32, activation='relu')(encoder)\n",
    "            \n",
    "            decoder = Dense(128, activation=\"relu\")(encoder)\n",
    "            decoder = Dense(256, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoder.summary()\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c76ea4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now Defining model 1/12\n",
      " - Size of training set: (1006, 8, 34)\n",
      "(1006, 8, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 17:42:05.773888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.1-8d929/x86_64-centos7-gcc8-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.1-f3599/x86_64-centos7-gcc8-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/8u222-884d8/x86_64-centos7-gcc8-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.30-e5b21/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/3.6.3-dfb24/x86_64-centos7-gcc8-opt/lib64/R/library/readr/rcon\n",
      "2022-06-22 17:42:05.773959: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-22 17:42:05.774037: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-khowey): /proc/driver/nvidia/version does not exist\n",
      "2022-06-22 17:42:05.774592: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 272)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          69888       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          4224        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          33024       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 34)           8738        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 214,064\n",
      "Trainable params: 214,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 2/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 102)          0           input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          26368       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          32896       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           4128        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          4224        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          33024       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 34)           8738        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 34)           8738        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 34)           8738        dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 3/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 102)          0           input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          26368       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          32896       dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           4128        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          4224        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          33024       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 34)           8738        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 34)           8738        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 34)           8738        dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 4/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 102)          0           input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          26368       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          32896       dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 32)           4128        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          4224        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 256)          33024       dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 34)           8738        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 34)           8738        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 34)           8738        dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 5/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 102)          0           input_18[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 256)          26368       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 128)          32896       dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 32)           4128        dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          4224        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 256)          33024       dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 34)           8738        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 34)           8738        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 34)           8738        dense_41[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 6/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 68)           0           input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 256)          17664       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          32896       dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 32)           4128        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 128)          4224        dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 256)          33024       dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 34)           8738        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 34)           8738        dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 7/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 68)           0           input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 256)          17664       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 128)          32896       dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 32)           4128        dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 128)          4224        dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 256)          33024       dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 34)           8738        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 34)           8738        dense_56[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 8/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 68)           0           input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 256)          17664       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 128)          32896       dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 32)           4128        dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 128)          4224        dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 256)          33024       dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 34)           8738        dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 34)           8738        dense_63[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 9/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 68)           0           input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 256)          17664       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 128)          32896       dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 32)           4128        dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 128)          4224        dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 256)          33024       dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 34)           8738        dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 34)           8738        dense_70[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 10/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 68)           0           input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 256)          17664       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 128)          32896       dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 32)           4128        dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 128)          4224        dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 256)          33024       dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 34)           8738        dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 34)           8738        dense_77[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 11/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 68)           0           input_31[0][0]                   \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 256)          17664       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 128)          32896       dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 32)           4128        dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 128)          4224        dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 256)          33024       dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 34)           8738        dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 34)           8738        dense_84[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 12/12\n",
      " - Size of training set: (1006, 8, 34)\n",
      "(1006, 8, 34)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_39 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 272)          0           input_33[0][0]                   \n",
      "                                                                 input_34[0][0]                   \n",
      "                                                                 input_35[0][0]                   \n",
      "                                                                 input_36[0][0]                   \n",
      "                                                                 input_37[0][0]                   \n",
      "                                                                 input_38[0][0]                   \n",
      "                                                                 input_39[0][0]                   \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 256)          69888       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 128)          32896       dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 32)           4128        dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 128)          4224        dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 256)          33024       dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 214,064\n",
      "Trainable params: 214,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(histslist, vallist, autoencoders, train_normhist) = define_concatamash_autoencoder(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a44e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders):\n",
    "    \n",
    "    # Iterate through the training data to train corresponding autoencoders\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        if userfriendly: print('\\nNow training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 200\n",
    "        batch_size = 50\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                            epochs=nb_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                            verbose=1,\n",
    "                                callbacks= [earlystop] \n",
    "                            )\n",
    "        \n",
    "        # Create a plot of the model\n",
    "        \n",
    "        tf.keras.utils.plot_model(\n",
    "            autoencoder,\n",
    "            to_file=\"models/modelConcatamash{}.png\".format(i),\n",
    "            show_shapes=True,\n",
    "            show_dtype=False,\n",
    "            show_layer_names=False,\n",
    "            rankdir=\"TB\")\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52397fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now training model 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 17:42:07.316657: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-06-22 17:42:07.318828: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2194915000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 4s 45ms/step - loss: 0.0074 - dense_5_loss: 6.1070e-04 - dense_6_loss: 0.0012 - dense_7_loss: 8.5572e-04 - dense_8_loss: 0.0011 - dense_9_loss: 9.2062e-04 - dense_10_loss: 9.1915e-04 - dense_11_loss: 9.7356e-04 - dense_12_loss: 8.6078e-04 - val_loss: 4.9565e-04 - val_dense_5_loss: 4.7082e-05 - val_dense_6_loss: 1.2607e-04 - val_dense_7_loss: 6.8391e-05 - val_dense_8_loss: 4.0370e-05 - val_dense_9_loss: 3.0164e-05 - val_dense_10_loss: 8.3906e-05 - val_dense_11_loss: 6.5975e-05 - val_dense_12_loss: 3.3691e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.9975e-04 - dense_5_loss: 1.9269e-05 - dense_6_loss: 3.9497e-05 - dense_7_loss: 2.3884e-05 - dense_8_loss: 2.7787e-05 - dense_9_loss: 2.1097e-05 - dense_10_loss: 2.9014e-05 - dense_11_loss: 1.9859e-05 - dense_12_loss: 1.9347e-05 - val_loss: 5.8764e-05 - val_dense_5_loss: 4.3986e-06 - val_dense_6_loss: 1.1805e-05 - val_dense_7_loss: 6.8071e-06 - val_dense_8_loss: 1.1223e-05 - val_dense_9_loss: 6.4432e-06 - val_dense_10_loss: 7.3535e-06 - val_dense_11_loss: 5.0594e-06 - val_dense_12_loss: 5.6733e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 3.3620e-05 - dense_5_loss: 2.7460e-06 - dense_6_loss: 7.6056e-06 - dense_7_loss: 3.2377e-06 - dense_8_loss: 5.4240e-06 - dense_9_loss: 3.5205e-06 - dense_10_loss: 4.8723e-06 - dense_11_loss: 2.7350e-06 - dense_12_loss: 3.4792e-06 - val_loss: 1.6758e-05 - val_dense_5_loss: 1.2167e-06 - val_dense_6_loss: 4.8120e-06 - val_dense_7_loss: 8.1179e-07 - val_dense_8_loss: 3.1008e-06 - val_dense_9_loss: 1.5244e-06 - val_dense_10_loss: 2.0850e-06 - val_dense_11_loss: 1.2912e-06 - val_dense_12_loss: 1.9158e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.4388e-05 - dense_5_loss: 7.3345e-07 - dense_6_loss: 4.8064e-06 - dense_7_loss: 6.1794e-07 - dense_8_loss: 2.6727e-06 - dense_9_loss: 1.0293e-06 - dense_10_loss: 1.8479e-06 - dense_11_loss: 1.0970e-06 - dense_12_loss: 1.5836e-06 - val_loss: 1.3269e-05 - val_dense_5_loss: 4.8393e-07 - val_dense_6_loss: 4.4817e-06 - val_dense_7_loss: 5.3761e-07 - val_dense_8_loss: 2.5322e-06 - val_dense_9_loss: 1.0025e-06 - val_dense_10_loss: 1.6050e-06 - val_dense_11_loss: 9.9443e-07 - val_dense_12_loss: 1.6313e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2306e-05 - dense_5_loss: 4.4412e-07 - dense_6_loss: 4.4463e-06 - dense_7_loss: 4.6149e-07 - dense_8_loss: 2.3200e-06 - dense_9_loss: 8.2905e-07 - dense_10_loss: 1.4955e-06 - dense_11_loss: 8.9169e-07 - dense_12_loss: 1.4175e-06 - val_loss: 1.1125e-05 - val_dense_5_loss: 3.6135e-07 - val_dense_6_loss: 4.0838e-06 - val_dense_7_loss: 4.0556e-07 - val_dense_8_loss: 2.0890e-06 - val_dense_9_loss: 7.7702e-07 - val_dense_10_loss: 1.3214e-06 - val_dense_11_loss: 8.2070e-07 - val_dense_12_loss: 1.2661e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1876e-05 - dense_5_loss: 4.1833e-07 - dense_6_loss: 4.2884e-06 - dense_7_loss: 4.6713e-07 - dense_8_loss: 2.2318e-06 - dense_9_loss: 8.1468e-07 - dense_10_loss: 1.4099e-06 - dense_11_loss: 8.9153e-07 - dense_12_loss: 1.3543e-06 - val_loss: 1.0895e-05 - val_dense_5_loss: 3.8044e-07 - val_dense_6_loss: 3.9328e-06 - val_dense_7_loss: 4.3326e-07 - val_dense_8_loss: 2.0102e-06 - val_dense_9_loss: 8.1759e-07 - val_dense_10_loss: 1.2490e-06 - val_dense_11_loss: 8.3582e-07 - val_dense_12_loss: 1.2361e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1835e-05 - dense_5_loss: 4.3126e-07 - dense_6_loss: 4.2341e-06 - dense_7_loss: 4.7769e-07 - dense_8_loss: 2.2142e-06 - dense_9_loss: 8.2368e-07 - dense_10_loss: 1.3995e-06 - dense_11_loss: 9.0167e-07 - dense_12_loss: 1.3531e-06 - val_loss: 1.4478e-05 - val_dense_5_loss: 7.4610e-07 - val_dense_6_loss: 4.3768e-06 - val_dense_7_loss: 7.7033e-07 - val_dense_8_loss: 2.6293e-06 - val_dense_9_loss: 1.2161e-06 - val_dense_10_loss: 1.8372e-06 - val_dense_11_loss: 1.1901e-06 - val_dense_12_loss: 1.7119e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2909e-05 - dense_5_loss: 5.6207e-07 - dense_6_loss: 4.3149e-06 - dense_7_loss: 5.9788e-07 - dense_8_loss: 2.3647e-06 - dense_9_loss: 9.8376e-07 - dense_10_loss: 1.5684e-06 - dense_11_loss: 1.0317e-06 - dense_12_loss: 1.4857e-06 - val_loss: 1.2520e-05 - val_dense_5_loss: 6.1698e-07 - val_dense_6_loss: 4.0088e-06 - val_dense_7_loss: 6.2572e-07 - val_dense_8_loss: 2.2247e-06 - val_dense_9_loss: 1.0724e-06 - val_dense_10_loss: 1.4818e-06 - val_dense_11_loss: 1.0350e-06 - val_dense_12_loss: 1.4544e-06\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1816e-05 - dense_5_loss: 4.8104e-07 - dense_6_loss: 4.1085e-06 - dense_7_loss: 5.2381e-07 - dense_8_loss: 2.1689e-06 - dense_9_loss: 8.7825e-07 - dense_10_loss: 1.3647e-06 - dense_11_loss: 9.5113e-07 - dense_12_loss: 1.3401e-06 - val_loss: 1.0631e-05 - val_dense_5_loss: 4.0029e-07 - val_dense_6_loss: 3.7764e-06 - val_dense_7_loss: 4.5611e-07 - val_dense_8_loss: 1.9356e-06 - val_dense_9_loss: 8.2298e-07 - val_dense_10_loss: 1.1958e-06 - val_dense_11_loss: 8.5335e-07 - val_dense_12_loss: 1.1906e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1595e-05 - dense_5_loss: 4.5884e-07 - dense_6_loss: 4.0533e-06 - dense_7_loss: 5.1244e-07 - dense_8_loss: 2.1294e-06 - dense_9_loss: 8.6537e-07 - dense_10_loss: 1.3371e-06 - dense_11_loss: 9.3349e-07 - dense_12_loss: 1.3055e-06 - val_loss: 1.2953e-05 - val_dense_5_loss: 6.3412e-07 - val_dense_6_loss: 4.0918e-06 - val_dense_7_loss: 6.6426e-07 - val_dense_8_loss: 2.2798e-06 - val_dense_9_loss: 1.1420e-06 - val_dense_10_loss: 1.5429e-06 - val_dense_11_loss: 1.1196e-06 - val_dense_12_loss: 1.4789e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2042e-05 - dense_5_loss: 5.0330e-07 - dense_6_loss: 4.1404e-06 - dense_7_loss: 5.4725e-07 - dense_8_loss: 2.1942e-06 - dense_9_loss: 9.0914e-07 - dense_10_loss: 1.4106e-06 - dense_11_loss: 9.6965e-07 - dense_12_loss: 1.3673e-06 - val_loss: 1.2118e-05 - val_dense_5_loss: 5.1370e-07 - val_dense_6_loss: 4.0266e-06 - val_dense_7_loss: 5.7539e-07 - val_dense_8_loss: 2.2213e-06 - val_dense_9_loss: 9.9097e-07 - val_dense_10_loss: 1.4227e-06 - val_dense_11_loss: 9.7485e-07 - val_dense_12_loss: 1.3925e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3950e-05 - dense_5_loss: 7.3958e-07 - dense_6_loss: 4.2705e-06 - dense_7_loss: 7.5491e-07 - dense_8_loss: 2.4770e-06 - dense_9_loss: 1.1754e-06 - dense_10_loss: 1.7127e-06 - dense_11_loss: 1.2027e-06 - dense_12_loss: 1.6177e-06 - val_loss: 1.2300e-05 - val_dense_5_loss: 6.5702e-07 - val_dense_6_loss: 3.8414e-06 - val_dense_7_loss: 6.5021e-07 - val_dense_8_loss: 2.1451e-06 - val_dense_9_loss: 1.1051e-06 - val_dense_10_loss: 1.4759e-06 - val_dense_11_loss: 1.0976e-06 - val_dense_12_loss: 1.3279e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1728e-05 - dense_5_loss: 4.9380e-07 - dense_6_loss: 3.9778e-06 - dense_7_loss: 5.5278e-07 - dense_8_loss: 2.1145e-06 - dense_9_loss: 9.0939e-07 - dense_10_loss: 1.3643e-06 - dense_11_loss: 9.8209e-07 - dense_12_loss: 1.3331e-06 - val_loss: 1.1819e-05 - val_dense_5_loss: 5.8819e-07 - val_dense_6_loss: 3.7533e-06 - val_dense_7_loss: 6.4176e-07 - val_dense_8_loss: 2.0564e-06 - val_dense_9_loss: 1.0567e-06 - val_dense_10_loss: 1.3430e-06 - val_dense_11_loss: 1.0236e-06 - val_dense_12_loss: 1.3565e-06\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2608e-05 - dense_5_loss: 5.9854e-07 - dense_6_loss: 4.0529e-06 - dense_7_loss: 6.4490e-07 - dense_8_loss: 2.2572e-06 - dense_9_loss: 1.0325e-06 - dense_10_loss: 1.5038e-06 - dense_11_loss: 1.0652e-06 - dense_12_loss: 1.4527e-06 - val_loss: 1.2401e-05 - val_dense_5_loss: 6.3990e-07 - val_dense_6_loss: 3.8658e-06 - val_dense_7_loss: 6.7029e-07 - val_dense_8_loss: 2.1526e-06 - val_dense_9_loss: 1.0956e-06 - val_dense_10_loss: 1.4749e-06 - val_dense_11_loss: 1.0469e-06 - val_dense_12_loss: 1.4551e-06\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1751e-05 - dense_5_loss: 5.1597e-07 - dense_6_loss: 3.9493e-06 - dense_7_loss: 5.7267e-07 - dense_8_loss: 2.1035e-06 - dense_9_loss: 9.3436e-07 - dense_10_loss: 1.3477e-06 - dense_11_loss: 9.8952e-07 - dense_12_loss: 1.3379e-06 - val_loss: 1.0904e-05 - val_dense_5_loss: 4.2997e-07 - val_dense_6_loss: 3.6915e-06 - val_dense_7_loss: 5.2617e-07 - val_dense_8_loss: 1.9836e-06 - val_dense_9_loss: 8.9319e-07 - val_dense_10_loss: 1.2367e-06 - val_dense_11_loss: 9.2927e-07 - val_dense_12_loss: 1.2132e-06\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.1675e-05 - dense_5_loss: 5.1250e-07 - dense_6_loss: 3.8850e-06 - dense_7_loss: 5.7276e-07 - dense_8_loss: 2.0905e-06 - dense_9_loss: 9.3574e-07 - dense_10_loss: 1.3412e-06 - dense_11_loss: 1.0003e-06 - dense_12_loss: 1.3375e-06 - val_loss: 1.1033e-05 - val_dense_5_loss: 4.5826e-07 - val_dense_6_loss: 3.6983e-06 - val_dense_7_loss: 5.1931e-07 - val_dense_8_loss: 1.9985e-06 - val_dense_9_loss: 9.1112e-07 - val_dense_10_loss: 1.2889e-06 - val_dense_11_loss: 9.2503e-07 - val_dense_12_loss: 1.2339e-06\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.5067e-05 - dense_5_loss: 8.6872e-07 - dense_6_loss: 4.3070e-06 - dense_7_loss: 8.7089e-07 - dense_8_loss: 2.6537e-06 - dense_9_loss: 1.3518e-06 - dense_10_loss: 1.8989e-06 - dense_11_loss: 1.3389e-06 - dense_12_loss: 1.7774e-06 - val_loss: 1.4543e-05 - val_dense_5_loss: 9.0051e-07 - val_dense_6_loss: 4.0331e-06 - val_dense_7_loss: 9.6517e-07 - val_dense_8_loss: 2.4737e-06 - val_dense_9_loss: 1.4305e-06 - val_dense_10_loss: 1.7988e-06 - val_dense_11_loss: 1.2763e-06 - val_dense_12_loss: 1.6645e-06\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2843e-05 - dense_5_loss: 6.3688e-07 - dense_6_loss: 4.0093e-06 - dense_7_loss: 6.6694e-07 - dense_8_loss: 2.2633e-06 - dense_9_loss: 1.0865e-06 - dense_10_loss: 1.5627e-06 - dense_11_loss: 1.1217e-06 - dense_12_loss: 1.4956e-06 - val_loss: 1.0232e-05 - val_dense_5_loss: 4.1969e-07 - val_dense_6_loss: 3.4588e-06 - val_dense_7_loss: 4.7220e-07 - val_dense_8_loss: 1.8034e-06 - val_dense_9_loss: 8.6419e-07 - val_dense_10_loss: 1.1311e-06 - val_dense_11_loss: 8.9680e-07 - val_dense_12_loss: 1.1863e-06\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1948e-05 - dense_5_loss: 5.7932e-07 - dense_6_loss: 3.7687e-06 - dense_7_loss: 6.1200e-07 - dense_8_loss: 2.0822e-06 - dense_9_loss: 1.0248e-06 - dense_10_loss: 1.4022e-06 - dense_11_loss: 1.0763e-06 - dense_12_loss: 1.4024e-06 - val_loss: 1.0166e-05 - val_dense_5_loss: 4.1803e-07 - val_dense_6_loss: 3.3982e-06 - val_dense_7_loss: 4.9186e-07 - val_dense_8_loss: 1.7674e-06 - val_dense_9_loss: 8.6197e-07 - val_dense_10_loss: 1.1600e-06 - val_dense_11_loss: 8.9776e-07 - val_dense_12_loss: 1.1713e-06\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0573e-05 - dense_5_loss: 4.4645e-07 - dense_6_loss: 3.5115e-06 - dense_7_loss: 5.1494e-07 - dense_8_loss: 1.8334e-06 - dense_9_loss: 8.8407e-07 - dense_10_loss: 1.1962e-06 - dense_11_loss: 9.6057e-07 - dense_12_loss: 1.2254e-06 - val_loss: 9.9662e-06 - val_dense_5_loss: 4.2036e-07 - val_dense_6_loss: 3.3028e-06 - val_dense_7_loss: 4.8337e-07 - val_dense_8_loss: 1.7125e-06 - val_dense_9_loss: 8.7754e-07 - val_dense_10_loss: 1.1343e-06 - val_dense_11_loss: 8.9903e-07 - val_dense_12_loss: 1.1362e-06\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0651e-05 - dense_5_loss: 4.7066e-07 - dense_6_loss: 3.4727e-06 - dense_7_loss: 5.3215e-07 - dense_8_loss: 1.8341e-06 - dense_9_loss: 9.0416e-07 - dense_10_loss: 1.2038e-06 - dense_11_loss: 9.8602e-07 - dense_12_loss: 1.2471e-06 - val_loss: 1.0178e-05 - val_dense_5_loss: 4.8077e-07 - val_dense_6_loss: 3.2463e-06 - val_dense_7_loss: 5.1043e-07 - val_dense_8_loss: 1.7655e-06 - val_dense_9_loss: 9.1233e-07 - val_dense_10_loss: 1.1578e-06 - val_dense_11_loss: 9.3248e-07 - val_dense_12_loss: 1.1729e-06\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0659e-05 - dense_5_loss: 4.8674e-07 - dense_6_loss: 3.4265e-06 - dense_7_loss: 5.4392e-07 - dense_8_loss: 1.8300e-06 - dense_9_loss: 9.1489e-07 - dense_10_loss: 1.2237e-06 - dense_11_loss: 9.8957e-07 - dense_12_loss: 1.2433e-06 - val_loss: 9.6552e-06 - val_dense_5_loss: 4.4874e-07 - val_dense_6_loss: 3.1078e-06 - val_dense_7_loss: 4.9630e-07 - val_dense_8_loss: 1.6320e-06 - val_dense_9_loss: 8.8124e-07 - val_dense_10_loss: 1.0715e-06 - val_dense_11_loss: 9.1198e-07 - val_dense_12_loss: 1.1056e-06\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0676e-05 - dense_5_loss: 5.0604e-07 - dense_6_loss: 3.3423e-06 - dense_7_loss: 5.6807e-07 - dense_8_loss: 1.8136e-06 - dense_9_loss: 9.5674e-07 - dense_10_loss: 1.2193e-06 - dense_11_loss: 1.0257e-06 - dense_12_loss: 1.2443e-06 - val_loss: 1.0221e-05 - val_dense_5_loss: 4.5891e-07 - val_dense_6_loss: 3.2005e-06 - val_dense_7_loss: 5.1666e-07 - val_dense_8_loss: 1.7704e-06 - val_dense_9_loss: 9.1979e-07 - val_dense_10_loss: 1.1970e-06 - val_dense_11_loss: 9.4013e-07 - val_dense_12_loss: 1.2177e-06\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1807e-05 - dense_5_loss: 6.1225e-07 - dense_6_loss: 3.5055e-06 - dense_7_loss: 6.5268e-07 - dense_8_loss: 2.0337e-06 - dense_9_loss: 1.0711e-06 - dense_10_loss: 1.4148e-06 - dense_11_loss: 1.1100e-06 - dense_12_loss: 1.4068e-06 - val_loss: 9.4338e-06 - val_dense_5_loss: 4.3394e-07 - val_dense_6_loss: 2.9975e-06 - val_dense_7_loss: 4.8958e-07 - val_dense_8_loss: 1.5839e-06 - val_dense_9_loss: 8.7769e-07 - val_dense_10_loss: 1.0488e-06 - val_dense_11_loss: 9.1318e-07 - val_dense_12_loss: 1.0892e-06\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0480e-05 - dense_5_loss: 5.1568e-07 - dense_6_loss: 3.2035e-06 - dense_7_loss: 5.6583e-07 - dense_8_loss: 1.7597e-06 - dense_9_loss: 9.6337e-07 - dense_10_loss: 1.2032e-06 - dense_11_loss: 1.0320e-06 - dense_12_loss: 1.2369e-06 - val_loss: 1.2523e-05 - val_dense_5_loss: 6.1671e-07 - val_dense_6_loss: 3.5317e-06 - val_dense_7_loss: 7.2293e-07 - val_dense_8_loss: 2.2025e-06 - val_dense_9_loss: 1.2093e-06 - val_dense_10_loss: 1.6077e-06 - val_dense_11_loss: 1.1633e-06 - val_dense_12_loss: 1.4687e-06\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0328e-05 - dense_5_loss: 5.1349e-07 - dense_6_loss: 3.1279e-06 - dense_7_loss: 5.6795e-07 - dense_8_loss: 1.7272e-06 - dense_9_loss: 9.5247e-07 - dense_10_loss: 1.1942e-06 - dense_11_loss: 1.0253e-06 - dense_12_loss: 1.2195e-06 - val_loss: 9.5307e-06 - val_dense_5_loss: 4.7895e-07 - val_dense_6_loss: 2.8723e-06 - val_dense_7_loss: 5.2803e-07 - val_dense_8_loss: 1.5363e-06 - val_dense_9_loss: 9.8648e-07 - val_dense_10_loss: 1.0446e-06 - val_dense_11_loss: 9.6507e-07 - val_dense_12_loss: 1.1190e-06\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1978e-05 - dense_5_loss: 6.8227e-07 - dense_6_loss: 3.3564e-06 - dense_7_loss: 7.0352e-07 - dense_8_loss: 1.9965e-06 - dense_9_loss: 1.1516e-06 - dense_10_loss: 1.4498e-06 - dense_11_loss: 1.1916e-06 - dense_12_loss: 1.4460e-06 - val_loss: 1.8486e-05 - val_dense_5_loss: 1.2790e-06 - val_dense_6_loss: 4.4698e-06 - val_dense_7_loss: 1.0656e-06 - val_dense_8_loss: 3.3479e-06 - val_dense_9_loss: 1.7919e-06 - val_dense_10_loss: 2.5929e-06 - val_dense_11_loss: 1.6306e-06 - val_dense_12_loss: 2.3085e-06\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1379e-05 - dense_5_loss: 6.5059e-07 - dense_6_loss: 3.1325e-06 - dense_7_loss: 6.7806e-07 - dense_8_loss: 1.9008e-06 - dense_9_loss: 1.1203e-06 - dense_10_loss: 1.3717e-06 - dense_11_loss: 1.1574e-06 - dense_12_loss: 1.3677e-06 - val_loss: 8.7899e-06 - val_dense_5_loss: 4.2352e-07 - val_dense_6_loss: 2.6481e-06 - val_dense_7_loss: 4.7599e-07 - val_dense_8_loss: 1.4550e-06 - val_dense_9_loss: 8.7406e-07 - val_dense_10_loss: 9.6533e-07 - val_dense_11_loss: 9.1319e-07 - val_dense_12_loss: 1.0348e-06\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 8ms/step - loss: 9.2751e-06 - dense_5_loss: 4.6039e-07 - dense_6_loss: 2.7707e-06 - dense_7_loss: 5.1926e-07 - dense_8_loss: 1.5181e-06 - dense_9_loss: 8.7604e-07 - dense_10_loss: 1.0523e-06 - dense_11_loss: 9.6842e-07 - dense_12_loss: 1.1099e-06 - val_loss: 9.5322e-06 - val_dense_5_loss: 4.9849e-07 - val_dense_6_loss: 2.8330e-06 - val_dense_7_loss: 5.4476e-07 - val_dense_8_loss: 1.5727e-06 - val_dense_9_loss: 9.5852e-07 - val_dense_10_loss: 1.0052e-06 - val_dense_11_loss: 9.8497e-07 - val_dense_12_loss: 1.1345e-06\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 9.5463e-06 - dense_5_loss: 5.0739e-07 - dense_6_loss: 2.7567e-06 - dense_7_loss: 5.4731e-07 - dense_8_loss: 1.5683e-06 - dense_9_loss: 9.1284e-07 - dense_10_loss: 1.0983e-06 - dense_11_loss: 1.0000e-06 - dense_12_loss: 1.1555e-06 - val_loss: 8.4850e-06 - val_dense_5_loss: 4.4741e-07 - val_dense_6_loss: 2.4370e-06 - val_dense_7_loss: 4.8290e-07 - val_dense_8_loss: 1.3716e-06 - val_dense_9_loss: 8.8405e-07 - val_dense_10_loss: 9.5288e-07 - val_dense_11_loss: 9.1188e-07 - val_dense_12_loss: 9.9740e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 9.7488e-06 - dense_5_loss: 5.5252e-07 - dense_6_loss: 2.6660e-06 - dense_7_loss: 5.7844e-07 - dense_8_loss: 1.5834e-06 - dense_9_loss: 9.9717e-07 - dense_10_loss: 1.1385e-06 - dense_11_loss: 1.0525e-06 - dense_12_loss: 1.1802e-06 - val_loss: 8.5960e-06 - val_dense_5_loss: 4.7682e-07 - val_dense_6_loss: 2.3300e-06 - val_dense_7_loss: 5.3271e-07 - val_dense_8_loss: 1.3981e-06 - val_dense_9_loss: 9.4442e-07 - val_dense_10_loss: 9.6218e-07 - val_dense_11_loss: 9.5506e-07 - val_dense_12_loss: 9.9677e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 8.6706e-06 - dense_5_loss: 4.8040e-07 - dense_6_loss: 2.3838e-06 - dense_7_loss: 5.1871e-07 - dense_8_loss: 1.3881e-06 - dense_9_loss: 9.0686e-07 - dense_10_loss: 9.7625e-07 - dense_11_loss: 9.7291e-07 - dense_12_loss: 1.0435e-06 - val_loss: 7.8375e-06 - val_dense_5_loss: 4.2834e-07 - val_dense_6_loss: 2.1376e-06 - val_dense_7_loss: 4.7128e-07 - val_dense_8_loss: 1.2535e-06 - val_dense_9_loss: 8.6492e-07 - val_dense_10_loss: 8.5840e-07 - val_dense_11_loss: 8.9293e-07 - val_dense_12_loss: 9.3050e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.1259e-05 - dense_5_loss: 7.2404e-07 - dense_6_loss: 2.7615e-06 - dense_7_loss: 7.2318e-07 - dense_8_loss: 1.8423e-06 - dense_9_loss: 1.1808e-06 - dense_10_loss: 1.4170e-06 - dense_11_loss: 1.2091e-06 - dense_12_loss: 1.4010e-06 - val_loss: 9.5172e-06 - val_dense_5_loss: 5.2239e-07 - val_dense_6_loss: 2.4271e-06 - val_dense_7_loss: 6.1801e-07 - val_dense_8_loss: 1.5778e-06 - val_dense_9_loss: 1.0888e-06 - val_dense_10_loss: 1.1517e-06 - val_dense_11_loss: 9.8281e-07 - val_dense_12_loss: 1.1486e-06\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 8.6553e-06 - dense_5_loss: 4.9097e-07 - dense_6_loss: 2.2847e-06 - dense_7_loss: 5.2217e-07 - dense_8_loss: 1.4093e-06 - dense_9_loss: 9.0490e-07 - dense_10_loss: 1.0140e-06 - dense_11_loss: 9.6802e-07 - dense_12_loss: 1.0612e-06 - val_loss: 7.8212e-06 - val_dense_5_loss: 4.2926e-07 - val_dense_6_loss: 2.0839e-06 - val_dense_7_loss: 4.6838e-07 - val_dense_8_loss: 1.2204e-06 - val_dense_9_loss: 8.8329e-07 - val_dense_10_loss: 9.0375e-07 - val_dense_11_loss: 8.6657e-07 - val_dense_12_loss: 9.6567e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.9238e-06 - dense_5_loss: 4.6020e-07 - dense_6_loss: 2.0358e-06 - dense_7_loss: 5.0377e-07 - dense_8_loss: 1.2519e-06 - dense_9_loss: 8.7120e-07 - dense_10_loss: 8.8992e-07 - dense_11_loss: 9.4538e-07 - dense_12_loss: 9.6551e-07 - val_loss: 8.4478e-06 - val_dense_5_loss: 4.5822e-07 - val_dense_6_loss: 2.3231e-06 - val_dense_7_loss: 4.7945e-07 - val_dense_8_loss: 1.4851e-06 - val_dense_9_loss: 8.8267e-07 - val_dense_10_loss: 9.5196e-07 - val_dense_11_loss: 9.1132e-07 - val_dense_12_loss: 9.5596e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.8539e-06 - dense_5_loss: 4.6311e-07 - dense_6_loss: 1.9921e-06 - dense_7_loss: 4.9574e-07 - dense_8_loss: 1.2702e-06 - dense_9_loss: 8.7054e-07 - dense_10_loss: 8.7287e-07 - dense_11_loss: 9.3720e-07 - dense_12_loss: 9.5205e-07 - val_loss: 7.4035e-06 - val_dense_5_loss: 4.6187e-07 - val_dense_6_loss: 1.7638e-06 - val_dense_7_loss: 4.9774e-07 - val_dense_8_loss: 1.1344e-06 - val_dense_9_loss: 9.2829e-07 - val_dense_10_loss: 8.0714e-07 - val_dense_11_loss: 9.2420e-07 - val_dense_12_loss: 8.8611e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.1568e-06 - dense_5_loss: 5.7874e-07 - dense_6_loss: 2.1928e-06 - dense_7_loss: 5.8595e-07 - dense_8_loss: 1.4965e-06 - dense_9_loss: 1.0211e-06 - dense_10_loss: 1.1046e-06 - dense_11_loss: 1.0479e-06 - dense_12_loss: 1.1293e-06 - val_loss: 1.2222e-05 - val_dense_5_loss: 8.2824e-07 - val_dense_6_loss: 2.8333e-06 - val_dense_7_loss: 6.9972e-07 - val_dense_8_loss: 2.2513e-06 - val_dense_9_loss: 1.3205e-06 - val_dense_10_loss: 1.5918e-06 - val_dense_11_loss: 1.1837e-06 - val_dense_12_loss: 1.5132e-06\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 8.3914e-06 - dense_5_loss: 5.3447e-07 - dense_6_loss: 2.0044e-06 - dense_7_loss: 5.3133e-07 - dense_8_loss: 1.3706e-06 - dense_9_loss: 9.3661e-07 - dense_10_loss: 9.8761e-07 - dense_11_loss: 9.8522e-07 - dense_12_loss: 1.0410e-06 - val_loss: 9.5260e-06 - val_dense_5_loss: 5.2016e-07 - val_dense_6_loss: 2.2564e-06 - val_dense_7_loss: 5.7001e-07 - val_dense_8_loss: 1.6467e-06 - val_dense_9_loss: 1.1015e-06 - val_dense_10_loss: 1.2065e-06 - val_dense_11_loss: 1.0619e-06 - val_dense_12_loss: 1.1628e-06\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.4618e-06 - dense_5_loss: 4.8142e-07 - dense_6_loss: 1.7545e-06 - dense_7_loss: 4.8919e-07 - dense_8_loss: 1.1966e-06 - dense_9_loss: 8.6707e-07 - dense_10_loss: 8.2191e-07 - dense_11_loss: 9.4103e-07 - dense_12_loss: 9.1008e-07 - val_loss: 6.5457e-06 - val_dense_5_loss: 4.1625e-07 - val_dense_6_loss: 1.5128e-06 - val_dense_7_loss: 4.2951e-07 - val_dense_8_loss: 1.0530e-06 - val_dense_9_loss: 8.4584e-07 - val_dense_10_loss: 6.7362e-07 - val_dense_11_loss: 8.6204e-07 - val_dense_12_loss: 7.5262e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.5649e-06 - dense_5_loss: 4.0940e-07 - dense_6_loss: 1.5071e-06 - dense_7_loss: 4.3581e-07 - dense_8_loss: 1.0432e-06 - dense_9_loss: 8.1295e-07 - dense_10_loss: 6.9587e-07 - dense_11_loss: 8.7903e-07 - dense_12_loss: 7.8157e-07 - val_loss: 6.1258e-06 - val_dense_5_loss: 3.6432e-07 - val_dense_6_loss: 1.4407e-06 - val_dense_7_loss: 4.0081e-07 - val_dense_8_loss: 9.9936e-07 - val_dense_9_loss: 7.9212e-07 - val_dense_10_loss: 6.2671e-07 - val_dense_11_loss: 8.0745e-07 - val_dense_12_loss: 6.9432e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.9127e-06 - dense_5_loss: 4.2836e-07 - dense_6_loss: 1.5708e-06 - dense_7_loss: 4.5821e-07 - dense_8_loss: 1.1207e-06 - dense_9_loss: 8.3310e-07 - dense_10_loss: 7.7828e-07 - dense_11_loss: 8.9761e-07 - dense_12_loss: 8.2570e-07 - val_loss: 8.5380e-06 - val_dense_5_loss: 4.4607e-07 - val_dense_6_loss: 2.2541e-06 - val_dense_7_loss: 4.5778e-07 - val_dense_8_loss: 1.4601e-06 - val_dense_9_loss: 8.3658e-07 - val_dense_10_loss: 1.1867e-06 - val_dense_11_loss: 8.9579e-07 - val_dense_12_loss: 1.0008e-06\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.7823e-06 - dense_5_loss: 4.2507e-07 - dense_6_loss: 1.5141e-06 - dense_7_loss: 4.4998e-07 - dense_8_loss: 1.1038e-06 - dense_9_loss: 8.2222e-07 - dense_10_loss: 7.5762e-07 - dense_11_loss: 8.9440e-07 - dense_12_loss: 8.1503e-07 - val_loss: 6.1467e-06 - val_dense_5_loss: 3.9656e-07 - val_dense_6_loss: 1.2848e-06 - val_dense_7_loss: 4.2852e-07 - val_dense_8_loss: 9.5318e-07 - val_dense_9_loss: 8.5189e-07 - val_dense_10_loss: 6.2424e-07 - val_dense_11_loss: 8.7248e-07 - val_dense_12_loss: 7.3506e-07\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 8ms/step - loss: 7.3010e-06 - dense_5_loss: 4.5616e-07 - dense_6_loss: 1.6912e-06 - dense_7_loss: 4.5489e-07 - dense_8_loss: 1.2167e-06 - dense_9_loss: 8.3235e-07 - dense_10_loss: 8.3408e-07 - dense_11_loss: 9.3396e-07 - dense_12_loss: 8.8173e-07 - val_loss: 6.2533e-06 - val_dense_5_loss: 3.6378e-07 - val_dense_6_loss: 1.4473e-06 - val_dense_7_loss: 4.0244e-07 - val_dense_8_loss: 1.0431e-06 - val_dense_9_loss: 7.8950e-07 - val_dense_10_loss: 6.6594e-07 - val_dense_11_loss: 7.9241e-07 - val_dense_12_loss: 7.4880e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.8293e-06 - dense_5_loss: 3.5525e-07 - dense_6_loss: 1.3075e-06 - dense_7_loss: 3.9501e-07 - dense_8_loss: 9.3137e-07 - dense_9_loss: 7.3072e-07 - dense_10_loss: 6.0446e-07 - dense_11_loss: 8.2006e-07 - dense_12_loss: 6.8494e-07 - val_loss: 6.6396e-06 - val_dense_5_loss: 3.4053e-07 - val_dense_6_loss: 1.7519e-06 - val_dense_7_loss: 3.9015e-07 - val_dense_8_loss: 1.1318e-06 - val_dense_9_loss: 7.7932e-07 - val_dense_10_loss: 7.2060e-07 - val_dense_11_loss: 7.7984e-07 - val_dense_12_loss: 7.4536e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.6898e-06 - dense_5_loss: 3.4392e-07 - dense_6_loss: 1.2886e-06 - dense_7_loss: 3.8675e-07 - dense_8_loss: 9.0242e-07 - dense_9_loss: 7.1548e-07 - dense_10_loss: 5.8565e-07 - dense_11_loss: 8.0947e-07 - dense_12_loss: 6.5753e-07 - val_loss: 5.4542e-06 - val_dense_5_loss: 3.4186e-07 - val_dense_6_loss: 1.1519e-06 - val_dense_7_loss: 3.8011e-07 - val_dense_8_loss: 8.5229e-07 - val_dense_9_loss: 7.5013e-07 - val_dense_10_loss: 5.5473e-07 - val_dense_11_loss: 7.9180e-07 - val_dense_12_loss: 6.3139e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3374e-05 - dense_5_loss: 9.2346e-07 - dense_6_loss: 2.8962e-06 - dense_7_loss: 8.4701e-07 - dense_8_loss: 2.3314e-06 - dense_9_loss: 1.3611e-06 - dense_10_loss: 1.8831e-06 - dense_11_loss: 1.3449e-06 - dense_12_loss: 1.7865e-06 - val_loss: 6.9832e-06 - val_dense_5_loss: 3.8421e-07 - val_dense_6_loss: 1.7911e-06 - val_dense_7_loss: 3.9206e-07 - val_dense_8_loss: 1.2401e-06 - val_dense_9_loss: 7.5716e-07 - val_dense_10_loss: 8.3828e-07 - val_dense_11_loss: 8.0991e-07 - val_dense_12_loss: 7.7030e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.2602e-06 - dense_5_loss: 3.8461e-07 - dense_6_loss: 1.5022e-06 - dense_7_loss: 4.0426e-07 - dense_8_loss: 1.0264e-06 - dense_9_loss: 7.2374e-07 - dense_10_loss: 6.6329e-07 - dense_11_loss: 8.2695e-07 - dense_12_loss: 7.2863e-07 - val_loss: 5.6262e-06 - val_dense_5_loss: 3.0197e-07 - val_dense_6_loss: 1.3299e-06 - val_dense_7_loss: 3.5198e-07 - val_dense_8_loss: 8.8256e-07 - val_dense_9_loss: 7.1149e-07 - val_dense_10_loss: 6.6472e-07 - val_dense_11_loss: 7.3204e-07 - val_dense_12_loss: 6.5154e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.3859e-06 - dense_5_loss: 3.1704e-07 - dense_6_loss: 1.2370e-06 - dense_7_loss: 3.4510e-07 - dense_8_loss: 8.6753e-07 - dense_9_loss: 6.6636e-07 - dense_10_loss: 5.5553e-07 - dense_11_loss: 7.7723e-07 - dense_12_loss: 6.2013e-07 - val_loss: 5.9181e-06 - val_dense_5_loss: 3.2484e-07 - val_dense_6_loss: 1.4093e-06 - val_dense_7_loss: 3.8876e-07 - val_dense_8_loss: 1.0596e-06 - val_dense_9_loss: 6.9564e-07 - val_dense_10_loss: 5.9460e-07 - val_dense_11_loss: 7.5939e-07 - val_dense_12_loss: 6.8595e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.2230e-06 - dense_5_loss: 3.0167e-07 - dense_6_loss: 1.1594e-06 - dense_7_loss: 3.4435e-07 - dense_8_loss: 8.3651e-07 - dense_9_loss: 6.6757e-07 - dense_10_loss: 5.3303e-07 - dense_11_loss: 7.7982e-07 - dense_12_loss: 6.0067e-07 - val_loss: 5.3201e-06 - val_dense_5_loss: 3.1922e-07 - val_dense_6_loss: 1.0977e-06 - val_dense_7_loss: 3.7837e-07 - val_dense_8_loss: 8.1187e-07 - val_dense_9_loss: 7.4789e-07 - val_dense_10_loss: 5.6415e-07 - val_dense_11_loss: 8.0873e-07 - val_dense_12_loss: 5.9222e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.1084e-06 - dense_5_loss: 3.0263e-07 - dense_6_loss: 1.0962e-06 - dense_7_loss: 3.4507e-07 - dense_8_loss: 8.0482e-07 - dense_9_loss: 6.7218e-07 - dense_10_loss: 5.2417e-07 - dense_11_loss: 7.7227e-07 - dense_12_loss: 5.9101e-07 - val_loss: 5.2030e-06 - val_dense_5_loss: 2.8294e-07 - val_dense_6_loss: 1.1488e-06 - val_dense_7_loss: 3.3105e-07 - val_dense_8_loss: 8.5298e-07 - val_dense_9_loss: 7.0616e-07 - val_dense_10_loss: 5.5472e-07 - val_dense_11_loss: 7.4762e-07 - val_dense_12_loss: 5.7872e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.8084e-06 - dense_5_loss: 3.2482e-07 - dense_6_loss: 1.3470e-06 - dense_7_loss: 3.5742e-07 - dense_8_loss: 9.6376e-07 - dense_9_loss: 6.9198e-07 - dense_10_loss: 6.5145e-07 - dense_11_loss: 7.8677e-07 - dense_12_loss: 6.8521e-07 - val_loss: 4.9761e-06 - val_dense_5_loss: 3.2985e-07 - val_dense_6_loss: 1.0141e-06 - val_dense_7_loss: 3.3933e-07 - val_dense_8_loss: 7.9888e-07 - val_dense_9_loss: 6.9833e-07 - val_dense_10_loss: 5.1647e-07 - val_dense_11_loss: 7.3491e-07 - val_dense_12_loss: 5.4424e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.2748e-06 - dense_5_loss: 3.2562e-07 - dense_6_loss: 1.1218e-06 - dense_7_loss: 3.5101e-07 - dense_8_loss: 8.4816e-07 - dense_9_loss: 6.7859e-07 - dense_10_loss: 5.6278e-07 - dense_11_loss: 7.7153e-07 - dense_12_loss: 6.1524e-07 - val_loss: 4.9798e-06 - val_dense_5_loss: 2.7274e-07 - val_dense_6_loss: 1.0894e-06 - val_dense_7_loss: 3.1334e-07 - val_dense_8_loss: 8.0506e-07 - val_dense_9_loss: 6.7689e-07 - val_dense_10_loss: 5.6073e-07 - val_dense_11_loss: 7.1824e-07 - val_dense_12_loss: 5.4341e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.8522e-06 - dense_5_loss: 2.8781e-07 - dense_6_loss: 1.0325e-06 - dense_7_loss: 3.3024e-07 - dense_8_loss: 7.6140e-07 - dense_9_loss: 6.4166e-07 - dense_10_loss: 5.0459e-07 - dense_11_loss: 7.4162e-07 - dense_12_loss: 5.5237e-07 - val_loss: 4.7470e-06 - val_dense_5_loss: 2.6967e-07 - val_dense_6_loss: 1.0156e-06 - val_dense_7_loss: 3.1099e-07 - val_dense_8_loss: 7.6673e-07 - val_dense_9_loss: 6.5286e-07 - val_dense_10_loss: 4.8470e-07 - val_dense_11_loss: 7.0728e-07 - val_dense_12_loss: 5.3917e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.0900e-06 - dense_5_loss: 3.0922e-07 - dense_6_loss: 1.0850e-06 - dense_7_loss: 3.4250e-07 - dense_8_loss: 8.0628e-07 - dense_9_loss: 6.5638e-07 - dense_10_loss: 5.4077e-07 - dense_11_loss: 7.5838e-07 - dense_12_loss: 5.9150e-07 - val_loss: 5.0451e-06 - val_dense_5_loss: 2.9996e-07 - val_dense_6_loss: 1.0321e-06 - val_dense_7_loss: 3.5514e-07 - val_dense_8_loss: 7.6693e-07 - val_dense_9_loss: 7.0194e-07 - val_dense_10_loss: 5.6611e-07 - val_dense_11_loss: 7.3464e-07 - val_dense_12_loss: 5.8832e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.9182e-06 - dense_5_loss: 2.9133e-07 - dense_6_loss: 1.0582e-06 - dense_7_loss: 3.2530e-07 - dense_8_loss: 7.8480e-07 - dense_9_loss: 6.4298e-07 - dense_10_loss: 5.1626e-07 - dense_11_loss: 7.4236e-07 - dense_12_loss: 5.5693e-07 - val_loss: 5.1883e-06 - val_dense_5_loss: 3.7286e-07 - val_dense_6_loss: 1.0450e-06 - val_dense_7_loss: 3.7729e-07 - val_dense_8_loss: 7.7487e-07 - val_dense_9_loss: 7.3603e-07 - val_dense_10_loss: 5.3350e-07 - val_dense_11_loss: 7.5978e-07 - val_dense_12_loss: 5.8899e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8594e-06 - dense_5_loss: 2.8963e-07 - dense_6_loss: 1.0221e-06 - dense_7_loss: 3.3013e-07 - dense_8_loss: 7.6053e-07 - dense_9_loss: 6.4760e-07 - dense_10_loss: 5.0637e-07 - dense_11_loss: 7.4451e-07 - dense_12_loss: 5.5859e-07 - val_loss: 5.2746e-06 - val_dense_5_loss: 3.4546e-07 - val_dense_6_loss: 1.1044e-06 - val_dense_7_loss: 4.0459e-07 - val_dense_8_loss: 8.8717e-07 - val_dense_9_loss: 6.7689e-07 - val_dense_10_loss: 5.0605e-07 - val_dense_11_loss: 7.5621e-07 - val_dense_12_loss: 5.9377e-07\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 4.9950e-06 - dense_5_loss: 3.0378e-07 - dense_6_loss: 1.0559e-06 - dense_7_loss: 3.4113e-07 - dense_8_loss: 7.9291e-07 - dense_9_loss: 6.4610e-07 - dense_10_loss: 5.2422e-07 - dense_11_loss: 7.5710e-07 - dense_12_loss: 5.7380e-07 - val_loss: 5.3440e-06 - val_dense_5_loss: 3.2083e-07 - val_dense_6_loss: 1.1493e-06 - val_dense_7_loss: 3.6065e-07 - val_dense_8_loss: 8.7574e-07 - val_dense_9_loss: 7.2280e-07 - val_dense_10_loss: 5.3485e-07 - val_dense_11_loss: 7.6414e-07 - val_dense_12_loss: 6.1566e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.8094e-06 - dense_5_loss: 3.5961e-07 - dense_6_loss: 1.2391e-06 - dense_7_loss: 3.9429e-07 - dense_8_loss: 9.2688e-07 - dense_9_loss: 7.2337e-07 - dense_10_loss: 6.6195e-07 - dense_11_loss: 8.1276e-07 - dense_12_loss: 6.9149e-07 - val_loss: 8.0076e-06 - val_dense_5_loss: 7.6947e-07 - val_dense_6_loss: 1.3819e-06 - val_dense_7_loss: 6.5201e-07 - val_dense_8_loss: 1.2666e-06 - val_dense_9_loss: 1.0880e-06 - val_dense_10_loss: 8.5934e-07 - val_dense_11_loss: 1.0176e-06 - val_dense_12_loss: 9.7266e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.5854e-06 - dense_5_loss: 3.6069e-07 - dense_6_loss: 1.1962e-06 - dense_7_loss: 3.8042e-07 - dense_8_loss: 8.8094e-07 - dense_9_loss: 7.0673e-07 - dense_10_loss: 5.9634e-07 - dense_11_loss: 8.1845e-07 - dense_12_loss: 6.4558e-07 - val_loss: 4.7635e-06 - val_dense_5_loss: 2.8017e-07 - val_dense_6_loss: 9.9305e-07 - val_dense_7_loss: 3.1911e-07 - val_dense_8_loss: 7.4283e-07 - val_dense_9_loss: 6.7935e-07 - val_dense_10_loss: 4.8613e-07 - val_dense_11_loss: 7.3130e-07 - val_dense_12_loss: 5.3161e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.7899e-06 - dense_5_loss: 2.7702e-07 - dense_6_loss: 1.0216e-06 - dense_7_loss: 3.1901e-07 - dense_8_loss: 7.4066e-07 - dense_9_loss: 6.4656e-07 - dense_10_loss: 4.9914e-07 - dense_11_loss: 7.4310e-07 - dense_12_loss: 5.4284e-07 - val_loss: 5.2824e-06 - val_dense_5_loss: 2.9112e-07 - val_dense_6_loss: 1.2430e-06 - val_dense_7_loss: 3.1684e-07 - val_dense_8_loss: 8.0200e-07 - val_dense_9_loss: 6.7863e-07 - val_dense_10_loss: 6.3303e-07 - val_dense_11_loss: 7.2215e-07 - val_dense_12_loss: 5.9561e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 8.3012e-06 - dense_5_loss: 5.8270e-07 - dense_6_loss: 1.7130e-06 - dense_7_loss: 5.5942e-07 - dense_8_loss: 1.3391e-06 - dense_9_loss: 9.5075e-07 - dense_10_loss: 1.0560e-06 - dense_11_loss: 1.0213e-06 - dense_12_loss: 1.0790e-06 - val_loss: 8.3110e-06 - val_dense_5_loss: 7.6655e-07 - val_dense_6_loss: 1.2727e-06 - val_dense_7_loss: 8.2519e-07 - val_dense_8_loss: 1.1418e-06 - val_dense_9_loss: 1.1613e-06 - val_dense_10_loss: 8.5268e-07 - val_dense_11_loss: 1.2364e-06 - val_dense_12_loss: 1.0543e-06\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.0515e-06 - dense_5_loss: 4.1594e-07 - dense_6_loss: 1.2841e-06 - dense_7_loss: 4.4054e-07 - dense_8_loss: 9.4168e-07 - dense_9_loss: 7.6337e-07 - dense_10_loss: 6.4384e-07 - dense_11_loss: 8.5781e-07 - dense_12_loss: 7.0428e-07 - val_loss: 5.2508e-06 - val_dense_5_loss: 2.9707e-07 - val_dense_6_loss: 1.2236e-06 - val_dense_7_loss: 3.4069e-07 - val_dense_8_loss: 9.0119e-07 - val_dense_9_loss: 6.8399e-07 - val_dense_10_loss: 5.1544e-07 - val_dense_11_loss: 7.4374e-07 - val_dense_12_loss: 5.4508e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8536e-06 - dense_5_loss: 2.7411e-07 - dense_6_loss: 1.0751e-06 - dense_7_loss: 3.2557e-07 - dense_8_loss: 7.6081e-07 - dense_9_loss: 6.2502e-07 - dense_10_loss: 5.1192e-07 - dense_11_loss: 7.3593e-07 - dense_12_loss: 5.4521e-07 - val_loss: 4.7419e-06 - val_dense_5_loss: 3.0870e-07 - val_dense_6_loss: 9.8623e-07 - val_dense_7_loss: 3.1969e-07 - val_dense_8_loss: 7.0933e-07 - val_dense_9_loss: 7.2576e-07 - val_dense_10_loss: 4.7416e-07 - val_dense_11_loss: 7.0153e-07 - val_dense_12_loss: 5.1654e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.8318e-06 - dense_5_loss: 2.7698e-07 - dense_6_loss: 1.0533e-06 - dense_7_loss: 3.1200e-07 - dense_8_loss: 7.5316e-07 - dense_9_loss: 6.3729e-07 - dense_10_loss: 5.2361e-07 - dense_11_loss: 7.2439e-07 - dense_12_loss: 5.5109e-07 - val_loss: 4.7478e-06 - val_dense_5_loss: 2.7123e-07 - val_dense_6_loss: 1.0079e-06 - val_dense_7_loss: 3.0886e-07 - val_dense_8_loss: 7.1963e-07 - val_dense_9_loss: 6.9307e-07 - val_dense_10_loss: 4.7190e-07 - val_dense_11_loss: 7.6624e-07 - val_dense_12_loss: 5.0898e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8931e-06 - dense_5_loss: 2.8059e-07 - dense_6_loss: 1.0566e-06 - dense_7_loss: 3.2495e-07 - dense_8_loss: 7.4475e-07 - dense_9_loss: 6.4749e-07 - dense_10_loss: 5.2867e-07 - dense_11_loss: 7.4792e-07 - dense_12_loss: 5.6210e-07 - val_loss: 4.8684e-06 - val_dense_5_loss: 2.7744e-07 - val_dense_6_loss: 1.0567e-06 - val_dense_7_loss: 3.0829e-07 - val_dense_8_loss: 7.3015e-07 - val_dense_9_loss: 6.7049e-07 - val_dense_10_loss: 5.1113e-07 - val_dense_11_loss: 7.3452e-07 - val_dense_12_loss: 5.7977e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.4505e-06 - dense_5_loss: 3.2457e-07 - dense_6_loss: 1.2227e-06 - dense_7_loss: 3.4608e-07 - dense_8_loss: 8.5819e-07 - dense_9_loss: 6.6851e-07 - dense_10_loss: 6.1454e-07 - dense_11_loss: 7.7220e-07 - dense_12_loss: 6.4372e-07 - val_loss: 5.0428e-06 - val_dense_5_loss: 2.6983e-07 - val_dense_6_loss: 1.1902e-06 - val_dense_7_loss: 3.0733e-07 - val_dense_8_loss: 8.1815e-07 - val_dense_9_loss: 6.7924e-07 - val_dense_10_loss: 5.1470e-07 - val_dense_11_loss: 7.0212e-07 - val_dense_12_loss: 5.6123e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.2155e-06 - dense_5_loss: 3.7096e-07 - dense_6_loss: 1.4324e-06 - dense_7_loss: 3.8406e-07 - dense_8_loss: 1.0054e-06 - dense_9_loss: 7.1802e-07 - dense_10_loss: 7.4689e-07 - dense_11_loss: 8.1778e-07 - dense_12_loss: 7.3992e-07 - val_loss: 4.7807e-06 - val_dense_5_loss: 2.7564e-07 - val_dense_6_loss: 9.5781e-07 - val_dense_7_loss: 3.6402e-07 - val_dense_8_loss: 7.2683e-07 - val_dense_9_loss: 6.7117e-07 - val_dense_10_loss: 5.0057e-07 - val_dense_11_loss: 7.5513e-07 - val_dense_12_loss: 5.2952e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.4582e-06 - dense_5_loss: 3.4542e-07 - dense_6_loss: 1.1423e-06 - dense_7_loss: 3.7921e-07 - dense_8_loss: 8.3992e-07 - dense_9_loss: 7.0385e-07 - dense_10_loss: 6.1790e-07 - dense_11_loss: 7.8814e-07 - dense_12_loss: 6.4151e-07 - val_loss: 6.2452e-06 - val_dense_5_loss: 4.4528e-07 - val_dense_6_loss: 1.2035e-06 - val_dense_7_loss: 5.3314e-07 - val_dense_8_loss: 9.0992e-07 - val_dense_9_loss: 9.0667e-07 - val_dense_10_loss: 7.2493e-07 - val_dense_11_loss: 8.2831e-07 - val_dense_12_loss: 6.9344e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.1784e-06 - dense_5_loss: 3.0662e-07 - dense_6_loss: 1.1297e-06 - dense_7_loss: 3.4196e-07 - dense_8_loss: 7.9251e-07 - dense_9_loss: 6.6729e-07 - dense_10_loss: 5.8492e-07 - dense_11_loss: 7.5962e-07 - dense_12_loss: 5.9570e-07 - val_loss: 4.8286e-06 - val_dense_5_loss: 2.9458e-07 - val_dense_6_loss: 1.0377e-06 - val_dense_7_loss: 3.2398e-07 - val_dense_8_loss: 7.2658e-07 - val_dense_9_loss: 6.5960e-07 - val_dense_10_loss: 5.6040e-07 - val_dense_11_loss: 7.0429e-07 - val_dense_12_loss: 5.2149e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.6131e-06 - dense_5_loss: 2.7325e-07 - dense_6_loss: 9.7146e-07 - dense_7_loss: 3.1428e-07 - dense_8_loss: 6.8671e-07 - dense_9_loss: 6.2130e-07 - dense_10_loss: 4.9254e-07 - dense_11_loss: 7.2891e-07 - dense_12_loss: 5.2469e-07 - val_loss: 4.5281e-06 - val_dense_5_loss: 2.7391e-07 - val_dense_6_loss: 8.9171e-07 - val_dense_7_loss: 3.1656e-07 - val_dense_8_loss: 6.6464e-07 - val_dense_9_loss: 6.4450e-07 - val_dense_10_loss: 4.6592e-07 - val_dense_11_loss: 7.6572e-07 - val_dense_12_loss: 5.0508e-07\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 8ms/step - loss: 4.5963e-06 - dense_5_loss: 2.7306e-07 - dense_6_loss: 9.5266e-07 - dense_7_loss: 3.2557e-07 - dense_8_loss: 6.7646e-07 - dense_9_loss: 6.3266e-07 - dense_10_loss: 4.8353e-07 - dense_11_loss: 7.3263e-07 - dense_12_loss: 5.1975e-07 - val_loss: 5.0786e-06 - val_dense_5_loss: 3.0946e-07 - val_dense_6_loss: 1.0699e-06 - val_dense_7_loss: 3.4309e-07 - val_dense_8_loss: 8.2048e-07 - val_dense_9_loss: 6.6842e-07 - val_dense_10_loss: 5.6816e-07 - val_dense_11_loss: 7.3944e-07 - val_dense_12_loss: 5.5969e-07\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.7275e-06 - dense_5_loss: 3.4390e-07 - dense_6_loss: 1.2897e-06 - dense_7_loss: 3.7334e-07 - dense_8_loss: 8.9289e-07 - dense_9_loss: 6.7823e-07 - dense_10_loss: 6.7567e-07 - dense_11_loss: 7.9921e-07 - dense_12_loss: 6.7460e-07 - val_loss: 5.2021e-06 - val_dense_5_loss: 3.4480e-07 - val_dense_6_loss: 1.0667e-06 - val_dense_7_loss: 3.7332e-07 - val_dense_8_loss: 7.7509e-07 - val_dense_9_loss: 7.1595e-07 - val_dense_10_loss: 5.7702e-07 - val_dense_11_loss: 7.9038e-07 - val_dense_12_loss: 5.5891e-07\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7955e-06 - dense_5_loss: 2.9675e-07 - dense_6_loss: 9.8801e-07 - dense_7_loss: 3.4858e-07 - dense_8_loss: 7.0514e-07 - dense_9_loss: 6.4123e-07 - dense_10_loss: 5.1442e-07 - dense_11_loss: 7.4751e-07 - dense_12_loss: 5.5383e-07 - val_loss: 5.2617e-06 - val_dense_5_loss: 3.7857e-07 - val_dense_6_loss: 1.1130e-06 - val_dense_7_loss: 3.5493e-07 - val_dense_8_loss: 8.4104e-07 - val_dense_9_loss: 7.0724e-07 - val_dense_10_loss: 5.6953e-07 - val_dense_11_loss: 7.1785e-07 - val_dense_12_loss: 5.7956e-07\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5.7925e-06 - dense_5_loss: 3.8806e-07 - dense_6_loss: 1.1915e-06 - dense_7_loss: 3.9877e-07 - dense_8_loss: 8.8570e-07 - dense_9_loss: 7.2148e-07 - dense_10_loss: 6.8390e-07 - dense_11_loss: 8.2868e-07 - dense_12_loss: 6.9433e-07 - val_loss: 6.8395e-06 - val_dense_5_loss: 4.0034e-07 - val_dense_6_loss: 1.5515e-06 - val_dense_7_loss: 3.8679e-07 - val_dense_8_loss: 1.0115e-06 - val_dense_9_loss: 7.6916e-07 - val_dense_10_loss: 9.6596e-07 - val_dense_11_loss: 8.7663e-07 - val_dense_12_loss: 8.7750e-07\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.5702e-06 - dense_5_loss: 3.2765e-07 - dense_6_loss: 1.2511e-06 - dense_7_loss: 3.6163e-07 - dense_8_loss: 8.5827e-07 - dense_9_loss: 6.8313e-07 - dense_10_loss: 6.5360e-07 - dense_11_loss: 7.8420e-07 - dense_12_loss: 6.5066e-07 - val_loss: 5.0758e-06 - val_dense_5_loss: 3.4283e-07 - val_dense_6_loss: 1.0395e-06 - val_dense_7_loss: 3.9793e-07 - val_dense_8_loss: 7.1407e-07 - val_dense_9_loss: 7.0068e-07 - val_dense_10_loss: 5.3418e-07 - val_dense_11_loss: 7.7744e-07 - val_dense_12_loss: 5.6915e-07\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.9601e-06 - dense_5_loss: 3.9032e-07 - dense_6_loss: 1.2156e-06 - dense_7_loss: 4.2814e-07 - dense_8_loss: 8.8753e-07 - dense_9_loss: 7.4926e-07 - dense_10_loss: 7.1357e-07 - dense_11_loss: 8.4761e-07 - dense_12_loss: 7.2807e-07 - val_loss: 4.6045e-06 - val_dense_5_loss: 2.8129e-07 - val_dense_6_loss: 9.3612e-07 - val_dense_7_loss: 3.1458e-07 - val_dense_8_loss: 6.4569e-07 - val_dense_9_loss: 6.6320e-07 - val_dense_10_loss: 4.8870e-07 - val_dense_11_loss: 7.1075e-07 - val_dense_12_loss: 5.6419e-07\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.3224e-06 - dense_5_loss: 3.5775e-07 - dense_6_loss: 1.0689e-06 - dense_7_loss: 3.8487e-07 - dense_8_loss: 7.7114e-07 - dense_9_loss: 7.0095e-07 - dense_10_loss: 6.0299e-07 - dense_11_loss: 8.0354e-07 - dense_12_loss: 6.3236e-07 - val_loss: 6.1697e-06 - val_dense_5_loss: 4.4353e-07 - val_dense_6_loss: 1.0513e-06 - val_dense_7_loss: 4.9859e-07 - val_dense_8_loss: 9.0889e-07 - val_dense_9_loss: 8.7338e-07 - val_dense_10_loss: 6.8881e-07 - val_dense_11_loss: 9.2234e-07 - val_dense_12_loss: 7.8278e-07\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.2318e-06 - dense_5_loss: 3.4504e-07 - dense_6_loss: 1.0543e-06 - dense_7_loss: 3.8327e-07 - dense_8_loss: 7.6418e-07 - dense_9_loss: 7.0603e-07 - dense_10_loss: 5.6990e-07 - dense_11_loss: 7.9622e-07 - dense_12_loss: 6.1290e-07 - val_loss: 5.1692e-06 - val_dense_5_loss: 3.7365e-07 - val_dense_6_loss: 9.5347e-07 - val_dense_7_loss: 4.3145e-07 - val_dense_8_loss: 7.4074e-07 - val_dense_9_loss: 7.5036e-07 - val_dense_10_loss: 5.0855e-07 - val_dense_11_loss: 7.4258e-07 - val_dense_12_loss: 6.6838e-07\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8881e-06 - dense_5_loss: 2.9390e-07 - dense_6_loss: 1.0172e-06 - dense_7_loss: 3.4637e-07 - dense_8_loss: 7.1798e-07 - dense_9_loss: 6.5200e-07 - dense_10_loss: 5.3592e-07 - dense_11_loss: 7.5561e-07 - dense_12_loss: 5.6914e-07 - val_loss: 4.7171e-06 - val_dense_5_loss: 2.6580e-07 - val_dense_6_loss: 1.0020e-06 - val_dense_7_loss: 3.0612e-07 - val_dense_8_loss: 6.9527e-07 - val_dense_9_loss: 6.5401e-07 - val_dense_10_loss: 5.1495e-07 - val_dense_11_loss: 7.5961e-07 - val_dense_12_loss: 5.1938e-07\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.1908e-06 - dense_5_loss: 3.2953e-07 - dense_6_loss: 1.0585e-06 - dense_7_loss: 3.7705e-07 - dense_8_loss: 7.6073e-07 - dense_9_loss: 6.8610e-07 - dense_10_loss: 5.7702e-07 - dense_11_loss: 7.8931e-07 - dense_12_loss: 6.1258e-07 - val_loss: 5.0347e-06 - val_dense_5_loss: 3.6807e-07 - val_dense_6_loss: 9.2579e-07 - val_dense_7_loss: 4.0420e-07 - val_dense_8_loss: 6.9833e-07 - val_dense_9_loss: 7.5783e-07 - val_dense_10_loss: 5.2759e-07 - val_dense_11_loss: 7.7958e-07 - val_dense_12_loss: 5.7332e-07\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.0398e-06 - dense_5_loss: 3.1407e-07 - dense_6_loss: 1.0613e-06 - dense_7_loss: 3.6150e-07 - dense_8_loss: 7.4217e-07 - dense_9_loss: 6.5342e-07 - dense_10_loss: 5.5725e-07 - dense_11_loss: 7.6667e-07 - dense_12_loss: 5.8341e-07 - val_loss: 4.9682e-06 - val_dense_5_loss: 3.1850e-07 - val_dense_6_loss: 9.3714e-07 - val_dense_7_loss: 4.0052e-07 - val_dense_8_loss: 6.9273e-07 - val_dense_9_loss: 7.5094e-07 - val_dense_10_loss: 5.1198e-07 - val_dense_11_loss: 7.7246e-07 - val_dense_12_loss: 5.8395e-07\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7674e-06 - dense_5_loss: 3.0507e-07 - dense_6_loss: 9.6180e-07 - dense_7_loss: 3.4640e-07 - dense_8_loss: 6.8226e-07 - dense_9_loss: 6.4503e-07 - dense_10_loss: 5.1575e-07 - dense_11_loss: 7.5411e-07 - dense_12_loss: 5.5701e-07 - val_loss: 5.6380e-06 - val_dense_5_loss: 4.3663e-07 - val_dense_6_loss: 1.0575e-06 - val_dense_7_loss: 3.9186e-07 - val_dense_8_loss: 8.2874e-07 - val_dense_9_loss: 8.0778e-07 - val_dense_10_loss: 6.0991e-07 - val_dense_11_loss: 8.1960e-07 - val_dense_12_loss: 6.8595e-07\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.1600e-06 - dense_5_loss: 3.3321e-07 - dense_6_loss: 1.0445e-06 - dense_7_loss: 3.6744e-07 - dense_8_loss: 7.4409e-07 - dense_9_loss: 6.9562e-07 - dense_10_loss: 5.7363e-07 - dense_11_loss: 7.9332e-07 - dense_12_loss: 6.0821e-07 - val_loss: 4.6329e-06 - val_dense_5_loss: 2.9795e-07 - val_dense_6_loss: 8.9111e-07 - val_dense_7_loss: 3.7043e-07 - val_dense_8_loss: 6.2214e-07 - val_dense_9_loss: 6.8778e-07 - val_dense_10_loss: 5.0323e-07 - val_dense_11_loss: 7.4895e-07 - val_dense_12_loss: 5.1130e-07\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.0722e-06 - dense_5_loss: 3.3472e-07 - dense_6_loss: 9.9621e-07 - dense_7_loss: 3.7530e-07 - dense_8_loss: 7.1719e-07 - dense_9_loss: 6.9131e-07 - dense_10_loss: 5.6748e-07 - dense_11_loss: 7.9035e-07 - dense_12_loss: 5.9965e-07 - val_loss: 4.7395e-06 - val_dense_5_loss: 2.8175e-07 - val_dense_6_loss: 9.6793e-07 - val_dense_7_loss: 3.6863e-07 - val_dense_8_loss: 6.8542e-07 - val_dense_9_loss: 6.8308e-07 - val_dense_10_loss: 4.6951e-07 - val_dense_11_loss: 7.3981e-07 - val_dense_12_loss: 5.4337e-07\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 5.3389e-06 - dense_5_loss: 3.4197e-07 - dense_6_loss: 1.0972e-06 - dense_7_loss: 3.8045e-07 - dense_8_loss: 7.7063e-07 - dense_9_loss: 7.0019e-07 - dense_10_loss: 6.1635e-07 - dense_11_loss: 7.9531e-07 - dense_12_loss: 6.3683e-07 - val_loss: 5.2299e-06 - val_dense_5_loss: 3.0569e-07 - val_dense_6_loss: 1.2510e-06 - val_dense_7_loss: 3.1420e-07 - val_dense_8_loss: 6.8849e-07 - val_dense_9_loss: 7.4736e-07 - val_dense_10_loss: 5.7643e-07 - val_dense_11_loss: 7.4187e-07 - val_dense_12_loss: 6.0486e-07\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.6971e-06 - dense_5_loss: 3.0133e-07 - dense_6_loss: 9.3425e-07 - dense_7_loss: 3.4025e-07 - dense_8_loss: 6.4200e-07 - dense_9_loss: 6.6906e-07 - dense_10_loss: 5.0009e-07 - dense_11_loss: 7.6812e-07 - dense_12_loss: 5.4203e-07 - val_loss: 4.7552e-06 - val_dense_5_loss: 3.0199e-07 - val_dense_6_loss: 9.7839e-07 - val_dense_7_loss: 3.3835e-07 - val_dense_8_loss: 6.6227e-07 - val_dense_9_loss: 6.9366e-07 - val_dense_10_loss: 4.7949e-07 - val_dense_11_loss: 7.6423e-07 - val_dense_12_loss: 5.3685e-07\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 4.9114e-06 - dense_5_loss: 3.2160e-07 - dense_6_loss: 9.8253e-07 - dense_7_loss: 3.5374e-07 - dense_8_loss: 6.8895e-07 - dense_9_loss: 6.8304e-07 - dense_10_loss: 5.3168e-07 - dense_11_loss: 7.8191e-07 - dense_12_loss: 5.6792e-07 - val_loss: 4.8079e-06 - val_dense_5_loss: 3.5085e-07 - val_dense_6_loss: 8.4584e-07 - val_dense_7_loss: 3.5908e-07 - val_dense_8_loss: 6.1950e-07 - val_dense_9_loss: 7.5333e-07 - val_dense_10_loss: 5.3916e-07 - val_dense_11_loss: 7.7302e-07 - val_dense_12_loss: 5.6714e-07\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5.0558e-06 - dense_5_loss: 3.4336e-07 - dense_6_loss: 1.0033e-06 - dense_7_loss: 3.7944e-07 - dense_8_loss: 6.9140e-07 - dense_9_loss: 6.8559e-07 - dense_10_loss: 5.6628e-07 - dense_11_loss: 7.9162e-07 - dense_12_loss: 5.9473e-07 - val_loss: 5.6355e-06 - val_dense_5_loss: 3.8815e-07 - val_dense_6_loss: 9.6869e-07 - val_dense_7_loss: 5.6136e-07 - val_dense_8_loss: 7.8813e-07 - val_dense_9_loss: 7.9073e-07 - val_dense_10_loss: 5.9824e-07 - val_dense_11_loss: 8.7100e-07 - val_dense_12_loss: 6.6922e-07\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.0162e-06 - dense_5_loss: 3.2877e-07 - dense_6_loss: 9.7953e-07 - dense_7_loss: 3.8282e-07 - dense_8_loss: 7.0213e-07 - dense_9_loss: 6.8972e-07 - dense_10_loss: 5.5162e-07 - dense_11_loss: 7.8688e-07 - dense_12_loss: 5.9469e-07 - val_loss: 6.0205e-06 - val_dense_5_loss: 5.0350e-07 - val_dense_6_loss: 1.0084e-06 - val_dense_7_loss: 4.7039e-07 - val_dense_8_loss: 7.7079e-07 - val_dense_9_loss: 8.4638e-07 - val_dense_10_loss: 6.4618e-07 - val_dense_11_loss: 9.9045e-07 - val_dense_12_loss: 7.8440e-07\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.3534e-06 - dense_5_loss: 4.5004e-07 - dense_6_loss: 1.2762e-06 - dense_7_loss: 4.6364e-07 - dense_8_loss: 9.2561e-07 - dense_9_loss: 8.0727e-07 - dense_10_loss: 7.2429e-07 - dense_11_loss: 9.2412e-07 - dense_12_loss: 7.8220e-07 - val_loss: 4.5508e-06 - val_dense_5_loss: 2.8545e-07 - val_dense_6_loss: 8.7435e-07 - val_dense_7_loss: 3.5439e-07 - val_dense_8_loss: 6.2398e-07 - val_dense_9_loss: 7.0344e-07 - val_dense_10_loss: 4.7903e-07 - val_dense_11_loss: 7.1720e-07 - val_dense_12_loss: 5.1295e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "\n",
      "Now training model 2/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 2s 23ms/step - loss: 0.0018 - dense_18_loss: 6.2903e-04 - dense_19_loss: 6.3618e-04 - dense_20_loss: 4.9426e-04 - val_loss: 2.9074e-04 - val_dense_18_loss: 9.4674e-05 - val_dense_19_loss: 8.6217e-05 - val_dense_20_loss: 1.0985e-04\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.1507e-04 - dense_18_loss: 8.2378e-05 - dense_19_loss: 4.9494e-05 - dense_20_loss: 8.3199e-05 - val_loss: 1.4800e-04 - val_dense_18_loss: 6.3690e-05 - val_dense_19_loss: 2.7554e-05 - val_dense_20_loss: 5.6757e-05\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.2623e-04 - dense_18_loss: 6.3138e-05 - dense_19_loss: 2.3982e-05 - dense_20_loss: 3.9113e-05 - val_loss: 8.3621e-05 - val_dense_18_loss: 5.1762e-05 - val_dense_19_loss: 1.4621e-05 - val_dense_20_loss: 1.7238e-05\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.8698e-05 - dense_18_loss: 4.7696e-05 - dense_19_loss: 1.1676e-05 - dense_20_loss: 9.3266e-06 - val_loss: 4.9214e-05 - val_dense_18_loss: 3.6082e-05 - val_dense_19_loss: 8.2227e-06 - val_dense_20_loss: 4.9091e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 3.9630e-05 - dense_18_loss: 2.7543e-05 - dense_19_loss: 7.2934e-06 - dense_20_loss: 4.7941e-06 - val_loss: 2.6830e-05 - val_dense_18_loss: 1.5029e-05 - val_dense_19_loss: 6.8494e-06 - val_dense_20_loss: 4.9515e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.9374e-05 - dense_18_loss: 9.0505e-06 - dense_19_loss: 5.6701e-06 - dense_20_loss: 4.6531e-06 - val_loss: 1.4505e-05 - val_dense_18_loss: 5.9443e-06 - val_dense_19_loss: 4.9310e-06 - val_dense_20_loss: 3.6292e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2202e-05 - dense_18_loss: 4.7558e-06 - dense_19_loss: 4.0809e-06 - dense_20_loss: 3.3649e-06 - val_loss: 1.1227e-05 - val_dense_18_loss: 3.9574e-06 - val_dense_19_loss: 4.3827e-06 - val_dense_20_loss: 2.8863e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0189e-05 - dense_18_loss: 3.7167e-06 - dense_19_loss: 3.9187e-06 - dense_20_loss: 2.5540e-06 - val_loss: 9.9134e-06 - val_dense_18_loss: 3.2360e-06 - val_dense_19_loss: 4.3859e-06 - val_dense_20_loss: 2.2915e-06\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.8888e-06 - dense_18_loss: 3.0489e-06 - dense_19_loss: 3.8216e-06 - dense_20_loss: 2.0182e-06 - val_loss: 8.3909e-06 - val_dense_18_loss: 2.5824e-06 - val_dense_19_loss: 4.1487e-06 - val_dense_20_loss: 1.6597e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.6246e-06 - dense_18_loss: 2.3707e-06 - dense_19_loss: 3.6970e-06 - dense_20_loss: 1.5569e-06 - val_loss: 7.3169e-06 - val_dense_18_loss: 1.9797e-06 - val_dense_19_loss: 3.9917e-06 - val_dense_20_loss: 1.3455e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.4304e-06 - dense_18_loss: 1.7994e-06 - dense_19_loss: 3.4193e-06 - dense_20_loss: 1.2117e-06 - val_loss: 6.1772e-06 - val_dense_18_loss: 1.4440e-06 - val_dense_19_loss: 3.6720e-06 - val_dense_20_loss: 1.0611e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.4467e-06 - dense_18_loss: 1.3578e-06 - dense_19_loss: 3.1404e-06 - dense_20_loss: 9.4849e-07 - val_loss: 5.1710e-06 - val_dense_18_loss: 1.0304e-06 - val_dense_19_loss: 3.3522e-06 - val_dense_20_loss: 7.8836e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.6979e-06 - dense_18_loss: 1.0303e-06 - dense_19_loss: 2.8941e-06 - dense_20_loss: 7.7338e-07 - val_loss: 4.8495e-06 - val_dense_18_loss: 9.3719e-07 - val_dense_19_loss: 3.2334e-06 - val_dense_20_loss: 6.7893e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.1560e-06 - dense_18_loss: 8.6098e-07 - dense_19_loss: 2.6449e-06 - dense_20_loss: 6.5014e-07 - val_loss: 4.1313e-06 - val_dense_18_loss: 7.0315e-07 - val_dense_19_loss: 2.8360e-06 - val_dense_20_loss: 5.9213e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.6762e-06 - dense_18_loss: 7.4045e-07 - dense_19_loss: 2.3652e-06 - dense_20_loss: 5.7064e-07 - val_loss: 3.8117e-06 - val_dense_18_loss: 6.4241e-07 - val_dense_19_loss: 2.6417e-06 - val_dense_20_loss: 5.2750e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.3889e-06 - dense_18_loss: 6.7283e-07 - dense_19_loss: 2.1902e-06 - dense_20_loss: 5.2586e-07 - val_loss: 3.6182e-06 - val_dense_18_loss: 6.7529e-07 - val_dense_19_loss: 2.4285e-06 - val_dense_20_loss: 5.1443e-07\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 3.2319e-06 - dense_18_loss: 6.4468e-07 - dense_19_loss: 2.0551e-06 - dense_20_loss: 5.3208e-07 - val_loss: 3.3778e-06 - val_dense_18_loss: 5.9115e-07 - val_dense_19_loss: 2.2855e-06 - val_dense_20_loss: 5.0124e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.1055e-06 - dense_18_loss: 6.4288e-07 - dense_19_loss: 1.9444e-06 - dense_20_loss: 5.1821e-07 - val_loss: 3.8301e-06 - val_dense_18_loss: 6.4189e-07 - val_dense_19_loss: 2.6110e-06 - val_dense_20_loss: 5.7727e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.0192e-06 - dense_18_loss: 6.2229e-07 - dense_19_loss: 1.8363e-06 - dense_20_loss: 5.6061e-07 - val_loss: 3.5532e-06 - val_dense_18_loss: 8.7980e-07 - val_dense_19_loss: 2.0615e-06 - val_dense_20_loss: 6.1191e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.8264e-06 - dense_18_loss: 6.7746e-07 - dense_19_loss: 1.6285e-06 - dense_20_loss: 5.2045e-07 - val_loss: 2.8643e-06 - val_dense_18_loss: 5.6455e-07 - val_dense_19_loss: 1.8040e-06 - val_dense_20_loss: 4.9579e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.4995e-06 - dense_18_loss: 5.6705e-07 - dense_19_loss: 1.4409e-06 - dense_20_loss: 4.9150e-07 - val_loss: 2.9616e-06 - val_dense_18_loss: 6.2947e-07 - val_dense_19_loss: 1.7106e-06 - val_dense_20_loss: 6.2153e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.4996e-06 - dense_18_loss: 5.8650e-07 - dense_19_loss: 1.3714e-06 - dense_20_loss: 5.4171e-07 - val_loss: 2.8067e-06 - val_dense_18_loss: 6.9790e-07 - val_dense_19_loss: 1.5598e-06 - val_dense_20_loss: 5.4893e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.3141e-06 - dense_18_loss: 6.0721e-07 - dense_19_loss: 1.2174e-06 - dense_20_loss: 4.8944e-07 - val_loss: 2.4518e-06 - val_dense_18_loss: 5.6839e-07 - val_dense_19_loss: 1.3491e-06 - val_dense_20_loss: 5.3433e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.0173e-06 - dense_18_loss: 5.1024e-07 - dense_19_loss: 1.0582e-06 - dense_20_loss: 4.4885e-07 - val_loss: 2.4879e-06 - val_dense_18_loss: 7.3573e-07 - val_dense_19_loss: 1.2538e-06 - val_dense_20_loss: 4.9834e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.9640e-06 - dense_18_loss: 5.4159e-07 - dense_19_loss: 9.5897e-07 - dense_20_loss: 4.6345e-07 - val_loss: 2.0456e-06 - val_dense_18_loss: 5.0297e-07 - val_dense_19_loss: 1.0946e-06 - val_dense_20_loss: 4.4800e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8451e-06 - dense_18_loss: 5.2066e-07 - dense_19_loss: 8.8982e-07 - dense_20_loss: 4.3467e-07 - val_loss: 2.2134e-06 - val_dense_18_loss: 6.9266e-07 - val_dense_19_loss: 1.0443e-06 - val_dense_20_loss: 4.7646e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.9708e-06 - dense_18_loss: 6.3922e-07 - dense_19_loss: 8.6316e-07 - dense_20_loss: 4.6845e-07 - val_loss: 2.0077e-06 - val_dense_18_loss: 6.8553e-07 - val_dense_19_loss: 9.0086e-07 - val_dense_20_loss: 4.2135e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7597e-06 - dense_18_loss: 5.5856e-07 - dense_19_loss: 7.9340e-07 - dense_20_loss: 4.0779e-07 - val_loss: 2.1386e-06 - val_dense_18_loss: 7.5034e-07 - val_dense_19_loss: 8.8442e-07 - val_dense_20_loss: 5.0380e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6637e-06 - dense_18_loss: 5.2954e-07 - dense_19_loss: 7.4589e-07 - dense_20_loss: 3.8823e-07 - val_loss: 1.7904e-06 - val_dense_18_loss: 4.7617e-07 - val_dense_19_loss: 9.1125e-07 - val_dense_20_loss: 4.0297e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.5762e-06 - dense_18_loss: 4.7667e-07 - dense_19_loss: 7.2144e-07 - dense_20_loss: 3.7812e-07 - val_loss: 1.6141e-06 - val_dense_18_loss: 4.5726e-07 - val_dense_19_loss: 7.9064e-07 - val_dense_20_loss: 3.6616e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3633e-06 - dense_18_loss: 4.3454e-07 - dense_19_loss: 6.0916e-07 - dense_20_loss: 3.1958e-07 - val_loss: 1.6913e-06 - val_dense_18_loss: 6.2688e-07 - val_dense_19_loss: 7.3680e-07 - val_dense_20_loss: 3.2761e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4043e-06 - dense_18_loss: 5.0903e-07 - dense_19_loss: 5.9507e-07 - dense_20_loss: 3.0018e-07 - val_loss: 1.4061e-06 - val_dense_18_loss: 4.1803e-07 - val_dense_19_loss: 6.7493e-07 - val_dense_20_loss: 3.1312e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4415e-06 - dense_18_loss: 5.2457e-07 - dense_19_loss: 6.2163e-07 - dense_20_loss: 2.9532e-07 - val_loss: 1.4511e-06 - val_dense_18_loss: 4.3376e-07 - val_dense_19_loss: 6.8053e-07 - val_dense_20_loss: 3.3685e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2978e-06 - dense_18_loss: 4.3341e-07 - dense_19_loss: 5.8175e-07 - dense_20_loss: 2.8269e-07 - val_loss: 1.3378e-06 - val_dense_18_loss: 4.4064e-07 - val_dense_19_loss: 6.0892e-07 - val_dense_20_loss: 2.8825e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2645e-06 - dense_18_loss: 4.5533e-07 - dense_19_loss: 5.5380e-07 - dense_20_loss: 2.5542e-07 - val_loss: 1.6350e-06 - val_dense_18_loss: 7.3687e-07 - val_dense_19_loss: 6.2075e-07 - val_dense_20_loss: 2.7739e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1997e-06 - dense_18_loss: 4.3004e-07 - dense_19_loss: 5.2593e-07 - dense_20_loss: 2.4374e-07 - val_loss: 1.2566e-06 - val_dense_18_loss: 3.7066e-07 - val_dense_19_loss: 5.8693e-07 - val_dense_20_loss: 2.9903e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1066e-06 - dense_18_loss: 3.7372e-07 - dense_19_loss: 4.9487e-07 - dense_20_loss: 2.3804e-07 - val_loss: 1.3856e-06 - val_dense_18_loss: 4.9397e-07 - val_dense_19_loss: 6.2923e-07 - val_dense_20_loss: 2.6239e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3790e-06 - dense_18_loss: 5.7338e-07 - dense_19_loss: 5.6811e-07 - dense_20_loss: 2.3751e-07 - val_loss: 2.1288e-06 - val_dense_18_loss: 8.1179e-07 - val_dense_19_loss: 1.0506e-06 - val_dense_20_loss: 2.6634e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6474e-06 - dense_18_loss: 7.2842e-07 - dense_19_loss: 6.6449e-07 - dense_20_loss: 2.5453e-07 - val_loss: 1.2373e-06 - val_dense_18_loss: 3.9727e-07 - val_dense_19_loss: 5.7878e-07 - val_dense_20_loss: 2.6122e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1616e-06 - dense_18_loss: 3.9049e-07 - dense_19_loss: 5.4705e-07 - dense_20_loss: 2.2409e-07 - val_loss: 1.3250e-06 - val_dense_18_loss: 5.2514e-07 - val_dense_19_loss: 5.3141e-07 - val_dense_20_loss: 2.6849e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0857e-06 - dense_18_loss: 3.8465e-07 - dense_19_loss: 4.6148e-07 - dense_20_loss: 2.3954e-07 - val_loss: 1.2895e-06 - val_dense_18_loss: 4.2177e-07 - val_dense_19_loss: 6.1996e-07 - val_dense_20_loss: 2.4775e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0814e-06 - dense_18_loss: 3.9782e-07 - dense_19_loss: 4.7484e-07 - dense_20_loss: 2.0878e-07 - val_loss: 1.1179e-06 - val_dense_18_loss: 3.4206e-07 - val_dense_19_loss: 5.4396e-07 - val_dense_20_loss: 2.3193e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0466e-06 - dense_18_loss: 3.9218e-07 - dense_19_loss: 4.4562e-07 - dense_20_loss: 2.0881e-07 - val_loss: 1.1885e-06 - val_dense_18_loss: 4.4207e-07 - val_dense_19_loss: 5.0608e-07 - val_dense_20_loss: 2.4039e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0132e-06 - dense_18_loss: 3.5013e-07 - dense_19_loss: 4.5643e-07 - dense_20_loss: 2.0665e-07 - val_loss: 1.4799e-06 - val_dense_18_loss: 5.4891e-07 - val_dense_19_loss: 6.8970e-07 - val_dense_20_loss: 2.4129e-07\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3093e-06 - dense_18_loss: 4.8440e-07 - dense_19_loss: 5.9847e-07 - dense_20_loss: 2.2643e-07 - val_loss: 1.1275e-06 - val_dense_18_loss: 3.8415e-07 - val_dense_19_loss: 5.0962e-07 - val_dense_20_loss: 2.3369e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3026e-06 - dense_18_loss: 4.9216e-07 - dense_19_loss: 5.9026e-07 - dense_20_loss: 2.2016e-07 - val_loss: 1.3193e-06 - val_dense_18_loss: 4.2879e-07 - val_dense_19_loss: 6.0770e-07 - val_dense_20_loss: 2.8284e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1266e-06 - dense_18_loss: 4.3580e-07 - dense_19_loss: 4.6605e-07 - dense_20_loss: 2.2473e-07 - val_loss: 1.2005e-06 - val_dense_18_loss: 4.2554e-07 - val_dense_19_loss: 5.4634e-07 - val_dense_20_loss: 2.2865e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.8940e-07 - dense_18_loss: 3.4895e-07 - dense_19_loss: 4.4862e-07 - dense_20_loss: 1.9183e-07 - val_loss: 1.1362e-06 - val_dense_18_loss: 3.8235e-07 - val_dense_19_loss: 5.3304e-07 - val_dense_20_loss: 2.2081e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1262e-06 - dense_18_loss: 3.8362e-07 - dense_19_loss: 5.1431e-07 - dense_20_loss: 2.2828e-07 - val_loss: 1.3684e-06 - val_dense_18_loss: 5.4227e-07 - val_dense_19_loss: 5.3536e-07 - val_dense_20_loss: 2.9078e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0642e-06 - dense_18_loss: 4.3787e-07 - dense_19_loss: 4.2943e-07 - dense_20_loss: 1.9687e-07 - val_loss: 9.9224e-07 - val_dense_18_loss: 3.3230e-07 - val_dense_19_loss: 4.5660e-07 - val_dense_20_loss: 2.0334e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.7817e-07 - dense_18_loss: 3.6736e-07 - dense_19_loss: 4.1573e-07 - dense_20_loss: 1.9508e-07 - val_loss: 1.7893e-06 - val_dense_18_loss: 6.0923e-07 - val_dense_19_loss: 8.7628e-07 - val_dense_20_loss: 3.0378e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1095e-06 - dense_18_loss: 3.7741e-07 - dense_19_loss: 4.6709e-07 - dense_20_loss: 2.6499e-07 - val_loss: 1.0326e-06 - val_dense_18_loss: 3.7442e-07 - val_dense_19_loss: 4.4705e-07 - val_dense_20_loss: 2.1111e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0847e-06 - dense_18_loss: 4.6671e-07 - dense_19_loss: 4.3551e-07 - dense_20_loss: 1.8247e-07 - val_loss: 1.0863e-06 - val_dense_18_loss: 4.5080e-07 - val_dense_19_loss: 4.4346e-07 - val_dense_20_loss: 1.9208e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.8965e-07 - dense_18_loss: 3.5208e-07 - dense_19_loss: 3.7632e-07 - dense_20_loss: 1.6124e-07 - val_loss: 1.1293e-06 - val_dense_18_loss: 4.0380e-07 - val_dense_19_loss: 5.0655e-07 - val_dense_20_loss: 2.1896e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.2765e-07 - dense_18_loss: 3.3722e-07 - dense_19_loss: 4.1698e-07 - dense_20_loss: 1.7345e-07 - val_loss: 9.4297e-07 - val_dense_18_loss: 3.0999e-07 - val_dense_19_loss: 4.2814e-07 - val_dense_20_loss: 2.0483e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.1179e-07 - dense_18_loss: 3.6444e-07 - dense_19_loss: 3.8420e-07 - dense_20_loss: 1.6315e-07 - val_loss: 1.1418e-06 - val_dense_18_loss: 4.7817e-07 - val_dense_19_loss: 4.8407e-07 - val_dense_20_loss: 1.7959e-07\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5014e-07 - dense_18_loss: 3.7441e-07 - dense_19_loss: 4.1797e-07 - dense_20_loss: 1.5776e-07 - val_loss: 1.1797e-06 - val_dense_18_loss: 4.0581e-07 - val_dense_19_loss: 5.0075e-07 - val_dense_20_loss: 2.7313e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1710e-06 - dense_18_loss: 4.2720e-07 - dense_19_loss: 4.8848e-07 - dense_20_loss: 2.5527e-07 - val_loss: 1.1693e-06 - val_dense_18_loss: 4.7242e-07 - val_dense_19_loss: 4.4706e-07 - val_dense_20_loss: 2.4984e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6018e-07 - dense_18_loss: 3.8117e-07 - dense_19_loss: 4.0406e-07 - dense_20_loss: 1.7495e-07 - val_loss: 1.0734e-06 - val_dense_18_loss: 3.7580e-07 - val_dense_19_loss: 4.5284e-07 - val_dense_20_loss: 2.4473e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0026e-06 - dense_18_loss: 4.4983e-07 - dense_19_loss: 3.8985e-07 - dense_20_loss: 1.6296e-07 - val_loss: 1.0651e-06 - val_dense_18_loss: 3.9085e-07 - val_dense_19_loss: 4.4389e-07 - val_dense_20_loss: 2.3039e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.0053e-06 - dense_18_loss: 3.9243e-07 - dense_19_loss: 4.2769e-07 - dense_20_loss: 1.8518e-07 - val_loss: 1.0255e-06 - val_dense_18_loss: 3.5030e-07 - val_dense_19_loss: 4.7349e-07 - val_dense_20_loss: 2.0176e-07\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1640e-06 - dense_18_loss: 4.6327e-07 - dense_19_loss: 5.0876e-07 - dense_20_loss: 1.9199e-07 - val_loss: 1.1616e-06 - val_dense_18_loss: 3.7108e-07 - val_dense_19_loss: 6.0735e-07 - val_dense_20_loss: 1.8318e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9523e-07 - dense_18_loss: 4.0140e-07 - dense_19_loss: 4.3878e-07 - dense_20_loss: 1.5504e-07 - val_loss: 1.0270e-06 - val_dense_18_loss: 3.4835e-07 - val_dense_19_loss: 5.0134e-07 - val_dense_20_loss: 1.7735e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1796e-06 - dense_18_loss: 4.1551e-07 - dense_19_loss: 5.7294e-07 - dense_20_loss: 1.9118e-07 - val_loss: 1.6866e-06 - val_dense_18_loss: 6.3157e-07 - val_dense_19_loss: 6.1556e-07 - val_dense_20_loss: 4.3950e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2048e-06 - dense_18_loss: 4.2121e-07 - dense_19_loss: 5.8737e-07 - dense_20_loss: 1.9621e-07 - val_loss: 9.8876e-07 - val_dense_18_loss: 3.5007e-07 - val_dense_19_loss: 4.5035e-07 - val_dense_20_loss: 1.8834e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3467e-07 - dense_18_loss: 3.4854e-07 - dense_19_loss: 3.8000e-07 - dense_20_loss: 2.0613e-07 - val_loss: 1.4273e-06 - val_dense_18_loss: 4.6120e-07 - val_dense_19_loss: 7.1490e-07 - val_dense_20_loss: 2.5121e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2201e-06 - dense_18_loss: 4.7499e-07 - dense_19_loss: 4.9938e-07 - dense_20_loss: 2.4577e-07 - val_loss: 1.5493e-06 - val_dense_18_loss: 4.4131e-07 - val_dense_19_loss: 8.2453e-07 - val_dense_20_loss: 2.8341e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1627e-06 - dense_18_loss: 4.2932e-07 - dense_19_loss: 5.3619e-07 - dense_20_loss: 1.9721e-07 - val_loss: 1.1057e-06 - val_dense_18_loss: 3.1979e-07 - val_dense_19_loss: 4.8942e-07 - val_dense_20_loss: 2.9645e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3197e-06 - dense_18_loss: 5.3981e-07 - dense_19_loss: 5.4846e-07 - dense_20_loss: 2.3147e-07 - val_loss: 3.6477e-06 - val_dense_18_loss: 1.3176e-06 - val_dense_19_loss: 1.9705e-06 - val_dense_20_loss: 3.5959e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3682e-06 - dense_18_loss: 4.9397e-07 - dense_19_loss: 6.4577e-07 - dense_20_loss: 2.2845e-07 - val_loss: 1.2010e-06 - val_dense_18_loss: 3.9852e-07 - val_dense_19_loss: 5.2542e-07 - val_dense_20_loss: 2.7704e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00070: early stopping\n",
      "\n",
      "Now training model 3/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 2s 22ms/step - loss: 0.0017 - dense_26_loss: 6.6023e-04 - dense_27_loss: 6.3977e-04 - dense_28_loss: 4.3442e-04 - val_loss: 1.6609e-04 - val_dense_26_loss: 3.2082e-05 - val_dense_27_loss: 6.4837e-05 - val_dense_28_loss: 6.9176e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1531e-04 - dense_26_loss: 2.6529e-05 - dense_27_loss: 3.6142e-05 - dense_28_loss: 5.2640e-05 - val_loss: 6.8903e-05 - val_dense_26_loss: 1.5531e-05 - val_dense_27_loss: 1.6853e-05 - val_dense_28_loss: 3.6518e-05\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 6ms/step - loss: 6.0207e-05 - dense_26_loss: 1.3976e-05 - dense_27_loss: 1.4646e-05 - dense_28_loss: 3.1585e-05 - val_loss: 4.8510e-05 - val_dense_26_loss: 1.0918e-05 - val_dense_27_loss: 1.1465e-05 - val_dense_28_loss: 2.6127e-05\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.4499e-05 - dense_26_loss: 1.1529e-05 - dense_27_loss: 1.1325e-05 - dense_28_loss: 2.1645e-05 - val_loss: 3.6479e-05 - val_dense_26_loss: 9.9048e-06 - val_dense_27_loss: 9.2293e-06 - val_dense_28_loss: 1.7345e-05\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.1152e-05 - dense_26_loss: 1.0099e-05 - dense_27_loss: 9.1527e-06 - dense_28_loss: 1.1900e-05 - val_loss: 2.1331e-05 - val_dense_26_loss: 8.0073e-06 - val_dense_27_loss: 6.8067e-06 - val_dense_28_loss: 6.5172e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8415e-05 - dense_26_loss: 7.6330e-06 - dense_27_loss: 6.8997e-06 - dense_28_loss: 3.8825e-06 - val_loss: 1.2664e-05 - val_dense_26_loss: 5.6626e-06 - val_dense_27_loss: 5.1444e-06 - val_dense_28_loss: 1.8567e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2693e-05 - dense_26_loss: 5.5723e-06 - dense_27_loss: 5.5395e-06 - dense_28_loss: 1.5816e-06 - val_loss: 9.8578e-06 - val_dense_26_loss: 4.3123e-06 - val_dense_27_loss: 4.2978e-06 - val_dense_28_loss: 1.2477e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0669e-05 - dense_26_loss: 4.6077e-06 - dense_27_loss: 4.8043e-06 - dense_28_loss: 1.2571e-06 - val_loss: 8.6970e-06 - val_dense_26_loss: 3.6887e-06 - val_dense_27_loss: 3.8545e-06 - val_dense_28_loss: 1.1538e-06\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.5576e-06 - dense_26_loss: 4.0148e-06 - dense_27_loss: 4.3081e-06 - dense_28_loss: 1.2346e-06 - val_loss: 7.7894e-06 - val_dense_26_loss: 3.1378e-06 - val_dense_27_loss: 3.4558e-06 - val_dense_28_loss: 1.1958e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.4320e-06 - dense_26_loss: 3.3942e-06 - dense_27_loss: 3.7814e-06 - dense_28_loss: 1.2564e-06 - val_loss: 6.7633e-06 - val_dense_26_loss: 2.6101e-06 - val_dense_27_loss: 3.0024e-06 - val_dense_28_loss: 1.1508e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1344e-06 - dense_26_loss: 2.7205e-06 - dense_27_loss: 3.1510e-06 - dense_28_loss: 1.2629e-06 - val_loss: 5.8283e-06 - val_dense_26_loss: 2.2036e-06 - val_dense_27_loss: 2.4397e-06 - val_dense_28_loss: 1.1849e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.8333e-06 - dense_26_loss: 2.1200e-06 - dense_27_loss: 2.5008e-06 - dense_28_loss: 1.2124e-06 - val_loss: 4.7562e-06 - val_dense_26_loss: 1.6462e-06 - val_dense_27_loss: 1.9600e-06 - val_dense_28_loss: 1.1500e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.5950e-06 - dense_26_loss: 1.5989e-06 - dense_27_loss: 1.8891e-06 - dense_28_loss: 1.1071e-06 - val_loss: 3.6445e-06 - val_dense_26_loss: 1.2488e-06 - val_dense_27_loss: 1.4405e-06 - val_dense_28_loss: 9.5524e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.6861e-06 - dense_26_loss: 1.2488e-06 - dense_27_loss: 1.4428e-06 - dense_28_loss: 9.9453e-07 - val_loss: 3.1186e-06 - val_dense_26_loss: 1.0360e-06 - val_dense_27_loss: 1.1655e-06 - val_dense_28_loss: 9.1713e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.9577e-06 - dense_26_loss: 9.7670e-07 - dense_27_loss: 1.1174e-06 - dense_28_loss: 8.6357e-07 - val_loss: 2.5638e-06 - val_dense_26_loss: 8.5636e-07 - val_dense_27_loss: 9.3862e-07 - val_dense_28_loss: 7.6883e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.4321e-06 - dense_26_loss: 8.2596e-07 - dense_27_loss: 8.8025e-07 - dense_28_loss: 7.2586e-07 - val_loss: 2.1656e-06 - val_dense_26_loss: 7.4423e-07 - val_dense_27_loss: 7.5265e-07 - val_dense_28_loss: 6.6873e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.1157e-06 - dense_26_loss: 7.3029e-07 - dense_27_loss: 7.5027e-07 - dense_28_loss: 6.3516e-07 - val_loss: 2.0051e-06 - val_dense_26_loss: 6.6223e-07 - val_dense_27_loss: 7.1838e-07 - val_dense_28_loss: 6.2447e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8674e-06 - dense_26_loss: 6.5216e-07 - dense_27_loss: 6.6681e-07 - dense_28_loss: 5.4842e-07 - val_loss: 1.7788e-06 - val_dense_26_loss: 6.5997e-07 - val_dense_27_loss: 6.2958e-07 - val_dense_28_loss: 4.8920e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6697e-06 - dense_26_loss: 5.9605e-07 - dense_27_loss: 6.1586e-07 - dense_28_loss: 4.5776e-07 - val_loss: 1.6141e-06 - val_dense_26_loss: 5.7595e-07 - val_dense_27_loss: 6.0132e-07 - val_dense_28_loss: 4.3682e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5294e-06 - dense_26_loss: 5.4833e-07 - dense_27_loss: 5.7322e-07 - dense_28_loss: 4.0785e-07 - val_loss: 1.4627e-06 - val_dense_26_loss: 5.2542e-07 - val_dense_27_loss: 5.5114e-07 - val_dense_28_loss: 3.8614e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3829e-06 - dense_26_loss: 5.0271e-07 - dense_27_loss: 5.4258e-07 - dense_28_loss: 3.3757e-07 - val_loss: 1.3545e-06 - val_dense_26_loss: 5.2575e-07 - val_dense_27_loss: 5.1932e-07 - val_dense_28_loss: 3.0946e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2500e-06 - dense_26_loss: 4.6460e-07 - dense_27_loss: 5.0462e-07 - dense_28_loss: 2.8075e-07 - val_loss: 1.4492e-06 - val_dense_26_loss: 5.8379e-07 - val_dense_27_loss: 5.5893e-07 - val_dense_28_loss: 3.0643e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2231e-06 - dense_26_loss: 4.6902e-07 - dense_27_loss: 4.9431e-07 - dense_28_loss: 2.5978e-07 - val_loss: 1.0992e-06 - val_dense_26_loss: 4.1704e-07 - val_dense_27_loss: 4.6023e-07 - val_dense_28_loss: 2.2197e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0482e-06 - dense_26_loss: 4.0462e-07 - dense_27_loss: 4.4463e-07 - dense_28_loss: 1.9893e-07 - val_loss: 1.0462e-06 - val_dense_26_loss: 4.0554e-07 - val_dense_27_loss: 4.4700e-07 - val_dense_28_loss: 1.9364e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.9473e-07 - dense_26_loss: 3.8952e-07 - dense_27_loss: 4.2900e-07 - dense_28_loss: 1.7622e-07 - val_loss: 9.8547e-07 - val_dense_26_loss: 3.9521e-07 - val_dense_27_loss: 4.3013e-07 - val_dense_28_loss: 1.6013e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4913e-07 - dense_26_loss: 3.8037e-07 - dense_27_loss: 4.2063e-07 - dense_28_loss: 1.4814e-07 - val_loss: 9.4553e-07 - val_dense_26_loss: 3.7688e-07 - val_dense_27_loss: 4.2655e-07 - val_dense_28_loss: 1.4210e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6623e-07 - dense_26_loss: 3.5386e-07 - dense_27_loss: 3.8558e-07 - dense_28_loss: 1.2680e-07 - val_loss: 8.8578e-07 - val_dense_26_loss: 3.4754e-07 - val_dense_27_loss: 3.9097e-07 - val_dense_28_loss: 1.4727e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2005e-07 - dense_26_loss: 3.3864e-07 - dense_27_loss: 3.7087e-07 - dense_28_loss: 1.1054e-07 - val_loss: 8.5704e-07 - val_dense_26_loss: 3.5089e-07 - val_dense_27_loss: 3.8966e-07 - val_dense_28_loss: 1.1649e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.9840e-07 - dense_26_loss: 3.3573e-07 - dense_27_loss: 3.6196e-07 - dense_28_loss: 1.0071e-07 - val_loss: 8.2464e-07 - val_dense_26_loss: 3.2834e-07 - val_dense_27_loss: 3.6120e-07 - val_dense_28_loss: 1.3510e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.6254e-07 - dense_26_loss: 3.1708e-07 - dense_27_loss: 3.4886e-07 - dense_28_loss: 9.6602e-08 - val_loss: 8.4767e-07 - val_dense_26_loss: 3.5054e-07 - val_dense_27_loss: 3.7686e-07 - val_dense_28_loss: 1.2027e-07\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8852e-07 - dense_26_loss: 3.3302e-07 - dense_27_loss: 3.5990e-07 - dense_28_loss: 9.5604e-08 - val_loss: 1.0632e-06 - val_dense_26_loss: 4.2753e-07 - val_dense_27_loss: 4.6084e-07 - val_dense_28_loss: 1.7481e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.0468e-07 - dense_26_loss: 3.4048e-07 - dense_27_loss: 3.6642e-07 - dense_28_loss: 9.7778e-08 - val_loss: 7.4736e-07 - val_dense_26_loss: 3.0859e-07 - val_dense_27_loss: 3.4782e-07 - val_dense_28_loss: 9.0952e-08\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.1954e-07 - dense_26_loss: 3.0304e-07 - dense_27_loss: 3.3816e-07 - dense_28_loss: 7.8331e-08 - val_loss: 7.8122e-07 - val_dense_26_loss: 3.1426e-07 - val_dense_27_loss: 3.7085e-07 - val_dense_28_loss: 9.6115e-08\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1131e-07 - dense_26_loss: 3.0333e-07 - dense_27_loss: 3.3069e-07 - dense_28_loss: 7.7286e-08 - val_loss: 7.3583e-07 - val_dense_26_loss: 3.0722e-07 - val_dense_27_loss: 3.4468e-07 - val_dense_28_loss: 8.3927e-08\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9660e-07 - dense_26_loss: 3.0023e-07 - dense_27_loss: 3.2230e-07 - dense_28_loss: 7.4066e-08 - val_loss: 7.8108e-07 - val_dense_26_loss: 3.2691e-07 - val_dense_27_loss: 3.5305e-07 - val_dense_28_loss: 1.0112e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0052e-07 - dense_26_loss: 2.9843e-07 - dense_27_loss: 3.2782e-07 - dense_28_loss: 7.4264e-08 - val_loss: 7.5111e-07 - val_dense_26_loss: 3.2206e-07 - val_dense_27_loss: 3.5112e-07 - val_dense_28_loss: 7.7933e-08\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.9934e-07 - dense_26_loss: 3.0320e-07 - dense_27_loss: 3.2228e-07 - dense_28_loss: 7.3853e-08 - val_loss: 7.3145e-07 - val_dense_26_loss: 3.1048e-07 - val_dense_27_loss: 3.4450e-07 - val_dense_28_loss: 7.6466e-08\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.8228e-07 - dense_26_loss: 2.9311e-07 - dense_27_loss: 3.1773e-07 - dense_28_loss: 7.1434e-08 - val_loss: 7.1121e-07 - val_dense_26_loss: 2.9736e-07 - val_dense_27_loss: 3.4114e-07 - val_dense_28_loss: 7.2701e-08\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7560e-07 - dense_26_loss: 2.8788e-07 - dense_27_loss: 3.1954e-07 - dense_28_loss: 6.8182e-08 - val_loss: 6.7839e-07 - val_dense_26_loss: 2.8914e-07 - val_dense_27_loss: 3.2028e-07 - val_dense_28_loss: 6.8968e-08\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7160e-07 - dense_26_loss: 2.9083e-07 - dense_27_loss: 3.1438e-07 - dense_28_loss: 6.6389e-08 - val_loss: 7.1131e-07 - val_dense_26_loss: 3.0177e-07 - val_dense_27_loss: 3.3597e-07 - val_dense_28_loss: 7.3572e-08\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7531e-07 - dense_26_loss: 2.8637e-07 - dense_27_loss: 3.1673e-07 - dense_28_loss: 7.2203e-08 - val_loss: 6.8823e-07 - val_dense_26_loss: 2.8946e-07 - val_dense_27_loss: 3.2964e-07 - val_dense_28_loss: 6.9128e-08\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6384e-07 - dense_26_loss: 2.8555e-07 - dense_27_loss: 3.1277e-07 - dense_28_loss: 6.5512e-08 - val_loss: 7.1156e-07 - val_dense_26_loss: 2.8339e-07 - val_dense_27_loss: 3.4369e-07 - val_dense_28_loss: 8.4478e-08\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.7778e-07 - dense_26_loss: 2.8606e-07 - dense_27_loss: 3.1979e-07 - dense_28_loss: 7.1937e-08 - val_loss: 7.2220e-07 - val_dense_26_loss: 3.1360e-07 - val_dense_27_loss: 3.3143e-07 - val_dense_28_loss: 7.7173e-08\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.1018e-07 - dense_26_loss: 3.0405e-07 - dense_27_loss: 3.2694e-07 - dense_28_loss: 7.9188e-08 - val_loss: 7.5526e-07 - val_dense_26_loss: 3.1889e-07 - val_dense_27_loss: 3.5690e-07 - val_dense_28_loss: 7.9475e-08\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9824e-07 - dense_26_loss: 3.0144e-07 - dense_27_loss: 3.2754e-07 - dense_28_loss: 6.9268e-08 - val_loss: 8.2499e-07 - val_dense_26_loss: 3.3174e-07 - val_dense_27_loss: 3.6664e-07 - val_dense_28_loss: 1.2661e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2091e-07 - dense_26_loss: 3.0467e-07 - dense_27_loss: 3.3526e-07 - dense_28_loss: 8.0981e-08 - val_loss: 7.7023e-07 - val_dense_26_loss: 2.9825e-07 - val_dense_27_loss: 3.7209e-07 - val_dense_28_loss: 9.9882e-08\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8869e-07 - dense_26_loss: 2.9320e-07 - dense_27_loss: 3.1946e-07 - dense_28_loss: 7.6031e-08 - val_loss: 6.8877e-07 - val_dense_26_loss: 2.8293e-07 - val_dense_27_loss: 3.3194e-07 - val_dense_28_loss: 7.3911e-08\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7640e-07 - dense_26_loss: 2.8991e-07 - dense_27_loss: 3.1722e-07 - dense_28_loss: 6.9277e-08 - val_loss: 7.9475e-07 - val_dense_26_loss: 3.3094e-07 - val_dense_27_loss: 3.3550e-07 - val_dense_28_loss: 1.2831e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 7.0589e-07 - dense_26_loss: 3.0174e-07 - dense_27_loss: 3.2489e-07 - dense_28_loss: 7.9259e-08 - val_loss: 6.9018e-07 - val_dense_26_loss: 2.9293e-07 - val_dense_27_loss: 3.3408e-07 - val_dense_28_loss: 6.3170e-08\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6752e-07 - dense_26_loss: 2.8863e-07 - dense_27_loss: 3.1132e-07 - dense_28_loss: 6.7571e-08 - val_loss: 7.6072e-07 - val_dense_26_loss: 3.3399e-07 - val_dense_27_loss: 3.4233e-07 - val_dense_28_loss: 8.4399e-08\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8030e-07 - dense_26_loss: 2.9098e-07 - dense_27_loss: 3.1748e-07 - dense_28_loss: 7.1839e-08 - val_loss: 7.3027e-07 - val_dense_26_loss: 2.9232e-07 - val_dense_27_loss: 3.4718e-07 - val_dense_28_loss: 9.0775e-08\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6661e-07 - dense_26_loss: 2.8467e-07 - dense_27_loss: 3.1267e-07 - dense_28_loss: 6.9265e-08 - val_loss: 6.8919e-07 - val_dense_26_loss: 2.9732e-07 - val_dense_27_loss: 3.1666e-07 - val_dense_28_loss: 7.5211e-08\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "\n",
      "Now training model 4/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 2s 22ms/step - loss: 0.0022 - dense_34_loss: 9.1286e-04 - dense_35_loss: 7.4415e-04 - dense_36_loss: 5.0936e-04 - val_loss: 1.7013e-04 - val_dense_34_loss: 5.6854e-05 - val_dense_35_loss: 5.3160e-05 - val_dense_36_loss: 6.0116e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1275e-04 - dense_34_loss: 3.7679e-05 - dense_35_loss: 3.6580e-05 - dense_36_loss: 3.8488e-05 - val_loss: 7.3843e-05 - val_dense_34_loss: 2.1893e-05 - val_dense_35_loss: 2.5056e-05 - val_dense_36_loss: 2.6895e-05\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.9981e-05 - dense_34_loss: 1.9439e-05 - dense_35_loss: 1.9829e-05 - dense_36_loss: 2.0713e-05 - val_loss: 4.6587e-05 - val_dense_34_loss: 1.5215e-05 - val_dense_35_loss: 1.5777e-05 - val_dense_36_loss: 1.5596e-05\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 3.4037e-05 - dense_34_loss: 1.1494e-05 - dense_35_loss: 1.2000e-05 - dense_36_loss: 1.0543e-05 - val_loss: 1.9653e-05 - val_dense_34_loss: 6.8336e-06 - val_dense_35_loss: 6.8470e-06 - val_dense_36_loss: 5.9721e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0881e-05 - dense_34_loss: 3.9484e-06 - dense_35_loss: 3.6422e-06 - dense_36_loss: 3.2899e-06 - val_loss: 4.3162e-06 - val_dense_34_loss: 1.5942e-06 - val_dense_35_loss: 1.3252e-06 - val_dense_36_loss: 1.3968e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.8989e-06 - dense_34_loss: 1.0360e-06 - dense_35_loss: 8.9427e-07 - dense_36_loss: 9.6860e-07 - val_loss: 1.9446e-06 - val_dense_34_loss: 6.9790e-07 - val_dense_35_loss: 6.3155e-07 - val_dense_36_loss: 6.1510e-07\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8603e-06 - dense_34_loss: 6.5750e-07 - dense_35_loss: 5.9252e-07 - dense_36_loss: 6.1028e-07 - val_loss: 1.7845e-06 - val_dense_34_loss: 6.2748e-07 - val_dense_35_loss: 5.4817e-07 - val_dense_36_loss: 6.0886e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7540e-06 - dense_34_loss: 6.1260e-07 - dense_35_loss: 5.4992e-07 - dense_36_loss: 5.9147e-07 - val_loss: 1.7150e-06 - val_dense_34_loss: 6.1976e-07 - val_dense_35_loss: 5.5116e-07 - val_dense_36_loss: 5.4412e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7197e-06 - dense_34_loss: 6.0006e-07 - dense_35_loss: 5.4158e-07 - dense_36_loss: 5.7801e-07 - val_loss: 1.7169e-06 - val_dense_34_loss: 6.1178e-07 - val_dense_35_loss: 5.4353e-07 - val_dense_36_loss: 5.6163e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7289e-06 - dense_34_loss: 6.0200e-07 - dense_35_loss: 5.3985e-07 - dense_36_loss: 5.8710e-07 - val_loss: 1.6369e-06 - val_dense_34_loss: 5.8337e-07 - val_dense_35_loss: 5.1632e-07 - val_dense_36_loss: 5.3723e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6911e-06 - dense_34_loss: 5.8901e-07 - dense_35_loss: 5.2457e-07 - dense_36_loss: 5.7749e-07 - val_loss: 1.6659e-06 - val_dense_34_loss: 5.9640e-07 - val_dense_35_loss: 5.3502e-07 - val_dense_36_loss: 5.3445e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6961e-06 - dense_34_loss: 5.8575e-07 - dense_35_loss: 5.2668e-07 - dense_36_loss: 5.8367e-07 - val_loss: 1.6398e-06 - val_dense_34_loss: 5.8003e-07 - val_dense_35_loss: 5.1705e-07 - val_dense_36_loss: 5.4271e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.6868e-06 - dense_34_loss: 5.8291e-07 - dense_35_loss: 5.1897e-07 - dense_36_loss: 5.8490e-07 - val_loss: 1.6675e-06 - val_dense_34_loss: 5.8454e-07 - val_dense_35_loss: 5.3096e-07 - val_dense_36_loss: 5.5196e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6889e-06 - dense_34_loss: 5.8050e-07 - dense_35_loss: 5.1776e-07 - dense_36_loss: 5.9065e-07 - val_loss: 1.6378e-06 - val_dense_34_loss: 5.6864e-07 - val_dense_35_loss: 5.0991e-07 - val_dense_36_loss: 5.5920e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6909e-06 - dense_34_loss: 5.7764e-07 - dense_35_loss: 5.1653e-07 - dense_36_loss: 5.9669e-07 - val_loss: 1.6877e-06 - val_dense_34_loss: 5.9714e-07 - val_dense_35_loss: 5.3305e-07 - val_dense_36_loss: 5.5754e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.6863e-06 - dense_34_loss: 5.7410e-07 - dense_35_loss: 5.1513e-07 - dense_36_loss: 5.9708e-07 - val_loss: 1.6782e-06 - val_dense_34_loss: 5.8303e-07 - val_dense_35_loss: 5.3034e-07 - val_dense_36_loss: 5.6483e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6933e-06 - dense_34_loss: 5.7208e-07 - dense_35_loss: 5.1537e-07 - dense_36_loss: 6.0581e-07 - val_loss: 1.6538e-06 - val_dense_34_loss: 5.6822e-07 - val_dense_35_loss: 5.2056e-07 - val_dense_36_loss: 5.6503e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6942e-06 - dense_34_loss: 5.7519e-07 - dense_35_loss: 5.1131e-07 - dense_36_loss: 6.0775e-07 - val_loss: 1.6644e-06 - val_dense_34_loss: 5.8015e-07 - val_dense_35_loss: 5.3022e-07 - val_dense_36_loss: 5.5406e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6872e-06 - dense_34_loss: 5.6994e-07 - dense_35_loss: 5.0867e-07 - dense_36_loss: 6.0863e-07 - val_loss: 1.6001e-06 - val_dense_34_loss: 5.4830e-07 - val_dense_35_loss: 4.9471e-07 - val_dense_36_loss: 5.5711e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6614e-06 - dense_34_loss: 5.6127e-07 - dense_35_loss: 4.9800e-07 - dense_36_loss: 6.0215e-07 - val_loss: 1.7064e-06 - val_dense_34_loss: 5.9180e-07 - val_dense_35_loss: 5.3978e-07 - val_dense_36_loss: 5.7486e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7046e-06 - dense_34_loss: 5.7091e-07 - dense_35_loss: 5.0763e-07 - dense_36_loss: 6.2603e-07 - val_loss: 1.7242e-06 - val_dense_34_loss: 5.9194e-07 - val_dense_35_loss: 5.3997e-07 - val_dense_36_loss: 5.9229e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7034e-06 - dense_34_loss: 5.6624e-07 - dense_35_loss: 5.1016e-07 - dense_36_loss: 6.2705e-07 - val_loss: 1.6556e-06 - val_dense_34_loss: 5.5895e-07 - val_dense_35_loss: 5.1806e-07 - val_dense_36_loss: 5.7857e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6560e-06 - dense_34_loss: 5.5226e-07 - dense_35_loss: 4.9735e-07 - dense_36_loss: 6.0638e-07 - val_loss: 1.8123e-06 - val_dense_34_loss: 6.0949e-07 - val_dense_35_loss: 6.0951e-07 - val_dense_36_loss: 5.9327e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7240e-06 - dense_34_loss: 5.7573e-07 - dense_35_loss: 5.1793e-07 - dense_36_loss: 6.3032e-07 - val_loss: 1.7401e-06 - val_dense_34_loss: 6.3856e-07 - val_dense_35_loss: 5.3901e-07 - val_dense_36_loss: 5.6257e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7036e-06 - dense_34_loss: 5.6410e-07 - dense_35_loss: 5.0924e-07 - dense_36_loss: 6.3031e-07 - val_loss: 1.6616e-06 - val_dense_34_loss: 5.5841e-07 - val_dense_35_loss: 4.9471e-07 - val_dense_36_loss: 6.0852e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6587e-06 - dense_34_loss: 5.4936e-07 - dense_35_loss: 4.9065e-07 - dense_36_loss: 6.1865e-07 - val_loss: 1.7148e-06 - val_dense_34_loss: 6.0957e-07 - val_dense_35_loss: 5.1409e-07 - val_dense_36_loss: 5.9109e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.7012e-06 - dense_34_loss: 5.6114e-07 - dense_35_loss: 5.0729e-07 - dense_36_loss: 6.3274e-07 - val_loss: 1.7184e-06 - val_dense_34_loss: 6.0202e-07 - val_dense_35_loss: 5.3190e-07 - val_dense_36_loss: 5.8450e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.6821e-06 - dense_34_loss: 5.5382e-07 - dense_35_loss: 4.9600e-07 - dense_36_loss: 6.3231e-07 - val_loss: 1.6121e-06 - val_dense_34_loss: 5.3715e-07 - val_dense_35_loss: 4.8900e-07 - val_dense_36_loss: 5.8598e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6616e-06 - dense_34_loss: 5.4365e-07 - dense_35_loss: 4.8606e-07 - dense_36_loss: 6.3192e-07 - val_loss: 1.6476e-06 - val_dense_34_loss: 5.5241e-07 - val_dense_35_loss: 4.7778e-07 - val_dense_36_loss: 6.1741e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6596e-06 - dense_34_loss: 5.4463e-07 - dense_35_loss: 4.8142e-07 - dense_36_loss: 6.3358e-07 - val_loss: 1.7875e-06 - val_dense_34_loss: 5.9981e-07 - val_dense_35_loss: 5.4800e-07 - val_dense_36_loss: 6.3970e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "\n",
      "Now training model 5/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 2s 23ms/step - loss: 0.0018 - dense_42_loss: 7.5569e-04 - dense_43_loss: 6.6302e-04 - dense_44_loss: 4.2197e-04 - val_loss: 1.5291e-04 - val_dense_42_loss: 4.4423e-05 - val_dense_43_loss: 3.6964e-05 - val_dense_44_loss: 7.1518e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1276e-04 - dense_42_loss: 2.9913e-05 - dense_43_loss: 2.7398e-05 - dense_44_loss: 5.5450e-05 - val_loss: 7.2890e-05 - val_dense_42_loss: 1.5908e-05 - val_dense_43_loss: 1.6879e-05 - val_dense_44_loss: 4.0103e-05\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.3305e-05 - dense_42_loss: 1.2713e-05 - dense_43_loss: 1.2096e-05 - dense_44_loss: 2.8496e-05 - val_loss: 3.3127e-05 - val_dense_42_loss: 1.0587e-05 - val_dense_43_loss: 8.1622e-06 - val_dense_44_loss: 1.4378e-05\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.8179e-05 - dense_42_loss: 7.0121e-06 - dense_43_loss: 5.1143e-06 - dense_44_loss: 6.0525e-06 - val_loss: 7.6170e-06 - val_dense_42_loss: 3.4342e-06 - val_dense_43_loss: 2.4701e-06 - val_dense_44_loss: 1.7127e-06\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 6ms/step - loss: 4.5163e-06 - dense_42_loss: 1.8928e-06 - dense_43_loss: 1.5561e-06 - dense_44_loss: 1.0673e-06 - val_loss: 2.3925e-06 - val_dense_42_loss: 8.7887e-07 - val_dense_43_loss: 9.2367e-07 - val_dense_44_loss: 5.8995e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.1203e-06 - dense_42_loss: 7.5253e-07 - dense_43_loss: 8.2135e-07 - dense_44_loss: 5.4646e-07 - val_loss: 1.8085e-06 - val_dense_42_loss: 6.4177e-07 - val_dense_43_loss: 7.2534e-07 - val_dense_44_loss: 4.4142e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.9140e-06 - dense_42_loss: 6.7638e-07 - dense_43_loss: 7.4031e-07 - dense_44_loss: 4.9732e-07 - val_loss: 1.7505e-06 - val_dense_42_loss: 6.2342e-07 - val_dense_43_loss: 6.8999e-07 - val_dense_44_loss: 4.3713e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8710e-06 - dense_42_loss: 6.6075e-07 - dense_43_loss: 7.2400e-07 - dense_44_loss: 4.8629e-07 - val_loss: 1.7685e-06 - val_dense_42_loss: 6.2508e-07 - val_dense_43_loss: 6.9309e-07 - val_dense_44_loss: 4.5036e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8566e-06 - dense_42_loss: 6.5497e-07 - dense_43_loss: 7.1501e-07 - dense_44_loss: 4.8662e-07 - val_loss: 1.7575e-06 - val_dense_42_loss: 6.1001e-07 - val_dense_43_loss: 6.8852e-07 - val_dense_44_loss: 4.5901e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8664e-06 - dense_42_loss: 6.5696e-07 - dense_43_loss: 7.1840e-07 - dense_44_loss: 4.9104e-07 - val_loss: 1.7364e-06 - val_dense_42_loss: 6.1619e-07 - val_dense_43_loss: 6.8241e-07 - val_dense_44_loss: 4.3775e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8572e-06 - dense_42_loss: 6.5524e-07 - dense_43_loss: 7.1548e-07 - dense_44_loss: 4.8650e-07 - val_loss: 1.7342e-06 - val_dense_42_loss: 6.1670e-07 - val_dense_43_loss: 6.8535e-07 - val_dense_44_loss: 4.3212e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8522e-06 - dense_42_loss: 6.5094e-07 - dense_43_loss: 7.1734e-07 - dense_44_loss: 4.8395e-07 - val_loss: 1.7834e-06 - val_dense_42_loss: 6.2373e-07 - val_dense_43_loss: 6.9424e-07 - val_dense_44_loss: 4.6540e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8639e-06 - dense_42_loss: 6.5543e-07 - dense_43_loss: 7.1918e-07 - dense_44_loss: 4.8930e-07 - val_loss: 1.7802e-06 - val_dense_42_loss: 6.0991e-07 - val_dense_43_loss: 6.7791e-07 - val_dense_44_loss: 4.9233e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8554e-06 - dense_42_loss: 6.4992e-07 - dense_43_loss: 7.1576e-07 - dense_44_loss: 4.8969e-07 - val_loss: 1.7726e-06 - val_dense_42_loss: 6.4180e-07 - val_dense_43_loss: 6.9206e-07 - val_dense_44_loss: 4.3874e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8438e-06 - dense_42_loss: 6.5254e-07 - dense_43_loss: 7.0970e-07 - dense_44_loss: 4.8160e-07 - val_loss: 1.8683e-06 - val_dense_42_loss: 6.3150e-07 - val_dense_43_loss: 6.9882e-07 - val_dense_44_loss: 5.3795e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8622e-06 - dense_42_loss: 6.5389e-07 - dense_43_loss: 7.1348e-07 - dense_44_loss: 4.9483e-07 - val_loss: 1.7584e-06 - val_dense_42_loss: 6.2504e-07 - val_dense_43_loss: 6.8818e-07 - val_dense_44_loss: 4.4521e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8556e-06 - dense_42_loss: 6.5490e-07 - dense_43_loss: 7.1495e-07 - dense_44_loss: 4.8577e-07 - val_loss: 1.7275e-06 - val_dense_42_loss: 6.1112e-07 - val_dense_43_loss: 6.7718e-07 - val_dense_44_loss: 4.3924e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8592e-06 - dense_42_loss: 6.5692e-07 - dense_43_loss: 7.0997e-07 - dense_44_loss: 4.9227e-07 - val_loss: 1.7278e-06 - val_dense_42_loss: 6.2386e-07 - val_dense_43_loss: 6.7365e-07 - val_dense_44_loss: 4.3025e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8465e-06 - dense_42_loss: 6.5317e-07 - dense_43_loss: 7.0749e-07 - dense_44_loss: 4.8589e-07 - val_loss: 1.7746e-06 - val_dense_42_loss: 6.1985e-07 - val_dense_43_loss: 6.8035e-07 - val_dense_44_loss: 4.7436e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8335e-06 - dense_42_loss: 6.4677e-07 - dense_43_loss: 7.0913e-07 - dense_44_loss: 4.7757e-07 - val_loss: 1.7575e-06 - val_dense_42_loss: 6.3203e-07 - val_dense_43_loss: 6.8958e-07 - val_dense_44_loss: 4.3586e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8458e-06 - dense_42_loss: 6.5402e-07 - dense_43_loss: 7.0618e-07 - dense_44_loss: 4.8563e-07 - val_loss: 1.7505e-06 - val_dense_42_loss: 6.0612e-07 - val_dense_43_loss: 6.7865e-07 - val_dense_44_loss: 4.6572e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8176e-06 - dense_42_loss: 6.4009e-07 - dense_43_loss: 6.9776e-07 - dense_44_loss: 4.7976e-07 - val_loss: 1.7398e-06 - val_dense_42_loss: 6.0361e-07 - val_dense_43_loss: 6.6745e-07 - val_dense_44_loss: 4.6872e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8463e-06 - dense_42_loss: 6.4349e-07 - dense_43_loss: 7.0807e-07 - dense_44_loss: 4.9471e-07 - val_loss: 1.8315e-06 - val_dense_42_loss: 6.6329e-07 - val_dense_43_loss: 7.1153e-07 - val_dense_44_loss: 4.5669e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.9141e-06 - dense_42_loss: 6.7142e-07 - dense_43_loss: 7.2409e-07 - dense_44_loss: 5.1858e-07 - val_loss: 1.9267e-06 - val_dense_42_loss: 7.2313e-07 - val_dense_43_loss: 7.5486e-07 - val_dense_44_loss: 4.4868e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.9147e-06 - dense_42_loss: 6.7721e-07 - dense_43_loss: 7.2915e-07 - dense_44_loss: 5.0830e-07 - val_loss: 1.8003e-06 - val_dense_42_loss: 6.3192e-07 - val_dense_43_loss: 7.1576e-07 - val_dense_44_loss: 4.5263e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8839e-06 - dense_42_loss: 6.6098e-07 - dense_43_loss: 7.1784e-07 - dense_44_loss: 5.0508e-07 - val_loss: 1.7954e-06 - val_dense_42_loss: 6.3532e-07 - val_dense_43_loss: 6.7533e-07 - val_dense_44_loss: 4.8477e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Now training model 6/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 19ms/step - loss: 8.4580e-04 - dense_50_loss: 5.1345e-04 - dense_51_loss: 3.3235e-04 - val_loss: 5.6871e-05 - val_dense_50_loss: 2.4650e-05 - val_dense_51_loss: 3.2221e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.8642e-05 - dense_50_loss: 2.0047e-05 - dense_51_loss: 1.8595e-05 - val_loss: 1.4803e-05 - val_dense_50_loss: 9.7223e-06 - val_dense_51_loss: 5.0803e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2045e-05 - dense_50_loss: 9.2999e-06 - dense_51_loss: 2.7449e-06 - val_loss: 7.9901e-06 - val_dense_50_loss: 6.5382e-06 - val_dense_51_loss: 1.4520e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2921e-06 - dense_50_loss: 8.1378e-06 - dense_51_loss: 1.1543e-06 - val_loss: 7.4023e-06 - val_dense_50_loss: 6.5107e-06 - val_dense_51_loss: 8.9158e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.9059e-06 - dense_50_loss: 7.9216e-06 - dense_51_loss: 9.8428e-07 - val_loss: 6.6775e-06 - val_dense_50_loss: 5.8120e-06 - val_dense_51_loss: 8.6543e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3226e-06 - dense_50_loss: 7.3935e-06 - dense_51_loss: 9.2902e-07 - val_loss: 6.7076e-06 - val_dense_50_loss: 5.8244e-06 - val_dense_51_loss: 8.8313e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9776e-06 - dense_50_loss: 7.0352e-06 - dense_51_loss: 9.4235e-07 - val_loss: 5.9797e-06 - val_dense_50_loss: 5.1269e-06 - val_dense_51_loss: 8.5284e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4105e-06 - dense_50_loss: 6.4340e-06 - dense_51_loss: 9.7646e-07 - val_loss: 5.6579e-06 - val_dense_50_loss: 4.7655e-06 - val_dense_51_loss: 8.9239e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7905e-06 - dense_50_loss: 5.7084e-06 - dense_51_loss: 1.0820e-06 - val_loss: 4.9458e-06 - val_dense_50_loss: 3.9733e-06 - val_dense_51_loss: 9.7259e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.8226e-06 - dense_50_loss: 4.6536e-06 - dense_51_loss: 1.1690e-06 - val_loss: 3.9921e-06 - val_dense_50_loss: 2.9746e-06 - val_dense_51_loss: 1.0174e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.6063e-06 - dense_50_loss: 3.3544e-06 - dense_51_loss: 1.2520e-06 - val_loss: 3.0414e-06 - val_dense_50_loss: 2.0428e-06 - val_dense_51_loss: 9.9858e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.1041e-06 - dense_50_loss: 2.0176e-06 - dense_51_loss: 1.0865e-06 - val_loss: 2.1223e-06 - val_dense_50_loss: 1.2614e-06 - val_dense_51_loss: 8.6090e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.9667e-06 - dense_50_loss: 1.1183e-06 - dense_51_loss: 8.4844e-07 - val_loss: 1.3903e-06 - val_dense_50_loss: 6.9977e-07 - val_dense_51_loss: 6.9049e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3182e-06 - dense_50_loss: 6.6628e-07 - dense_51_loss: 6.5195e-07 - val_loss: 1.0915e-06 - val_dense_50_loss: 5.1138e-07 - val_dense_51_loss: 5.8014e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0275e-06 - dense_50_loss: 4.9530e-07 - dense_51_loss: 5.3222e-07 - val_loss: 9.3343e-07 - val_dense_50_loss: 4.2552e-07 - val_dense_51_loss: 5.0791e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0834e-07 - dense_50_loss: 4.2576e-07 - dense_51_loss: 4.8258e-07 - val_loss: 8.9654e-07 - val_dense_50_loss: 4.0301e-07 - val_dense_51_loss: 4.9353e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.8558e-07 - dense_50_loss: 4.1134e-07 - dense_51_loss: 4.7424e-07 - val_loss: 9.4802e-07 - val_dense_50_loss: 4.6120e-07 - val_dense_51_loss: 4.8682e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.6458e-07 - dense_50_loss: 4.0854e-07 - dense_51_loss: 4.5604e-07 - val_loss: 8.8116e-07 - val_dense_50_loss: 3.9801e-07 - val_dense_51_loss: 4.8314e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.5558e-07 - dense_50_loss: 4.0488e-07 - dense_51_loss: 4.5070e-07 - val_loss: 8.7796e-07 - val_dense_50_loss: 3.8704e-07 - val_dense_51_loss: 4.9093e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3472e-07 - dense_50_loss: 3.9095e-07 - dense_51_loss: 4.4377e-07 - val_loss: 8.8678e-07 - val_dense_50_loss: 3.9223e-07 - val_dense_51_loss: 4.9455e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3142e-07 - dense_50_loss: 3.9102e-07 - dense_51_loss: 4.4041e-07 - val_loss: 8.7653e-07 - val_dense_50_loss: 4.0500e-07 - val_dense_51_loss: 4.7152e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3429e-07 - dense_50_loss: 3.9418e-07 - dense_51_loss: 4.4012e-07 - val_loss: 8.2941e-07 - val_dense_50_loss: 3.7359e-07 - val_dense_51_loss: 4.5583e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2648e-07 - dense_50_loss: 3.9204e-07 - dense_51_loss: 4.3444e-07 - val_loss: 9.3796e-07 - val_dense_50_loss: 4.8225e-07 - val_dense_51_loss: 4.5571e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7164e-07 - dense_50_loss: 4.2409e-07 - dense_51_loss: 4.4754e-07 - val_loss: 8.3222e-07 - val_dense_50_loss: 3.7940e-07 - val_dense_51_loss: 4.5283e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0199e-07 - dense_50_loss: 3.7975e-07 - dense_51_loss: 4.2224e-07 - val_loss: 8.2870e-07 - val_dense_50_loss: 3.8347e-07 - val_dense_51_loss: 4.4523e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0553e-07 - dense_50_loss: 3.8545e-07 - dense_51_loss: 4.2008e-07 - val_loss: 8.0595e-07 - val_dense_50_loss: 3.7076e-07 - val_dense_51_loss: 4.3519e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1179e-07 - dense_50_loss: 4.0121e-07 - dense_51_loss: 4.1058e-07 - val_loss: 8.1735e-07 - val_dense_50_loss: 3.7850e-07 - val_dense_51_loss: 4.3885e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2144e-07 - dense_50_loss: 4.0285e-07 - dense_51_loss: 4.1858e-07 - val_loss: 8.4231e-07 - val_dense_50_loss: 4.0574e-07 - val_dense_51_loss: 4.3657e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0563e-07 - dense_50_loss: 3.9856e-07 - dense_51_loss: 4.0707e-07 - val_loss: 8.4300e-07 - val_dense_50_loss: 3.6850e-07 - val_dense_51_loss: 4.7449e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9295e-07 - dense_50_loss: 3.8642e-07 - dense_51_loss: 4.0653e-07 - val_loss: 7.9939e-07 - val_dense_50_loss: 3.8058e-07 - val_dense_51_loss: 4.1881e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9087e-07 - dense_50_loss: 3.9295e-07 - dense_51_loss: 3.9792e-07 - val_loss: 8.0378e-07 - val_dense_50_loss: 3.6068e-07 - val_dense_51_loss: 4.4310e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7617e-07 - dense_50_loss: 3.7945e-07 - dense_51_loss: 3.9672e-07 - val_loss: 9.2158e-07 - val_dense_50_loss: 4.4742e-07 - val_dense_51_loss: 4.7416e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1390e-07 - dense_50_loss: 4.0752e-07 - dense_51_loss: 4.0638e-07 - val_loss: 8.3857e-07 - val_dense_50_loss: 4.1433e-07 - val_dense_51_loss: 4.2423e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6040e-07 - dense_50_loss: 3.8047e-07 - dense_51_loss: 3.7993e-07 - val_loss: 8.6280e-07 - val_dense_50_loss: 4.4589e-07 - val_dense_51_loss: 4.1692e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2297e-07 - dense_50_loss: 4.2593e-07 - dense_51_loss: 3.9704e-07 - val_loss: 9.6911e-07 - val_dense_50_loss: 5.4828e-07 - val_dense_51_loss: 4.2083e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8525e-07 - dense_50_loss: 5.1473e-07 - dense_51_loss: 3.7051e-07 - val_loss: 9.2235e-07 - val_dense_50_loss: 5.3193e-07 - val_dense_51_loss: 3.9041e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4904e-07 - dense_50_loss: 3.8737e-07 - dense_51_loss: 3.6166e-07 - val_loss: 8.5895e-07 - val_dense_50_loss: 4.4057e-07 - val_dense_51_loss: 4.1838e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7526e-07 - dense_50_loss: 3.9681e-07 - dense_51_loss: 3.7845e-07 - val_loss: 7.3951e-07 - val_dense_50_loss: 3.5426e-07 - val_dense_51_loss: 3.8525e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2619e-07 - dense_50_loss: 3.6165e-07 - dense_51_loss: 3.6453e-07 - val_loss: 7.5208e-07 - val_dense_50_loss: 3.6763e-07 - val_dense_51_loss: 3.8445e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1805e-07 - dense_50_loss: 3.6804e-07 - dense_51_loss: 3.5001e-07 - val_loss: 7.2956e-07 - val_dense_50_loss: 3.5307e-07 - val_dense_51_loss: 3.7649e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3974e-07 - dense_50_loss: 3.8638e-07 - dense_51_loss: 3.5336e-07 - val_loss: 7.6743e-07 - val_dense_50_loss: 3.9557e-07 - val_dense_51_loss: 3.7186e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6007e-07 - dense_50_loss: 4.2670e-07 - dense_51_loss: 3.3337e-07 - val_loss: 7.9133e-07 - val_dense_50_loss: 3.8786e-07 - val_dense_51_loss: 4.0347e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "\n",
      "Now training model 7/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 20ms/step - loss: 0.0011 - dense_57_loss: 6.5350e-04 - dense_58_loss: 4.1295e-04 - val_loss: 5.9919e-05 - val_dense_57_loss: 2.6158e-05 - val_dense_58_loss: 3.3761e-05\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 6ms/step - loss: 3.8455e-05 - dense_57_loss: 1.9623e-05 - dense_58_loss: 1.8833e-05 - val_loss: 1.6276e-05 - val_dense_57_loss: 1.0741e-05 - val_dense_58_loss: 5.5352e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3110e-05 - dense_57_loss: 1.0606e-05 - dense_58_loss: 2.5045e-06 - val_loss: 7.8461e-06 - val_dense_57_loss: 6.8958e-06 - val_dense_58_loss: 9.5032e-07\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.8139e-06 - dense_57_loss: 8.9589e-06 - dense_58_loss: 8.5498e-07 - val_loss: 7.4061e-06 - val_dense_57_loss: 6.6749e-06 - val_dense_58_loss: 7.3116e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3414e-06 - dense_57_loss: 8.6073e-06 - dense_58_loss: 7.3409e-07 - val_loss: 7.1051e-06 - val_dense_57_loss: 6.4044e-06 - val_dense_58_loss: 7.0072e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.1441e-06 - dense_57_loss: 8.4057e-06 - dense_58_loss: 7.3843e-07 - val_loss: 7.0133e-06 - val_dense_57_loss: 6.2993e-06 - val_dense_58_loss: 7.1399e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.9871e-06 - dense_57_loss: 8.2005e-06 - dense_58_loss: 7.8658e-07 - val_loss: 6.8798e-06 - val_dense_57_loss: 6.0896e-06 - val_dense_58_loss: 7.9015e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7959e-06 - dense_57_loss: 7.8921e-06 - dense_58_loss: 9.0376e-07 - val_loss: 6.5603e-06 - val_dense_57_loss: 5.7406e-06 - val_dense_58_loss: 8.1964e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1259e-06 - dense_57_loss: 7.2008e-06 - dense_58_loss: 9.2508e-07 - val_loss: 6.1274e-06 - val_dense_57_loss: 5.2710e-06 - val_dense_58_loss: 8.5640e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3345e-06 - dense_57_loss: 6.3546e-06 - dense_58_loss: 9.7996e-07 - val_loss: 5.4737e-06 - val_dense_57_loss: 4.5665e-06 - val_dense_58_loss: 9.0718e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1212e-06 - dense_57_loss: 5.0615e-06 - dense_58_loss: 1.0597e-06 - val_loss: 4.2616e-06 - val_dense_57_loss: 3.2974e-06 - val_dense_58_loss: 9.6420e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.7171e-06 - dense_57_loss: 3.5562e-06 - dense_58_loss: 1.1609e-06 - val_loss: 3.0078e-06 - val_dense_57_loss: 1.9990e-06 - val_dense_58_loss: 1.0088e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.1233e-06 - dense_57_loss: 1.9677e-06 - dense_58_loss: 1.1555e-06 - val_loss: 2.0104e-06 - val_dense_57_loss: 1.0348e-06 - val_dense_58_loss: 9.7560e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.0143e-06 - dense_57_loss: 9.9608e-07 - dense_58_loss: 1.0182e-06 - val_loss: 1.4034e-06 - val_dense_57_loss: 6.0238e-07 - val_dense_58_loss: 8.0098e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3278e-06 - dense_57_loss: 5.4684e-07 - dense_58_loss: 7.8093e-07 - val_loss: 1.0469e-06 - val_dense_57_loss: 4.0373e-07 - val_dense_58_loss: 6.4322e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.8447e-07 - dense_57_loss: 3.8382e-07 - dense_58_loss: 6.0065e-07 - val_loss: 9.5571e-07 - val_dense_57_loss: 3.7587e-07 - val_dense_58_loss: 5.7984e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.4729e-07 - dense_57_loss: 3.4512e-07 - dense_58_loss: 5.0216e-07 - val_loss: 8.6178e-07 - val_dense_57_loss: 3.3752e-07 - val_dense_58_loss: 5.2426e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9871e-07 - dense_57_loss: 3.3723e-07 - dense_58_loss: 4.6148e-07 - val_loss: 8.3325e-07 - val_dense_57_loss: 3.4160e-07 - val_dense_58_loss: 4.9164e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8243e-07 - dense_57_loss: 3.3116e-07 - dense_58_loss: 4.5127e-07 - val_loss: 8.2110e-07 - val_dense_57_loss: 3.4166e-07 - val_dense_58_loss: 4.7945e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7631e-07 - dense_57_loss: 3.3134e-07 - dense_58_loss: 4.4497e-07 - val_loss: 8.1447e-07 - val_dense_57_loss: 3.3731e-07 - val_dense_58_loss: 4.7717e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6918e-07 - dense_57_loss: 3.3295e-07 - dense_58_loss: 4.3622e-07 - val_loss: 7.9211e-07 - val_dense_57_loss: 3.3089e-07 - val_dense_58_loss: 4.6122e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6316e-07 - dense_57_loss: 3.3012e-07 - dense_58_loss: 4.3303e-07 - val_loss: 8.3609e-07 - val_dense_57_loss: 3.5404e-07 - val_dense_58_loss: 4.8205e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7163e-07 - dense_57_loss: 3.3854e-07 - dense_58_loss: 4.3310e-07 - val_loss: 7.9937e-07 - val_dense_57_loss: 3.3531e-07 - val_dense_58_loss: 4.6406e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6930e-07 - dense_57_loss: 3.3781e-07 - dense_58_loss: 4.3149e-07 - val_loss: 7.9882e-07 - val_dense_57_loss: 3.3937e-07 - val_dense_58_loss: 4.5945e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5619e-07 - dense_57_loss: 3.2835e-07 - dense_58_loss: 4.2784e-07 - val_loss: 8.1441e-07 - val_dense_57_loss: 3.5798e-07 - val_dense_58_loss: 4.5643e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5915e-07 - dense_57_loss: 3.4269e-07 - dense_58_loss: 4.1647e-07 - val_loss: 8.2234e-07 - val_dense_57_loss: 3.5014e-07 - val_dense_58_loss: 4.7219e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6180e-07 - dense_57_loss: 3.3703e-07 - dense_58_loss: 4.2477e-07 - val_loss: 7.8253e-07 - val_dense_57_loss: 3.4273e-07 - val_dense_58_loss: 4.3980e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4899e-07 - dense_57_loss: 3.3457e-07 - dense_58_loss: 4.1441e-07 - val_loss: 7.8855e-07 - val_dense_57_loss: 3.4634e-07 - val_dense_58_loss: 4.4221e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5794e-07 - dense_57_loss: 3.3913e-07 - dense_58_loss: 4.1880e-07 - val_loss: 7.9059e-07 - val_dense_57_loss: 3.5073e-07 - val_dense_58_loss: 4.3986e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2996e-07 - dense_57_loss: 3.2775e-07 - dense_58_loss: 4.0221e-07 - val_loss: 8.0952e-07 - val_dense_57_loss: 3.5280e-07 - val_dense_58_loss: 4.5673e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3723e-07 - dense_57_loss: 3.4209e-07 - dense_58_loss: 3.9514e-07 - val_loss: 8.1256e-07 - val_dense_57_loss: 3.7995e-07 - val_dense_58_loss: 4.3262e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4756e-07 - dense_57_loss: 3.5196e-07 - dense_58_loss: 3.9559e-07 - val_loss: 9.5823e-07 - val_dense_57_loss: 5.3158e-07 - val_dense_58_loss: 4.2665e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0665e-07 - dense_57_loss: 4.1133e-07 - dense_58_loss: 3.9532e-07 - val_loss: 9.0621e-07 - val_dense_57_loss: 4.6737e-07 - val_dense_58_loss: 4.3884e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4341e-07 - dense_57_loss: 3.4987e-07 - dense_58_loss: 3.9354e-07 - val_loss: 7.8367e-07 - val_dense_57_loss: 3.3844e-07 - val_dense_58_loss: 4.4523e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1174e-07 - dense_57_loss: 3.2941e-07 - dense_58_loss: 3.8233e-07 - val_loss: 7.4553e-07 - val_dense_57_loss: 3.3355e-07 - val_dense_58_loss: 4.1199e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2637e-07 - dense_57_loss: 3.4238e-07 - dense_58_loss: 3.8398e-07 - val_loss: 7.3829e-07 - val_dense_57_loss: 3.3274e-07 - val_dense_58_loss: 4.0555e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1395e-07 - dense_57_loss: 3.3611e-07 - dense_58_loss: 3.7784e-07 - val_loss: 7.9320e-07 - val_dense_57_loss: 3.5497e-07 - val_dense_58_loss: 4.3822e-07\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2628e-07 - dense_57_loss: 3.3791e-07 - dense_58_loss: 3.8837e-07 - val_loss: 7.9924e-07 - val_dense_57_loss: 3.5138e-07 - val_dense_58_loss: 4.4786e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0910e-07 - dense_57_loss: 3.2759e-07 - dense_58_loss: 3.8151e-07 - val_loss: 8.4532e-07 - val_dense_57_loss: 4.3204e-07 - val_dense_58_loss: 4.1328e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4800e-07 - dense_57_loss: 3.8020e-07 - dense_58_loss: 3.6780e-07 - val_loss: 7.8381e-07 - val_dense_57_loss: 3.8375e-07 - val_dense_58_loss: 4.0006e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9522e-07 - dense_57_loss: 3.3178e-07 - dense_58_loss: 3.6344e-07 - val_loss: 7.5402e-07 - val_dense_57_loss: 3.5985e-07 - val_dense_58_loss: 3.9417e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1287e-07 - dense_57_loss: 3.3103e-07 - dense_58_loss: 3.8184e-07 - val_loss: 7.8413e-07 - val_dense_57_loss: 3.6153e-07 - val_dense_58_loss: 4.2260e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0224e-07 - dense_57_loss: 3.3036e-07 - dense_58_loss: 3.7188e-07 - val_loss: 7.7208e-07 - val_dense_57_loss: 3.2979e-07 - val_dense_58_loss: 4.4229e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9377e-07 - dense_57_loss: 3.2802e-07 - dense_58_loss: 3.6575e-07 - val_loss: 8.2071e-07 - val_dense_57_loss: 3.7793e-07 - val_dense_58_loss: 4.4277e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7061e-07 - dense_57_loss: 3.2005e-07 - dense_58_loss: 3.5056e-07 - val_loss: 7.5442e-07 - val_dense_57_loss: 3.6004e-07 - val_dense_58_loss: 3.9438e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9133e-07 - dense_57_loss: 3.5141e-07 - dense_58_loss: 3.3992e-07 - val_loss: 7.3347e-07 - val_dense_57_loss: 3.6634e-07 - val_dense_58_loss: 3.6713e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0291e-07 - dense_57_loss: 3.5862e-07 - dense_58_loss: 3.4429e-07 - val_loss: 8.2672e-07 - val_dense_57_loss: 4.1456e-07 - val_dense_58_loss: 4.1216e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1034e-07 - dense_57_loss: 3.6199e-07 - dense_58_loss: 3.4835e-07 - val_loss: 7.3689e-07 - val_dense_57_loss: 3.4936e-07 - val_dense_58_loss: 3.8753e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6316e-07 - dense_57_loss: 3.2325e-07 - dense_58_loss: 3.3991e-07 - val_loss: 6.8956e-07 - val_dense_57_loss: 3.2446e-07 - val_dense_58_loss: 3.6510e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3989e-07 - dense_57_loss: 3.1150e-07 - dense_58_loss: 3.2840e-07 - val_loss: 7.0388e-07 - val_dense_57_loss: 3.3067e-07 - val_dense_58_loss: 3.7321e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6228e-07 - dense_57_loss: 3.2431e-07 - dense_58_loss: 3.3797e-07 - val_loss: 6.5455e-07 - val_dense_57_loss: 3.0522e-07 - val_dense_58_loss: 3.4934e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3581e-07 - dense_57_loss: 3.2441e-07 - dense_58_loss: 3.1140e-07 - val_loss: 7.7765e-07 - val_dense_57_loss: 4.0837e-07 - val_dense_58_loss: 3.6928e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3625e-07 - dense_57_loss: 3.2034e-07 - dense_58_loss: 3.1590e-07 - val_loss: 7.8115e-07 - val_dense_57_loss: 3.6928e-07 - val_dense_58_loss: 4.1188e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5003e-07 - dense_57_loss: 3.3159e-07 - dense_58_loss: 3.1844e-07 - val_loss: 8.0007e-07 - val_dense_57_loss: 4.5037e-07 - val_dense_58_loss: 3.4970e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8724e-07 - dense_57_loss: 3.7771e-07 - dense_58_loss: 3.0954e-07 - val_loss: 7.2537e-07 - val_dense_57_loss: 3.5845e-07 - val_dense_58_loss: 3.6692e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "\n",
      "Now training model 8/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 19ms/step - loss: 9.7901e-04 - dense_64_loss: 6.5727e-04 - dense_65_loss: 3.2175e-04 - val_loss: 7.0123e-05 - val_dense_64_loss: 4.7408e-05 - val_dense_65_loss: 2.2715e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.9245e-05 - dense_64_loss: 2.5669e-05 - dense_65_loss: 1.3576e-05 - val_loss: 1.5096e-05 - val_dense_64_loss: 1.0586e-05 - val_dense_65_loss: 4.5096e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1307e-05 - dense_64_loss: 8.8546e-06 - dense_65_loss: 2.4528e-06 - val_loss: 6.8401e-06 - val_dense_64_loss: 5.8741e-06 - val_dense_65_loss: 9.6602e-07\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0470e-06 - dense_64_loss: 7.1374e-06 - dense_65_loss: 9.0962e-07 - val_loss: 6.2256e-06 - val_dense_64_loss: 5.4575e-06 - val_dense_65_loss: 7.6813e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6014e-06 - dense_64_loss: 6.8818e-06 - dense_65_loss: 7.1956e-07 - val_loss: 5.9798e-06 - val_dense_64_loss: 5.2998e-06 - val_dense_65_loss: 6.8001e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.3852e-06 - dense_64_loss: 6.7211e-06 - dense_65_loss: 6.6415e-07 - val_loss: 5.9065e-06 - val_dense_64_loss: 5.2436e-06 - val_dense_65_loss: 6.6290e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3886e-06 - dense_64_loss: 6.6956e-06 - dense_65_loss: 6.9300e-07 - val_loss: 5.7406e-06 - val_dense_64_loss: 5.0700e-06 - val_dense_65_loss: 6.7055e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1879e-06 - dense_64_loss: 6.4851e-06 - dense_65_loss: 7.0278e-07 - val_loss: 5.6071e-06 - val_dense_64_loss: 4.9412e-06 - val_dense_65_loss: 6.6584e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9323e-06 - dense_64_loss: 6.2589e-06 - dense_65_loss: 6.7347e-07 - val_loss: 5.4778e-06 - val_dense_64_loss: 4.7570e-06 - val_dense_65_loss: 7.2079e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7429e-06 - dense_64_loss: 6.0158e-06 - dense_65_loss: 7.2708e-07 - val_loss: 5.1617e-06 - val_dense_64_loss: 4.4555e-06 - val_dense_65_loss: 7.0621e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3060e-06 - dense_64_loss: 5.5522e-06 - dense_65_loss: 7.5385e-07 - val_loss: 4.8770e-06 - val_dense_64_loss: 4.1361e-06 - val_dense_65_loss: 7.4091e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.7668e-06 - dense_64_loss: 4.9779e-06 - dense_65_loss: 7.8882e-07 - val_loss: 4.6986e-06 - val_dense_64_loss: 3.8353e-06 - val_dense_65_loss: 8.6324e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0596e-06 - dense_64_loss: 4.1426e-06 - dense_65_loss: 9.1693e-07 - val_loss: 3.6830e-06 - val_dense_64_loss: 2.8184e-06 - val_dense_65_loss: 8.6461e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.9536e-06 - dense_64_loss: 2.9761e-06 - dense_65_loss: 9.7753e-07 - val_loss: 2.8106e-06 - val_dense_64_loss: 1.8945e-06 - val_dense_65_loss: 9.1617e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.9162e-06 - dense_64_loss: 1.8890e-06 - dense_65_loss: 1.0272e-06 - val_loss: 2.1930e-06 - val_dense_64_loss: 1.2529e-06 - val_dense_65_loss: 9.4004e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.2305e-06 - dense_64_loss: 1.2243e-06 - dense_65_loss: 1.0062e-06 - val_loss: 1.6839e-06 - val_dense_64_loss: 8.3414e-07 - val_dense_65_loss: 8.4976e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6242e-06 - dense_64_loss: 7.9929e-07 - dense_65_loss: 8.2496e-07 - val_loss: 1.4597e-06 - val_dense_64_loss: 7.4721e-07 - val_dense_65_loss: 7.1253e-07\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3066e-06 - dense_64_loss: 6.3370e-07 - dense_65_loss: 6.7286e-07 - val_loss: 1.1551e-06 - val_dense_64_loss: 5.4017e-07 - val_dense_65_loss: 6.1491e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0860e-06 - dense_64_loss: 5.1351e-07 - dense_65_loss: 5.7250e-07 - val_loss: 1.0516e-06 - val_dense_64_loss: 4.9989e-07 - val_dense_65_loss: 5.5174e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0054e-06 - dense_64_loss: 4.8791e-07 - dense_65_loss: 5.1748e-07 - val_loss: 1.0017e-06 - val_dense_64_loss: 4.7189e-07 - val_dense_65_loss: 5.2984e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5692e-07 - dense_64_loss: 4.5824e-07 - dense_65_loss: 4.9868e-07 - val_loss: 1.0581e-06 - val_dense_64_loss: 5.4062e-07 - val_dense_65_loss: 5.1753e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4519e-07 - dense_64_loss: 4.6563e-07 - dense_65_loss: 4.7956e-07 - val_loss: 1.0220e-06 - val_dense_64_loss: 4.8910e-07 - val_dense_65_loss: 5.3286e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4452e-07 - dense_64_loss: 4.5274e-07 - dense_65_loss: 4.9179e-07 - val_loss: 9.7487e-07 - val_dense_64_loss: 4.8408e-07 - val_dense_65_loss: 4.9079e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8607e-07 - dense_64_loss: 4.3265e-07 - dense_65_loss: 4.5342e-07 - val_loss: 9.8802e-07 - val_dense_64_loss: 4.6662e-07 - val_dense_65_loss: 5.2140e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3872e-07 - dense_64_loss: 4.6511e-07 - dense_65_loss: 4.7361e-07 - val_loss: 9.8022e-07 - val_dense_64_loss: 4.8779e-07 - val_dense_65_loss: 4.9244e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0615e-07 - dense_64_loss: 4.6244e-07 - dense_65_loss: 4.4371e-07 - val_loss: 9.2468e-07 - val_dense_64_loss: 4.5217e-07 - val_dense_65_loss: 4.7251e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0260e-07 - dense_64_loss: 4.6571e-07 - dense_65_loss: 4.3690e-07 - val_loss: 1.0878e-06 - val_dense_64_loss: 6.1930e-07 - val_dense_65_loss: 4.6848e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0538e-07 - dense_64_loss: 4.7029e-07 - dense_65_loss: 4.3509e-07 - val_loss: 9.6403e-07 - val_dense_64_loss: 4.4539e-07 - val_dense_65_loss: 5.1864e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.9139e-07 - dense_64_loss: 4.6080e-07 - dense_65_loss: 4.3059e-07 - val_loss: 9.0043e-07 - val_dense_64_loss: 4.5079e-07 - val_dense_65_loss: 4.4964e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.5742e-07 - dense_64_loss: 4.3405e-07 - dense_65_loss: 4.2337e-07 - val_loss: 9.2591e-07 - val_dense_64_loss: 4.7140e-07 - val_dense_65_loss: 4.5451e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6213e-07 - dense_64_loss: 4.3720e-07 - dense_65_loss: 4.2492e-07 - val_loss: 8.9855e-07 - val_dense_64_loss: 4.5841e-07 - val_dense_65_loss: 4.4014e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3982e-07 - dense_64_loss: 4.2917e-07 - dense_65_loss: 4.1065e-07 - val_loss: 9.3505e-07 - val_dense_64_loss: 4.8869e-07 - val_dense_65_loss: 4.4636e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.5528e-07 - dense_64_loss: 4.5251e-07 - dense_65_loss: 4.0278e-07 - val_loss: 9.5297e-07 - val_dense_64_loss: 5.0221e-07 - val_dense_65_loss: 4.5075e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6686e-07 - dense_64_loss: 4.6697e-07 - dense_65_loss: 3.9988e-07 - val_loss: 8.9492e-07 - val_dense_64_loss: 4.5303e-07 - val_dense_65_loss: 4.4189e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6014e-07 - dense_64_loss: 4.6722e-07 - dense_65_loss: 3.9291e-07 - val_loss: 1.2521e-06 - val_dense_64_loss: 8.1525e-07 - val_dense_65_loss: 4.3689e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6760e-07 - dense_64_loss: 4.7682e-07 - dense_65_loss: 3.9078e-07 - val_loss: 8.7556e-07 - val_dense_64_loss: 4.6476e-07 - val_dense_65_loss: 4.1080e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7762e-07 - dense_64_loss: 4.9486e-07 - dense_65_loss: 3.8276e-07 - val_loss: 8.7615e-07 - val_dense_64_loss: 4.3371e-07 - val_dense_65_loss: 4.4244e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.9348e-07 - dense_64_loss: 4.9180e-07 - dense_65_loss: 4.0168e-07 - val_loss: 8.7895e-07 - val_dense_64_loss: 4.7312e-07 - val_dense_65_loss: 4.0583e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2734e-07 - dense_64_loss: 5.5585e-07 - dense_65_loss: 3.7149e-07 - val_loss: 9.7521e-07 - val_dense_64_loss: 5.2095e-07 - val_dense_65_loss: 4.5426e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.5889e-07 - dense_64_loss: 4.7246e-07 - dense_65_loss: 3.8643e-07 - val_loss: 8.9217e-07 - val_dense_64_loss: 4.6028e-07 - val_dense_65_loss: 4.3188e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2075e-07 - dense_64_loss: 4.5441e-07 - dense_65_loss: 3.6635e-07 - val_loss: 8.3627e-07 - val_dense_64_loss: 4.4620e-07 - val_dense_65_loss: 3.9007e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0661e-07 - dense_64_loss: 5.2668e-07 - dense_65_loss: 3.7994e-07 - val_loss: 9.9673e-07 - val_dense_64_loss: 5.6955e-07 - val_dense_65_loss: 4.2718e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3654e-07 - dense_64_loss: 4.6531e-07 - dense_65_loss: 3.7124e-07 - val_loss: 9.0498e-07 - val_dense_64_loss: 5.0304e-07 - val_dense_65_loss: 4.0194e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1199e-07 - dense_64_loss: 4.4968e-07 - dense_65_loss: 3.6231e-07 - val_loss: 8.6232e-07 - val_dense_64_loss: 4.8540e-07 - val_dense_65_loss: 3.7691e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.9891e-07 - dense_64_loss: 4.5057e-07 - dense_65_loss: 3.4833e-07 - val_loss: 8.7973e-07 - val_dense_64_loss: 4.8257e-07 - val_dense_65_loss: 3.9716e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8218e-07 - dense_64_loss: 4.4234e-07 - dense_65_loss: 3.3985e-07 - val_loss: 8.4203e-07 - val_dense_64_loss: 4.5541e-07 - val_dense_65_loss: 3.8662e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "\n",
      "Now training model 9/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 2s 19ms/step - loss: 0.0012 - dense_71_loss: 7.3335e-04 - dense_72_loss: 4.2008e-04 - val_loss: 6.5051e-05 - val_dense_71_loss: 4.0953e-05 - val_dense_72_loss: 2.4098e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.2514e-05 - dense_71_loss: 1.8253e-05 - dense_72_loss: 1.4260e-05 - val_loss: 1.3797e-05 - val_dense_71_loss: 8.4144e-06 - val_dense_72_loss: 5.3824e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.9981e-06 - dense_71_loss: 7.7282e-06 - dense_72_loss: 2.2698e-06 - val_loss: 5.7735e-06 - val_dense_71_loss: 4.8454e-06 - val_dense_72_loss: 9.2810e-07\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9696e-06 - dense_71_loss: 6.0739e-06 - dense_72_loss: 8.9571e-07 - val_loss: 5.2532e-06 - val_dense_71_loss: 4.5164e-06 - val_dense_72_loss: 7.3671e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6371e-06 - dense_71_loss: 5.8514e-06 - dense_72_loss: 7.8572e-07 - val_loss: 5.2118e-06 - val_dense_71_loss: 4.4762e-06 - val_dense_72_loss: 7.3555e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5066e-06 - dense_71_loss: 5.7291e-06 - dense_72_loss: 7.7743e-07 - val_loss: 5.0584e-06 - val_dense_71_loss: 4.3177e-06 - val_dense_72_loss: 7.4069e-07\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 6.2829e-06 - dense_71_loss: 5.4971e-06 - dense_72_loss: 7.8583e-07 - val_loss: 4.7875e-06 - val_dense_71_loss: 4.0439e-06 - val_dense_72_loss: 7.4359e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.9988e-06 - dense_71_loss: 5.2152e-06 - dense_72_loss: 7.8359e-07 - val_loss: 4.5363e-06 - val_dense_71_loss: 3.8123e-06 - val_dense_72_loss: 7.2396e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5495e-06 - dense_71_loss: 4.7806e-06 - dense_72_loss: 7.6887e-07 - val_loss: 4.3582e-06 - val_dense_71_loss: 3.5962e-06 - val_dense_72_loss: 7.6198e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0753e-06 - dense_71_loss: 4.2753e-06 - dense_72_loss: 7.9998e-07 - val_loss: 3.7899e-06 - val_dense_71_loss: 3.0285e-06 - val_dense_72_loss: 7.6142e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.3355e-06 - dense_71_loss: 3.5280e-06 - dense_72_loss: 8.0751e-07 - val_loss: 3.2031e-06 - val_dense_71_loss: 2.4284e-06 - val_dense_72_loss: 7.7470e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.5167e-06 - dense_71_loss: 2.6853e-06 - dense_72_loss: 8.3142e-07 - val_loss: 2.5674e-06 - val_dense_71_loss: 1.7725e-06 - val_dense_72_loss: 7.9491e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.6133e-06 - dense_71_loss: 1.7799e-06 - dense_72_loss: 8.3340e-07 - val_loss: 1.8093e-06 - val_dense_71_loss: 1.0652e-06 - val_dense_72_loss: 7.4408e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8391e-06 - dense_71_loss: 1.0841e-06 - dense_72_loss: 7.5504e-07 - val_loss: 1.4381e-06 - val_dense_71_loss: 7.7438e-07 - val_dense_72_loss: 6.6372e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3434e-06 - dense_71_loss: 7.0522e-07 - dense_72_loss: 6.3817e-07 - val_loss: 1.1328e-06 - val_dense_71_loss: 5.2211e-07 - val_dense_72_loss: 6.1065e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0872e-06 - dense_71_loss: 5.1292e-07 - dense_72_loss: 5.7430e-07 - val_loss: 9.9618e-07 - val_dense_71_loss: 4.3337e-07 - val_dense_72_loss: 5.6281e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3181e-07 - dense_71_loss: 4.2497e-07 - dense_72_loss: 5.0685e-07 - val_loss: 9.4271e-07 - val_dense_71_loss: 4.2268e-07 - val_dense_72_loss: 5.2003e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8023e-07 - dense_71_loss: 4.0627e-07 - dense_72_loss: 4.7396e-07 - val_loss: 9.1015e-07 - val_dense_71_loss: 4.0631e-07 - val_dense_72_loss: 5.0384e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.9063e-07 - dense_71_loss: 4.0434e-07 - dense_72_loss: 4.8630e-07 - val_loss: 9.4167e-07 - val_dense_71_loss: 4.4615e-07 - val_dense_72_loss: 4.9552e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.5897e-07 - dense_71_loss: 3.9535e-07 - dense_72_loss: 4.6362e-07 - val_loss: 9.4434e-07 - val_dense_71_loss: 4.4805e-07 - val_dense_72_loss: 4.9629e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3953e-07 - dense_71_loss: 3.9196e-07 - dense_72_loss: 4.4757e-07 - val_loss: 8.5993e-07 - val_dense_71_loss: 3.8275e-07 - val_dense_72_loss: 4.7719e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1519e-07 - dense_71_loss: 3.7587e-07 - dense_72_loss: 4.3932e-07 - val_loss: 8.7307e-07 - val_dense_71_loss: 3.8772e-07 - val_dense_72_loss: 4.8535e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0475e-07 - dense_71_loss: 3.6727e-07 - dense_72_loss: 4.3748e-07 - val_loss: 8.5936e-07 - val_dense_71_loss: 3.8182e-07 - val_dense_72_loss: 4.7755e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2163e-07 - dense_71_loss: 3.7222e-07 - dense_72_loss: 4.4941e-07 - val_loss: 8.3190e-07 - val_dense_71_loss: 3.7141e-07 - val_dense_72_loss: 4.6049e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8757e-07 - dense_71_loss: 3.6577e-07 - dense_72_loss: 4.2180e-07 - val_loss: 8.9624e-07 - val_dense_71_loss: 4.2118e-07 - val_dense_72_loss: 4.7506e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0630e-07 - dense_71_loss: 3.8329e-07 - dense_72_loss: 4.2301e-07 - val_loss: 8.4863e-07 - val_dense_71_loss: 3.9308e-07 - val_dense_72_loss: 4.5555e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9719e-07 - dense_71_loss: 3.7553e-07 - dense_72_loss: 4.2166e-07 - val_loss: 8.3436e-07 - val_dense_71_loss: 3.7023e-07 - val_dense_72_loss: 4.6413e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7629e-07 - dense_71_loss: 3.6463e-07 - dense_72_loss: 4.1166e-07 - val_loss: 8.1451e-07 - val_dense_71_loss: 3.7777e-07 - val_dense_72_loss: 4.3674e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7248e-07 - dense_71_loss: 3.6316e-07 - dense_72_loss: 4.0932e-07 - val_loss: 7.9868e-07 - val_dense_71_loss: 3.6701e-07 - val_dense_72_loss: 4.3167e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6826e-07 - dense_71_loss: 3.6544e-07 - dense_72_loss: 4.0283e-07 - val_loss: 8.3752e-07 - val_dense_71_loss: 3.9438e-07 - val_dense_72_loss: 4.4315e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7392e-07 - dense_71_loss: 3.7396e-07 - dense_72_loss: 3.9996e-07 - val_loss: 8.5696e-07 - val_dense_71_loss: 4.0731e-07 - val_dense_72_loss: 4.4965e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7151e-07 - dense_71_loss: 3.7760e-07 - dense_72_loss: 3.9390e-07 - val_loss: 8.1377e-07 - val_dense_71_loss: 3.9015e-07 - val_dense_72_loss: 4.2362e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6643e-07 - dense_71_loss: 3.7645e-07 - dense_72_loss: 3.8998e-07 - val_loss: 8.0448e-07 - val_dense_71_loss: 3.9007e-07 - val_dense_72_loss: 4.1441e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.6429e-07 - dense_71_loss: 3.7583e-07 - dense_72_loss: 3.8846e-07 - val_loss: 7.8017e-07 - val_dense_71_loss: 3.5875e-07 - val_dense_72_loss: 4.2142e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3447e-07 - dense_71_loss: 3.6465e-07 - dense_72_loss: 3.6983e-07 - val_loss: 8.3574e-07 - val_dense_71_loss: 4.1564e-07 - val_dense_72_loss: 4.2011e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5820e-07 - dense_71_loss: 3.9413e-07 - dense_72_loss: 3.6407e-07 - val_loss: 8.5542e-07 - val_dense_71_loss: 4.6729e-07 - val_dense_72_loss: 3.8813e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7857e-07 - dense_71_loss: 4.2064e-07 - dense_72_loss: 3.5792e-07 - val_loss: 9.3724e-07 - val_dense_71_loss: 4.9417e-07 - val_dense_72_loss: 4.4307e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 7.5799e-07 - dense_71_loss: 4.0675e-07 - dense_72_loss: 3.5124e-07 - val_loss: 8.2807e-07 - val_dense_71_loss: 4.4732e-07 - val_dense_72_loss: 3.8075e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5109e-07 - dense_71_loss: 4.0470e-07 - dense_72_loss: 3.4639e-07 - val_loss: 7.6981e-07 - val_dense_71_loss: 3.8839e-07 - val_dense_72_loss: 3.8142e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.0531e-07 - dense_71_loss: 3.6353e-07 - dense_72_loss: 3.4178e-07 - val_loss: 7.7064e-07 - val_dense_71_loss: 3.9068e-07 - val_dense_72_loss: 3.7995e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9066e-07 - dense_71_loss: 3.5132e-07 - dense_72_loss: 3.3935e-07 - val_loss: 7.9541e-07 - val_dense_71_loss: 4.2042e-07 - val_dense_72_loss: 3.7499e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "\n",
      "Now training model 10/12\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 20ms/step - loss: 0.0012 - dense_78_loss: 7.7906e-04 - dense_79_loss: 4.0929e-04 - val_loss: 4.7525e-05 - val_dense_78_loss: 2.6786e-05 - val_dense_79_loss: 2.0740e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.3118e-05 - dense_78_loss: 1.8220e-05 - dense_79_loss: 1.4898e-05 - val_loss: 1.2612e-05 - val_dense_78_loss: 7.5758e-06 - val_dense_79_loss: 5.0364e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6818e-06 - dense_78_loss: 6.3027e-06 - dense_79_loss: 2.3791e-06 - val_loss: 5.4141e-06 - val_dense_78_loss: 4.1297e-06 - val_dense_79_loss: 1.2844e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.7392e-06 - dense_78_loss: 4.8398e-06 - dense_79_loss: 8.9942e-07 - val_loss: 4.4355e-06 - val_dense_78_loss: 3.6329e-06 - val_dense_79_loss: 8.0263e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4502e-06 - dense_78_loss: 4.7474e-06 - dense_79_loss: 7.0280e-07 - val_loss: 4.2624e-06 - val_dense_78_loss: 3.6007e-06 - val_dense_79_loss: 6.6175e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3497e-06 - dense_78_loss: 4.6817e-06 - dense_79_loss: 6.6806e-07 - val_loss: 4.4330e-06 - val_dense_78_loss: 3.7679e-06 - val_dense_79_loss: 6.6512e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.4313e-06 - dense_78_loss: 4.7409e-06 - dense_79_loss: 6.9050e-07 - val_loss: 4.3066e-06 - val_dense_78_loss: 3.5936e-06 - val_dense_79_loss: 7.1302e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3682e-06 - dense_78_loss: 4.6740e-06 - dense_79_loss: 6.9414e-07 - val_loss: 4.2299e-06 - val_dense_78_loss: 3.5480e-06 - val_dense_79_loss: 6.8183e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2950e-06 - dense_78_loss: 4.5937e-06 - dense_79_loss: 7.0130e-07 - val_loss: 4.1492e-06 - val_dense_78_loss: 3.4705e-06 - val_dense_79_loss: 6.7872e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.1972e-06 - dense_78_loss: 4.5144e-06 - dense_79_loss: 6.8276e-07 - val_loss: 4.0731e-06 - val_dense_78_loss: 3.4053e-06 - val_dense_79_loss: 6.6775e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.1646e-06 - dense_78_loss: 4.4618e-06 - dense_79_loss: 7.0284e-07 - val_loss: 4.0620e-06 - val_dense_78_loss: 3.3442e-06 - val_dense_79_loss: 7.1783e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0635e-06 - dense_78_loss: 4.3398e-06 - dense_79_loss: 7.2370e-07 - val_loss: 3.9908e-06 - val_dense_78_loss: 3.2465e-06 - val_dense_79_loss: 7.4429e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.8505e-06 - dense_78_loss: 4.1232e-06 - dense_79_loss: 7.2724e-07 - val_loss: 3.7926e-06 - val_dense_78_loss: 3.0665e-06 - val_dense_79_loss: 7.2611e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5558e-06 - dense_78_loss: 3.8406e-06 - dense_79_loss: 7.1524e-07 - val_loss: 3.7132e-06 - val_dense_78_loss: 3.0310e-06 - val_dense_79_loss: 6.8224e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2535e-06 - dense_78_loss: 3.5204e-06 - dense_79_loss: 7.3307e-07 - val_loss: 3.2719e-06 - val_dense_78_loss: 2.5314e-06 - val_dense_79_loss: 7.4041e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.7973e-06 - dense_78_loss: 3.0434e-06 - dense_79_loss: 7.5382e-07 - val_loss: 2.9579e-06 - val_dense_78_loss: 2.1934e-06 - val_dense_79_loss: 7.6442e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.2738e-06 - dense_78_loss: 2.5174e-06 - dense_79_loss: 7.5633e-07 - val_loss: 2.3890e-06 - val_dense_78_loss: 1.6662e-06 - val_dense_79_loss: 7.2277e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.4830e-06 - dense_78_loss: 1.7480e-06 - dense_79_loss: 7.3498e-07 - val_loss: 2.0029e-06 - val_dense_78_loss: 1.2855e-06 - val_dense_79_loss: 7.1740e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.9411e-06 - dense_78_loss: 1.2193e-06 - dense_79_loss: 7.2181e-07 - val_loss: 1.5818e-06 - val_dense_78_loss: 8.7362e-07 - val_dense_79_loss: 7.0821e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5631e-06 - dense_78_loss: 8.6350e-07 - dense_79_loss: 6.9961e-07 - val_loss: 1.4877e-06 - val_dense_78_loss: 8.0950e-07 - val_dense_79_loss: 6.7819e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3418e-06 - dense_78_loss: 6.8970e-07 - dense_79_loss: 6.5210e-07 - val_loss: 1.2916e-06 - val_dense_78_loss: 6.5184e-07 - val_dense_79_loss: 6.3980e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2192e-06 - dense_78_loss: 6.2879e-07 - dense_79_loss: 5.9038e-07 - val_loss: 1.2141e-06 - val_dense_78_loss: 6.1391e-07 - val_dense_79_loss: 6.0024e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1195e-06 - dense_78_loss: 5.7012e-07 - dense_79_loss: 5.4936e-07 - val_loss: 1.1888e-06 - val_dense_78_loss: 6.1637e-07 - val_dense_79_loss: 5.7243e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0824e-06 - dense_78_loss: 5.5372e-07 - dense_79_loss: 5.2871e-07 - val_loss: 1.1574e-06 - val_dense_78_loss: 5.9352e-07 - val_dense_79_loss: 5.6391e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1166e-06 - dense_78_loss: 5.8402e-07 - dense_79_loss: 5.3263e-07 - val_loss: 1.2129e-06 - val_dense_78_loss: 6.3734e-07 - val_dense_79_loss: 5.7557e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0928e-06 - dense_78_loss: 5.5653e-07 - dense_79_loss: 5.3626e-07 - val_loss: 1.1339e-06 - val_dense_78_loss: 5.4635e-07 - val_dense_79_loss: 5.8760e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0965e-06 - dense_78_loss: 5.5889e-07 - dense_79_loss: 5.3761e-07 - val_loss: 1.1653e-06 - val_dense_78_loss: 5.9935e-07 - val_dense_79_loss: 5.6598e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0735e-06 - dense_78_loss: 5.3297e-07 - dense_79_loss: 5.4050e-07 - val_loss: 1.1348e-06 - val_dense_78_loss: 5.4356e-07 - val_dense_79_loss: 5.9128e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0615e-06 - dense_78_loss: 5.3382e-07 - dense_79_loss: 5.2772e-07 - val_loss: 1.1418e-06 - val_dense_78_loss: 5.6702e-07 - val_dense_79_loss: 5.7474e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0669e-06 - dense_78_loss: 5.5305e-07 - dense_79_loss: 5.1386e-07 - val_loss: 1.1084e-06 - val_dense_78_loss: 5.3684e-07 - val_dense_79_loss: 5.7153e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0486e-06 - dense_78_loss: 5.2839e-07 - dense_79_loss: 5.2019e-07 - val_loss: 1.1118e-06 - val_dense_78_loss: 5.3506e-07 - val_dense_79_loss: 5.7678e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0559e-06 - dense_78_loss: 5.2313e-07 - dense_79_loss: 5.3280e-07 - val_loss: 1.1169e-06 - val_dense_78_loss: 5.6476e-07 - val_dense_79_loss: 5.5217e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0539e-06 - dense_78_loss: 5.4318e-07 - dense_79_loss: 5.1069e-07 - val_loss: 1.1407e-06 - val_dense_78_loss: 5.9804e-07 - val_dense_79_loss: 5.4266e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0857e-06 - dense_78_loss: 5.7774e-07 - dense_79_loss: 5.0799e-07 - val_loss: 1.1370e-06 - val_dense_78_loss: 5.8877e-07 - val_dense_79_loss: 5.4828e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0476e-06 - dense_78_loss: 5.3554e-07 - dense_79_loss: 5.1201e-07 - val_loss: 1.1003e-06 - val_dense_78_loss: 5.5540e-07 - val_dense_79_loss: 5.4488e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0566e-06 - dense_78_loss: 5.5362e-07 - dense_79_loss: 5.0300e-07 - val_loss: 1.0895e-06 - val_dense_78_loss: 5.4470e-07 - val_dense_79_loss: 5.4485e-07\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0653e-06 - dense_78_loss: 5.5492e-07 - dense_79_loss: 5.1042e-07 - val_loss: 1.1009e-06 - val_dense_78_loss: 5.6672e-07 - val_dense_79_loss: 5.3414e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0179e-06 - dense_78_loss: 5.2162e-07 - dense_79_loss: 4.9632e-07 - val_loss: 1.3069e-06 - val_dense_78_loss: 7.0588e-07 - val_dense_79_loss: 6.0099e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1360e-06 - dense_78_loss: 5.7638e-07 - dense_79_loss: 5.5959e-07 - val_loss: 1.1051e-06 - val_dense_78_loss: 5.6774e-07 - val_dense_79_loss: 5.3734e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0259e-06 - dense_78_loss: 5.2720e-07 - dense_79_loss: 4.9867e-07 - val_loss: 1.0909e-06 - val_dense_78_loss: 5.5879e-07 - val_dense_79_loss: 5.3210e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1016e-06 - dense_78_loss: 5.7187e-07 - dense_79_loss: 5.2968e-07 - val_loss: 1.0784e-06 - val_dense_78_loss: 5.4043e-07 - val_dense_79_loss: 5.3798e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0943e-06 - dense_78_loss: 5.6945e-07 - dense_79_loss: 5.2487e-07 - val_loss: 1.1032e-06 - val_dense_78_loss: 5.7973e-07 - val_dense_79_loss: 5.2347e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0490e-06 - dense_78_loss: 5.5337e-07 - dense_79_loss: 4.9562e-07 - val_loss: 1.0762e-06 - val_dense_78_loss: 5.3499e-07 - val_dense_79_loss: 5.4125e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9508e-07 - dense_78_loss: 5.1769e-07 - dense_79_loss: 4.7739e-07 - val_loss: 1.0601e-06 - val_dense_78_loss: 5.4759e-07 - val_dense_79_loss: 5.1255e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0445e-06 - dense_78_loss: 5.6449e-07 - dense_79_loss: 4.7996e-07 - val_loss: 1.0179e-06 - val_dense_78_loss: 5.1332e-07 - val_dense_79_loss: 5.0462e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.7088e-07 - dense_78_loss: 5.0897e-07 - dense_79_loss: 4.6192e-07 - val_loss: 1.1362e-06 - val_dense_78_loss: 5.2933e-07 - val_dense_79_loss: 6.0686e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1506e-06 - dense_78_loss: 6.1488e-07 - dense_79_loss: 5.3568e-07 - val_loss: 1.0919e-06 - val_dense_78_loss: 5.6750e-07 - val_dense_79_loss: 5.2440e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.8950e-07 - dense_78_loss: 5.2218e-07 - dense_79_loss: 4.6732e-07 - val_loss: 1.0483e-06 - val_dense_78_loss: 5.3707e-07 - val_dense_79_loss: 5.1120e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0232e-06 - dense_78_loss: 5.5882e-07 - dense_79_loss: 4.6442e-07 - val_loss: 1.2154e-06 - val_dense_78_loss: 6.9538e-07 - val_dense_79_loss: 5.2002e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0963e-06 - dense_78_loss: 6.3686e-07 - dense_79_loss: 4.5947e-07 - val_loss: 1.0383e-06 - val_dense_78_loss: 5.5750e-07 - val_dense_79_loss: 4.8081e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9542e-07 - dense_78_loss: 5.4517e-07 - dense_79_loss: 4.5025e-07 - val_loss: 1.0801e-06 - val_dense_78_loss: 6.0834e-07 - val_dense_79_loss: 4.7180e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0344e-06 - dense_78_loss: 5.8503e-07 - dense_79_loss: 4.4937e-07 - val_loss: 1.0845e-06 - val_dense_78_loss: 6.1073e-07 - val_dense_79_loss: 4.7378e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3946e-07 - dense_78_loss: 5.0872e-07 - dense_79_loss: 4.3074e-07 - val_loss: 9.8777e-07 - val_dense_78_loss: 5.4542e-07 - val_dense_79_loss: 4.4235e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3491e-07 - dense_78_loss: 5.1829e-07 - dense_79_loss: 4.1662e-07 - val_loss: 9.4999e-07 - val_dense_78_loss: 5.0659e-07 - val_dense_79_loss: 4.4340e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2965e-07 - dense_78_loss: 5.2172e-07 - dense_79_loss: 4.0793e-07 - val_loss: 1.1129e-06 - val_dense_78_loss: 6.8285e-07 - val_dense_79_loss: 4.3001e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5822e-07 - dense_78_loss: 5.5400e-07 - dense_79_loss: 4.0423e-07 - val_loss: 1.0674e-06 - val_dense_78_loss: 6.3892e-07 - val_dense_79_loss: 4.2849e-07\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3911e-07 - dense_78_loss: 5.4167e-07 - dense_79_loss: 3.9745e-07 - val_loss: 1.0036e-06 - val_dense_78_loss: 5.8532e-07 - val_dense_79_loss: 4.1832e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2477e-07 - dense_78_loss: 5.4125e-07 - dense_79_loss: 3.8353e-07 - val_loss: 1.1447e-06 - val_dense_78_loss: 5.6668e-07 - val_dense_79_loss: 5.7799e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6458e-07 - dense_78_loss: 5.3967e-07 - dense_79_loss: 4.2490e-07 - val_loss: 9.5911e-07 - val_dense_78_loss: 4.9853e-07 - val_dense_79_loss: 4.6058e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4220e-07 - dense_78_loss: 5.4249e-07 - dense_79_loss: 3.9971e-07 - val_loss: 9.5107e-07 - val_dense_78_loss: 5.4010e-07 - val_dense_79_loss: 4.1097e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8399e-07 - dense_78_loss: 5.1595e-07 - dense_79_loss: 3.6804e-07 - val_loss: 8.8972e-07 - val_dense_78_loss: 5.0244e-07 - val_dense_79_loss: 3.8729e-07\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.4461e-07 - dense_78_loss: 4.9640e-07 - dense_79_loss: 3.4821e-07 - val_loss: 9.7551e-07 - val_dense_78_loss: 5.7753e-07 - val_dense_79_loss: 3.9798e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3885e-07 - dense_78_loss: 5.6993e-07 - dense_79_loss: 3.6892e-07 - val_loss: 1.1440e-06 - val_dense_78_loss: 7.1383e-07 - val_dense_79_loss: 4.3019e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7590e-07 - dense_78_loss: 5.2567e-07 - dense_79_loss: 3.5023e-07 - val_loss: 9.1279e-07 - val_dense_78_loss: 4.9923e-07 - val_dense_79_loss: 4.1356e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4289e-07 - dense_78_loss: 5.9458e-07 - dense_79_loss: 3.4832e-07 - val_loss: 9.0573e-07 - val_dense_78_loss: 5.2073e-07 - val_dense_79_loss: 3.8500e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1879e-07 - dense_78_loss: 4.8869e-07 - dense_79_loss: 3.3010e-07 - val_loss: 9.4947e-07 - val_dense_78_loss: 5.6942e-07 - val_dense_79_loss: 3.8005e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.5865e-07 - dense_78_loss: 5.2788e-07 - dense_79_loss: 3.3077e-07 - val_loss: 9.5086e-07 - val_dense_78_loss: 5.9032e-07 - val_dense_79_loss: 3.6054e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.1413e-07 - dense_78_loss: 5.8569e-07 - dense_79_loss: 3.2844e-07 - val_loss: 8.8191e-07 - val_dense_78_loss: 5.2110e-07 - val_dense_79_loss: 3.6081e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2485e-07 - dense_78_loss: 5.1453e-07 - dense_79_loss: 3.1032e-07 - val_loss: 9.6398e-07 - val_dense_78_loss: 6.1611e-07 - val_dense_79_loss: 3.4787e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.4819e-07 - dense_78_loss: 5.2624e-07 - dense_79_loss: 3.2196e-07 - val_loss: 8.8533e-07 - val_dense_78_loss: 5.2517e-07 - val_dense_79_loss: 3.6016e-07\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.0859e-07 - dense_78_loss: 5.0189e-07 - dense_79_loss: 3.0670e-07 - val_loss: 8.4250e-07 - val_dense_78_loss: 4.9660e-07 - val_dense_79_loss: 3.4590e-07\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2917e-07 - dense_78_loss: 5.3102e-07 - dense_79_loss: 2.9815e-07 - val_loss: 8.6611e-07 - val_dense_78_loss: 5.3062e-07 - val_dense_79_loss: 3.3550e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0841e-07 - dense_78_loss: 5.9977e-07 - dense_79_loss: 3.0864e-07 - val_loss: 7.9998e-07 - val_dense_78_loss: 4.8875e-07 - val_dense_79_loss: 3.1123e-07\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3199e-07 - dense_78_loss: 5.3751e-07 - dense_79_loss: 2.9448e-07 - val_loss: 1.1585e-06 - val_dense_78_loss: 5.6837e-07 - val_dense_79_loss: 5.9017e-07\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1900e-07 - dense_78_loss: 5.1049e-07 - dense_79_loss: 3.0851e-07 - val_loss: 9.9763e-07 - val_dense_78_loss: 6.1099e-07 - val_dense_79_loss: 3.8663e-07\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7390e-07 - dense_78_loss: 5.8473e-07 - dense_79_loss: 2.8917e-07 - val_loss: 8.2222e-07 - val_dense_78_loss: 5.2547e-07 - val_dense_79_loss: 2.9675e-07\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2991e-07 - dense_78_loss: 4.6943e-07 - dense_79_loss: 2.6048e-07 - val_loss: 9.3518e-07 - val_dense_78_loss: 6.1441e-07 - val_dense_79_loss: 3.2077e-07\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8082e-07 - dense_78_loss: 5.1919e-07 - dense_79_loss: 2.6163e-07 - val_loss: 8.6742e-07 - val_dense_78_loss: 5.7072e-07 - val_dense_79_loss: 2.9670e-07\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6020e-07 - dense_78_loss: 5.0997e-07 - dense_79_loss: 2.5023e-07 - val_loss: 8.1185e-07 - val_dense_78_loss: 5.0004e-07 - val_dense_79_loss: 3.1181e-07\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9788e-07 - dense_78_loss: 5.4234e-07 - dense_79_loss: 2.5554e-07 - val_loss: 9.2410e-07 - val_dense_78_loss: 6.3613e-07 - val_dense_79_loss: 2.8797e-07\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5005e-07 - dense_78_loss: 5.1331e-07 - dense_79_loss: 2.3674e-07 - val_loss: 9.7831e-07 - val_dense_78_loss: 5.8977e-07 - val_dense_79_loss: 3.8854e-07\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7359e-07 - dense_78_loss: 5.2428e-07 - dense_79_loss: 2.4932e-07 - val_loss: 7.1934e-07 - val_dense_78_loss: 4.8222e-07 - val_dense_79_loss: 2.3712e-07\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3144e-07 - dense_78_loss: 5.0067e-07 - dense_79_loss: 2.3077e-07 - val_loss: 1.1740e-06 - val_dense_78_loss: 8.8423e-07 - val_dense_79_loss: 2.8981e-07\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2408e-07 - dense_78_loss: 5.7202e-07 - dense_79_loss: 2.5207e-07 - val_loss: 8.4086e-07 - val_dense_78_loss: 5.0511e-07 - val_dense_79_loss: 3.3576e-07\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2189e-07 - dense_78_loss: 4.8074e-07 - dense_79_loss: 2.4115e-07 - val_loss: 7.5403e-07 - val_dense_78_loss: 4.8909e-07 - val_dense_79_loss: 2.6494e-07\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0462e-07 - dense_78_loss: 4.7143e-07 - dense_79_loss: 2.3319e-07 - val_loss: 8.2303e-07 - val_dense_78_loss: 5.8947e-07 - val_dense_79_loss: 2.3355e-07\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0965e-07 - dense_78_loss: 4.8962e-07 - dense_79_loss: 2.2003e-07 - val_loss: 7.4948e-07 - val_dense_78_loss: 4.9716e-07 - val_dense_79_loss: 2.5231e-07\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8708e-07 - dense_78_loss: 4.7480e-07 - dense_79_loss: 2.1228e-07 - val_loss: 7.4719e-07 - val_dense_78_loss: 5.1976e-07 - val_dense_79_loss: 2.2743e-07\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8980e-07 - dense_78_loss: 4.8522e-07 - dense_79_loss: 2.0458e-07 - val_loss: 8.0665e-07 - val_dense_78_loss: 4.8695e-07 - val_dense_79_loss: 3.1970e-07\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3882e-07 - dense_78_loss: 6.7127e-07 - dense_79_loss: 2.6755e-07 - val_loss: 8.6649e-07 - val_dense_78_loss: 6.3480e-07 - val_dense_79_loss: 2.3168e-07\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7822e-07 - dense_78_loss: 5.5907e-07 - dense_79_loss: 2.1916e-07 - val_loss: 9.4376e-07 - val_dense_78_loss: 6.1497e-07 - val_dense_79_loss: 3.2879e-07\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2118e-07 - dense_78_loss: 5.8217e-07 - dense_79_loss: 2.3901e-07 - val_loss: 6.9615e-07 - val_dense_78_loss: 4.8534e-07 - val_dense_79_loss: 2.1081e-07\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0201e-07 - dense_78_loss: 5.0280e-07 - dense_79_loss: 1.9921e-07 - val_loss: 8.3729e-07 - val_dense_78_loss: 5.9057e-07 - val_dense_79_loss: 2.4672e-07\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7372e-07 - dense_78_loss: 4.7773e-07 - dense_79_loss: 1.9599e-07 - val_loss: 7.8699e-07 - val_dense_78_loss: 5.8135e-07 - val_dense_79_loss: 2.0564e-07\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7819e-07 - dense_78_loss: 4.9574e-07 - dense_79_loss: 1.8245e-07 - val_loss: 7.0805e-07 - val_dense_78_loss: 5.2837e-07 - val_dense_79_loss: 1.7969e-07\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.4007e-07 - dense_78_loss: 4.6779e-07 - dense_79_loss: 1.7228e-07 - val_loss: 8.0892e-07 - val_dense_78_loss: 5.9674e-07 - val_dense_79_loss: 2.1219e-07\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9391e-07 - dense_78_loss: 4.9940e-07 - dense_79_loss: 1.9451e-07 - val_loss: 6.6744e-07 - val_dense_78_loss: 4.6532e-07 - val_dense_79_loss: 2.0212e-07\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0780e-07 - dense_78_loss: 5.1695e-07 - dense_79_loss: 1.9084e-07 - val_loss: 7.2122e-07 - val_dense_78_loss: 5.2402e-07 - val_dense_79_loss: 1.9721e-07\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9384e-07 - dense_78_loss: 5.8439e-07 - dense_79_loss: 2.0945e-07 - val_loss: 7.8541e-07 - val_dense_78_loss: 5.7144e-07 - val_dense_79_loss: 2.1397e-07\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7683e-07 - dense_78_loss: 4.9021e-07 - dense_79_loss: 1.8662e-07 - val_loss: 6.3821e-07 - val_dense_78_loss: 4.6062e-07 - val_dense_79_loss: 1.7759e-07\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3392e-07 - dense_78_loss: 4.7209e-07 - dense_79_loss: 1.6183e-07 - val_loss: 7.0786e-07 - val_dense_78_loss: 4.7419e-07 - val_dense_79_loss: 2.3367e-07\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9662e-07 - dense_78_loss: 5.2307e-07 - dense_79_loss: 1.7355e-07 - val_loss: 6.6640e-07 - val_dense_78_loss: 4.9730e-07 - val_dense_79_loss: 1.6910e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00102: early stopping\n",
      "\n",
      "Now training model 11/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 19ms/step - loss: 8.0419e-04 - dense_85_loss: 5.1968e-04 - dense_86_loss: 2.8451e-04 - val_loss: 5.3770e-05 - val_dense_85_loss: 2.8703e-05 - val_dense_86_loss: 2.5066e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.0686e-05 - dense_85_loss: 1.4746e-05 - dense_86_loss: 1.5940e-05 - val_loss: 1.1503e-05 - val_dense_85_loss: 7.3739e-06 - val_dense_86_loss: 4.1294e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1707e-06 - dense_85_loss: 6.3261e-06 - dense_86_loss: 1.8446e-06 - val_loss: 5.0871e-06 - val_dense_85_loss: 4.0301e-06 - val_dense_86_loss: 1.0570e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.8501e-06 - dense_85_loss: 5.0047e-06 - dense_86_loss: 8.4546e-07 - val_loss: 4.3870e-06 - val_dense_85_loss: 3.6687e-06 - val_dense_86_loss: 7.1837e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.4489e-06 - dense_85_loss: 4.7563e-06 - dense_86_loss: 6.9263e-07 - val_loss: 4.2223e-06 - val_dense_85_loss: 3.5666e-06 - val_dense_86_loss: 6.5567e-07\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2951e-06 - dense_85_loss: 4.6213e-06 - dense_86_loss: 6.7371e-07 - val_loss: 4.4382e-06 - val_dense_85_loss: 3.7774e-06 - val_dense_86_loss: 6.6080e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2859e-06 - dense_85_loss: 4.5765e-06 - dense_86_loss: 7.0931e-07 - val_loss: 4.0974e-06 - val_dense_85_loss: 3.3955e-06 - val_dense_86_loss: 7.0187e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0137e-06 - dense_85_loss: 4.3105e-06 - dense_86_loss: 7.0322e-07 - val_loss: 3.8589e-06 - val_dense_85_loss: 3.1865e-06 - val_dense_86_loss: 6.7240e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.7590e-06 - dense_85_loss: 4.0540e-06 - dense_86_loss: 7.0504e-07 - val_loss: 3.6999e-06 - val_dense_85_loss: 3.0201e-06 - val_dense_86_loss: 6.7983e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5158e-06 - dense_85_loss: 3.7818e-06 - dense_86_loss: 7.3398e-07 - val_loss: 3.7027e-06 - val_dense_85_loss: 2.9080e-06 - val_dense_86_loss: 7.9469e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2267e-06 - dense_85_loss: 3.4386e-06 - dense_86_loss: 7.8806e-07 - val_loss: 3.2558e-06 - val_dense_85_loss: 2.4980e-06 - val_dense_86_loss: 7.5776e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.7505e-06 - dense_85_loss: 2.9419e-06 - dense_86_loss: 8.0863e-07 - val_loss: 2.9828e-06 - val_dense_85_loss: 2.1756e-06 - val_dense_86_loss: 8.0714e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.2374e-06 - dense_85_loss: 2.4327e-06 - dense_86_loss: 8.0467e-07 - val_loss: 2.4381e-06 - val_dense_85_loss: 1.6849e-06 - val_dense_86_loss: 7.5314e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.6754e-06 - dense_85_loss: 1.8836e-06 - dense_86_loss: 7.9175e-07 - val_loss: 2.1951e-06 - val_dense_85_loss: 1.4794e-06 - val_dense_86_loss: 7.1575e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.2871e-06 - dense_85_loss: 1.5237e-06 - dense_86_loss: 7.6340e-07 - val_loss: 1.8029e-06 - val_dense_85_loss: 1.0953e-06 - val_dense_86_loss: 7.0755e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8639e-06 - dense_85_loss: 1.1548e-06 - dense_86_loss: 7.0909e-07 - val_loss: 1.5610e-06 - val_dense_85_loss: 9.1557e-07 - val_dense_86_loss: 6.4547e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5427e-06 - dense_85_loss: 8.8998e-07 - dense_86_loss: 6.5276e-07 - val_loss: 1.3447e-06 - val_dense_85_loss: 7.4321e-07 - val_dense_86_loss: 6.0146e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3244e-06 - dense_85_loss: 7.3993e-07 - dense_86_loss: 5.8443e-07 - val_loss: 1.2561e-06 - val_dense_85_loss: 6.8497e-07 - val_dense_86_loss: 5.7110e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1734e-06 - dense_85_loss: 6.4444e-07 - dense_86_loss: 5.2898e-07 - val_loss: 1.2126e-06 - val_dense_85_loss: 6.3945e-07 - val_dense_86_loss: 5.7316e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1298e-06 - dense_85_loss: 6.1054e-07 - dense_86_loss: 5.1931e-07 - val_loss: 1.1466e-06 - val_dense_85_loss: 6.2853e-07 - val_dense_86_loss: 5.1809e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0427e-06 - dense_85_loss: 5.5957e-07 - dense_86_loss: 4.8310e-07 - val_loss: 1.0990e-06 - val_dense_85_loss: 5.5196e-07 - val_dense_86_loss: 5.4704e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0314e-06 - dense_85_loss: 5.5168e-07 - dense_86_loss: 4.7976e-07 - val_loss: 1.1015e-06 - val_dense_85_loss: 5.7292e-07 - val_dense_86_loss: 5.2855e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0211e-06 - dense_85_loss: 5.4874e-07 - dense_86_loss: 4.7232e-07 - val_loss: 1.0353e-06 - val_dense_85_loss: 5.3441e-07 - val_dense_86_loss: 5.0090e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9614e-07 - dense_85_loss: 5.3453e-07 - dense_86_loss: 4.6162e-07 - val_loss: 1.0372e-06 - val_dense_85_loss: 5.3700e-07 - val_dense_86_loss: 5.0019e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0317e-06 - dense_85_loss: 5.6853e-07 - dense_86_loss: 4.6312e-07 - val_loss: 1.1223e-06 - val_dense_85_loss: 6.0812e-07 - val_dense_86_loss: 5.1413e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0433e-06 - dense_85_loss: 5.7578e-07 - dense_86_loss: 4.6757e-07 - val_loss: 1.0465e-06 - val_dense_85_loss: 5.4322e-07 - val_dense_86_loss: 5.0326e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0117e-06 - dense_85_loss: 5.4002e-07 - dense_86_loss: 4.7165e-07 - val_loss: 1.0325e-06 - val_dense_85_loss: 5.3591e-07 - val_dense_86_loss: 4.9658e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.7381e-07 - dense_85_loss: 5.2007e-07 - dense_86_loss: 4.5374e-07 - val_loss: 1.0744e-06 - val_dense_85_loss: 5.5823e-07 - val_dense_86_loss: 5.1622e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1062e-06 - dense_85_loss: 6.1378e-07 - dense_86_loss: 4.9246e-07 - val_loss: 1.1461e-06 - val_dense_85_loss: 6.6062e-07 - val_dense_86_loss: 4.8544e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9715e-07 - dense_85_loss: 5.4684e-07 - dense_86_loss: 4.5031e-07 - val_loss: 1.0559e-06 - val_dense_85_loss: 5.4999e-07 - val_dense_86_loss: 5.0588e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0027e-06 - dense_85_loss: 5.4408e-07 - dense_86_loss: 4.5860e-07 - val_loss: 1.0474e-06 - val_dense_85_loss: 5.6468e-07 - val_dense_86_loss: 4.8269e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0951e-06 - dense_85_loss: 6.5064e-07 - dense_86_loss: 4.4446e-07 - val_loss: 1.0833e-06 - val_dense_85_loss: 5.9706e-07 - val_dense_86_loss: 4.8627e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9642e-07 - dense_85_loss: 5.3930e-07 - dense_86_loss: 4.5712e-07 - val_loss: 1.1431e-06 - val_dense_85_loss: 6.0243e-07 - val_dense_86_loss: 5.4066e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0777e-06 - dense_85_loss: 6.3046e-07 - dense_86_loss: 4.4723e-07 - val_loss: 9.9432e-07 - val_dense_85_loss: 5.1410e-07 - val_dense_86_loss: 4.8022e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6288e-07 - dense_85_loss: 5.2805e-07 - dense_86_loss: 4.3482e-07 - val_loss: 1.0254e-06 - val_dense_85_loss: 5.3667e-07 - val_dense_86_loss: 4.8870e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9073e-07 - dense_85_loss: 5.3570e-07 - dense_86_loss: 4.5503e-07 - val_loss: 1.0883e-06 - val_dense_85_loss: 5.4261e-07 - val_dense_86_loss: 5.4565e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5276e-07 - dense_85_loss: 5.2365e-07 - dense_86_loss: 4.2911e-07 - val_loss: 1.0464e-06 - val_dense_85_loss: 5.6062e-07 - val_dense_86_loss: 4.8576e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5935e-06 - dense_85_loss: 1.1379e-06 - dense_86_loss: 4.5554e-07 - val_loss: 1.2399e-06 - val_dense_85_loss: 7.7067e-07 - val_dense_86_loss: 4.6920e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0192e-06 - dense_85_loss: 5.8309e-07 - dense_86_loss: 4.3615e-07 - val_loss: 9.7777e-07 - val_dense_85_loss: 5.4205e-07 - val_dense_86_loss: 4.3572e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2003e-07 - dense_85_loss: 5.1509e-07 - dense_86_loss: 4.0494e-07 - val_loss: 1.0024e-06 - val_dense_85_loss: 5.8219e-07 - val_dense_86_loss: 4.2023e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5265e-07 - dense_85_loss: 5.5293e-07 - dense_86_loss: 3.9972e-07 - val_loss: 9.4750e-07 - val_dense_85_loss: 5.2329e-07 - val_dense_86_loss: 4.2421e-07\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 9.1733e-07 - dense_85_loss: 5.1560e-07 - dense_86_loss: 4.0173e-07 - val_loss: 9.5065e-07 - val_dense_85_loss: 5.1731e-07 - val_dense_86_loss: 4.3334e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4584e-07 - dense_85_loss: 5.4534e-07 - dense_86_loss: 4.0050e-07 - val_loss: 1.0872e-06 - val_dense_85_loss: 6.1306e-07 - val_dense_86_loss: 4.7415e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4190e-07 - dense_85_loss: 5.4649e-07 - dense_86_loss: 3.9541e-07 - val_loss: 9.0978e-07 - val_dense_85_loss: 5.1842e-07 - val_dense_86_loss: 3.9136e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6070e-07 - dense_85_loss: 4.9666e-07 - dense_86_loss: 3.6404e-07 - val_loss: 9.6843e-07 - val_dense_85_loss: 5.7114e-07 - val_dense_86_loss: 3.9729e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0467e-07 - dense_85_loss: 5.4107e-07 - dense_86_loss: 3.6360e-07 - val_loss: 1.0168e-06 - val_dense_85_loss: 6.2196e-07 - val_dense_86_loss: 3.9482e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.9963e-07 - dense_85_loss: 5.4206e-07 - dense_86_loss: 3.5758e-07 - val_loss: 8.7073e-07 - val_dense_85_loss: 5.0515e-07 - val_dense_86_loss: 3.6557e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3190e-07 - dense_85_loss: 4.8952e-07 - dense_86_loss: 3.4239e-07 - val_loss: 9.4164e-07 - val_dense_85_loss: 5.7906e-07 - val_dense_86_loss: 3.6259e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5887e-07 - dense_85_loss: 6.1413e-07 - dense_86_loss: 3.4475e-07 - val_loss: 9.9325e-07 - val_dense_85_loss: 5.5194e-07 - val_dense_86_loss: 4.4132e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.4663e-07 - dense_85_loss: 5.0672e-07 - dense_86_loss: 3.3992e-07 - val_loss: 8.5896e-07 - val_dense_85_loss: 5.3083e-07 - val_dense_86_loss: 3.2813e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8721e-07 - dense_85_loss: 5.7146e-07 - dense_86_loss: 3.1576e-07 - val_loss: 1.0433e-06 - val_dense_85_loss: 6.2389e-07 - val_dense_86_loss: 4.1943e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8595e-07 - dense_85_loss: 5.6635e-07 - dense_86_loss: 3.1960e-07 - val_loss: 8.9712e-07 - val_dense_85_loss: 5.4801e-07 - val_dense_86_loss: 3.4911e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3862e-07 - dense_85_loss: 5.2869e-07 - dense_86_loss: 3.0993e-07 - val_loss: 9.9751e-07 - val_dense_85_loss: 6.6581e-07 - val_dense_86_loss: 3.3170e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8280e-07 - dense_85_loss: 5.8061e-07 - dense_86_loss: 3.0219e-07 - val_loss: 1.1265e-06 - val_dense_85_loss: 7.9114e-07 - val_dense_86_loss: 3.3532e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3896e-07 - dense_85_loss: 5.5114e-07 - dense_86_loss: 2.8782e-07 - val_loss: 1.1231e-06 - val_dense_85_loss: 6.0267e-07 - val_dense_86_loss: 5.2047e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0254e-07 - dense_85_loss: 5.9867e-07 - dense_86_loss: 3.0387e-07 - val_loss: 9.0096e-07 - val_dense_85_loss: 5.5056e-07 - val_dense_86_loss: 3.5040e-07\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3132e-07 - dense_85_loss: 5.4754e-07 - dense_86_loss: 2.8378e-07 - val_loss: 8.3844e-07 - val_dense_85_loss: 5.4389e-07 - val_dense_86_loss: 2.9455e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.9774e-07 - dense_85_loss: 5.1865e-07 - dense_86_loss: 2.7910e-07 - val_loss: 1.0537e-06 - val_dense_85_loss: 6.3545e-07 - val_dense_86_loss: 4.1820e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2521e-07 - dense_85_loss: 6.3550e-07 - dense_86_loss: 2.8971e-07 - val_loss: 8.4399e-07 - val_dense_85_loss: 5.1176e-07 - val_dense_86_loss: 3.3223e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2930e-07 - dense_85_loss: 5.6222e-07 - dense_86_loss: 2.6708e-07 - val_loss: 1.3006e-06 - val_dense_85_loss: 7.3256e-07 - val_dense_86_loss: 5.6807e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0326e-07 - dense_85_loss: 5.7897e-07 - dense_86_loss: 3.2430e-07 - val_loss: 9.6517e-07 - val_dense_85_loss: 6.3928e-07 - val_dense_86_loss: 3.2590e-07\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.9405e-07 - dense_85_loss: 5.2270e-07 - dense_86_loss: 2.7135e-07 - val_loss: 7.6283e-07 - val_dense_85_loss: 5.0041e-07 - val_dense_86_loss: 2.6242e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5020e-07 - dense_85_loss: 5.0045e-07 - dense_86_loss: 2.4975e-07 - val_loss: 1.0746e-06 - val_dense_85_loss: 6.5050e-07 - val_dense_86_loss: 4.2411e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.5290e-07 - dense_85_loss: 5.7988e-07 - dense_86_loss: 2.7302e-07 - val_loss: 1.3949e-06 - val_dense_85_loss: 1.1173e-06 - val_dense_86_loss: 2.7757e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.7571e-07 - dense_85_loss: 7.2412e-07 - dense_86_loss: 2.5159e-07 - val_loss: 8.3722e-07 - val_dense_85_loss: 5.6047e-07 - val_dense_86_loss: 2.7675e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5916e-07 - dense_85_loss: 5.1896e-07 - dense_86_loss: 2.4020e-07 - val_loss: 7.0582e-07 - val_dense_85_loss: 4.7578e-07 - val_dense_86_loss: 2.3004e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9974e-07 - dense_85_loss: 4.8206e-07 - dense_86_loss: 2.1768e-07 - val_loss: 6.6695e-07 - val_dense_85_loss: 4.5308e-07 - val_dense_86_loss: 2.1387e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3663e-07 - dense_85_loss: 4.5021e-07 - dense_86_loss: 1.8642e-07 - val_loss: 7.1829e-07 - val_dense_85_loss: 4.8358e-07 - val_dense_86_loss: 2.3470e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1999e-07 - dense_85_loss: 4.9831e-07 - dense_86_loss: 2.2168e-07 - val_loss: 9.2438e-07 - val_dense_85_loss: 5.6509e-07 - val_dense_86_loss: 3.5929e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.8240e-07 - dense_85_loss: 5.4183e-07 - dense_86_loss: 2.4057e-07 - val_loss: 1.0502e-06 - val_dense_85_loss: 7.3313e-07 - val_dense_86_loss: 3.1708e-07\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.5232e-07 - dense_85_loss: 5.3696e-07 - dense_86_loss: 2.1536e-07 - val_loss: 1.0004e-06 - val_dense_85_loss: 6.8071e-07 - val_dense_86_loss: 3.1970e-07\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3763e-07 - dense_85_loss: 6.2264e-07 - dense_86_loss: 2.1499e-07 - val_loss: 9.5571e-07 - val_dense_85_loss: 7.2974e-07 - val_dense_86_loss: 2.2597e-07\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3771e-07 - dense_85_loss: 5.8515e-07 - dense_86_loss: 2.5256e-07 - val_loss: 6.5487e-07 - val_dense_85_loss: 4.7007e-07 - val_dense_86_loss: 1.8480e-07\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0998e-07 - dense_85_loss: 5.2659e-07 - dense_86_loss: 1.8338e-07 - val_loss: 8.9048e-07 - val_dense_85_loss: 6.5012e-07 - val_dense_86_loss: 2.4036e-07\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.3850e-07 - dense_85_loss: 5.3707e-07 - dense_86_loss: 2.0143e-07 - val_loss: 7.7185e-07 - val_dense_85_loss: 5.4480e-07 - val_dense_86_loss: 2.2705e-07\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7718e-07 - dense_85_loss: 4.8009e-07 - dense_86_loss: 1.9710e-07 - val_loss: 8.9814e-07 - val_dense_85_loss: 6.3155e-07 - val_dense_86_loss: 2.6660e-07\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6453e-07 - dense_85_loss: 5.4665e-07 - dense_86_loss: 2.1787e-07 - val_loss: 9.0424e-07 - val_dense_85_loss: 6.4236e-07 - val_dense_86_loss: 2.6189e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.2577e-07 - dense_85_loss: 5.7532e-07 - dense_86_loss: 2.5045e-07 - val_loss: 8.3251e-07 - val_dense_85_loss: 5.9741e-07 - val_dense_86_loss: 2.3510e-07\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5394e-07 - dense_85_loss: 4.8046e-07 - dense_86_loss: 1.7348e-07 - val_loss: 7.5365e-07 - val_dense_85_loss: 5.4385e-07 - val_dense_86_loss: 2.0981e-07\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.1587e-07 - dense_85_loss: 5.2565e-07 - dense_86_loss: 1.9022e-07 - val_loss: 6.6819e-07 - val_dense_85_loss: 4.5901e-07 - val_dense_86_loss: 2.0919e-07\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8093e-07 - dense_85_loss: 5.0408e-07 - dense_86_loss: 1.7685e-07 - val_loss: 6.3982e-07 - val_dense_85_loss: 4.8380e-07 - val_dense_86_loss: 1.5602e-07\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3824e-07 - dense_85_loss: 4.8048e-07 - dense_86_loss: 1.5776e-07 - val_loss: 8.8395e-07 - val_dense_85_loss: 5.5878e-07 - val_dense_86_loss: 3.2517e-07\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.4912e-07 - dense_85_loss: 4.8329e-07 - dense_86_loss: 1.6584e-07 - val_loss: 7.3035e-07 - val_dense_85_loss: 5.7220e-07 - val_dense_86_loss: 1.5815e-07\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3287e-07 - dense_85_loss: 4.7670e-07 - dense_86_loss: 1.5618e-07 - val_loss: 7.5633e-07 - val_dense_85_loss: 5.3214e-07 - val_dense_86_loss: 2.2419e-07\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3556e-07 - dense_85_loss: 5.9859e-07 - dense_86_loss: 2.3697e-07 - val_loss: 1.0033e-06 - val_dense_85_loss: 7.2143e-07 - val_dense_86_loss: 2.8191e-07\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5316e-07 - dense_85_loss: 4.8151e-07 - dense_86_loss: 1.7165e-07 - val_loss: 7.2117e-07 - val_dense_85_loss: 4.8164e-07 - val_dense_86_loss: 2.3953e-07\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.2636e-07 - dense_85_loss: 4.7392e-07 - dense_86_loss: 1.5244e-07 - val_loss: 7.2609e-07 - val_dense_85_loss: 4.9541e-07 - val_dense_86_loss: 2.3067e-07\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7367e-07 - dense_85_loss: 6.2170e-07 - dense_86_loss: 2.5197e-07 - val_loss: 7.7610e-07 - val_dense_85_loss: 6.0899e-07 - val_dense_86_loss: 1.6711e-07\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8408e-07 - dense_85_loss: 5.4930e-07 - dense_86_loss: 2.3478e-07 - val_loss: 7.3817e-07 - val_dense_85_loss: 5.7704e-07 - val_dense_86_loss: 1.6114e-07\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.9148e-07 - dense_85_loss: 4.4922e-07 - dense_86_loss: 1.4225e-07 - val_loss: 6.5594e-07 - val_dense_85_loss: 4.7650e-07 - val_dense_86_loss: 1.7944e-07\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.9997e-07 - dense_85_loss: 4.5931e-07 - dense_86_loss: 1.4066e-07 - val_loss: 5.6792e-07 - val_dense_85_loss: 4.2926e-07 - val_dense_86_loss: 1.3867e-07\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1357e-07 - dense_85_loss: 4.7885e-07 - dense_86_loss: 1.3472e-07 - val_loss: 6.8118e-07 - val_dense_85_loss: 5.0992e-07 - val_dense_86_loss: 1.7126e-07\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5592e-07 - dense_85_loss: 4.7658e-07 - dense_86_loss: 1.7933e-07 - val_loss: 7.5458e-07 - val_dense_85_loss: 5.6711e-07 - val_dense_86_loss: 1.8747e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00093: early stopping\n",
      "\n",
      "Now training model 12/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 4s 42ms/step - loss: 0.0070 - dense_92_loss: 7.1885e-04 - dense_93_loss: 0.0011 - dense_94_loss: 8.9198e-04 - dense_95_loss: 0.0010 - dense_96_loss: 7.6528e-04 - dense_97_loss: 8.4945e-04 - dense_98_loss: 8.5781e-04 - dense_99_loss: 8.0856e-04 - val_loss: 4.8756e-04 - val_dense_92_loss: 6.8498e-05 - val_dense_93_loss: 4.3691e-05 - val_dense_94_loss: 5.6412e-05 - val_dense_95_loss: 6.4827e-05 - val_dense_96_loss: 5.5722e-05 - val_dense_97_loss: 7.3538e-05 - val_dense_98_loss: 5.3634e-05 - val_dense_99_loss: 7.1237e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.9614e-04 - dense_92_loss: 3.0769e-05 - dense_93_loss: 2.3579e-05 - dense_94_loss: 1.9489e-05 - dense_95_loss: 2.6772e-05 - dense_96_loss: 2.0203e-05 - dense_97_loss: 2.4541e-05 - dense_98_loss: 2.7145e-05 - dense_99_loss: 2.3640e-05 - val_loss: 6.3638e-05 - val_dense_92_loss: 1.0579e-05 - val_dense_93_loss: 1.1228e-05 - val_dense_94_loss: 6.4258e-06 - val_dense_95_loss: 7.6193e-06 - val_dense_96_loss: 6.4272e-06 - val_dense_97_loss: 7.1597e-06 - val_dense_98_loss: 8.9691e-06 - val_dense_99_loss: 5.2300e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.2895e-05 - dense_92_loss: 4.0260e-06 - dense_93_loss: 6.0303e-06 - dense_94_loss: 3.0602e-06 - dense_95_loss: 4.7308e-06 - dense_96_loss: 3.0851e-06 - dense_97_loss: 3.7519e-06 - dense_98_loss: 4.4752e-06 - dense_99_loss: 3.7349e-06 - val_loss: 1.8010e-05 - val_dense_92_loss: 1.4942e-06 - val_dense_93_loss: 3.7094e-06 - val_dense_94_loss: 1.7710e-06 - val_dense_95_loss: 2.7083e-06 - val_dense_96_loss: 1.5244e-06 - val_dense_97_loss: 2.0475e-06 - val_dense_98_loss: 2.1308e-06 - val_dense_99_loss: 2.6241e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.4709e-05 - dense_92_loss: 1.0689e-06 - dense_93_loss: 3.5757e-06 - dense_94_loss: 9.4079e-07 - dense_95_loss: 2.6268e-06 - dense_96_loss: 1.3676e-06 - dense_97_loss: 1.8216e-06 - dense_98_loss: 1.4324e-06 - dense_99_loss: 1.8757e-06 - val_loss: 1.4048e-05 - val_dense_92_loss: 8.4909e-07 - val_dense_93_loss: 3.5312e-06 - val_dense_94_loss: 8.3675e-07 - val_dense_95_loss: 2.5028e-06 - val_dense_96_loss: 1.2773e-06 - val_dense_97_loss: 1.8623e-06 - val_dense_98_loss: 1.3876e-06 - val_dense_99_loss: 1.8009e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2212e-05 - dense_92_loss: 6.8049e-07 - dense_93_loss: 3.2361e-06 - dense_94_loss: 6.0637e-07 - dense_95_loss: 2.2919e-06 - dense_96_loss: 1.0902e-06 - dense_97_loss: 1.5777e-06 - dense_98_loss: 1.1388e-06 - dense_99_loss: 1.5901e-06 - val_loss: 1.0861e-05 - val_dense_92_loss: 5.3441e-07 - val_dense_93_loss: 2.9600e-06 - val_dense_94_loss: 4.8995e-07 - val_dense_95_loss: 2.0473e-06 - val_dense_96_loss: 9.6875e-07 - val_dense_97_loss: 1.4211e-06 - val_dense_98_loss: 1.0513e-06 - val_dense_99_loss: 1.3881e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1401e-05 - dense_92_loss: 5.8433e-07 - dense_93_loss: 3.1017e-06 - dense_94_loss: 5.1865e-07 - dense_95_loss: 2.1763e-06 - dense_96_loss: 9.9444e-07 - dense_97_loss: 1.4807e-06 - dense_98_loss: 1.0608e-06 - dense_99_loss: 1.4840e-06 - val_loss: 1.2719e-05 - val_dense_92_loss: 7.3291e-07 - val_dense_93_loss: 3.2297e-06 - val_dense_94_loss: 7.1773e-07 - val_dense_95_loss: 2.3025e-06 - val_dense_96_loss: 1.1827e-06 - val_dense_97_loss: 1.6546e-06 - val_dense_98_loss: 1.1952e-06 - val_dense_99_loss: 1.7035e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1999e-05 - dense_92_loss: 6.7434e-07 - dense_93_loss: 3.1311e-06 - dense_94_loss: 6.0748e-07 - dense_95_loss: 2.2433e-06 - dense_96_loss: 1.0927e-06 - dense_97_loss: 1.5712e-06 - dense_98_loss: 1.1186e-06 - dense_99_loss: 1.5600e-06 - val_loss: 1.1687e-05 - val_dense_92_loss: 6.5171e-07 - val_dense_93_loss: 2.9467e-06 - val_dense_94_loss: 6.4976e-07 - val_dense_95_loss: 2.1167e-06 - val_dense_96_loss: 1.0931e-06 - val_dense_97_loss: 1.5147e-06 - val_dense_98_loss: 1.1830e-06 - val_dense_99_loss: 1.5311e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.1467e-05 - dense_92_loss: 6.0112e-07 - dense_93_loss: 3.0675e-06 - dense_94_loss: 5.5145e-07 - dense_95_loss: 2.1879e-06 - dense_96_loss: 1.0238e-06 - dense_97_loss: 1.4831e-06 - dense_98_loss: 1.0768e-06 - dense_99_loss: 1.4757e-06 - val_loss: 1.1038e-05 - val_dense_92_loss: 5.6541e-07 - val_dense_93_loss: 2.8655e-06 - val_dense_94_loss: 5.4393e-07 - val_dense_95_loss: 2.0479e-06 - val_dense_96_loss: 1.0193e-06 - val_dense_97_loss: 1.4577e-06 - val_dense_98_loss: 1.0975e-06 - val_dense_99_loss: 1.4408e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1721e-05 - dense_92_loss: 6.3194e-07 - dense_93_loss: 3.0758e-06 - dense_94_loss: 5.7381e-07 - dense_95_loss: 2.2146e-06 - dense_96_loss: 1.0600e-06 - dense_97_loss: 1.5303e-06 - dense_98_loss: 1.1051e-06 - dense_99_loss: 1.5297e-06 - val_loss: 1.0746e-05 - val_dense_92_loss: 5.5221e-07 - val_dense_93_loss: 2.8364e-06 - val_dense_94_loss: 5.1834e-07 - val_dense_95_loss: 2.0158e-06 - val_dense_96_loss: 1.0093e-06 - val_dense_97_loss: 1.3843e-06 - val_dense_98_loss: 1.0653e-06 - val_dense_99_loss: 1.3642e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.4130e-05 - dense_92_loss: 9.5819e-07 - dense_93_loss: 3.3302e-06 - dense_94_loss: 8.8564e-07 - dense_95_loss: 2.5254e-06 - dense_96_loss: 1.3955e-06 - dense_97_loss: 1.8316e-06 - dense_98_loss: 1.3475e-06 - dense_99_loss: 1.8561e-06 - val_loss: 1.1042e-05 - val_dense_92_loss: 5.6401e-07 - val_dense_93_loss: 2.9298e-06 - val_dense_94_loss: 5.3468e-07 - val_dense_95_loss: 2.1023e-06 - val_dense_96_loss: 1.0122e-06 - val_dense_97_loss: 1.4670e-06 - val_dense_98_loss: 1.0504e-06 - val_dense_99_loss: 1.3816e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1864e-05 - dense_92_loss: 6.7360e-07 - dense_93_loss: 3.0185e-06 - dense_94_loss: 6.2409e-07 - dense_95_loss: 2.2335e-06 - dense_96_loss: 1.1195e-06 - dense_97_loss: 1.5397e-06 - dense_98_loss: 1.1359e-06 - dense_99_loss: 1.5193e-06 - val_loss: 1.1184e-05 - val_dense_92_loss: 5.9804e-07 - val_dense_93_loss: 2.8739e-06 - val_dense_94_loss: 5.9433e-07 - val_dense_95_loss: 2.0721e-06 - val_dense_96_loss: 1.0752e-06 - val_dense_97_loss: 1.4260e-06 - val_dense_98_loss: 1.1205e-06 - val_dense_99_loss: 1.4237e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.5422e-05 - dense_92_loss: 1.0983e-06 - dense_93_loss: 3.5267e-06 - dense_94_loss: 1.0374e-06 - dense_95_loss: 2.7206e-06 - dense_96_loss: 1.5379e-06 - dense_97_loss: 2.0148e-06 - dense_98_loss: 1.4401e-06 - dense_99_loss: 2.0464e-06 - val_loss: 1.0880e-05 - val_dense_92_loss: 5.4441e-07 - val_dense_93_loss: 2.8695e-06 - val_dense_94_loss: 5.0276e-07 - val_dense_95_loss: 2.0628e-06 - val_dense_96_loss: 1.0104e-06 - val_dense_97_loss: 1.4599e-06 - val_dense_98_loss: 1.0508e-06 - val_dense_99_loss: 1.3791e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1166e-05 - dense_92_loss: 5.8686e-07 - dense_93_loss: 2.9210e-06 - dense_94_loss: 5.3913e-07 - dense_95_loss: 2.1457e-06 - dense_96_loss: 1.0292e-06 - dense_97_loss: 1.4450e-06 - dense_98_loss: 1.0695e-06 - dense_99_loss: 1.4292e-06 - val_loss: 1.0868e-05 - val_dense_92_loss: 5.9022e-07 - val_dense_93_loss: 2.8481e-06 - val_dense_94_loss: 5.3043e-07 - val_dense_95_loss: 2.0498e-06 - val_dense_96_loss: 1.0375e-06 - val_dense_97_loss: 1.3881e-06 - val_dense_98_loss: 1.0603e-06 - val_dense_99_loss: 1.3632e-06\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1276e-05 - dense_92_loss: 6.1905e-07 - dense_93_loss: 2.8935e-06 - dense_94_loss: 5.6642e-07 - dense_95_loss: 2.1576e-06 - dense_96_loss: 1.0640e-06 - dense_97_loss: 1.4445e-06 - dense_98_loss: 1.0859e-06 - dense_99_loss: 1.4450e-06 - val_loss: 1.0672e-05 - val_dense_92_loss: 5.4153e-07 - val_dense_93_loss: 2.7584e-06 - val_dense_94_loss: 5.1980e-07 - val_dense_95_loss: 2.0665e-06 - val_dense_96_loss: 1.0291e-06 - val_dense_97_loss: 1.3575e-06 - val_dense_98_loss: 1.0530e-06 - val_dense_99_loss: 1.3457e-06\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2739e-05 - dense_92_loss: 7.9942e-07 - dense_93_loss: 3.1019e-06 - dense_94_loss: 7.3599e-07 - dense_95_loss: 2.3642e-06 - dense_96_loss: 1.2408e-06 - dense_97_loss: 1.6389e-06 - dense_98_loss: 1.2070e-06 - dense_99_loss: 1.6512e-06 - val_loss: 1.0472e-05 - val_dense_92_loss: 5.4703e-07 - val_dense_93_loss: 2.7043e-06 - val_dense_94_loss: 5.1884e-07 - val_dense_95_loss: 1.9787e-06 - val_dense_96_loss: 1.0186e-06 - val_dense_97_loss: 1.3434e-06 - val_dense_98_loss: 1.0504e-06 - val_dense_99_loss: 1.3103e-06\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1278e-05 - dense_92_loss: 6.2973e-07 - dense_93_loss: 2.8612e-06 - dense_94_loss: 5.7363e-07 - dense_95_loss: 2.1529e-06 - dense_96_loss: 1.0775e-06 - dense_97_loss: 1.4464e-06 - dense_98_loss: 1.0972e-06 - dense_99_loss: 1.4397e-06 - val_loss: 1.0454e-05 - val_dense_92_loss: 5.4931e-07 - val_dense_93_loss: 2.6819e-06 - val_dense_94_loss: 5.3963e-07 - val_dense_95_loss: 1.9747e-06 - val_dense_96_loss: 1.0161e-06 - val_dense_97_loss: 1.3441e-06 - val_dense_98_loss: 1.0500e-06 - val_dense_99_loss: 1.2982e-06\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2575e-05 - dense_92_loss: 7.9132e-07 - dense_93_loss: 3.0172e-06 - dense_94_loss: 7.3603e-07 - dense_95_loss: 2.3179e-06 - dense_96_loss: 1.2447e-06 - dense_97_loss: 1.6185e-06 - dense_98_loss: 1.2225e-06 - dense_99_loss: 1.6267e-06 - val_loss: 3.0430e-05 - val_dense_92_loss: 3.2197e-06 - val_dense_93_loss: 5.3477e-06 - val_dense_94_loss: 2.9348e-06 - val_dense_95_loss: 4.3910e-06 - val_dense_96_loss: 3.3610e-06 - val_dense_97_loss: 4.0484e-06 - val_dense_98_loss: 2.9023e-06 - val_dense_99_loss: 4.2251e-06\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 2.2894e-05 - dense_92_loss: 2.0910e-06 - dense_93_loss: 4.3220e-06 - dense_94_loss: 2.0049e-06 - dense_95_loss: 3.6363e-06 - dense_96_loss: 2.5531e-06 - dense_97_loss: 3.0085e-06 - dense_98_loss: 2.1745e-06 - dense_99_loss: 3.1032e-06 - val_loss: 1.0544e-05 - val_dense_92_loss: 5.2523e-07 - val_dense_93_loss: 2.7533e-06 - val_dense_94_loss: 4.9860e-07 - val_dense_95_loss: 2.0172e-06 - val_dense_96_loss: 9.9790e-07 - val_dense_97_loss: 1.3840e-06 - val_dense_98_loss: 1.0589e-06 - val_dense_99_loss: 1.3088e-06\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1909e-05 - dense_92_loss: 7.0727e-07 - dense_93_loss: 2.9309e-06 - dense_94_loss: 6.5574e-07 - dense_95_loss: 2.2325e-06 - dense_96_loss: 1.1534e-06 - dense_97_loss: 1.5410e-06 - dense_98_loss: 1.1529e-06 - dense_99_loss: 1.5355e-06 - val_loss: 1.1324e-05 - val_dense_92_loss: 6.3335e-07 - val_dense_93_loss: 2.7698e-06 - val_dense_94_loss: 6.2742e-07 - val_dense_95_loss: 2.0697e-06 - val_dense_96_loss: 1.1358e-06 - val_dense_97_loss: 1.4592e-06 - val_dense_98_loss: 1.2087e-06 - val_dense_99_loss: 1.4203e-06\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1260e-05 - dense_92_loss: 6.2838e-07 - dense_93_loss: 2.8406e-06 - dense_94_loss: 5.7396e-07 - dense_95_loss: 2.1606e-06 - dense_96_loss: 1.0739e-06 - dense_97_loss: 1.4414e-06 - dense_98_loss: 1.1011e-06 - dense_99_loss: 1.4400e-06 - val_loss: 1.0269e-05 - val_dense_92_loss: 5.1165e-07 - val_dense_93_loss: 2.6489e-06 - val_dense_94_loss: 4.9559e-07 - val_dense_95_loss: 1.9481e-06 - val_dense_96_loss: 1.0066e-06 - val_dense_97_loss: 1.3201e-06 - val_dense_98_loss: 1.0252e-06 - val_dense_99_loss: 1.3128e-06\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0782e-05 - dense_92_loss: 5.5675e-07 - dense_93_loss: 2.7913e-06 - dense_94_loss: 5.0743e-07 - dense_95_loss: 2.0973e-06 - dense_96_loss: 1.0126e-06 - dense_97_loss: 1.3996e-06 - dense_98_loss: 1.0457e-06 - dense_99_loss: 1.3710e-06 - val_loss: 1.0511e-05 - val_dense_92_loss: 5.5655e-07 - val_dense_93_loss: 2.7065e-06 - val_dense_94_loss: 5.0372e-07 - val_dense_95_loss: 2.0332e-06 - val_dense_96_loss: 1.0124e-06 - val_dense_97_loss: 1.3476e-06 - val_dense_98_loss: 1.0448e-06 - val_dense_99_loss: 1.3062e-06\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0978e-05 - dense_92_loss: 5.8574e-07 - dense_93_loss: 2.7844e-06 - dense_94_loss: 5.3816e-07 - dense_95_loss: 2.1316e-06 - dense_96_loss: 1.0459e-06 - dense_97_loss: 1.4225e-06 - dense_98_loss: 1.0806e-06 - dense_99_loss: 1.3892e-06 - val_loss: 1.1148e-05 - val_dense_92_loss: 6.4736e-07 - val_dense_93_loss: 2.6966e-06 - val_dense_94_loss: 6.0690e-07 - val_dense_95_loss: 2.1381e-06 - val_dense_96_loss: 1.1608e-06 - val_dense_97_loss: 1.4161e-06 - val_dense_98_loss: 1.1343e-06 - val_dense_99_loss: 1.3482e-06\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0945e-05 - dense_92_loss: 5.8846e-07 - dense_93_loss: 2.7626e-06 - dense_94_loss: 5.4416e-07 - dense_95_loss: 2.1169e-06 - dense_96_loss: 1.0484e-06 - dense_97_loss: 1.4288e-06 - dense_98_loss: 1.0766e-06 - dense_99_loss: 1.3797e-06 - val_loss: 1.0260e-05 - val_dense_92_loss: 5.2462e-07 - val_dense_93_loss: 2.5931e-06 - val_dense_94_loss: 5.1831e-07 - val_dense_95_loss: 1.9393e-06 - val_dense_96_loss: 1.0353e-06 - val_dense_97_loss: 1.3275e-06 - val_dense_98_loss: 1.0447e-06 - val_dense_99_loss: 1.2767e-06\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0597e-05 - dense_92_loss: 5.7572e-07 - dense_93_loss: 2.6573e-06 - dense_94_loss: 5.1576e-07 - dense_95_loss: 2.0498e-06 - dense_96_loss: 1.0353e-06 - dense_97_loss: 1.3609e-06 - dense_98_loss: 1.0597e-06 - dense_99_loss: 1.3428e-06 - val_loss: 1.0156e-05 - val_dense_92_loss: 5.3454e-07 - val_dense_93_loss: 2.5176e-06 - val_dense_94_loss: 5.1019e-07 - val_dense_95_loss: 1.9037e-06 - val_dense_96_loss: 1.0360e-06 - val_dense_97_loss: 1.3128e-06 - val_dense_98_loss: 1.0682e-06 - val_dense_99_loss: 1.2724e-06\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0439e-05 - dense_92_loss: 5.7502e-07 - dense_93_loss: 2.6038e-06 - dense_94_loss: 5.0423e-07 - dense_95_loss: 2.0070e-06 - dense_96_loss: 1.0384e-06 - dense_97_loss: 1.3326e-06 - dense_98_loss: 1.0559e-06 - dense_99_loss: 1.3220e-06 - val_loss: 1.0988e-05 - val_dense_92_loss: 5.9013e-07 - val_dense_93_loss: 2.8643e-06 - val_dense_94_loss: 5.3603e-07 - val_dense_95_loss: 2.1068e-06 - val_dense_96_loss: 1.0396e-06 - val_dense_97_loss: 1.4609e-06 - val_dense_98_loss: 1.0755e-06 - val_dense_99_loss: 1.3143e-06\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0726e-05 - dense_92_loss: 5.9449e-07 - dense_93_loss: 2.6726e-06 - dense_94_loss: 5.2924e-07 - dense_95_loss: 2.0665e-06 - dense_96_loss: 1.0497e-06 - dense_97_loss: 1.3920e-06 - dense_98_loss: 1.0707e-06 - dense_99_loss: 1.3509e-06 - val_loss: 1.0193e-05 - val_dense_92_loss: 5.6430e-07 - val_dense_93_loss: 2.5349e-06 - val_dense_94_loss: 5.0271e-07 - val_dense_95_loss: 1.9437e-06 - val_dense_96_loss: 1.0334e-06 - val_dense_97_loss: 1.3197e-06 - val_dense_98_loss: 1.0302e-06 - val_dense_99_loss: 1.2639e-06\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0539e-05 - dense_92_loss: 5.9261e-07 - dense_93_loss: 2.5803e-06 - dense_94_loss: 5.3394e-07 - dense_95_loss: 2.0291e-06 - dense_96_loss: 1.0524e-06 - dense_97_loss: 1.3501e-06 - dense_98_loss: 1.0643e-06 - dense_99_loss: 1.3365e-06 - val_loss: 1.0544e-05 - val_dense_92_loss: 6.0911e-07 - val_dense_93_loss: 2.5089e-06 - val_dense_94_loss: 5.6760e-07 - val_dense_95_loss: 1.9344e-06 - val_dense_96_loss: 1.0957e-06 - val_dense_97_loss: 1.3526e-06 - val_dense_98_loss: 1.1432e-06 - val_dense_99_loss: 1.3324e-06\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0854e-05 - dense_92_loss: 6.3924e-07 - dense_93_loss: 2.5980e-06 - dense_94_loss: 5.8475e-07 - dense_95_loss: 2.0414e-06 - dense_96_loss: 1.1078e-06 - dense_97_loss: 1.3781e-06 - dense_98_loss: 1.1157e-06 - dense_99_loss: 1.3892e-06 - val_loss: 9.9640e-06 - val_dense_92_loss: 5.4896e-07 - val_dense_93_loss: 2.4054e-06 - val_dense_94_loss: 5.1725e-07 - val_dense_95_loss: 1.8548e-06 - val_dense_96_loss: 1.0415e-06 - val_dense_97_loss: 1.2769e-06 - val_dense_98_loss: 1.0322e-06 - val_dense_99_loss: 1.2870e-06\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0592e-05 - dense_92_loss: 6.1608e-07 - dense_93_loss: 2.5514e-06 - dense_94_loss: 5.4944e-07 - dense_95_loss: 2.0016e-06 - dense_96_loss: 1.0778e-06 - dense_97_loss: 1.3488e-06 - dense_98_loss: 1.0835e-06 - dense_99_loss: 1.3631e-06 - val_loss: 1.0727e-05 - val_dense_92_loss: 6.9345e-07 - val_dense_93_loss: 2.4737e-06 - val_dense_94_loss: 5.8987e-07 - val_dense_95_loss: 1.9329e-06 - val_dense_96_loss: 1.1272e-06 - val_dense_97_loss: 1.3832e-06 - val_dense_98_loss: 1.1858e-06 - val_dense_99_loss: 1.3405e-06\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2870e-05 - dense_92_loss: 9.0240e-07 - dense_93_loss: 2.8172e-06 - dense_94_loss: 8.3701e-07 - dense_95_loss: 2.2925e-06 - dense_96_loss: 1.3638e-06 - dense_97_loss: 1.6593e-06 - dense_98_loss: 1.3168e-06 - dense_99_loss: 1.6806e-06 - val_loss: 1.0322e-05 - val_dense_92_loss: 5.7100e-07 - val_dense_93_loss: 2.4677e-06 - val_dense_94_loss: 5.2187e-07 - val_dense_95_loss: 1.9873e-06 - val_dense_96_loss: 1.0815e-06 - val_dense_97_loss: 1.3033e-06 - val_dense_98_loss: 1.0755e-06 - val_dense_99_loss: 1.3140e-06\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0774e-05 - dense_92_loss: 6.6062e-07 - dense_93_loss: 2.4977e-06 - dense_94_loss: 5.9863e-07 - dense_95_loss: 2.0292e-06 - dense_96_loss: 1.1231e-06 - dense_97_loss: 1.3675e-06 - dense_98_loss: 1.1255e-06 - dense_99_loss: 1.3713e-06 - val_loss: 1.0593e-05 - val_dense_92_loss: 6.6349e-07 - val_dense_93_loss: 2.4210e-06 - val_dense_94_loss: 6.0680e-07 - val_dense_95_loss: 1.9314e-06 - val_dense_96_loss: 1.1396e-06 - val_dense_97_loss: 1.3576e-06 - val_dense_98_loss: 1.1319e-06 - val_dense_99_loss: 1.3411e-06\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0457e-05 - dense_92_loss: 6.2826e-07 - dense_93_loss: 2.4569e-06 - dense_94_loss: 5.5937e-07 - dense_95_loss: 1.9643e-06 - dense_96_loss: 1.0819e-06 - dense_97_loss: 1.3266e-06 - dense_98_loss: 1.0934e-06 - dense_99_loss: 1.3464e-06 - val_loss: 1.0027e-05 - val_dense_92_loss: 6.1039e-07 - val_dense_93_loss: 2.3073e-06 - val_dense_94_loss: 5.3581e-07 - val_dense_95_loss: 1.8377e-06 - val_dense_96_loss: 1.0974e-06 - val_dense_97_loss: 1.2731e-06 - val_dense_98_loss: 1.1302e-06 - val_dense_99_loss: 1.2354e-06\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0950e-05 - dense_92_loss: 6.8888e-07 - dense_93_loss: 2.4952e-06 - dense_94_loss: 6.2018e-07 - dense_95_loss: 2.0344e-06 - dense_96_loss: 1.1647e-06 - dense_97_loss: 1.4104e-06 - dense_98_loss: 1.1576e-06 - dense_99_loss: 1.3786e-06 - val_loss: 1.0677e-05 - val_dense_92_loss: 6.8455e-07 - val_dense_93_loss: 2.3669e-06 - val_dense_94_loss: 6.4546e-07 - val_dense_95_loss: 1.8618e-06 - val_dense_96_loss: 1.1664e-06 - val_dense_97_loss: 1.3664e-06 - val_dense_98_loss: 1.2207e-06 - val_dense_99_loss: 1.3651e-06\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0431e-05 - dense_92_loss: 6.4013e-07 - dense_93_loss: 2.3995e-06 - dense_94_loss: 5.6185e-07 - dense_95_loss: 1.9618e-06 - dense_96_loss: 1.1007e-06 - dense_97_loss: 1.3457e-06 - dense_98_loss: 1.1024e-06 - dense_99_loss: 1.3192e-06 - val_loss: 1.0080e-05 - val_dense_92_loss: 6.0632e-07 - val_dense_93_loss: 2.2932e-06 - val_dense_94_loss: 5.6322e-07 - val_dense_95_loss: 1.7858e-06 - val_dense_96_loss: 1.1202e-06 - val_dense_97_loss: 1.3062e-06 - val_dense_98_loss: 1.1108e-06 - val_dense_99_loss: 1.2945e-06\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0511e-05 - dense_92_loss: 6.6249e-07 - dense_93_loss: 2.3581e-06 - dense_94_loss: 5.8889e-07 - dense_95_loss: 1.9484e-06 - dense_96_loss: 1.1329e-06 - dense_97_loss: 1.3287e-06 - dense_98_loss: 1.1255e-06 - dense_99_loss: 1.3664e-06 - val_loss: 1.0428e-05 - val_dense_92_loss: 6.6208e-07 - val_dense_93_loss: 2.2850e-06 - val_dense_94_loss: 5.8972e-07 - val_dense_95_loss: 1.8165e-06 - val_dense_96_loss: 1.1428e-06 - val_dense_97_loss: 1.3387e-06 - val_dense_98_loss: 1.1616e-06 - val_dense_99_loss: 1.4321e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0194e-05 - dense_92_loss: 6.1958e-07 - dense_93_loss: 2.3324e-06 - dense_94_loss: 5.4176e-07 - dense_95_loss: 1.9119e-06 - dense_96_loss: 1.0881e-06 - dense_97_loss: 1.3092e-06 - dense_98_loss: 1.0870e-06 - dense_99_loss: 1.3038e-06 - val_loss: 1.0035e-05 - val_dense_92_loss: 6.1430e-07 - val_dense_93_loss: 2.2160e-06 - val_dense_94_loss: 5.8460e-07 - val_dense_95_loss: 1.7713e-06 - val_dense_96_loss: 1.1045e-06 - val_dense_97_loss: 1.3123e-06 - val_dense_98_loss: 1.1477e-06 - val_dense_99_loss: 1.2844e-06\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1275e-05 - dense_92_loss: 7.8158e-07 - dense_93_loss: 2.3910e-06 - dense_94_loss: 7.0450e-07 - dense_95_loss: 2.0230e-06 - dense_96_loss: 1.2551e-06 - dense_97_loss: 1.4396e-06 - dense_98_loss: 1.2122e-06 - dense_99_loss: 1.4676e-06 - val_loss: 1.1706e-05 - val_dense_92_loss: 7.6454e-07 - val_dense_93_loss: 2.5133e-06 - val_dense_94_loss: 6.9054e-07 - val_dense_95_loss: 2.0686e-06 - val_dense_96_loss: 1.3265e-06 - val_dense_97_loss: 1.5795e-06 - val_dense_98_loss: 1.2510e-06 - val_dense_99_loss: 1.5123e-06\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0253e-05 - dense_92_loss: 6.7209e-07 - dense_93_loss: 2.2552e-06 - dense_94_loss: 5.8969e-07 - dense_95_loss: 1.8696e-06 - dense_96_loss: 1.1390e-06 - dense_97_loss: 1.3070e-06 - dense_98_loss: 1.1208e-06 - dense_99_loss: 1.2994e-06 - val_loss: 9.4516e-06 - val_dense_92_loss: 5.8347e-07 - val_dense_93_loss: 2.0877e-06 - val_dense_94_loss: 5.0739e-07 - val_dense_95_loss: 1.6943e-06 - val_dense_96_loss: 1.0722e-06 - val_dense_97_loss: 1.1890e-06 - val_dense_98_loss: 1.0982e-06 - val_dense_99_loss: 1.2194e-06\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0161e-05 - dense_92_loss: 6.7452e-07 - dense_93_loss: 2.2068e-06 - dense_94_loss: 5.8251e-07 - dense_95_loss: 1.8666e-06 - dense_96_loss: 1.1296e-06 - dense_97_loss: 1.2662e-06 - dense_98_loss: 1.1359e-06 - dense_99_loss: 1.2986e-06 - val_loss: 9.2220e-06 - val_dense_92_loss: 6.1688e-07 - val_dense_93_loss: 2.0002e-06 - val_dense_94_loss: 5.0617e-07 - val_dense_95_loss: 1.6657e-06 - val_dense_96_loss: 1.0563e-06 - val_dense_97_loss: 1.1484e-06 - val_dense_98_loss: 1.0692e-06 - val_dense_99_loss: 1.1591e-06\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.5663e-06 - dense_92_loss: 6.2346e-07 - dense_93_loss: 2.0786e-06 - dense_94_loss: 5.2466e-07 - dense_95_loss: 1.7676e-06 - dense_96_loss: 1.0722e-06 - dense_97_loss: 1.1890e-06 - dense_98_loss: 1.0913e-06 - dense_99_loss: 1.2196e-06 - val_loss: 9.0189e-06 - val_dense_92_loss: 5.7968e-07 - val_dense_93_loss: 1.9417e-06 - val_dense_94_loss: 5.0353e-07 - val_dense_95_loss: 1.6183e-06 - val_dense_96_loss: 1.0450e-06 - val_dense_97_loss: 1.1109e-06 - val_dense_98_loss: 1.0696e-06 - val_dense_99_loss: 1.1502e-06\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.2340e-06 - dense_92_loss: 5.9471e-07 - dense_93_loss: 1.9793e-06 - dense_94_loss: 5.0726e-07 - dense_95_loss: 1.7046e-06 - dense_96_loss: 1.0528e-06 - dense_97_loss: 1.1571e-06 - dense_98_loss: 1.0650e-06 - dense_99_loss: 1.1732e-06 - val_loss: 8.9622e-06 - val_dense_92_loss: 5.5476e-07 - val_dense_93_loss: 1.9339e-06 - val_dense_94_loss: 4.9561e-07 - val_dense_95_loss: 1.5835e-06 - val_dense_96_loss: 1.0416e-06 - val_dense_97_loss: 1.1376e-06 - val_dense_98_loss: 1.0843e-06 - val_dense_99_loss: 1.1310e-06\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 9.9731e-06 - dense_92_loss: 6.9636e-07 - dense_93_loss: 2.0356e-06 - dense_94_loss: 6.2496e-07 - dense_95_loss: 1.7684e-06 - dense_96_loss: 1.1689e-06 - dense_97_loss: 1.2480e-06 - dense_98_loss: 1.1487e-06 - dense_99_loss: 1.2822e-06 - val_loss: 1.8086e-05 - val_dense_92_loss: 1.5355e-06 - val_dense_93_loss: 3.2439e-06 - val_dense_94_loss: 1.5964e-06 - val_dense_95_loss: 2.7900e-06 - val_dense_96_loss: 2.2366e-06 - val_dense_97_loss: 2.3721e-06 - val_dense_98_loss: 1.9111e-06 - val_dense_99_loss: 2.4001e-06\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3976e-05 - dense_92_loss: 1.1549e-06 - dense_93_loss: 2.6113e-06 - dense_94_loss: 1.0840e-06 - dense_95_loss: 2.3438e-06 - dense_96_loss: 1.6205e-06 - dense_97_loss: 1.8114e-06 - dense_98_loss: 1.5131e-06 - dense_99_loss: 1.8374e-06 - val_loss: 1.3155e-05 - val_dense_92_loss: 1.0734e-06 - val_dense_93_loss: 2.4871e-06 - val_dense_94_loss: 9.9689e-07 - val_dense_95_loss: 2.1028e-06 - val_dense_96_loss: 1.5171e-06 - val_dense_97_loss: 1.6232e-06 - val_dense_98_loss: 1.5228e-06 - val_dense_99_loss: 1.8319e-06\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 9.9238e-06 - dense_92_loss: 6.8225e-07 - dense_93_loss: 2.0170e-06 - dense_94_loss: 6.0684e-07 - dense_95_loss: 1.7992e-06 - dense_96_loss: 1.1334e-06 - dense_97_loss: 1.2436e-06 - dense_98_loss: 1.1507e-06 - dense_99_loss: 1.2908e-06 - val_loss: 9.1175e-06 - val_dense_92_loss: 6.0614e-07 - val_dense_93_loss: 1.9336e-06 - val_dense_94_loss: 5.3901e-07 - val_dense_95_loss: 1.6122e-06 - val_dense_96_loss: 1.0580e-06 - val_dense_97_loss: 1.1274e-06 - val_dense_98_loss: 1.0595e-06 - val_dense_99_loss: 1.1816e-06\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.0063e-06 - dense_92_loss: 6.1757e-07 - dense_93_loss: 1.8454e-06 - dense_94_loss: 5.1108e-07 - dense_95_loss: 1.6348e-06 - dense_96_loss: 1.0533e-06 - dense_97_loss: 1.1177e-06 - dense_98_loss: 1.0633e-06 - dense_99_loss: 1.1632e-06 - val_loss: 9.3757e-06 - val_dense_92_loss: 6.3350e-07 - val_dense_93_loss: 1.8747e-06 - val_dense_94_loss: 5.3912e-07 - val_dense_95_loss: 1.7105e-06 - val_dense_96_loss: 1.1996e-06 - val_dense_97_loss: 1.1574e-06 - val_dense_98_loss: 1.0990e-06 - val_dense_99_loss: 1.1619e-06\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.2102e-06 - dense_92_loss: 6.4200e-07 - dense_93_loss: 1.8269e-06 - dense_94_loss: 5.3678e-07 - dense_95_loss: 1.6527e-06 - dense_96_loss: 1.1310e-06 - dense_97_loss: 1.1219e-06 - dense_98_loss: 1.1045e-06 - dense_99_loss: 1.1944e-06 - val_loss: 8.7250e-06 - val_dense_92_loss: 5.8783e-07 - val_dense_93_loss: 1.6922e-06 - val_dense_94_loss: 5.1881e-07 - val_dense_95_loss: 1.4807e-06 - val_dense_96_loss: 1.1283e-06 - val_dense_97_loss: 1.0778e-06 - val_dense_98_loss: 1.1449e-06 - val_dense_99_loss: 1.0945e-06\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 8.4640e-06 - dense_92_loss: 5.9160e-07 - dense_93_loss: 1.6582e-06 - dense_94_loss: 4.9129e-07 - dense_95_loss: 1.4869e-06 - dense_96_loss: 1.0249e-06 - dense_97_loss: 1.0403e-06 - dense_98_loss: 1.0769e-06 - dense_99_loss: 1.0939e-06 - val_loss: 8.2385e-06 - val_dense_92_loss: 5.9408e-07 - val_dense_93_loss: 1.5905e-06 - val_dense_94_loss: 4.9562e-07 - val_dense_95_loss: 1.3988e-06 - val_dense_96_loss: 1.0308e-06 - val_dense_97_loss: 1.0236e-06 - val_dense_98_loss: 1.0602e-06 - val_dense_99_loss: 1.0450e-06\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 8.3364e-06 - dense_92_loss: 5.8527e-07 - dense_93_loss: 1.5951e-06 - dense_94_loss: 5.0361e-07 - dense_95_loss: 1.4586e-06 - dense_96_loss: 1.0272e-06 - dense_97_loss: 1.0318e-06 - dense_98_loss: 1.0557e-06 - dense_99_loss: 1.0792e-06 - val_loss: 8.1203e-06 - val_dense_92_loss: 6.0161e-07 - val_dense_93_loss: 1.4971e-06 - val_dense_94_loss: 4.8427e-07 - val_dense_95_loss: 1.3720e-06 - val_dense_96_loss: 1.0382e-06 - val_dense_97_loss: 1.0005e-06 - val_dense_98_loss: 1.0739e-06 - val_dense_99_loss: 1.0527e-06\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 8.3962e-06 - dense_92_loss: 6.1408e-07 - dense_93_loss: 1.5646e-06 - dense_94_loss: 5.2160e-07 - dense_95_loss: 1.4425e-06 - dense_96_loss: 1.0628e-06 - dense_97_loss: 1.0267e-06 - dense_98_loss: 1.0768e-06 - dense_99_loss: 1.0871e-06 - val_loss: 8.3106e-06 - val_dense_92_loss: 5.5608e-07 - val_dense_93_loss: 1.5204e-06 - val_dense_94_loss: 5.0543e-07 - val_dense_95_loss: 1.4103e-06 - val_dense_96_loss: 1.1254e-06 - val_dense_97_loss: 1.0187e-06 - val_dense_98_loss: 1.1023e-06 - val_dense_99_loss: 1.0719e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 8.3012e-06 - dense_92_loss: 6.0190e-07 - dense_93_loss: 1.5043e-06 - dense_94_loss: 5.2667e-07 - dense_95_loss: 1.4187e-06 - dense_96_loss: 1.0526e-06 - dense_97_loss: 1.0229e-06 - dense_98_loss: 1.0842e-06 - dense_99_loss: 1.0899e-06 - val_loss: 7.7580e-06 - val_dense_92_loss: 5.4366e-07 - val_dense_93_loss: 1.4081e-06 - val_dense_94_loss: 4.7484e-07 - val_dense_95_loss: 1.3042e-06 - val_dense_96_loss: 1.0024e-06 - val_dense_97_loss: 9.4991e-07 - val_dense_98_loss: 1.0351e-06 - val_dense_99_loss: 1.0398e-06\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 9.5234e-06 - dense_92_loss: 7.5293e-07 - dense_93_loss: 1.6650e-06 - dense_94_loss: 6.7297e-07 - dense_95_loss: 1.5677e-06 - dense_96_loss: 1.1952e-06 - dense_97_loss: 1.1912e-06 - dense_98_loss: 1.2022e-06 - dense_99_loss: 1.2761e-06 - val_loss: 8.6119e-06 - val_dense_92_loss: 6.3665e-07 - val_dense_93_loss: 1.4829e-06 - val_dense_94_loss: 5.9996e-07 - val_dense_95_loss: 1.4026e-06 - val_dense_96_loss: 1.0857e-06 - val_dense_97_loss: 1.1111e-06 - val_dense_98_loss: 1.2106e-06 - val_dense_99_loss: 1.0824e-06\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 8.3471e-06 - dense_92_loss: 6.1988e-07 - dense_93_loss: 1.4434e-06 - dense_94_loss: 5.6340e-07 - dense_95_loss: 1.3822e-06 - dense_96_loss: 1.0617e-06 - dense_97_loss: 1.0520e-06 - dense_98_loss: 1.1023e-06 - dense_99_loss: 1.1222e-06 - val_loss: 8.2912e-06 - val_dense_92_loss: 5.8206e-07 - val_dense_93_loss: 1.5679e-06 - val_dense_94_loss: 4.7944e-07 - val_dense_95_loss: 1.4302e-06 - val_dense_96_loss: 1.0126e-06 - val_dense_97_loss: 9.9974e-07 - val_dense_98_loss: 1.0619e-06 - val_dense_99_loss: 1.1574e-06\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.8335e-06 - dense_92_loss: 5.7723e-07 - dense_93_loss: 1.3558e-06 - dense_94_loss: 5.0597e-07 - dense_95_loss: 1.2976e-06 - dense_96_loss: 1.0181e-06 - dense_97_loss: 9.5878e-07 - dense_98_loss: 1.0614e-06 - dense_99_loss: 1.0585e-06 - val_loss: 7.8230e-06 - val_dense_92_loss: 5.7125e-07 - val_dense_93_loss: 1.2578e-06 - val_dense_94_loss: 5.4939e-07 - val_dense_95_loss: 1.2841e-06 - val_dense_96_loss: 1.0145e-06 - val_dense_97_loss: 9.1462e-07 - val_dense_98_loss: 1.1724e-06 - val_dense_99_loss: 1.0590e-06\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.5452e-06 - dense_92_loss: 5.4893e-07 - dense_93_loss: 1.2823e-06 - dense_94_loss: 4.9666e-07 - dense_95_loss: 1.2443e-06 - dense_96_loss: 9.8034e-07 - dense_97_loss: 9.3364e-07 - dense_98_loss: 1.0342e-06 - dense_99_loss: 1.0248e-06 - val_loss: 8.0469e-06 - val_dense_92_loss: 5.8956e-07 - val_dense_93_loss: 1.3049e-06 - val_dense_94_loss: 5.6933e-07 - val_dense_95_loss: 1.2234e-06 - val_dense_96_loss: 1.1509e-06 - val_dense_97_loss: 9.9235e-07 - val_dense_98_loss: 1.1183e-06 - val_dense_99_loss: 1.0982e-06\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.5821e-06 - dense_92_loss: 5.5655e-07 - dense_93_loss: 1.2471e-06 - dense_94_loss: 5.1457e-07 - dense_95_loss: 1.2271e-06 - dense_96_loss: 1.0036e-06 - dense_97_loss: 9.3440e-07 - dense_98_loss: 1.0646e-06 - dense_99_loss: 1.0342e-06 - val_loss: 7.2581e-06 - val_dense_92_loss: 5.0923e-07 - val_dense_93_loss: 1.1774e-06 - val_dense_94_loss: 5.1956e-07 - val_dense_95_loss: 1.1237e-06 - val_dense_96_loss: 9.6530e-07 - val_dense_97_loss: 9.3089e-07 - val_dense_98_loss: 1.0617e-06 - val_dense_99_loss: 9.7035e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.4412e-06 - dense_92_loss: 5.4487e-07 - dense_93_loss: 1.2177e-06 - dense_94_loss: 4.9601e-07 - dense_95_loss: 1.2011e-06 - dense_96_loss: 9.7806e-07 - dense_97_loss: 9.2146e-07 - dense_98_loss: 1.0512e-06 - dense_99_loss: 1.0309e-06 - val_loss: 7.1851e-06 - val_dense_92_loss: 5.1860e-07 - val_dense_93_loss: 1.1242e-06 - val_dense_94_loss: 5.1112e-07 - val_dense_95_loss: 1.0835e-06 - val_dense_96_loss: 9.6818e-07 - val_dense_97_loss: 8.9589e-07 - val_dense_98_loss: 1.0675e-06 - val_dense_99_loss: 1.0161e-06\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 7.3829e-06 - dense_92_loss: 5.5487e-07 - dense_93_loss: 1.1511e-06 - dense_94_loss: 5.2176e-07 - dense_95_loss: 1.1656e-06 - dense_96_loss: 9.8587e-07 - dense_97_loss: 9.2687e-07 - dense_98_loss: 1.0560e-06 - dense_99_loss: 1.0208e-06 - val_loss: 8.5890e-06 - val_dense_92_loss: 5.9650e-07 - val_dense_93_loss: 1.5017e-06 - val_dense_94_loss: 5.7479e-07 - val_dense_95_loss: 1.4027e-06 - val_dense_96_loss: 1.1250e-06 - val_dense_97_loss: 1.1316e-06 - val_dense_98_loss: 1.0580e-06 - val_dense_99_loss: 1.1987e-06\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 8.0145e-06 - dense_92_loss: 6.2512e-07 - dense_93_loss: 1.2532e-06 - dense_94_loss: 5.9635e-07 - dense_95_loss: 1.2343e-06 - dense_96_loss: 1.0559e-06 - dense_97_loss: 1.0128e-06 - dense_98_loss: 1.1095e-06 - dense_99_loss: 1.1273e-06 - val_loss: 6.9105e-06 - val_dense_92_loss: 4.5926e-07 - val_dense_93_loss: 1.1513e-06 - val_dense_94_loss: 4.7855e-07 - val_dense_95_loss: 1.0692e-06 - val_dense_96_loss: 9.2646e-07 - val_dense_97_loss: 8.8931e-07 - val_dense_98_loss: 1.0049e-06 - val_dense_99_loss: 9.3150e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.3594e-06 - dense_92_loss: 5.4191e-07 - dense_93_loss: 1.1394e-06 - dense_94_loss: 5.3819e-07 - dense_95_loss: 1.1416e-06 - dense_96_loss: 9.5853e-07 - dense_97_loss: 9.4629e-07 - dense_98_loss: 1.0574e-06 - dense_99_loss: 1.0361e-06 - val_loss: 9.8128e-06 - val_dense_92_loss: 7.9809e-07 - val_dense_93_loss: 1.4486e-06 - val_dense_94_loss: 9.7340e-07 - val_dense_95_loss: 1.3721e-06 - val_dense_96_loss: 1.2058e-06 - val_dense_97_loss: 1.2167e-06 - val_dense_98_loss: 1.4152e-06 - val_dense_99_loss: 1.3829e-06\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.5324e-06 - dense_92_loss: 5.4768e-07 - dense_93_loss: 1.1418e-06 - dense_94_loss: 5.6717e-07 - dense_95_loss: 1.1516e-06 - dense_96_loss: 9.9652e-07 - dense_97_loss: 9.6513e-07 - dense_98_loss: 1.0771e-06 - dense_99_loss: 1.0854e-06 - val_loss: 6.3428e-06 - val_dense_92_loss: 4.1302e-07 - val_dense_93_loss: 9.6563e-07 - val_dense_94_loss: 4.4233e-07 - val_dense_95_loss: 9.3909e-07 - val_dense_96_loss: 8.7779e-07 - val_dense_97_loss: 8.0402e-07 - val_dense_98_loss: 9.9402e-07 - val_dense_99_loss: 9.0687e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.5709e-06 - dense_92_loss: 4.6613e-07 - dense_93_loss: 9.5665e-07 - dense_94_loss: 4.6523e-07 - dense_95_loss: 9.9229e-07 - dense_96_loss: 9.0563e-07 - dense_97_loss: 8.4475e-07 - dense_98_loss: 1.0026e-06 - dense_99_loss: 9.3755e-07 - val_loss: 6.8259e-06 - val_dense_92_loss: 4.8912e-07 - val_dense_93_loss: 9.9118e-07 - val_dense_94_loss: 4.9801e-07 - val_dense_95_loss: 9.8577e-07 - val_dense_96_loss: 9.2624e-07 - val_dense_97_loss: 9.3473e-07 - val_dense_98_loss: 9.9738e-07 - val_dense_99_loss: 1.0034e-06\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.7445e-06 - dense_92_loss: 4.8970e-07 - dense_93_loss: 9.8534e-07 - dense_94_loss: 4.8100e-07 - dense_95_loss: 1.0066e-06 - dense_96_loss: 9.2600e-07 - dense_97_loss: 8.7847e-07 - dense_98_loss: 9.9974e-07 - dense_99_loss: 9.7766e-07 - val_loss: 8.0392e-06 - val_dense_92_loss: 6.7553e-07 - val_dense_93_loss: 1.0082e-06 - val_dense_94_loss: 7.6763e-07 - val_dense_95_loss: 1.0333e-06 - val_dense_96_loss: 1.0998e-06 - val_dense_97_loss: 1.0014e-06 - val_dense_98_loss: 1.2044e-06 - val_dense_99_loss: 1.2488e-06\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.3851e-06 - dense_92_loss: 5.4845e-07 - dense_93_loss: 1.0778e-06 - dense_94_loss: 5.5996e-07 - dense_95_loss: 1.0981e-06 - dense_96_loss: 9.7271e-07 - dense_97_loss: 9.8427e-07 - dense_98_loss: 1.0645e-06 - dense_99_loss: 1.0794e-06 - val_loss: 6.4266e-06 - val_dense_92_loss: 4.6333e-07 - val_dense_93_loss: 9.0523e-07 - val_dense_94_loss: 4.9553e-07 - val_dense_95_loss: 9.1871e-07 - val_dense_96_loss: 8.9042e-07 - val_dense_97_loss: 8.6157e-07 - val_dense_98_loss: 9.6657e-07 - val_dense_99_loss: 9.2519e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.6585e-06 - dense_92_loss: 4.6908e-07 - dense_93_loss: 9.5111e-07 - dense_94_loss: 4.9981e-07 - dense_95_loss: 9.7093e-07 - dense_96_loss: 9.0824e-07 - dense_97_loss: 8.8061e-07 - dense_98_loss: 9.9899e-07 - dense_99_loss: 9.7972e-07 - val_loss: 6.5469e-06 - val_dense_92_loss: 4.5427e-07 - val_dense_93_loss: 9.0998e-07 - val_dense_94_loss: 4.9508e-07 - val_dense_95_loss: 9.2679e-07 - val_dense_96_loss: 8.8226e-07 - val_dense_97_loss: 8.4507e-07 - val_dense_98_loss: 1.0642e-06 - val_dense_99_loss: 9.6930e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.4888e-06 - dense_92_loss: 4.6290e-07 - dense_93_loss: 9.1525e-07 - dense_94_loss: 4.7313e-07 - dense_95_loss: 9.3833e-07 - dense_96_loss: 8.9026e-07 - dense_97_loss: 8.5034e-07 - dense_98_loss: 9.9966e-07 - dense_99_loss: 9.5890e-07 - val_loss: 7.3133e-06 - val_dense_92_loss: 5.1785e-07 - val_dense_93_loss: 9.5117e-07 - val_dense_94_loss: 6.5056e-07 - val_dense_95_loss: 9.8585e-07 - val_dense_96_loss: 1.0626e-06 - val_dense_97_loss: 8.9853e-07 - val_dense_98_loss: 1.1378e-06 - val_dense_99_loss: 1.1089e-06\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.4626e-06 - dense_92_loss: 4.7262e-07 - dense_93_loss: 8.6604e-07 - dense_94_loss: 4.8813e-07 - dense_95_loss: 9.1733e-07 - dense_96_loss: 9.0471e-07 - dense_97_loss: 8.5466e-07 - dense_98_loss: 1.0170e-06 - dense_99_loss: 9.4210e-07 - val_loss: 5.8683e-06 - val_dense_92_loss: 4.3498e-07 - val_dense_93_loss: 7.6052e-07 - val_dense_94_loss: 4.3528e-07 - val_dense_95_loss: 7.9992e-07 - val_dense_96_loss: 8.4960e-07 - val_dense_97_loss: 7.7817e-07 - val_dense_98_loss: 9.3196e-07 - val_dense_99_loss: 8.7789e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.0448e-06 - dense_92_loss: 4.3590e-07 - dense_93_loss: 8.0092e-07 - dense_94_loss: 4.4624e-07 - dense_95_loss: 8.4238e-07 - dense_96_loss: 8.5488e-07 - dense_97_loss: 8.0266e-07 - dense_98_loss: 9.5668e-07 - dense_99_loss: 9.0515e-07 - val_loss: 6.0803e-06 - val_dense_92_loss: 4.3086e-07 - val_dense_93_loss: 7.8882e-07 - val_dense_94_loss: 4.2766e-07 - val_dense_95_loss: 8.1956e-07 - val_dense_96_loss: 9.0576e-07 - val_dense_97_loss: 8.1623e-07 - val_dense_98_loss: 9.7837e-07 - val_dense_99_loss: 9.1306e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.5918e-06 - dense_92_loss: 4.5491e-07 - dense_93_loss: 9.3460e-07 - dense_94_loss: 4.9829e-07 - dense_95_loss: 9.2876e-07 - dense_96_loss: 9.1310e-07 - dense_97_loss: 8.9088e-07 - dense_98_loss: 9.8842e-07 - dense_99_loss: 9.8283e-07 - val_loss: 6.0404e-06 - val_dense_92_loss: 4.2562e-07 - val_dense_93_loss: 7.6658e-07 - val_dense_94_loss: 4.3141e-07 - val_dense_95_loss: 8.0909e-07 - val_dense_96_loss: 8.9519e-07 - val_dense_97_loss: 7.9406e-07 - val_dense_98_loss: 9.6081e-07 - val_dense_99_loss: 9.5759e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.6381e-06 - dense_92_loss: 4.7181e-07 - dense_93_loss: 8.8929e-07 - dense_94_loss: 5.1864e-07 - dense_95_loss: 9.2510e-07 - dense_96_loss: 9.2600e-07 - dense_97_loss: 8.9662e-07 - dense_98_loss: 1.0142e-06 - dense_99_loss: 9.9644e-07 - val_loss: 5.8262e-06 - val_dense_92_loss: 3.8506e-07 - val_dense_93_loss: 7.9733e-07 - val_dense_94_loss: 4.5444e-07 - val_dense_95_loss: 7.8107e-07 - val_dense_96_loss: 8.1979e-07 - val_dense_97_loss: 7.7127e-07 - val_dense_98_loss: 9.4644e-07 - val_dense_99_loss: 8.7082e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.6785e-06 - dense_92_loss: 5.0121e-07 - dense_93_loss: 8.9427e-07 - dense_94_loss: 5.3800e-07 - dense_95_loss: 9.3088e-07 - dense_96_loss: 9.1871e-07 - dense_97_loss: 8.9274e-07 - dense_98_loss: 1.0198e-06 - dense_99_loss: 9.8288e-07 - val_loss: 7.0144e-06 - val_dense_92_loss: 4.8654e-07 - val_dense_93_loss: 1.0269e-06 - val_dense_94_loss: 4.9975e-07 - val_dense_95_loss: 9.7185e-07 - val_dense_96_loss: 1.0453e-06 - val_dense_97_loss: 9.3887e-07 - val_dense_98_loss: 1.0661e-06 - val_dense_99_loss: 9.7901e-07\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.0914e-06 - dense_92_loss: 4.2654e-07 - dense_93_loss: 8.0553e-07 - dense_94_loss: 4.6390e-07 - dense_95_loss: 8.2490e-07 - dense_96_loss: 8.7890e-07 - dense_97_loss: 8.2167e-07 - dense_98_loss: 9.6924e-07 - dense_99_loss: 9.0068e-07 - val_loss: 5.9985e-06 - val_dense_92_loss: 4.0813e-07 - val_dense_93_loss: 7.9054e-07 - val_dense_94_loss: 5.2346e-07 - val_dense_95_loss: 7.7791e-07 - val_dense_96_loss: 8.3846e-07 - val_dense_97_loss: 8.0648e-07 - val_dense_98_loss: 9.8974e-07 - val_dense_99_loss: 8.6378e-07\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.8142e-06 - dense_92_loss: 4.0293e-07 - dense_93_loss: 7.5246e-07 - dense_94_loss: 4.4801e-07 - dense_95_loss: 7.9573e-07 - dense_96_loss: 8.3962e-07 - dense_97_loss: 7.8117e-07 - dense_98_loss: 9.4590e-07 - dense_99_loss: 8.4843e-07 - val_loss: 5.7025e-06 - val_dense_92_loss: 3.7264e-07 - val_dense_93_loss: 7.0286e-07 - val_dense_94_loss: 4.3696e-07 - val_dense_95_loss: 7.5191e-07 - val_dense_96_loss: 8.5163e-07 - val_dense_97_loss: 7.6044e-07 - val_dense_98_loss: 9.6890e-07 - val_dense_99_loss: 8.5721e-07\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.8836e-06 - dense_92_loss: 3.9842e-07 - dense_93_loss: 7.7272e-07 - dense_94_loss: 4.4639e-07 - dense_95_loss: 8.1960e-07 - dense_96_loss: 8.5255e-07 - dense_97_loss: 7.9515e-07 - dense_98_loss: 9.2149e-07 - dense_99_loss: 8.7730e-07 - val_loss: 6.0943e-06 - val_dense_92_loss: 3.9156e-07 - val_dense_93_loss: 8.8719e-07 - val_dense_94_loss: 4.4728e-07 - val_dense_95_loss: 8.2153e-07 - val_dense_96_loss: 8.5847e-07 - val_dense_97_loss: 8.6844e-07 - val_dense_98_loss: 9.5308e-07 - val_dense_99_loss: 8.6671e-07\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.2047e-06 - dense_92_loss: 4.4040e-07 - dense_93_loss: 8.4566e-07 - dense_94_loss: 4.6714e-07 - dense_95_loss: 8.6015e-07 - dense_96_loss: 8.6778e-07 - dense_97_loss: 8.3323e-07 - dense_98_loss: 9.7392e-07 - dense_99_loss: 9.1642e-07 - val_loss: 5.8971e-06 - val_dense_92_loss: 3.8219e-07 - val_dense_93_loss: 8.0764e-07 - val_dense_94_loss: 4.0819e-07 - val_dense_95_loss: 8.2864e-07 - val_dense_96_loss: 8.6222e-07 - val_dense_97_loss: 8.0556e-07 - val_dense_98_loss: 9.2025e-07 - val_dense_99_loss: 8.8237e-07\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.8438e-06 - dense_92_loss: 4.1429e-07 - dense_93_loss: 7.3890e-07 - dense_94_loss: 4.4752e-07 - dense_95_loss: 7.7798e-07 - dense_96_loss: 8.6327e-07 - dense_97_loss: 7.8849e-07 - dense_98_loss: 9.4032e-07 - dense_99_loss: 8.7303e-07 - val_loss: 6.8244e-06 - val_dense_92_loss: 5.1014e-07 - val_dense_93_loss: 8.2400e-07 - val_dense_94_loss: 6.0400e-07 - val_dense_95_loss: 8.7398e-07 - val_dense_96_loss: 9.9395e-07 - val_dense_97_loss: 9.0099e-07 - val_dense_98_loss: 1.1654e-06 - val_dense_99_loss: 9.5196e-07\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.7180e-06 - dense_92_loss: 4.8044e-07 - dense_93_loss: 9.0787e-07 - dense_94_loss: 5.3182e-07 - dense_95_loss: 9.1773e-07 - dense_96_loss: 9.3979e-07 - dense_97_loss: 9.3037e-07 - dense_98_loss: 1.0130e-06 - dense_99_loss: 9.9694e-07 - val_loss: 5.7016e-06 - val_dense_92_loss: 3.6469e-07 - val_dense_93_loss: 7.2155e-07 - val_dense_94_loss: 4.3728e-07 - val_dense_95_loss: 7.7299e-07 - val_dense_96_loss: 8.3648e-07 - val_dense_97_loss: 8.1260e-07 - val_dense_98_loss: 9.3067e-07 - val_dense_99_loss: 8.2537e-07\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.6389e-06 - dense_92_loss: 4.6647e-07 - dense_93_loss: 8.9592e-07 - dense_94_loss: 5.2552e-07 - dense_95_loss: 9.2376e-07 - dense_96_loss: 9.1431e-07 - dense_97_loss: 9.3700e-07 - dense_98_loss: 9.9983e-07 - dense_99_loss: 9.7609e-07 - val_loss: 6.0464e-06 - val_dense_92_loss: 3.8070e-07 - val_dense_93_loss: 7.9198e-07 - val_dense_94_loss: 4.8302e-07 - val_dense_95_loss: 8.4561e-07 - val_dense_96_loss: 8.6561e-07 - val_dense_97_loss: 8.1708e-07 - val_dense_98_loss: 9.8319e-07 - val_dense_99_loss: 8.7923e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.0513e-06 - dense_92_loss: 4.3893e-07 - dense_93_loss: 7.5782e-07 - dense_94_loss: 4.8340e-07 - dense_95_loss: 7.9811e-07 - dense_96_loss: 8.7323e-07 - dense_97_loss: 8.2997e-07 - dense_98_loss: 9.7177e-07 - dense_99_loss: 8.9803e-07 - val_loss: 5.4770e-06 - val_dense_92_loss: 3.7904e-07 - val_dense_93_loss: 6.6521e-07 - val_dense_94_loss: 4.2630e-07 - val_dense_95_loss: 6.8882e-07 - val_dense_96_loss: 8.4587e-07 - val_dense_97_loss: 7.5127e-07 - val_dense_98_loss: 9.1710e-07 - val_dense_99_loss: 8.0342e-07\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.6741e-06 - dense_92_loss: 3.9523e-07 - dense_93_loss: 7.1243e-07 - dense_94_loss: 4.3537e-07 - dense_95_loss: 7.5097e-07 - dense_96_loss: 8.4017e-07 - dense_97_loss: 7.7367e-07 - dense_98_loss: 9.2628e-07 - dense_99_loss: 8.3994e-07 - val_loss: 5.7730e-06 - val_dense_92_loss: 3.9659e-07 - val_dense_93_loss: 7.2832e-07 - val_dense_94_loss: 4.2021e-07 - val_dense_95_loss: 7.1781e-07 - val_dense_96_loss: 8.6672e-07 - val_dense_97_loss: 8.3288e-07 - val_dense_98_loss: 9.8948e-07 - val_dense_99_loss: 8.2103e-07\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.7021e-06 - dense_92_loss: 4.0019e-07 - dense_93_loss: 7.2720e-07 - dense_94_loss: 4.3893e-07 - dense_95_loss: 7.4762e-07 - dense_96_loss: 8.4581e-07 - dense_97_loss: 7.7198e-07 - dense_98_loss: 9.3684e-07 - dense_99_loss: 8.3351e-07 - val_loss: 7.2261e-06 - val_dense_92_loss: 4.5698e-07 - val_dense_93_loss: 1.1839e-06 - val_dense_94_loss: 4.9080e-07 - val_dense_95_loss: 1.0197e-06 - val_dense_96_loss: 8.8943e-07 - val_dense_97_loss: 1.1016e-06 - val_dense_98_loss: 9.5942e-07 - val_dense_99_loss: 1.1244e-06\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.4414e-06 - dense_92_loss: 4.6759e-07 - dense_93_loss: 8.3580e-07 - dense_94_loss: 5.1561e-07 - dense_95_loss: 8.5596e-07 - dense_96_loss: 9.2706e-07 - dense_97_loss: 8.8350e-07 - dense_98_loss: 9.9703e-07 - dense_99_loss: 9.5884e-07 - val_loss: 5.8802e-06 - val_dense_92_loss: 4.2666e-07 - val_dense_93_loss: 7.1841e-07 - val_dense_94_loss: 4.5901e-07 - val_dense_95_loss: 7.6825e-07 - val_dense_96_loss: 9.1459e-07 - val_dense_97_loss: 8.1241e-07 - val_dense_98_loss: 9.2971e-07 - val_dense_99_loss: 8.5119e-07\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5.8652e-06 - dense_92_loss: 4.2264e-07 - dense_93_loss: 7.3581e-07 - dense_94_loss: 4.6240e-07 - dense_95_loss: 7.7681e-07 - dense_96_loss: 8.7453e-07 - dense_97_loss: 7.8760e-07 - dense_98_loss: 9.3681e-07 - dense_99_loss: 8.6863e-07 - val_loss: 5.9886e-06 - val_dense_92_loss: 4.1063e-07 - val_dense_93_loss: 8.6656e-07 - val_dense_94_loss: 4.2249e-07 - val_dense_95_loss: 8.4667e-07 - val_dense_96_loss: 8.9322e-07 - val_dense_97_loss: 7.6368e-07 - val_dense_98_loss: 9.1241e-07 - val_dense_99_loss: 8.7296e-07\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.7143e-06 - dense_92_loss: 4.9093e-07 - dense_93_loss: 9.2599e-07 - dense_94_loss: 5.2605e-07 - dense_95_loss: 8.9968e-07 - dense_96_loss: 9.2256e-07 - dense_97_loss: 9.2707e-07 - dense_98_loss: 1.0252e-06 - dense_99_loss: 9.9687e-07 - val_loss: 6.8856e-06 - val_dense_92_loss: 4.7854e-07 - val_dense_93_loss: 8.6382e-07 - val_dense_94_loss: 5.4409e-07 - val_dense_95_loss: 9.5192e-07 - val_dense_96_loss: 9.7718e-07 - val_dense_97_loss: 9.2596e-07 - val_dense_98_loss: 1.1058e-06 - val_dense_99_loss: 1.0383e-06\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.9477e-06 - dense_92_loss: 4.5145e-07 - dense_93_loss: 7.0986e-07 - dense_94_loss: 4.9406e-07 - dense_95_loss: 7.6559e-07 - dense_96_loss: 8.8774e-07 - dense_97_loss: 7.9409e-07 - dense_98_loss: 9.7835e-07 - dense_99_loss: 8.6658e-07 - val_loss: 6.2696e-06 - val_dense_92_loss: 4.8265e-07 - val_dense_93_loss: 7.4790e-07 - val_dense_94_loss: 5.8650e-07 - val_dense_95_loss: 7.4789e-07 - val_dense_96_loss: 9.3502e-07 - val_dense_97_loss: 8.5065e-07 - val_dense_98_loss: 1.0565e-06 - val_dense_99_loss: 8.6249e-07\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.6569e-06 - dense_92_loss: 4.6054e-07 - dense_93_loss: 9.5530e-07 - dense_94_loss: 5.0858e-07 - dense_95_loss: 9.2695e-07 - dense_96_loss: 9.1371e-07 - dense_97_loss: 9.1664e-07 - dense_98_loss: 9.8888e-07 - dense_99_loss: 9.8626e-07 - val_loss: 6.7253e-06 - val_dense_92_loss: 4.4170e-07 - val_dense_93_loss: 9.1153e-07 - val_dense_94_loss: 5.3977e-07 - val_dense_95_loss: 8.6753e-07 - val_dense_96_loss: 9.6616e-07 - val_dense_97_loss: 8.9924e-07 - val_dense_98_loss: 1.0037e-06 - val_dense_99_loss: 1.0957e-06\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.5222e-06 - dense_92_loss: 4.9354e-07 - dense_93_loss: 8.3006e-07 - dense_94_loss: 5.3895e-07 - dense_95_loss: 8.4452e-07 - dense_96_loss: 9.3540e-07 - dense_97_loss: 9.0478e-07 - dense_98_loss: 1.0044e-06 - dense_99_loss: 9.7054e-07 - val_loss: 6.0328e-06 - val_dense_92_loss: 3.7489e-07 - val_dense_93_loss: 7.7529e-07 - val_dense_94_loss: 4.6044e-07 - val_dense_95_loss: 9.2299e-07 - val_dense_96_loss: 8.4760e-07 - val_dense_97_loss: 8.2113e-07 - val_dense_98_loss: 9.5697e-07 - val_dense_99_loss: 8.7349e-07\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.6498e-06 - dense_92_loss: 4.1278e-07 - dense_93_loss: 6.7005e-07 - dense_94_loss: 4.7096e-07 - dense_95_loss: 7.0943e-07 - dense_96_loss: 8.4442e-07 - dense_97_loss: 7.7427e-07 - dense_98_loss: 9.4274e-07 - dense_99_loss: 8.2516e-07 - val_loss: 6.2928e-06 - val_dense_92_loss: 4.0801e-07 - val_dense_93_loss: 9.8979e-07 - val_dense_94_loss: 4.9248e-07 - val_dense_95_loss: 8.1590e-07 - val_dense_96_loss: 9.0122e-07 - val_dense_97_loss: 7.5470e-07 - val_dense_98_loss: 1.0214e-06 - val_dense_99_loss: 9.0928e-07\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.7932e-06 - dense_92_loss: 4.1366e-07 - dense_93_loss: 7.6032e-07 - dense_94_loss: 4.5515e-07 - dense_95_loss: 7.5528e-07 - dense_96_loss: 8.5844e-07 - dense_97_loss: 7.6934e-07 - dense_98_loss: 9.4836e-07 - dense_99_loss: 8.3266e-07 - val_loss: 5.6206e-06 - val_dense_92_loss: 3.8293e-07 - val_dense_93_loss: 7.3314e-07 - val_dense_94_loss: 4.2888e-07 - val_dense_95_loss: 7.4964e-07 - val_dense_96_loss: 8.3325e-07 - val_dense_97_loss: 7.3810e-07 - val_dense_98_loss: 9.2607e-07 - val_dense_99_loss: 8.2860e-07\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.3393e-06 - dense_92_loss: 3.8747e-07 - dense_93_loss: 6.3009e-07 - dense_94_loss: 4.2127e-07 - dense_95_loss: 6.6143e-07 - dense_96_loss: 8.1664e-07 - dense_97_loss: 7.3191e-07 - dense_98_loss: 9.1607e-07 - dense_99_loss: 7.7441e-07 - val_loss: 5.6248e-06 - val_dense_92_loss: 3.6688e-07 - val_dense_93_loss: 6.2785e-07 - val_dense_94_loss: 4.7216e-07 - val_dense_95_loss: 6.8326e-07 - val_dense_96_loss: 9.2367e-07 - val_dense_97_loss: 7.8902e-07 - val_dense_98_loss: 9.4807e-07 - val_dense_99_loss: 8.1385e-07\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.3186e-06 - dense_92_loss: 3.9609e-07 - dense_93_loss: 6.0786e-07 - dense_94_loss: 4.3217e-07 - dense_95_loss: 6.4674e-07 - dense_96_loss: 8.4037e-07 - dense_97_loss: 7.0396e-07 - dense_98_loss: 9.1495e-07 - dense_99_loss: 7.7644e-07 - val_loss: 6.3765e-06 - val_dense_92_loss: 4.9570e-07 - val_dense_93_loss: 7.5342e-07 - val_dense_94_loss: 5.2218e-07 - val_dense_95_loss: 7.4218e-07 - val_dense_96_loss: 1.0954e-06 - val_dense_97_loss: 7.7630e-07 - val_dense_98_loss: 1.0760e-06 - val_dense_99_loss: 9.1529e-07\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.7206e-06 - dense_92_loss: 4.3069e-07 - dense_93_loss: 6.7549e-07 - dense_94_loss: 4.6929e-07 - dense_95_loss: 6.9773e-07 - dense_96_loss: 8.9553e-07 - dense_97_loss: 7.6360e-07 - dense_98_loss: 9.6362e-07 - dense_99_loss: 8.2460e-07 - val_loss: 5.6381e-06 - val_dense_92_loss: 4.3974e-07 - val_dense_93_loss: 6.0564e-07 - val_dense_94_loss: 4.3988e-07 - val_dense_95_loss: 6.6314e-07 - val_dense_96_loss: 9.2149e-07 - val_dense_97_loss: 7.3273e-07 - val_dense_98_loss: 1.0139e-06 - val_dense_99_loss: 8.2164e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.4772e-06 - dense_92_loss: 4.1573e-07 - dense_93_loss: 6.3271e-07 - dense_94_loss: 4.3759e-07 - dense_95_loss: 6.5988e-07 - dense_96_loss: 8.5537e-07 - dense_97_loss: 7.3443e-07 - dense_98_loss: 9.4161e-07 - dense_99_loss: 7.9991e-07 - val_loss: 6.8449e-06 - val_dense_92_loss: 4.8750e-07 - val_dense_93_loss: 8.4732e-07 - val_dense_94_loss: 5.4754e-07 - val_dense_95_loss: 8.9548e-07 - val_dense_96_loss: 9.7502e-07 - val_dense_97_loss: 1.0114e-06 - val_dense_98_loss: 1.1848e-06 - val_dense_99_loss: 8.9587e-07\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.9115e-06 - dense_92_loss: 4.6436e-07 - dense_93_loss: 7.0776e-07 - dense_94_loss: 4.8672e-07 - dense_95_loss: 7.3005e-07 - dense_96_loss: 8.8490e-07 - dense_97_loss: 8.0615e-07 - dense_98_loss: 9.8594e-07 - dense_99_loss: 8.4558e-07 - val_loss: 6.7392e-06 - val_dense_92_loss: 5.0671e-07 - val_dense_93_loss: 9.3749e-07 - val_dense_94_loss: 4.8899e-07 - val_dense_95_loss: 9.5509e-07 - val_dense_96_loss: 9.2709e-07 - val_dense_97_loss: 9.1832e-07 - val_dense_98_loss: 1.0735e-06 - val_dense_99_loss: 9.3195e-07\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.8229e-06 - dense_92_loss: 4.7054e-07 - dense_93_loss: 6.7906e-07 - dense_94_loss: 4.8555e-07 - dense_95_loss: 7.1155e-07 - dense_96_loss: 8.8397e-07 - dense_97_loss: 7.7486e-07 - dense_98_loss: 9.8702e-07 - dense_99_loss: 8.3040e-07 - val_loss: 6.0239e-06 - val_dense_92_loss: 4.0147e-07 - val_dense_93_loss: 7.3540e-07 - val_dense_94_loss: 4.9354e-07 - val_dense_95_loss: 8.1748e-07 - val_dense_96_loss: 8.9384e-07 - val_dense_97_loss: 8.4122e-07 - val_dense_98_loss: 1.0340e-06 - val_dense_99_loss: 8.0690e-07\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.9466e-06 - dense_92_loss: 4.6099e-07 - dense_93_loss: 7.4274e-07 - dense_94_loss: 4.9265e-07 - dense_95_loss: 7.5489e-07 - dense_96_loss: 8.7922e-07 - dense_97_loss: 7.9109e-07 - dense_98_loss: 9.7485e-07 - dense_99_loss: 8.5015e-07 - val_loss: 5.3452e-06 - val_dense_92_loss: 3.7598e-07 - val_dense_93_loss: 5.9357e-07 - val_dense_94_loss: 4.4278e-07 - val_dense_95_loss: 6.4961e-07 - val_dense_96_loss: 8.4619e-07 - val_dense_97_loss: 7.2294e-07 - val_dense_98_loss: 9.3394e-07 - val_dense_99_loss: 7.8024e-07\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.4855e-06 - dense_92_loss: 4.0734e-07 - dense_93_loss: 6.4933e-07 - dense_94_loss: 4.4408e-07 - dense_95_loss: 6.7755e-07 - dense_96_loss: 8.6393e-07 - dense_97_loss: 7.2725e-07 - dense_98_loss: 9.2895e-07 - dense_99_loss: 7.8702e-07 - val_loss: 5.8525e-06 - val_dense_92_loss: 4.0560e-07 - val_dense_93_loss: 8.5898e-07 - val_dense_94_loss: 4.6225e-07 - val_dense_95_loss: 7.4807e-07 - val_dense_96_loss: 8.5611e-07 - val_dense_97_loss: 7.2893e-07 - val_dense_98_loss: 9.6653e-07 - val_dense_99_loss: 8.2600e-07\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.3226e-06 - dense_92_loss: 4.1105e-07 - dense_93_loss: 5.9212e-07 - dense_94_loss: 4.4877e-07 - dense_95_loss: 6.1620e-07 - dense_96_loss: 8.5137e-07 - dense_97_loss: 6.9803e-07 - dense_98_loss: 9.2787e-07 - dense_99_loss: 7.7716e-07 - val_loss: 5.6484e-06 - val_dense_92_loss: 4.1016e-07 - val_dense_93_loss: 7.3293e-07 - val_dense_94_loss: 4.5654e-07 - val_dense_95_loss: 6.6469e-07 - val_dense_96_loss: 8.8716e-07 - val_dense_97_loss: 7.9602e-07 - val_dense_98_loss: 9.0604e-07 - val_dense_99_loss: 7.9490e-07\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.2440e-06 - dense_92_loss: 5.0222e-07 - dense_93_loss: 7.1134e-07 - dense_94_loss: 5.6252e-07 - dense_95_loss: 7.3595e-07 - dense_96_loss: 9.6636e-07 - dense_97_loss: 8.3056e-07 - dense_98_loss: 1.0243e-06 - dense_99_loss: 9.1072e-07 - val_loss: 5.4893e-06 - val_dense_92_loss: 4.5692e-07 - val_dense_93_loss: 6.0408e-07 - val_dense_94_loss: 4.5408e-07 - val_dense_95_loss: 6.2886e-07 - val_dense_96_loss: 8.6767e-07 - val_dense_97_loss: 7.3492e-07 - val_dense_98_loss: 9.6702e-07 - val_dense_99_loss: 7.7571e-07\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5.5707e-06 - dense_92_loss: 4.4319e-07 - dense_93_loss: 6.2587e-07 - dense_94_loss: 4.8270e-07 - dense_95_loss: 6.3875e-07 - dense_96_loss: 8.8960e-07 - dense_97_loss: 7.3163e-07 - dense_98_loss: 9.6344e-07 - dense_99_loss: 7.9549e-07 - val_loss: 5.3127e-06 - val_dense_92_loss: 3.6423e-07 - val_dense_93_loss: 5.6578e-07 - val_dense_94_loss: 4.1237e-07 - val_dense_95_loss: 6.2876e-07 - val_dense_96_loss: 8.7320e-07 - val_dense_97_loss: 7.2033e-07 - val_dense_98_loss: 9.4777e-07 - val_dense_99_loss: 8.0027e-07\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.2720e-06 - dense_92_loss: 4.1391e-07 - dense_93_loss: 5.4210e-07 - dense_94_loss: 4.4272e-07 - dense_95_loss: 5.8907e-07 - dense_96_loss: 8.7716e-07 - dense_97_loss: 7.0086e-07 - dense_98_loss: 9.4705e-07 - dense_99_loss: 7.5915e-07 - val_loss: 5.7260e-06 - val_dense_92_loss: 4.0706e-07 - val_dense_93_loss: 6.1956e-07 - val_dense_94_loss: 4.8672e-07 - val_dense_95_loss: 7.6537e-07 - val_dense_96_loss: 9.2121e-07 - val_dense_97_loss: 8.1440e-07 - val_dense_98_loss: 9.3470e-07 - val_dense_99_loss: 7.7692e-07\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.1684e-06 - dense_92_loss: 4.9513e-07 - dense_93_loss: 7.1396e-07 - dense_94_loss: 5.4949e-07 - dense_95_loss: 7.3911e-07 - dense_96_loss: 9.5494e-07 - dense_97_loss: 8.2243e-07 - dense_98_loss: 1.0211e-06 - dense_99_loss: 8.7223e-07 - val_loss: 9.1595e-06 - val_dense_92_loss: 4.5153e-07 - val_dense_93_loss: 2.1740e-06 - val_dense_94_loss: 4.7003e-07 - val_dense_95_loss: 1.4843e-06 - val_dense_96_loss: 9.9474e-07 - val_dense_97_loss: 1.3318e-06 - val_dense_98_loss: 9.7243e-07 - val_dense_99_loss: 1.2806e-06\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.4112e-06 - dense_92_loss: 4.9498e-07 - dense_93_loss: 8.6596e-07 - dense_94_loss: 5.3522e-07 - dense_95_loss: 7.8627e-07 - dense_96_loss: 9.3241e-07 - dense_97_loss: 8.5123e-07 - dense_98_loss: 1.0120e-06 - dense_99_loss: 9.3317e-07 - val_loss: 5.3934e-06 - val_dense_92_loss: 4.1061e-07 - val_dense_93_loss: 5.5506e-07 - val_dense_94_loss: 4.9324e-07 - val_dense_95_loss: 5.9560e-07 - val_dense_96_loss: 9.1421e-07 - val_dense_97_loss: 6.8817e-07 - val_dense_98_loss: 9.6647e-07 - val_dense_99_loss: 7.7005e-07\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.3760e-06 - dense_92_loss: 4.3338e-07 - dense_93_loss: 5.6112e-07 - dense_94_loss: 4.7473e-07 - dense_95_loss: 5.8553e-07 - dense_96_loss: 8.8634e-07 - dense_97_loss: 6.9307e-07 - dense_98_loss: 9.7736e-07 - dense_99_loss: 7.6445e-07 - val_loss: 5.7720e-06 - val_dense_92_loss: 5.0483e-07 - val_dense_93_loss: 6.4967e-07 - val_dense_94_loss: 4.9404e-07 - val_dense_95_loss: 6.3059e-07 - val_dense_96_loss: 9.1847e-07 - val_dense_97_loss: 7.2636e-07 - val_dense_98_loss: 1.0767e-06 - val_dense_99_loss: 7.7136e-07\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.3538e-06 - dense_92_loss: 4.4671e-07 - dense_93_loss: 5.6258e-07 - dense_94_loss: 4.5510e-07 - dense_95_loss: 5.8421e-07 - dense_96_loss: 8.7438e-07 - dense_97_loss: 7.0031e-07 - dense_98_loss: 9.6121e-07 - dense_99_loss: 7.6934e-07 - val_loss: 5.3757e-06 - val_dense_92_loss: 4.7609e-07 - val_dense_93_loss: 4.9814e-07 - val_dense_94_loss: 5.0175e-07 - val_dense_95_loss: 5.5293e-07 - val_dense_96_loss: 9.1322e-07 - val_dense_97_loss: 6.8142e-07 - val_dense_98_loss: 9.7879e-07 - val_dense_99_loss: 7.7335e-07\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.1585e-06 - dense_92_loss: 4.3011e-07 - dense_93_loss: 5.1952e-07 - dense_94_loss: 4.4925e-07 - dense_95_loss: 5.4855e-07 - dense_96_loss: 8.6292e-07 - dense_97_loss: 6.5514e-07 - dense_98_loss: 9.3263e-07 - dense_99_loss: 7.6037e-07 - val_loss: 5.7456e-06 - val_dense_92_loss: 3.9937e-07 - val_dense_93_loss: 5.8859e-07 - val_dense_94_loss: 4.6783e-07 - val_dense_95_loss: 6.9750e-07 - val_dense_96_loss: 8.5268e-07 - val_dense_97_loss: 7.7503e-07 - val_dense_98_loss: 9.6599e-07 - val_dense_99_loss: 9.9859e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.0849e-06 - dense_92_loss: 4.8852e-07 - dense_93_loss: 7.5258e-07 - dense_94_loss: 5.3021e-07 - dense_95_loss: 7.2159e-07 - dense_96_loss: 9.2998e-07 - dense_97_loss: 7.8388e-07 - dense_98_loss: 1.0147e-06 - dense_99_loss: 8.6346e-07 - val_loss: 5.7252e-06 - val_dense_92_loss: 4.0012e-07 - val_dense_93_loss: 7.4318e-07 - val_dense_94_loss: 4.9769e-07 - val_dense_95_loss: 5.4935e-07 - val_dense_96_loss: 9.1549e-07 - val_dense_97_loss: 8.0890e-07 - val_dense_98_loss: 9.7955e-07 - val_dense_99_loss: 8.3088e-07\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.5350e-06 - dense_92_loss: 4.4624e-07 - dense_93_loss: 5.8964e-07 - dense_94_loss: 5.0021e-07 - dense_95_loss: 6.0886e-07 - dense_96_loss: 8.9998e-07 - dense_97_loss: 7.1543e-07 - dense_98_loss: 9.6345e-07 - dense_99_loss: 8.1124e-07 - val_loss: 5.6960e-06 - val_dense_92_loss: 3.8200e-07 - val_dense_93_loss: 6.5322e-07 - val_dense_94_loss: 4.9353e-07 - val_dense_95_loss: 7.0167e-07 - val_dense_96_loss: 8.6807e-07 - val_dense_97_loss: 8.3125e-07 - val_dense_98_loss: 1.0026e-06 - val_dense_99_loss: 7.6363e-07\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.0208e-06 - dense_92_loss: 4.1711e-07 - dense_93_loss: 4.7449e-07 - dense_94_loss: 4.4241e-07 - dense_95_loss: 5.1110e-07 - dense_96_loss: 8.5796e-07 - dense_97_loss: 6.4773e-07 - dense_98_loss: 9.5121e-07 - dense_99_loss: 7.1882e-07 - val_loss: 4.9388e-06 - val_dense_92_loss: 4.1485e-07 - val_dense_93_loss: 4.5784e-07 - val_dense_94_loss: 4.4209e-07 - val_dense_95_loss: 4.4475e-07 - val_dense_96_loss: 8.8913e-07 - val_dense_97_loss: 6.2031e-07 - val_dense_98_loss: 9.3707e-07 - val_dense_99_loss: 7.3279e-07\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.1431e-06 - dense_92_loss: 4.2517e-07 - dense_93_loss: 5.1494e-07 - dense_94_loss: 4.5650e-07 - dense_95_loss: 5.2538e-07 - dense_96_loss: 8.6018e-07 - dense_97_loss: 6.6341e-07 - dense_98_loss: 9.4663e-07 - dense_99_loss: 7.5090e-07 - val_loss: 5.3105e-06 - val_dense_92_loss: 4.0988e-07 - val_dense_93_loss: 4.7740e-07 - val_dense_94_loss: 4.7958e-07 - val_dense_95_loss: 5.4462e-07 - val_dense_96_loss: 9.4423e-07 - val_dense_97_loss: 6.3406e-07 - val_dense_98_loss: 1.0480e-06 - val_dense_99_loss: 7.7273e-07\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.6472e-06 - dense_92_loss: 4.6012e-07 - dense_93_loss: 6.3607e-07 - dense_94_loss: 4.9961e-07 - dense_95_loss: 6.1842e-07 - dense_96_loss: 9.0921e-07 - dense_97_loss: 7.5291e-07 - dense_98_loss: 9.6306e-07 - dense_99_loss: 8.0784e-07 - val_loss: 4.9267e-06 - val_dense_92_loss: 4.3058e-07 - val_dense_93_loss: 4.0640e-07 - val_dense_94_loss: 4.4294e-07 - val_dense_95_loss: 4.5268e-07 - val_dense_96_loss: 8.7740e-07 - val_dense_97_loss: 6.1474e-07 - val_dense_98_loss: 9.8156e-07 - val_dense_99_loss: 7.2042e-07\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.2685e-06 - dense_92_loss: 4.3433e-07 - dense_93_loss: 5.2209e-07 - dense_94_loss: 4.7282e-07 - dense_95_loss: 5.4488e-07 - dense_96_loss: 8.8498e-07 - dense_97_loss: 6.8605e-07 - dense_98_loss: 9.5838e-07 - dense_99_loss: 7.6501e-07 - val_loss: 7.8291e-06 - val_dense_92_loss: 7.0343e-07 - val_dense_93_loss: 6.4681e-07 - val_dense_94_loss: 9.5527e-07 - val_dense_95_loss: 7.2841e-07 - val_dense_96_loss: 1.2602e-06 - val_dense_97_loss: 9.4846e-07 - val_dense_98_loss: 1.3555e-06 - val_dense_99_loss: 1.2310e-06\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5.9557e-06 - dense_92_loss: 5.2996e-07 - dense_93_loss: 5.5476e-07 - dense_94_loss: 5.9060e-07 - dense_95_loss: 5.8831e-07 - dense_96_loss: 9.9964e-07 - dense_97_loss: 7.5421e-07 - dense_98_loss: 1.0548e-06 - dense_99_loss: 8.8340e-07 - val_loss: 5.7221e-06 - val_dense_92_loss: 4.9868e-07 - val_dense_93_loss: 4.6776e-07 - val_dense_94_loss: 5.6605e-07 - val_dense_95_loss: 5.0750e-07 - val_dense_96_loss: 9.3329e-07 - val_dense_97_loss: 8.6684e-07 - val_dense_98_loss: 1.1679e-06 - val_dense_99_loss: 7.1406e-07\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.9587e-06 - dense_92_loss: 4.3053e-07 - dense_93_loss: 4.1631e-07 - dense_94_loss: 4.6186e-07 - dense_95_loss: 4.5465e-07 - dense_96_loss: 8.5931e-07 - dense_97_loss: 6.5433e-07 - dense_98_loss: 9.7326e-07 - dense_99_loss: 7.0841e-07 - val_loss: 5.3179e-06 - val_dense_92_loss: 4.6905e-07 - val_dense_93_loss: 5.7123e-07 - val_dense_94_loss: 4.3987e-07 - val_dense_95_loss: 5.9674e-07 - val_dense_96_loss: 9.0754e-07 - val_dense_97_loss: 6.3251e-07 - val_dense_98_loss: 9.8756e-07 - val_dense_99_loss: 7.1342e-07\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.4389e-06 - dense_92_loss: 4.3436e-07 - dense_93_loss: 5.8663e-07 - dense_94_loss: 4.7897e-07 - dense_95_loss: 5.9930e-07 - dense_96_loss: 8.8208e-07 - dense_97_loss: 6.9769e-07 - dense_98_loss: 9.7267e-07 - dense_99_loss: 7.8718e-07 - val_loss: 5.0411e-06 - val_dense_92_loss: 3.8980e-07 - val_dense_93_loss: 5.1558e-07 - val_dense_94_loss: 4.6060e-07 - val_dense_95_loss: 4.8219e-07 - val_dense_96_loss: 8.8962e-07 - val_dense_97_loss: 6.0239e-07 - val_dense_98_loss: 9.6456e-07 - val_dense_99_loss: 7.3637e-07\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8815e-06 - dense_92_loss: 4.1446e-07 - dense_93_loss: 4.3848e-07 - dense_94_loss: 4.5188e-07 - dense_95_loss: 4.6424e-07 - dense_96_loss: 8.5453e-07 - dense_97_loss: 6.1450e-07 - dense_98_loss: 9.3403e-07 - dense_99_loss: 7.0936e-07 - val_loss: 5.9606e-06 - val_dense_92_loss: 5.1374e-07 - val_dense_93_loss: 5.6333e-07 - val_dense_94_loss: 5.1029e-07 - val_dense_95_loss: 7.2450e-07 - val_dense_96_loss: 9.7112e-07 - val_dense_97_loss: 7.0480e-07 - val_dense_98_loss: 1.1298e-06 - val_dense_99_loss: 8.4302e-07\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8600e-06 - dense_92_loss: 4.1043e-07 - dense_93_loss: 4.0980e-07 - dense_94_loss: 4.5870e-07 - dense_95_loss: 4.5116e-07 - dense_96_loss: 8.6009e-07 - dense_97_loss: 6.1258e-07 - dense_98_loss: 9.4347e-07 - dense_99_loss: 7.1381e-07 - val_loss: 5.6508e-06 - val_dense_92_loss: 5.2852e-07 - val_dense_93_loss: 4.2568e-07 - val_dense_94_loss: 5.0941e-07 - val_dense_95_loss: 5.0587e-07 - val_dense_96_loss: 1.0517e-06 - val_dense_97_loss: 6.7728e-07 - val_dense_98_loss: 1.0526e-06 - val_dense_99_loss: 8.9977e-07\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5.7471e-06 - dense_92_loss: 4.5025e-07 - dense_93_loss: 6.5363e-07 - dense_94_loss: 4.8503e-07 - dense_95_loss: 6.8662e-07 - dense_96_loss: 9.0176e-07 - dense_97_loss: 7.5773e-07 - dense_98_loss: 9.6894e-07 - dense_99_loss: 8.4310e-07 - val_loss: 4.9122e-06 - val_dense_92_loss: 3.9679e-07 - val_dense_93_loss: 4.0599e-07 - val_dense_94_loss: 4.2774e-07 - val_dense_95_loss: 3.9039e-07 - val_dense_96_loss: 8.6028e-07 - val_dense_97_loss: 6.5933e-07 - val_dense_98_loss: 1.0714e-06 - val_dense_99_loss: 7.0028e-07\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5.0999e-06 - dense_92_loss: 4.0831e-07 - dense_93_loss: 5.2620e-07 - dense_94_loss: 4.4252e-07 - dense_95_loss: 5.3046e-07 - dense_96_loss: 8.3832e-07 - dense_97_loss: 6.6389e-07 - dense_98_loss: 9.5195e-07 - dense_99_loss: 7.3824e-07 - val_loss: 5.0603e-06 - val_dense_92_loss: 4.2860e-07 - val_dense_93_loss: 3.5431e-07 - val_dense_94_loss: 4.9876e-07 - val_dense_95_loss: 3.9650e-07 - val_dense_96_loss: 8.5634e-07 - val_dense_97_loss: 6.5025e-07 - val_dense_98_loss: 1.0717e-06 - val_dense_99_loss: 8.0379e-07\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.3132e-06 - dense_92_loss: 4.2556e-07 - dense_93_loss: 5.4553e-07 - dense_94_loss: 4.8098e-07 - dense_95_loss: 5.4109e-07 - dense_96_loss: 8.7820e-07 - dense_97_loss: 6.9970e-07 - dense_98_loss: 9.6356e-07 - dense_99_loss: 7.7856e-07 - val_loss: 5.2067e-06 - val_dense_92_loss: 4.3742e-07 - val_dense_93_loss: 4.5563e-07 - val_dense_94_loss: 5.2037e-07 - val_dense_95_loss: 4.1552e-07 - val_dense_96_loss: 9.2033e-07 - val_dense_97_loss: 7.2628e-07 - val_dense_98_loss: 1.0107e-06 - val_dense_99_loss: 7.2042e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.6804e-06 - dense_92_loss: 3.9282e-07 - dense_93_loss: 3.9945e-07 - dense_94_loss: 4.3001e-07 - dense_95_loss: 4.2165e-07 - dense_96_loss: 8.3946e-07 - dense_97_loss: 6.0137e-07 - dense_98_loss: 9.2322e-07 - dense_99_loss: 6.7246e-07 - val_loss: 4.7727e-06 - val_dense_92_loss: 3.8111e-07 - val_dense_93_loss: 3.8183e-07 - val_dense_94_loss: 4.4283e-07 - val_dense_95_loss: 3.4661e-07 - val_dense_96_loss: 9.8485e-07 - val_dense_97_loss: 5.4766e-07 - val_dense_98_loss: 1.0194e-06 - val_dense_99_loss: 6.6838e-07\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7237e-06 - dense_92_loss: 4.1685e-07 - dense_93_loss: 4.0306e-07 - dense_94_loss: 4.4579e-07 - dense_95_loss: 4.1530e-07 - dense_96_loss: 8.4344e-07 - dense_97_loss: 5.9024e-07 - dense_98_loss: 9.3497e-07 - dense_99_loss: 6.7404e-07 - val_loss: 6.2971e-06 - val_dense_92_loss: 4.2036e-07 - val_dense_93_loss: 8.2057e-07 - val_dense_94_loss: 4.8712e-07 - val_dense_95_loss: 6.7920e-07 - val_dense_96_loss: 1.0180e-06 - val_dense_97_loss: 8.7692e-07 - val_dense_98_loss: 1.0528e-06 - val_dense_99_loss: 9.4217e-07\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.2033e-06 - dense_92_loss: 4.0749e-07 - dense_93_loss: 5.3642e-07 - dense_94_loss: 4.6099e-07 - dense_95_loss: 5.3947e-07 - dense_96_loss: 8.6315e-07 - dense_97_loss: 6.9772e-07 - dense_98_loss: 9.4393e-07 - dense_99_loss: 7.5408e-07 - val_loss: 6.0283e-06 - val_dense_92_loss: 4.0504e-07 - val_dense_93_loss: 7.9930e-07 - val_dense_94_loss: 4.7121e-07 - val_dense_95_loss: 7.1661e-07 - val_dense_96_loss: 9.0393e-07 - val_dense_97_loss: 7.5883e-07 - val_dense_98_loss: 9.6060e-07 - val_dense_99_loss: 1.0127e-06\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.2315e-06 - dense_92_loss: 4.2339e-07 - dense_93_loss: 5.4169e-07 - dense_94_loss: 4.5731e-07 - dense_95_loss: 5.2207e-07 - dense_96_loss: 8.8092e-07 - dense_97_loss: 6.9175e-07 - dense_98_loss: 9.6263e-07 - dense_99_loss: 7.5171e-07 - val_loss: 6.8342e-06 - val_dense_92_loss: 5.5833e-07 - val_dense_93_loss: 5.1278e-07 - val_dense_94_loss: 7.0444e-07 - val_dense_95_loss: 6.1116e-07 - val_dense_96_loss: 1.3648e-06 - val_dense_97_loss: 8.7589e-07 - val_dense_98_loss: 1.2369e-06 - val_dense_99_loss: 9.6986e-07\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.1618e-06 - dense_92_loss: 4.2652e-07 - dense_93_loss: 5.4987e-07 - dense_94_loss: 4.6571e-07 - dense_95_loss: 5.1132e-07 - dense_96_loss: 8.8311e-07 - dense_97_loss: 6.6338e-07 - dense_98_loss: 9.3447e-07 - dense_99_loss: 7.2746e-07 - val_loss: 4.9059e-06 - val_dense_92_loss: 3.5153e-07 - val_dense_93_loss: 4.9329e-07 - val_dense_94_loss: 4.2414e-07 - val_dense_95_loss: 4.7371e-07 - val_dense_96_loss: 8.7802e-07 - val_dense_97_loss: 6.1299e-07 - val_dense_98_loss: 9.1017e-07 - val_dense_99_loss: 7.6209e-07\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 4.8914e-06 - dense_92_loss: 4.1261e-07 - dense_93_loss: 4.6092e-07 - dense_94_loss: 4.6014e-07 - dense_95_loss: 4.4449e-07 - dense_96_loss: 8.6123e-07 - dense_97_loss: 6.1736e-07 - dense_98_loss: 9.2545e-07 - dense_99_loss: 7.0916e-07 - val_loss: 4.5041e-06 - val_dense_92_loss: 3.7885e-07 - val_dense_93_loss: 3.2836e-07 - val_dense_94_loss: 4.1952e-07 - val_dense_95_loss: 3.7820e-07 - val_dense_96_loss: 8.8436e-07 - val_dense_97_loss: 5.4668e-07 - val_dense_98_loss: 9.3282e-07 - val_dense_99_loss: 6.3529e-07\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7002e-06 - dense_92_loss: 3.9879e-07 - dense_93_loss: 4.0745e-07 - dense_94_loss: 4.3791e-07 - dense_95_loss: 4.0185e-07 - dense_96_loss: 8.6029e-07 - dense_97_loss: 6.0605e-07 - dense_98_loss: 9.1996e-07 - dense_99_loss: 6.6787e-07 - val_loss: 4.3756e-06 - val_dense_92_loss: 3.5853e-07 - val_dense_93_loss: 2.5233e-07 - val_dense_94_loss: 4.2844e-07 - val_dense_95_loss: 3.1215e-07 - val_dense_96_loss: 8.6521e-07 - val_dense_97_loss: 5.5353e-07 - val_dense_98_loss: 9.4878e-07 - val_dense_99_loss: 6.5658e-07\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.2272e-06 - dense_92_loss: 4.1436e-07 - dense_93_loss: 5.3140e-07 - dense_94_loss: 4.6695e-07 - dense_95_loss: 5.4957e-07 - dense_96_loss: 8.8993e-07 - dense_97_loss: 6.6256e-07 - dense_98_loss: 9.5002e-07 - dense_99_loss: 7.6246e-07 - val_loss: 6.2835e-06 - val_dense_92_loss: 3.8829e-07 - val_dense_93_loss: 1.0254e-06 - val_dense_94_loss: 4.4755e-07 - val_dense_95_loss: 8.2663e-07 - val_dense_96_loss: 9.0131e-07 - val_dense_97_loss: 7.9574e-07 - val_dense_98_loss: 9.6549e-07 - val_dense_99_loss: 9.3304e-07\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8376e-06 - dense_92_loss: 3.9662e-07 - dense_93_loss: 4.4904e-07 - dense_94_loss: 4.3531e-07 - dense_95_loss: 4.5747e-07 - dense_96_loss: 8.4674e-07 - dense_97_loss: 6.2808e-07 - dense_98_loss: 9.2877e-07 - dense_99_loss: 6.9558e-07 - val_loss: 5.4904e-06 - val_dense_92_loss: 4.7762e-07 - val_dense_93_loss: 3.5378e-07 - val_dense_94_loss: 5.7859e-07 - val_dense_95_loss: 3.7438e-07 - val_dense_96_loss: 9.5538e-07 - val_dense_97_loss: 6.7369e-07 - val_dense_98_loss: 1.1963e-06 - val_dense_99_loss: 8.8063e-07\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.7166e-06 - dense_92_loss: 4.1233e-07 - dense_93_loss: 3.4703e-07 - dense_94_loss: 4.7492e-07 - dense_95_loss: 3.8902e-07 - dense_96_loss: 8.5401e-07 - dense_97_loss: 5.7094e-07 - dense_98_loss: 9.7402e-07 - dense_99_loss: 6.9436e-07 - val_loss: 4.7573e-06 - val_dense_92_loss: 3.9819e-07 - val_dense_93_loss: 3.0541e-07 - val_dense_94_loss: 5.0782e-07 - val_dense_95_loss: 3.4415e-07 - val_dense_96_loss: 8.8588e-07 - val_dense_97_loss: 5.9995e-07 - val_dense_98_loss: 1.0425e-06 - val_dense_99_loss: 6.7337e-07\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.4338e-06 - dense_92_loss: 4.3341e-07 - dense_93_loss: 5.9359e-07 - dense_94_loss: 4.8841e-07 - dense_95_loss: 5.3076e-07 - dense_96_loss: 9.1184e-07 - dense_97_loss: 7.1341e-07 - dense_98_loss: 9.7487e-07 - dense_99_loss: 7.8750e-07 - val_loss: 4.4532e-06 - val_dense_92_loss: 3.5628e-07 - val_dense_93_loss: 3.0354e-07 - val_dense_94_loss: 4.6528e-07 - val_dense_95_loss: 3.4094e-07 - val_dense_96_loss: 8.9492e-07 - val_dense_97_loss: 5.5755e-07 - val_dense_98_loss: 9.1019e-07 - val_dense_99_loss: 6.2452e-07\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.4036e-06 - dense_92_loss: 3.8498e-07 - dense_93_loss: 3.2169e-07 - dense_94_loss: 4.1832e-07 - dense_95_loss: 3.6011e-07 - dense_96_loss: 8.2760e-07 - dense_97_loss: 5.5465e-07 - dense_98_loss: 9.0274e-07 - dense_99_loss: 6.3352e-07 - val_loss: 4.8999e-06 - val_dense_92_loss: 3.8989e-07 - val_dense_93_loss: 5.0114e-07 - val_dense_94_loss: 4.3780e-07 - val_dense_95_loss: 4.3304e-07 - val_dense_96_loss: 8.2469e-07 - val_dense_97_loss: 6.1471e-07 - val_dense_98_loss: 9.6430e-07 - val_dense_99_loss: 7.3435e-07\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.4587e-06 - dense_92_loss: 3.9118e-07 - dense_93_loss: 3.3696e-07 - dense_94_loss: 4.1619e-07 - dense_95_loss: 3.4918e-07 - dense_96_loss: 8.4921e-07 - dense_97_loss: 5.6152e-07 - dense_98_loss: 9.1737e-07 - dense_99_loss: 6.3710e-07 - val_loss: 5.8722e-06 - val_dense_92_loss: 4.3388e-07 - val_dense_93_loss: 6.1267e-07 - val_dense_94_loss: 4.4733e-07 - val_dense_95_loss: 6.2346e-07 - val_dense_96_loss: 9.7421e-07 - val_dense_97_loss: 7.7737e-07 - val_dense_98_loss: 1.0700e-06 - val_dense_99_loss: 9.3328e-07\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.1829e-06 - dense_92_loss: 4.1044e-07 - dense_93_loss: 5.1322e-07 - dense_94_loss: 4.3540e-07 - dense_95_loss: 5.4152e-07 - dense_96_loss: 8.8511e-07 - dense_97_loss: 6.9755e-07 - dense_98_loss: 9.5255e-07 - dense_99_loss: 7.4714e-07 - val_loss: 4.8325e-06 - val_dense_92_loss: 4.1700e-07 - val_dense_93_loss: 3.1335e-07 - val_dense_94_loss: 4.8002e-07 - val_dense_95_loss: 4.1386e-07 - val_dense_96_loss: 9.7038e-07 - val_dense_97_loss: 6.0365e-07 - val_dense_98_loss: 9.4735e-07 - val_dense_99_loss: 6.8689e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.6403e-06 - dense_92_loss: 3.9172e-07 - dense_93_loss: 3.9428e-07 - dense_94_loss: 4.2937e-07 - dense_95_loss: 4.2235e-07 - dense_96_loss: 8.3556e-07 - dense_97_loss: 5.7989e-07 - dense_98_loss: 9.2662e-07 - dense_99_loss: 6.6051e-07 - val_loss: 5.0753e-06 - val_dense_92_loss: 3.7250e-07 - val_dense_93_loss: 5.0821e-07 - val_dense_94_loss: 5.0547e-07 - val_dense_95_loss: 4.8532e-07 - val_dense_96_loss: 9.6931e-07 - val_dense_97_loss: 6.3272e-07 - val_dense_98_loss: 8.9161e-07 - val_dense_99_loss: 7.1022e-07\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8369e-06 - dense_92_loss: 3.8474e-07 - dense_93_loss: 4.5273e-07 - dense_94_loss: 4.3455e-07 - dense_95_loss: 4.8542e-07 - dense_96_loss: 8.4692e-07 - dense_97_loss: 6.4072e-07 - dense_98_loss: 8.9323e-07 - dense_99_loss: 6.9854e-07 - val_loss: 4.3545e-06 - val_dense_92_loss: 3.5376e-07 - val_dense_93_loss: 2.9661e-07 - val_dense_94_loss: 4.3264e-07 - val_dense_95_loss: 2.8799e-07 - val_dense_96_loss: 8.4324e-07 - val_dense_97_loss: 5.1927e-07 - val_dense_98_loss: 9.3891e-07 - val_dense_99_loss: 6.8210e-07\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.9629e-06 - dense_92_loss: 4.0809e-07 - dense_93_loss: 4.7932e-07 - dense_94_loss: 4.3702e-07 - dense_95_loss: 4.5963e-07 - dense_96_loss: 8.3261e-07 - dense_97_loss: 6.5380e-07 - dense_98_loss: 9.3722e-07 - dense_99_loss: 7.5518e-07 - val_loss: 5.1174e-06 - val_dense_92_loss: 4.4472e-07 - val_dense_93_loss: 2.6953e-07 - val_dense_94_loss: 5.3540e-07 - val_dense_95_loss: 3.4714e-07 - val_dense_96_loss: 1.0362e-06 - val_dense_97_loss: 5.9710e-07 - val_dense_98_loss: 1.1593e-06 - val_dense_99_loss: 7.2801e-07\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.7511e-06 - dense_92_loss: 4.1816e-07 - dense_93_loss: 3.4755e-07 - dense_94_loss: 4.5791e-07 - dense_95_loss: 3.7588e-07 - dense_96_loss: 8.6978e-07 - dense_97_loss: 6.0510e-07 - dense_98_loss: 9.7573e-07 - dense_99_loss: 7.0096e-07 - val_loss: 4.6891e-06 - val_dense_92_loss: 4.1307e-07 - val_dense_93_loss: 2.5978e-07 - val_dense_94_loss: 5.1768e-07 - val_dense_95_loss: 3.2986e-07 - val_dense_96_loss: 9.4698e-07 - val_dense_97_loss: 5.5543e-07 - val_dense_98_loss: 9.7704e-07 - val_dense_99_loss: 6.8929e-07\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7790e-06 - dense_92_loss: 4.0241e-07 - dense_93_loss: 4.0587e-07 - dense_94_loss: 4.4858e-07 - dense_95_loss: 4.2371e-07 - dense_96_loss: 8.4050e-07 - dense_97_loss: 6.3641e-07 - dense_98_loss: 9.2887e-07 - dense_99_loss: 6.9264e-07 - val_loss: 5.1143e-06 - val_dense_92_loss: 3.7870e-07 - val_dense_93_loss: 5.9538e-07 - val_dense_94_loss: 4.2442e-07 - val_dense_95_loss: 5.1374e-07 - val_dense_96_loss: 8.1412e-07 - val_dense_97_loss: 7.0845e-07 - val_dense_98_loss: 9.3986e-07 - val_dense_99_loss: 7.3969e-07\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.4365e-06 - dense_92_loss: 3.9433e-07 - dense_93_loss: 3.4556e-07 - dense_94_loss: 4.2381e-07 - dense_95_loss: 3.4920e-07 - dense_96_loss: 8.2565e-07 - dense_97_loss: 5.5662e-07 - dense_98_loss: 9.1133e-07 - dense_99_loss: 6.2996e-07 - val_loss: 5.2525e-06 - val_dense_92_loss: 4.1585e-07 - val_dense_93_loss: 4.9630e-07 - val_dense_94_loss: 4.7326e-07 - val_dense_95_loss: 4.4654e-07 - val_dense_96_loss: 8.7826e-07 - val_dense_97_loss: 7.1656e-07 - val_dense_98_loss: 1.0284e-06 - val_dense_99_loss: 7.9730e-07\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.6211e-06 - dense_92_loss: 4.0606e-07 - dense_93_loss: 3.6010e-07 - dense_94_loss: 4.4064e-07 - dense_95_loss: 3.6926e-07 - dense_96_loss: 8.4825e-07 - dense_97_loss: 5.9635e-07 - dense_98_loss: 9.3616e-07 - dense_99_loss: 6.6431e-07 - val_loss: 4.4552e-06 - val_dense_92_loss: 3.5981e-07 - val_dense_93_loss: 3.0708e-07 - val_dense_94_loss: 4.2916e-07 - val_dense_95_loss: 3.6636e-07 - val_dense_96_loss: 8.0615e-07 - val_dense_97_loss: 5.6970e-07 - val_dense_98_loss: 9.7542e-07 - val_dense_99_loss: 6.4154e-07\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.6809e-06 - dense_92_loss: 4.0158e-07 - dense_93_loss: 3.8164e-07 - dense_94_loss: 4.4073e-07 - dense_95_loss: 4.0252e-07 - dense_96_loss: 8.4106e-07 - dense_97_loss: 6.1128e-07 - dense_98_loss: 9.2761e-07 - dense_99_loss: 6.7445e-07 - val_loss: 4.5044e-06 - val_dense_92_loss: 3.6100e-07 - val_dense_93_loss: 3.6070e-07 - val_dense_94_loss: 4.4143e-07 - val_dense_95_loss: 3.8232e-07 - val_dense_96_loss: 8.0777e-07 - val_dense_97_loss: 5.9116e-07 - val_dense_98_loss: 9.1757e-07 - val_dense_99_loss: 6.4241e-07\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.4144e-06 - dense_92_loss: 3.7512e-07 - dense_93_loss: 3.5637e-07 - dense_94_loss: 4.2072e-07 - dense_95_loss: 3.5613e-07 - dense_96_loss: 8.1574e-07 - dense_97_loss: 5.6070e-07 - dense_98_loss: 8.9814e-07 - dense_99_loss: 6.3148e-07 - val_loss: 4.7028e-06 - val_dense_92_loss: 3.6688e-07 - val_dense_93_loss: 3.3087e-07 - val_dense_94_loss: 4.1083e-07 - val_dense_95_loss: 3.9673e-07 - val_dense_96_loss: 8.3914e-07 - val_dense_97_loss: 6.8822e-07 - val_dense_98_loss: 9.4430e-07 - val_dense_99_loss: 7.2579e-07\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.3291e-06 - dense_92_loss: 3.7249e-07 - dense_93_loss: 3.1884e-07 - dense_94_loss: 4.1323e-07 - dense_95_loss: 3.3520e-07 - dense_96_loss: 8.0210e-07 - dense_97_loss: 5.5198e-07 - dense_98_loss: 9.1528e-07 - dense_99_loss: 6.2000e-07 - val_loss: 5.2161e-06 - val_dense_92_loss: 3.9240e-07 - val_dense_93_loss: 4.8415e-07 - val_dense_94_loss: 4.2655e-07 - val_dense_95_loss: 5.3871e-07 - val_dense_96_loss: 8.4933e-07 - val_dense_97_loss: 5.8073e-07 - val_dense_98_loss: 1.0424e-06 - val_dense_99_loss: 9.0184e-07\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.6293e-06 - dense_92_loss: 3.9057e-07 - dense_93_loss: 3.8371e-07 - dense_94_loss: 4.2737e-07 - dense_95_loss: 4.0714e-07 - dense_96_loss: 8.3957e-07 - dense_97_loss: 5.7876e-07 - dense_98_loss: 9.3110e-07 - dense_99_loss: 6.7109e-07 - val_loss: 4.2967e-06 - val_dense_92_loss: 3.2742e-07 - val_dense_93_loss: 2.3156e-07 - val_dense_94_loss: 4.2059e-07 - val_dense_95_loss: 3.1193e-07 - val_dense_96_loss: 8.2916e-07 - val_dense_97_loss: 5.7343e-07 - val_dense_98_loss: 9.7401e-07 - val_dense_99_loss: 6.2861e-07\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.5070e-06 - dense_92_loss: 3.8639e-07 - dense_93_loss: 3.3700e-07 - dense_94_loss: 4.3068e-07 - dense_95_loss: 3.9095e-07 - dense_96_loss: 8.2782e-07 - dense_97_loss: 5.7124e-07 - dense_98_loss: 9.1838e-07 - dense_99_loss: 6.4452e-07 - val_loss: 5.3179e-06 - val_dense_92_loss: 4.1305e-07 - val_dense_93_loss: 4.3245e-07 - val_dense_94_loss: 6.0309e-07 - val_dense_95_loss: 4.7932e-07 - val_dense_96_loss: 9.5052e-07 - val_dense_97_loss: 6.3746e-07 - val_dense_98_loss: 9.5138e-07 - val_dense_99_loss: 8.5065e-07\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.6126e-06 - dense_92_loss: 3.9571e-07 - dense_93_loss: 3.6204e-07 - dense_94_loss: 4.4662e-07 - dense_95_loss: 3.8550e-07 - dense_96_loss: 8.4739e-07 - dense_97_loss: 5.8650e-07 - dense_98_loss: 9.4239e-07 - dense_99_loss: 6.4650e-07 - val_loss: 4.7613e-06 - val_dense_92_loss: 5.5823e-07 - val_dense_93_loss: 3.2341e-07 - val_dense_94_loss: 4.3432e-07 - val_dense_95_loss: 3.0440e-07 - val_dense_96_loss: 8.4717e-07 - val_dense_97_loss: 5.7706e-07 - val_dense_98_loss: 9.8930e-07 - val_dense_99_loss: 7.2745e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00146: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1167afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        print('evaluating model for '+histgroup[0])\n",
    "        print(histstruct.evaluate_classifier(histgroup)[0].shape)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    print('Found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "            thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "            mse_good.append( thismse )\n",
    "            print(run)\n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    print('Found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        print('Found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34546ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model for NormalizedHitResiduals_TIB__Layer__1\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_1\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_2\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_3\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_4\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+1\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-1\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+2\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-2\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+3\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-3\n",
      "(2831,)\n",
      "evaluating model for NormalizedHitResiduals_TOB__Layer__1\n",
      "(2831,)\n",
      "Found mse array for training set of following shape: (1678, 40)\n",
      "Found mse array for good set of following shape: (1537, 40)\n",
      "Found mse array for bad set of following shape: (44, 40)\n",
      "Found mse array for bad set of following shape: (35, 40)\n",
      "Found mse array for bad set of following shape: (46, 40)\n",
      "Found mse array for bad set of following shape: (19, 40)\n",
      "Found mse array for bad set of following shape: (22, 40)\n",
      "Found mse array for bad set of following shape: (28, 40)\n",
      "Found mse array for bad set of following shape: (12, 40)\n",
      "Found mse array for bad set of following shape: (32, 40)\n"
     ]
    }
   ],
   "source": [
    "(mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7105b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct, mse_train):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    #for dims in dimslist:\n",
    "    #    thismse = mse_train[:,dims]\n",
    "    #    if training_mode=='global': \n",
    "    #        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "    #        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "    #        #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "    #        #                                                    'up')\n",
    "    #    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    #    #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "    #    #                onlycontour=False, xlims=30, ylims=30, \n",
    "    #    #                onlypositive=True, transparency=0.5,\n",
    "    #    #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "    #    #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "    #    #                title='density fit of lumisection MSE')\n",
    "    #    ##plt.close('all') # release plot memory\n",
    "    #    fitfunclist.append(fitfunc)\n",
    "    # \n",
    "    #    \n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "    else: \n",
    "        fitfunc = GaussianKdeFitter.GaussianKdeFitter()\n",
    "        fitfunc.fit(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4988fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = fit_mse_distribution(histstruct, mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7437c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    print('--- good lumesections ---')\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    print('length of log prob array: '+str(len(logprob_good)))\n",
    "    print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "    #print(sorted(logprob_good))\n",
    "    \n",
    "    print('--- bad lumisections ---')\n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "    \n",
    "    print('length of log prob array: '+str(len(logprob_bad)))\n",
    "    print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "    #print(sorted(logprob_good))\n",
    "    #print(sorted(logprob_bad))\n",
    "    #print(logprob_bad)\n",
    "    \n",
    "    return [logprob_good, logprob_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a8ed5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- good lumesections ---\n",
      "length of log prob array: 1537\n",
      "minimum of log prob: 386.7475072481789\n",
      "--- bad lumisections ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4518/688802665.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of log prob array: 238\n",
      "maximum of log prob: 409.9382805076541\n"
     ]
    }
   ],
   "source": [
    "(logprob_good, logprob_bad) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09b777c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoder_individual(histstruct):\n",
    "    \n",
    "    msewps = []\n",
    "    for histname in histstruct.histnames:\n",
    "        \n",
    "        # Get histograms from histstruct\n",
    "        X_test_good = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'good']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        X_test_bad = X_test_bad = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'bad']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        # Get each model from the histstruct\n",
    "        autoencoder = histstruct.get_classifier(histname)\n",
    "        \n",
    "        # Getting evaluation criteria\n",
    "        prediction_test_good = autoencoder.reconstruct(X_test_good)\n",
    "        mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "        prediction_test_bad = autoencoder.reconstruct(X_test_bad)\n",
    "        mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "        \n",
    "        if userfriendly:\n",
    "            print('Average MSE on good set: ' + str(np.mean(mse_test_good)))\n",
    "            print('Average MSE on bad set: ' + str(np.mean(mse_test_bad)))\n",
    "        \n",
    "        if createPlots:\n",
    "            # Number of plots of each type to generate per model (so nplot * 2 * len(model))\n",
    "            nplot = 3\n",
    "            \n",
    "            # Good examples\n",
    "            print('Examples of good histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "            for i in randint: \n",
    "                histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "            \n",
    "            # Bad examples\n",
    "            print('Examples of bad histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "            for i in randint:\n",
    "                histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "        \n",
    "        # Attaching the bad histograms as a new set of rows under the good histograms\n",
    "        validation_data = np.vstack((X_test_good, X_test_bad))\n",
    "        validation_preds = np.vstack((prediction_test_good, prediction_test_bad))\n",
    "        # Creating labels to differentiate the data when we go to compare predictions\n",
    "        #     with actual label\n",
    "        labels = np.hstack((np.zeros(len(X_test_good)), np.ones(len(X_test_bad))))\n",
    "        \n",
    "        # Pick a working point to see \n",
    "        msewp = 0.5*(np.mean(mse_test_bad) - np.mean(mse_test_good))\n",
    "        print(\"Selected working point: \" + str(msewp))\n",
    "        \n",
    "        # Get data to pick a good working point for future evaluation\n",
    "        scores = aeu.mseTop10Raw(validation_data, validation_preds)\n",
    "        nsig = np.sum(labels)\n",
    "        nback = np.sum(1-labels)\n",
    "        \n",
    "        # Get some metrics for the user\n",
    "        tp = np.sum(np.where((labels==1) & (scores>msewp),1,0))/nsig\n",
    "        fp = np.sum(np.where((labels==0) & (scores>msewp),1,0))/nback\n",
    "        tn = 1-fp\n",
    "        fn = 1-tp\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2*precision*recall) / (precision + recall)\n",
    "        \n",
    "        if userfriendly:\n",
    "            print(accuracy)\n",
    "            print(precision)\n",
    "            print(recall)\n",
    "            print(f1)\n",
    "        \n",
    "    return msewps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "891a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad, biasFactor):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    badMin = min(np.where(logprob_bad != -np.inf, logprob_bad, np.inf))\n",
    "    goodMax = max(np.where(logprob_good != np.inf, logprob_good, -np.inf))\n",
    "    \n",
    "    # Getting rid of infinities\n",
    "    logprob_good[logprob_good > 500] = goodMax\n",
    "    logprob_bad[logprob_bad < 0] = badMin\n",
    "    # These only take effect if a histogram is grossly misclassified\n",
    "    logprob_good[logprob_good < badMin] = badMin\n",
    "    logprob_bad[logprob_bad > goodMax] = goodMax\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                       bcklabel='good', bckcolor='g', \n",
    "                       nbins=200, normalize=True,\n",
    "                       xaxtitle='negative logarithmic probability',\n",
    "                       yaxtitle='number of lumisections (normalized)')\n",
    "      \n",
    "    # Plot ROC curve for analysis\n",
    "    auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    # Average is biased towards better recall per user specifications\n",
    "    logprob_threshold = (1/(biasFactor + 1)) * (biasFactor*np.mean(logprob_good) + np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "    # logprob_threshold = 424\n",
    "    (_, _, _, tp, fp, tn, fn) = aeu.get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    print('Selected logprob threshold of ' + str(logprob_threshold))\n",
    "    \n",
    "    # Get metrics for analysis\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = (1 + biasFactor * biasFactor) * ((precision * recall) / ((biasFactor * biasFactor * precision) + recall)) \n",
    "    \n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('F-Measure: ' + str(f_measure))\n",
    "    \n",
    "    return logprob_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bbddf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected logprob threshold of 408.7107229493794\n",
      "Accuracy: 0.9962726144459084\n",
      "Precision: 0.996743820784274\n",
      "Recall: 0.9957983193277311\n",
      "F-Measure: 0.9958006749556555\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logprob_threshold = evaluate_autoencoders_combined(logprob_good, logprob_bad, biasFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msewps = evaluate_autoencoder_individual(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "356f7ddc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
