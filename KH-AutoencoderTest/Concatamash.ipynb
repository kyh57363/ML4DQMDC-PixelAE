{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba412492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 22:39:21.341165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.1-8d929/x86_64-centos7-gcc8-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.1-f3599/x86_64-centos7-gcc8-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/8u222-884d8/x86_64-centos7-gcc8-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.30-e5b21/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/3.6.3-dfb24/x86_64-centos7-gcc8-opt/lib64/R/library/readr/rcon\n",
      "2022-06-21 22:39:21.341201: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import SubHistStruct\n",
    "importlib.reload(SubHistStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed Controls and Run Mode\n",
    "\n",
    "# Disables all plots for large datasets where speed is more important\n",
    "createPlots = False\n",
    "\n",
    "# Control for the notebook - turn off user-friendly mode to enable faster runtimes\n",
    "userfriendly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2020c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation Parameters\n",
    "\n",
    "# Select the bias towards recall against precision, treated as a factor (so < 1 biases towards precision, 1 is equal importance, and > 1 biases towards recall)\n",
    "biasFactor = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4590f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = '../data/'\n",
    "\n",
    "# Select a list of good runs to train on in development training_mode\n",
    "# Should be validated by eye\n",
    "trainrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                   \"297598\":[[-1]],\n",
    "#                   \"297604\":[[-1]],   # A decently clean histogram\n",
    "                   \"297620\":[[-1]],   # A decently clean histogram\n",
    "                   \"297659\":[[-1]],   # An okay histogram\n",
    "                   \"297670\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                   \"299065\":[[-1]],   # A decently clean histogram\n",
    "                   \"299067\":[[-1]],   # A decently clean histogram\n",
    "                   \"299096\":[[-1]],\n",
    "                   \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "#                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "               '2017C':{\n",
    "                   \"299369\":[[-1]]\n",
    "               },\n",
    "              '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "# Select a list of good runs to test on in development training_mode\n",
    "# Should be validated by eye\n",
    "goodrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                    \"297598\":[[-1]],\n",
    "#                    \"297604\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297620\":[[-1]],   # A decently clean histogram\n",
    "                    \"297659\":[[-1]],   # An okay histogram\n",
    "                    \"297670\":[[-1]],   # A decently clean histogram\n",
    "                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                    \"299065\":[[-1]],   # A decently clean histogram\n",
    "                    \"299067\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299096\":[[-1]],\n",
    "#                    \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "              '2017C':{\n",
    "                  \"299368\":[[-1]]\n",
    "              },\n",
    "              '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "\n",
    "badrunsls = {'2017B':\n",
    "                {\n",
    "                    #\"297048\":[[-1]],\n",
    "                    #\"297282\":[[-1]],\n",
    "                    #\"297283\":[[-1]],\n",
    "                    #\"297284\":[[-1]],\n",
    "                    #\"297287\":[[-1]],\n",
    "                    #\"297288\":[[-1]],\n",
    "                    #\"297289\":[[-1]],\n",
    "                    \"299316\":[[-1]],\n",
    "                    \"299317\":[[-1]],\n",
    "                    \"299318\":[[-1]],\n",
    "                    \"299324\":[[-1]],\n",
    "                    \"299326\":[[-1]],\n",
    "                    #\"301086\":[[88,126]],\n",
    "                    #\"301086\":[[89,89]],\n",
    "                    #\"303948\":[[1710,1710]],\n",
    "                    \"297047\":[[-1]], #close but, true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297211\":[[-1]], #Reconstructs well\n",
    "#                   \"299325\":[[-1]], #Reconstructs well\n",
    "                    \"297664\":[[-1]], #true bad for all 8\n",
    "                    \"299317\":[[-1]], #true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297502\":[[-1]]\n",
    "                },\n",
    "             '2017C':{\n",
    "                 \"300781\":[[-1]], # bad for tracking (pixels were excluded.\n",
    "                 \"300079\":[[-1]], # is bad for strips and then also for tracking\n",
    "                 \"302029\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good \n",
    "                 \"300576\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                 \"300574\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                 \"300282\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                 \"301912\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "                 \"301086\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "                 \"300283\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300282\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300281\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "                 \"300239\":[[-1]], # Half bad for pixels (lost HV or readout card)\n",
    "                 \"301394\":[[-1]], # Marginal for pixels\n",
    "                 \"301183\":[[-1]], # Marginal for pixels\n",
    "                 \"300398\":[[-1]], # Marginal for pixels\n",
    "                 \"300389\":[[-1]], # Marginal for pixels\n",
    "                 \"300365\":[[-1]]  # Marginal for pixels\n",
    "              },\n",
    "             '2017E':{\n",
    "                 \"304740\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304776\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304506\":[[-1]], # Portcard problem for pixels\n",
    "                 \"304507\":[[-1]], # Portcard problem for pixels \n",
    "                 \"303989\":[[-1]], # Bad for pixels, power supply died\n",
    "                 \"303824\":[[-1]]  # Partly bad for strips due to a test\n",
    "             },\n",
    "             '2017F':{\n",
    "                 \"306422\":[[-1]], # Partly bad for strips - 2 data readouts failed \n",
    "                 \"306423\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "                 \"306425\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "                 \"305440\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "                 \"305441\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "                 \"305249\":[[-1]], # Bad for pixels - half of disk failed \n",
    "                 \"305250\":[[-1]], # Bad for pixels - half of disk failed\n",
    "                 \"305064\":[[-1]], # Marginal for pixels - some readout failed\n",
    "             },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "\n",
    "# The year and era being used\n",
    "year = '2017'\n",
    "era = 'B'\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = [\n",
    "    ['NormalizedHitResiduals_TIB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1', 'NormalizedHitResiduals_TIB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2',\n",
    "     'NormalizedHitResiduals_TIB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3' , 'NormalizedHitResiduals_TIB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4'],\n",
    "    ['chargeInner_PXLayer_1', 'chargeOuter_PXLayer_1', 'adc_PXLayer_1'],\n",
    "    ['chargeInner_PXLayer_2', 'chargeOuter_PXLayer_2', 'adc_PXLayer_2'],\n",
    "    ['chargeInner_PXLayer_3', 'chargeOuter_PXLayer_3', 'adc_PXLayer_3'],\n",
    "    ['chargeInner_PXLayer_4', 'chargeOuter_PXLayer_4', 'adc_PXLayer_4'],\n",
    "    ['charge_PXDisk_+1', 'adc_PXDisk_+1'],\n",
    "    ['charge_PXDisk_-1', 'adc_PXDisk_-1'],\n",
    "    ['charge_PXDisk_+2', 'adc_PXDisk_+2'],\n",
    "    ['charge_PXDisk_-2', 'adc_PXDisk_-2'],\n",
    "    ['charge_PXDisk_+3', 'adc_PXDisk_+3'],\n",
    "    ['charge_PXDisk_-3', 'adc_PXDisk_-3'],\n",
    "    ['NormalizedHitResiduals_TOB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__1', 'NormalizedHitResiduals_TOB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__2',\n",
    "     'NormalizedHitResiduals_TOB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__3' , 'NormalizedHitResiduals_TOB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__4']\n",
    "]\n",
    "\n",
    "# Read new data or use previously saved data & should data be saved\n",
    "readnew = True\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ffebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Set whether to train globally or locally or in a development/testing mode\n",
    "training_mode = 'development'\n",
    "\n",
    "# Selects whether to create a new histstruct or use a saved one\n",
    "readnew = True\n",
    "\n",
    "# Select whether to save a new histstruct\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6394238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames\n",
    "\n",
    "# Evaluate models seperately, as an ensemble, both, or neither\n",
    "individualEval = True\n",
    "ensembleEval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4051dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected runs/lumisections for training: \n",
      "{'297175': [[-1]], '297620': [[-1]], '297659': [[-1]], '297670': [[-1]], '299065': [[-1]], '299067': [[-1]], '299096': [[-1]], '299149': [[-1]]}\n",
      "selected runs/lumisections as good test set:\n",
      "{'297175': [[-1]], '297659': [[-1]], '297670': [[-1]], '297674': [[-1]], '297722': [[-1]], '299065': [[-1]], '299067': [[-1]], '299185': [[-1]], '299327': [[-1]], '299480': [[-1]]}\n",
      "selected runs/lumisections as bad test set:\n",
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n"
     ]
    }
   ],
   "source": [
    "### Define Training Mode Parameters - Combined Autoencoder\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use averages of training set)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    # - this only works for a single era\n",
    "    \n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+era+'_'+histnames[0][0]+'.csv') ) )\n",
    "    # Cherry picked really bad run\n",
    "    run_application = 299316\n",
    "    #run_application = 299317\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5\n",
    "        offset = 0 # normal case: offset = 0 (just use 5 previous runs)\n",
    "        \n",
    "        # Selects the 5 previous runs for training\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    #runsls_bad = badrunsls[year]\n",
    "    #runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_good = runsls_training\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)\n",
    "        \n",
    "elif training_mode == 'development':\n",
    "    # train on a user-defined subset of runs\n",
    "    \n",
    "    # Select runs to be used in training from the user-defined list\n",
    "    runsls_training = trainrunsls[year + era]\n",
    "    # Select bad runs to test on in the user-defined list\n",
    "    runsls_bad = badrunsls[year + era]\n",
    "    # Select good runs to test on in the user-defined list\n",
    "    runsls_good = goodrunsls[year + era]\n",
    "    \n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54180f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Classifiers cleared to preserve consistency\n",
      "Adding NormalizedHitResiduals_TIB__Layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4...\n",
      "Adding chargeInner_PXLayer_1...\n",
      "Adding chargeOuter_PXLayer_1...\n",
      "Adding adc_PXLayer_1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_2...\n",
      "Adding chargeOuter_PXLayer_2...\n",
      "Adding adc_PXLayer_2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_3...\n",
      "Adding chargeOuter_PXLayer_3...\n",
      "Adding adc_PXLayer_3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding chargeInner_PXLayer_4...\n",
      "Adding chargeOuter_PXLayer_4...\n",
      "Adding adc_PXLayer_4...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+1...\n",
      "Adding adc_PXDisk_+1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-1...\n",
      "Adding adc_PXDisk_-1...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+2...\n",
      "Adding adc_PXDisk_+2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-2...\n",
      "Adding adc_PXDisk_-2...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_+3...\n",
      "Adding adc_PXDisk_+3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding charge_PXDisk_-3...\n",
      "Adding adc_PXDisk_-3...\n",
      "WARNING in hist_utils.py / rebinhists: no rebinning performed since no suitable reduction factor was given. The rebinning factor (3) is not a divisor of the number of bins (34)\n",
      "Adding NormalizedHitResiduals_TOB__Layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4...\n",
      "Found 2831 histograms\n",
      "Created a histstruct with the following properties:\n",
      "- number of histogram types: 40\n",
      "- number of lumisections: 2831\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "\n",
    "# Create a new HistStruct from the data\n",
    "if readnew:\n",
    "    # Initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = SubHistStruct.SubHistStruct()\n",
    "    histstruct.reset_histlist(histnames)\n",
    "    \n",
    "    # Unpack histnames and add every histogram individually\n",
    "    for histnamegroup in histnames:\n",
    "        for histname in histnamegroup:\n",
    "            print('Adding {}...'.format(histname))\n",
    "            \n",
    "            # Bring the histograms into memory from storage for later use\n",
    "            filename = datadir + year + era + '/DF' + year + era + '_' + histname + '.csv'\n",
    "            df = dloader.get_dataframe_from_file( filename )\n",
    "            \n",
    "            # In case of local training, we can remove most of the histograms\n",
    "            if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "                runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "                df = dfu.select_runsls( df, runsls_total )\n",
    "                \n",
    "            # Store the data in the histstruct object managing this whole thing\n",
    "            histstruct.add_dataframe( df, rebinningfactor = 3 )\n",
    "        \n",
    "    print('Found {} histograms'.format(len(histstruct.runnbs)))\n",
    "\n",
    "# Load a previously saved HistStruct\n",
    "else:\n",
    "    # Load histstruct from storage\n",
    "    histstruct = HistStruct.HistStruct.load('test.pk1')\n",
    "    \n",
    "    # Count of bad runs, presumably for later use\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "if userfriendly:\n",
    "    print('Created a histstruct with the following properties:')\n",
    "    print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "    print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45931fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'299316': [[-1]], '299317': [[-1]], '299318': [[-1]], '299324': [[-1]], '299326': [[-1]], '297047': [[-1]], '297169': [[-1]], '297664': [[-1]]}\n",
      "Assigned masks: ['dcson', 'golden', 'highstat', 'lowstat', 'training', 'good', 'bad', 'bad0', 'bad1', 'bad2', 'bad3', 'bad4', 'bad5', 'bad6', 'bad7']\n"
     ]
    }
   ],
   "source": [
    "### Add Masks to Data\n",
    "\n",
    "if readnew:\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat' )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=100 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        print(runsls_bad)\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    if save:\n",
    "        histstruct.save('test.pk1')\n",
    "if userfriendly: print('Assigned masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d6a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the input data for analysis\n",
    "\n",
    "if((training_mode=='local' or training_mode == 'development') and createPlots):\n",
    "\n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )\n",
    "    \n",
    "elif( training_mode=='global' and createPlots):\n",
    "    \n",
    "    # bad test runs\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "                                labellist = ['typical good histograms','bad'],\n",
    "                                colorlist = ['blue','red'],\n",
    "                                transparencylist = [0.01,1.]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_concatamash_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            if userfriendly:\n",
    "                print('\\nNow Defining model {}/'.format(i + 1) \n",
    "                      + str(len(histnames)))\n",
    "                print(' - Size of training set: {}'.format(X_train.shape))\n",
    "            \n",
    "            ## Model parameters\n",
    "            print(X_train.shape)\n",
    "            \n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(256, activation=\"tanh\")(conc_layer)\n",
    "            encoder = Dense(128, activation='relu')(encoder)\n",
    "            \n",
    "            encoder = Dense(32, activation='relu')(encoder)\n",
    "            \n",
    "            decoder = Dense(128, activation=\"relu\")(encoder)\n",
    "            decoder = Dense(256, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoder.summary()\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c76ea4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now Defining model 1/12\n",
      " - Size of training set: (1006, 8, 34)\n",
      "(1006, 8, 34)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 272)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          69888       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          4224        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          33024       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 34)           8738        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 34)           8738        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 214,064\n",
      "Trainable params: 214,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 2/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 22:39:41.677392: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.1-8d929/x86_64-centos7-gcc8-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.1-f3599/x86_64-centos7-gcc8-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/8u222-884d8/x86_64-centos7-gcc8-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.30-e5b21/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/3.6.3-dfb24/x86_64-centos7-gcc8-opt/lib64/R/library/readr/rcon\n",
      "2022-06-21 22:39:41.677433: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-21 22:39:41.677499: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-khowey): /proc/driver/nvidia/version does not exist\n",
      "2022-06-21 22:39:41.677896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 102)          0           input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          26368       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          32896       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           4128        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          4224        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          33024       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 34)           8738        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 34)           8738        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 34)           8738        dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 3/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 102)          0           input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          26368       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          32896       dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           4128        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          4224        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          33024       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 34)           8738        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 34)           8738        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 34)           8738        dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 4/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 102)          0           input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          26368       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          32896       dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 32)           4128        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          4224        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 256)          33024       dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 34)           8738        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 34)           8738        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 34)           8738        dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 5/12\n",
      " - Size of training set: (1006, 3, 34)\n",
      "(1006, 3, 34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 102)          0           input_18[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 256)          26368       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 128)          32896       dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 32)           4128        dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          4224        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 256)          33024       dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 34)           8738        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 34)           8738        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 34)           8738        dense_41[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 126,854\n",
      "Trainable params: 126,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 6/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 68)           0           input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 256)          17664       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          32896       dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 32)           4128        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 128)          4224        dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 256)          33024       dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 34)           8738        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 34)           8738        dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 7/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 68)           0           input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 256)          17664       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 128)          32896       dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 32)           4128        dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 128)          4224        dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 256)          33024       dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 34)           8738        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 34)           8738        dense_56[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 8/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 68)           0           input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 256)          17664       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 128)          32896       dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 32)           4128        dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 128)          4224        dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 256)          33024       dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 34)           8738        dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 34)           8738        dense_63[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 9/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 68)           0           input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 256)          17664       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 128)          32896       dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 32)           4128        dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 128)          4224        dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 256)          33024       dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 34)           8738        dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 34)           8738        dense_70[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 10/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 68)           0           input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 256)          17664       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 128)          32896       dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 32)           4128        dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 128)          4224        dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 256)          33024       dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 34)           8738        dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 34)           8738        dense_77[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Now Defining model 11/12\n",
      " - Size of training set: (1006, 2, 34)\n",
      "(1006, 2, 34)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 68)           0           input_31[0][0]                   \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 256)          17664       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 128)          32896       dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 32)           4128        dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 128)          4224        dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 256)          33024       dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 34)           8738        dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 34)           8738        dense_84[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,412\n",
      "Trainable params: 109,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now Defining model 12/12\n",
      " - Size of training set: (1006, 8, 34)\n",
      "(1006, 8, 34)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_39 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 272)          0           input_33[0][0]                   \n",
      "                                                                 input_34[0][0]                   \n",
      "                                                                 input_35[0][0]                   \n",
      "                                                                 input_36[0][0]                   \n",
      "                                                                 input_37[0][0]                   \n",
      "                                                                 input_38[0][0]                   \n",
      "                                                                 input_39[0][0]                   \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 256)          69888       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 128)          32896       dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 32)           4128        dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 128)          4224        dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 256)          33024       dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 34)           8738        dense_91[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 214,064\n",
      "Trainable params: 214,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(histslist, vallist, autoencoders, train_normhist) = define_concatamash_autoencoder(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a44e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders):\n",
    "    \n",
    "    # Iterate through the training data to train corresponding autoencoders\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        if userfriendly: print('\\nNow training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 200\n",
    "        batch_size = 50\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                            epochs=nb_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                            verbose=1,\n",
    "                                callbacks= [earlystop] \n",
    "                            )\n",
    "        \n",
    "        # Create a plot of the model\n",
    "        \n",
    "        tf.keras.utils.plot_model(\n",
    "            autoencoder,\n",
    "            to_file=\"models/modelConcatamash{}.png\".format(i),\n",
    "            show_shapes=True,\n",
    "            show_dtype=False,\n",
    "            show_layer_names=False,\n",
    "            rankdir=\"TB\")\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52397fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now training model 1/12\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 22:39:42.852714: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-06-21 22:39:42.853182: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2900000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 56ms/step - loss: 0.0072 - dense_5_loss: 7.9005e-04 - dense_6_loss: 9.5852e-04 - dense_7_loss: 6.8858e-04 - dense_8_loss: 0.0012 - dense_9_loss: 8.2844e-04 - dense_10_loss: 9.5194e-04 - dense_11_loss: 8.6894e-04 - dense_12_loss: 9.8046e-04 - val_loss: 5.6638e-04 - val_dense_5_loss: 1.2112e-04 - val_dense_6_loss: 7.8187e-05 - val_dense_7_loss: 7.4354e-05 - val_dense_8_loss: 6.8538e-05 - val_dense_9_loss: 8.0874e-05 - val_dense_10_loss: 5.6441e-05 - val_dense_11_loss: 4.2490e-05 - val_dense_12_loss: 4.4382e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.1918e-04 - dense_5_loss: 3.9191e-05 - dense_6_loss: 2.9428e-05 - dense_7_loss: 2.7797e-05 - dense_8_loss: 3.3972e-05 - dense_9_loss: 2.5923e-05 - dense_10_loss: 2.1519e-05 - dense_11_loss: 2.0216e-05 - dense_12_loss: 2.1133e-05 - val_loss: 5.7226e-05 - val_dense_5_loss: 8.8653e-06 - val_dense_6_loss: 1.0641e-05 - val_dense_7_loss: 4.8776e-06 - val_dense_8_loss: 1.1960e-05 - val_dense_9_loss: 4.9869e-06 - val_dense_10_loss: 5.4105e-06 - val_dense_11_loss: 5.3756e-06 - val_dense_12_loss: 5.1092e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.5994e-05 - dense_5_loss: 3.9830e-06 - dense_6_loss: 7.3301e-06 - dense_7_loss: 3.3367e-06 - dense_8_loss: 6.4663e-06 - dense_9_loss: 3.4315e-06 - dense_10_loss: 4.4239e-06 - dense_11_loss: 3.0856e-06 - dense_12_loss: 3.9367e-06 - val_loss: 1.8465e-05 - val_dense_5_loss: 1.2759e-06 - val_dense_6_loss: 4.6396e-06 - val_dense_7_loss: 1.6495e-06 - val_dense_8_loss: 3.2224e-06 - val_dense_9_loss: 1.5801e-06 - val_dense_10_loss: 2.6524e-06 - val_dense_11_loss: 1.5207e-06 - val_dense_12_loss: 1.9244e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4819e-05 - dense_5_loss: 8.1577e-07 - dense_6_loss: 4.5435e-06 - dense_7_loss: 8.3955e-07 - dense_8_loss: 2.7725e-06 - dense_9_loss: 1.0943e-06 - dense_10_loss: 1.9724e-06 - dense_11_loss: 1.1259e-06 - dense_12_loss: 1.6551e-06 - val_loss: 1.2007e-05 - val_dense_5_loss: 5.0533e-07 - val_dense_6_loss: 4.0435e-06 - val_dense_7_loss: 4.8839e-07 - val_dense_8_loss: 2.2880e-06 - val_dense_9_loss: 8.3443e-07 - val_dense_10_loss: 1.5967e-06 - val_dense_11_loss: 8.8161e-07 - val_dense_12_loss: 1.3689e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.2181e-05 - dense_5_loss: 4.9640e-07 - dense_6_loss: 4.2155e-06 - dense_7_loss: 4.8342e-07 - dense_8_loss: 2.3378e-06 - dense_9_loss: 7.6828e-07 - dense_10_loss: 1.6068e-06 - dense_11_loss: 8.5696e-07 - dense_12_loss: 1.4159e-06 - val_loss: 1.1374e-05 - val_dense_5_loss: 4.3615e-07 - val_dense_6_loss: 3.9495e-06 - val_dense_7_loss: 4.3548e-07 - val_dense_8_loss: 2.1733e-06 - val_dense_9_loss: 7.6350e-07 - val_dense_10_loss: 1.4827e-06 - val_dense_11_loss: 8.0980e-07 - val_dense_12_loss: 1.3239e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.1771e-05 - dense_5_loss: 4.6221e-07 - dense_6_loss: 4.1152e-06 - dense_7_loss: 4.6247e-07 - dense_8_loss: 2.2570e-06 - dense_9_loss: 7.5235e-07 - dense_10_loss: 1.5413e-06 - dense_11_loss: 8.3459e-07 - dense_12_loss: 1.3459e-06 - val_loss: 1.1343e-05 - val_dense_5_loss: 4.7378e-07 - val_dense_6_loss: 3.8462e-06 - val_dense_7_loss: 4.6210e-07 - val_dense_8_loss: 2.1461e-06 - val_dense_9_loss: 8.1228e-07 - val_dense_10_loss: 1.4631e-06 - val_dense_11_loss: 8.2939e-07 - val_dense_12_loss: 1.3100e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.1703e-05 - dense_5_loss: 4.8776e-07 - dense_6_loss: 4.0189e-06 - dense_7_loss: 4.9093e-07 - dense_8_loss: 2.2282e-06 - dense_9_loss: 7.7492e-07 - dense_10_loss: 1.5226e-06 - dense_11_loss: 8.5388e-07 - dense_12_loss: 1.3257e-06 - val_loss: 1.1058e-05 - val_dense_5_loss: 4.6589e-07 - val_dense_6_loss: 3.7526e-06 - val_dense_7_loss: 4.6734e-07 - val_dense_8_loss: 2.0652e-06 - val_dense_9_loss: 7.9612e-07 - val_dense_10_loss: 1.4126e-06 - val_dense_11_loss: 8.3516e-07 - val_dense_12_loss: 1.2632e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.1505e-05 - dense_5_loss: 4.9226e-07 - dense_6_loss: 3.9322e-06 - dense_7_loss: 4.8731e-07 - dense_8_loss: 2.1862e-06 - dense_9_loss: 7.7706e-07 - dense_10_loss: 1.4807e-06 - dense_11_loss: 8.5496e-07 - dense_12_loss: 1.2940e-06 - val_loss: 1.0863e-05 - val_dense_5_loss: 4.7774e-07 - val_dense_6_loss: 3.6350e-06 - val_dense_7_loss: 4.8055e-07 - val_dense_8_loss: 2.0207e-06 - val_dense_9_loss: 7.9930e-07 - val_dense_10_loss: 1.3985e-06 - val_dense_11_loss: 8.2495e-07 - val_dense_12_loss: 1.2262e-06\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.1367e-05 - dense_5_loss: 5.0427e-07 - dense_6_loss: 3.8486e-06 - dense_7_loss: 5.0032e-07 - dense_8_loss: 2.1348e-06 - dense_9_loss: 7.9540e-07 - dense_10_loss: 1.4607e-06 - dense_11_loss: 8.5858e-07 - dense_12_loss: 1.2639e-06 - val_loss: 1.0644e-05 - val_dense_5_loss: 4.8871e-07 - val_dense_6_loss: 3.5422e-06 - val_dense_7_loss: 4.8335e-07 - val_dense_8_loss: 1.9731e-06 - val_dense_9_loss: 7.9858e-07 - val_dense_10_loss: 1.3469e-06 - val_dense_11_loss: 8.2581e-07 - val_dense_12_loss: 1.1848e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.1196e-05 - dense_5_loss: 5.2353e-07 - dense_6_loss: 3.7355e-06 - dense_7_loss: 5.1905e-07 - dense_8_loss: 2.0814e-06 - dense_9_loss: 8.1453e-07 - dense_10_loss: 1.4207e-06 - dense_11_loss: 8.6685e-07 - dense_12_loss: 1.2345e-06 - val_loss: 1.0665e-05 - val_dense_5_loss: 4.9801e-07 - val_dense_6_loss: 3.5006e-06 - val_dense_7_loss: 4.9860e-07 - val_dense_8_loss: 1.9664e-06 - val_dense_9_loss: 8.3221e-07 - val_dense_10_loss: 1.3461e-06 - val_dense_11_loss: 8.3702e-07 - val_dense_12_loss: 1.1861e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.1095e-05 - dense_5_loss: 5.4483e-07 - dense_6_loss: 3.6441e-06 - dense_7_loss: 5.2968e-07 - dense_8_loss: 2.0510e-06 - dense_9_loss: 8.2340e-07 - dense_10_loss: 1.4007e-06 - dense_11_loss: 8.7673e-07 - dense_12_loss: 1.2246e-06 - val_loss: 1.0588e-05 - val_dense_5_loss: 5.1756e-07 - val_dense_6_loss: 3.4197e-06 - val_dense_7_loss: 5.2080e-07 - val_dense_8_loss: 1.9362e-06 - val_dense_9_loss: 8.4672e-07 - val_dense_10_loss: 1.3265e-06 - val_dense_11_loss: 8.5459e-07 - val_dense_12_loss: 1.1660e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.0996e-05 - dense_5_loss: 5.4623e-07 - dense_6_loss: 3.5836e-06 - dense_7_loss: 5.3717e-07 - dense_8_loss: 2.0205e-06 - dense_9_loss: 8.3290e-07 - dense_10_loss: 1.3866e-06 - dense_11_loss: 8.8139e-07 - dense_12_loss: 1.2078e-06 - val_loss: 1.0451e-05 - val_dense_5_loss: 5.2448e-07 - val_dense_6_loss: 3.3431e-06 - val_dense_7_loss: 5.1627e-07 - val_dense_8_loss: 1.8955e-06 - val_dense_9_loss: 8.5918e-07 - val_dense_10_loss: 1.3041e-06 - val_dense_11_loss: 8.6561e-07 - val_dense_12_loss: 1.1423e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.1042e-05 - dense_5_loss: 5.7988e-07 - dense_6_loss: 3.5369e-06 - dense_7_loss: 5.5984e-07 - dense_8_loss: 2.0084e-06 - dense_9_loss: 8.7150e-07 - dense_10_loss: 1.3765e-06 - dense_11_loss: 8.9641e-07 - dense_12_loss: 1.2121e-06 - val_loss: 1.0371e-05 - val_dense_5_loss: 5.2446e-07 - val_dense_6_loss: 3.3235e-06 - val_dense_7_loss: 5.2190e-07 - val_dense_8_loss: 1.8798e-06 - val_dense_9_loss: 8.4329e-07 - val_dense_10_loss: 1.2881e-06 - val_dense_11_loss: 8.6937e-07 - val_dense_12_loss: 1.1203e-06\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0752e-05 - dense_5_loss: 5.5891e-07 - dense_6_loss: 3.4394e-06 - dense_7_loss: 5.4732e-07 - dense_8_loss: 1.9478e-06 - dense_9_loss: 8.5937e-07 - dense_10_loss: 1.3427e-06 - dense_11_loss: 8.8805e-07 - dense_12_loss: 1.1688e-06 - val_loss: 1.0229e-05 - val_dense_5_loss: 5.2561e-07 - val_dense_6_loss: 3.2558e-06 - val_dense_7_loss: 5.1538e-07 - val_dense_8_loss: 1.8387e-06 - val_dense_9_loss: 8.4655e-07 - val_dense_10_loss: 1.2760e-06 - val_dense_11_loss: 8.5158e-07 - val_dense_12_loss: 1.1192e-06\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 14ms/step - loss: 1.0654e-05 - dense_5_loss: 5.4946e-07 - dense_6_loss: 3.4099e-06 - dense_7_loss: 5.3831e-07 - dense_8_loss: 1.9320e-06 - dense_9_loss: 8.5191e-07 - dense_10_loss: 1.3322e-06 - dense_11_loss: 8.8501e-07 - dense_12_loss: 1.1550e-06 - val_loss: 1.0184e-05 - val_dense_5_loss: 5.3474e-07 - val_dense_6_loss: 3.2107e-06 - val_dense_7_loss: 5.2812e-07 - val_dense_8_loss: 1.8307e-06 - val_dense_9_loss: 8.6045e-07 - val_dense_10_loss: 1.2573e-06 - val_dense_11_loss: 8.6095e-07 - val_dense_12_loss: 1.1012e-06\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.0561e-05 - dense_5_loss: 5.6306e-07 - dense_6_loss: 3.3396e-06 - dense_7_loss: 5.5317e-07 - dense_8_loss: 1.9186e-06 - dense_9_loss: 8.6686e-07 - dense_10_loss: 1.2924e-06 - dense_11_loss: 8.9453e-07 - dense_12_loss: 1.1327e-06 - val_loss: 1.0257e-05 - val_dense_5_loss: 5.6989e-07 - val_dense_6_loss: 3.1866e-06 - val_dense_7_loss: 5.3997e-07 - val_dense_8_loss: 1.8326e-06 - val_dense_9_loss: 8.9305e-07 - val_dense_10_loss: 1.2575e-06 - val_dense_11_loss: 8.8563e-07 - val_dense_12_loss: 1.0914e-06\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0539e-05 - dense_5_loss: 5.8275e-07 - dense_6_loss: 3.2802e-06 - dense_7_loss: 5.6759e-07 - dense_8_loss: 1.8913e-06 - dense_9_loss: 8.8562e-07 - dense_10_loss: 1.2973e-06 - dense_11_loss: 9.0783e-07 - dense_12_loss: 1.1260e-06 - val_loss: 1.0123e-05 - val_dense_5_loss: 5.8704e-07 - val_dense_6_loss: 3.0695e-06 - val_dense_7_loss: 5.6832e-07 - val_dense_8_loss: 1.7766e-06 - val_dense_9_loss: 8.9827e-07 - val_dense_10_loss: 1.2152e-06 - val_dense_11_loss: 9.1959e-07 - val_dense_12_loss: 1.0887e-06\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0287e-05 - dense_5_loss: 5.9947e-07 - dense_6_loss: 3.1414e-06 - dense_7_loss: 5.7282e-07 - dense_8_loss: 1.8105e-06 - dense_9_loss: 8.9551e-07 - dense_10_loss: 1.2525e-06 - dense_11_loss: 9.2543e-07 - dense_12_loss: 1.0894e-06 - val_loss: 1.0240e-05 - val_dense_5_loss: 6.0271e-07 - val_dense_6_loss: 2.9974e-06 - val_dense_7_loss: 6.1764e-07 - val_dense_8_loss: 1.7650e-06 - val_dense_9_loss: 9.7177e-07 - val_dense_10_loss: 1.2140e-06 - val_dense_11_loss: 9.6611e-07 - val_dense_12_loss: 1.1050e-06\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.0563e-05 - dense_5_loss: 6.5205e-07 - dense_6_loss: 3.1336e-06 - dense_7_loss: 6.1953e-07 - dense_8_loss: 1.8450e-06 - dense_9_loss: 9.4570e-07 - dense_10_loss: 1.2826e-06 - dense_11_loss: 9.4969e-07 - dense_12_loss: 1.1350e-06 - val_loss: 1.0151e-05 - val_dense_5_loss: 6.1625e-07 - val_dense_6_loss: 2.9147e-06 - val_dense_7_loss: 6.1363e-07 - val_dense_8_loss: 1.7308e-06 - val_dense_9_loss: 9.6957e-07 - val_dense_10_loss: 1.2285e-06 - val_dense_11_loss: 9.9477e-07 - val_dense_12_loss: 1.0829e-06\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.0721e-05 - dense_5_loss: 6.8556e-07 - dense_6_loss: 3.1318e-06 - dense_7_loss: 6.4509e-07 - dense_8_loss: 1.8553e-06 - dense_9_loss: 9.7024e-07 - dense_10_loss: 1.3062e-06 - dense_11_loss: 9.7088e-07 - dense_12_loss: 1.1564e-06 - val_loss: 9.8089e-06 - val_dense_5_loss: 5.6490e-07 - val_dense_6_loss: 2.9775e-06 - val_dense_7_loss: 5.5511e-07 - val_dense_8_loss: 1.6730e-06 - val_dense_9_loss: 9.2156e-07 - val_dense_10_loss: 1.2036e-06 - val_dense_11_loss: 8.7804e-07 - val_dense_12_loss: 1.0352e-06\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.0249e-05 - dense_5_loss: 6.4162e-07 - dense_6_loss: 3.0130e-06 - dense_7_loss: 6.2100e-07 - dense_8_loss: 1.7538e-06 - dense_9_loss: 9.4890e-07 - dense_10_loss: 1.2474e-06 - dense_11_loss: 9.3435e-07 - dense_12_loss: 1.0885e-06 - val_loss: 9.7956e-06 - val_dense_5_loss: 6.3746e-07 - val_dense_6_loss: 2.8165e-06 - val_dense_7_loss: 6.3404e-07 - val_dense_8_loss: 1.6605e-06 - val_dense_9_loss: 9.2919e-07 - val_dense_10_loss: 1.1613e-06 - val_dense_11_loss: 9.1309e-07 - val_dense_12_loss: 1.0436e-06\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 9.9102e-06 - dense_5_loss: 6.2929e-07 - dense_6_loss: 2.8928e-06 - dense_7_loss: 5.9750e-07 - dense_8_loss: 1.6982e-06 - dense_9_loss: 9.2201e-07 - dense_10_loss: 1.1968e-06 - dense_11_loss: 9.2802e-07 - dense_12_loss: 1.0456e-06 - val_loss: 9.4229e-06 - val_dense_5_loss: 5.8172e-07 - val_dense_6_loss: 2.6985e-06 - val_dense_7_loss: 5.7741e-07 - val_dense_8_loss: 1.6148e-06 - val_dense_9_loss: 9.2192e-07 - val_dense_10_loss: 1.1361e-06 - val_dense_11_loss: 8.9877e-07 - val_dense_12_loss: 9.9363e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0151e-05 - dense_5_loss: 6.8898e-07 - dense_6_loss: 2.8767e-06 - dense_7_loss: 6.4104e-07 - dense_8_loss: 1.7211e-06 - dense_9_loss: 9.6769e-07 - dense_10_loss: 1.2154e-06 - dense_11_loss: 9.5238e-07 - dense_12_loss: 1.0874e-06 - val_loss: 1.0027e-05 - val_dense_5_loss: 6.8393e-07 - val_dense_6_loss: 2.7135e-06 - val_dense_7_loss: 6.2956e-07 - val_dense_8_loss: 1.7278e-06 - val_dense_9_loss: 1.0166e-06 - val_dense_10_loss: 1.2599e-06 - val_dense_11_loss: 9.2859e-07 - val_dense_12_loss: 1.0675e-06\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 9.8378e-06 - dense_5_loss: 6.5332e-07 - dense_6_loss: 2.8052e-06 - dense_7_loss: 6.0447e-07 - dense_8_loss: 1.6822e-06 - dense_9_loss: 9.4163e-07 - dense_10_loss: 1.1941e-06 - dense_11_loss: 9.3037e-07 - dense_12_loss: 1.0265e-06 - val_loss: 1.0889e-05 - val_dense_5_loss: 8.8322e-07 - val_dense_6_loss: 2.7783e-06 - val_dense_7_loss: 7.5427e-07 - val_dense_8_loss: 1.7851e-06 - val_dense_9_loss: 1.1259e-06 - val_dense_10_loss: 1.2709e-06 - val_dense_11_loss: 1.0720e-06 - val_dense_12_loss: 1.2196e-06\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 9.7996e-06 - dense_5_loss: 6.9207e-07 - dense_6_loss: 2.6996e-06 - dense_7_loss: 6.4212e-07 - dense_8_loss: 1.6364e-06 - dense_9_loss: 9.6158e-07 - dense_10_loss: 1.1724e-06 - dense_11_loss: 9.5758e-07 - dense_12_loss: 1.0379e-06 - val_loss: 9.1091e-06 - val_dense_5_loss: 6.3811e-07 - val_dense_6_loss: 2.5571e-06 - val_dense_7_loss: 5.7636e-07 - val_dense_8_loss: 1.4945e-06 - val_dense_9_loss: 9.2726e-07 - val_dense_10_loss: 1.0640e-06 - val_dense_11_loss: 8.9891e-07 - val_dense_12_loss: 9.5285e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 9.3973e-06 - dense_5_loss: 6.6071e-07 - dense_6_loss: 2.5924e-06 - dense_7_loss: 6.1779e-07 - dense_8_loss: 1.5640e-06 - dense_9_loss: 9.3454e-07 - dense_10_loss: 1.1196e-06 - dense_11_loss: 9.2683e-07 - dense_12_loss: 9.8147e-07 - val_loss: 9.5504e-06 - val_dense_5_loss: 7.5027e-07 - val_dense_6_loss: 2.4068e-06 - val_dense_7_loss: 7.0084e-07 - val_dense_8_loss: 1.5589e-06 - val_dense_9_loss: 1.0228e-06 - val_dense_10_loss: 1.1075e-06 - val_dense_11_loss: 9.6731e-07 - val_dense_12_loss: 1.0360e-06\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 9.6154e-06 - dense_5_loss: 7.1262e-07 - dense_6_loss: 2.5862e-06 - dense_7_loss: 6.5542e-07 - dense_8_loss: 1.5977e-06 - dense_9_loss: 9.6446e-07 - dense_10_loss: 1.1516e-06 - dense_11_loss: 9.4819e-07 - dense_12_loss: 9.9924e-07 - val_loss: 9.0131e-06 - val_dense_5_loss: 6.5867e-07 - val_dense_6_loss: 2.3405e-06 - val_dense_7_loss: 6.2822e-07 - val_dense_8_loss: 1.4820e-06 - val_dense_9_loss: 9.8186e-07 - val_dense_10_loss: 1.0488e-06 - val_dense_11_loss: 9.0397e-07 - val_dense_12_loss: 9.6908e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 9.3745e-06 - dense_5_loss: 7.1744e-07 - dense_6_loss: 2.4650e-06 - dense_7_loss: 6.5320e-07 - dense_8_loss: 1.5223e-06 - dense_9_loss: 9.6231e-07 - dense_10_loss: 1.1119e-06 - dense_11_loss: 9.6245e-07 - dense_12_loss: 9.7988e-07 - val_loss: 8.6612e-06 - val_dense_5_loss: 6.3236e-07 - val_dense_6_loss: 2.2690e-06 - val_dense_7_loss: 5.6589e-07 - val_dense_8_loss: 1.4032e-06 - val_dense_9_loss: 9.4842e-07 - val_dense_10_loss: 1.0236e-06 - val_dense_11_loss: 8.9882e-07 - val_dense_12_loss: 9.1999e-07\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 8ms/step - loss: 8.7467e-06 - dense_5_loss: 6.6251e-07 - dense_6_loss: 2.2838e-06 - dense_7_loss: 6.0961e-07 - dense_8_loss: 1.4027e-06 - dense_9_loss: 9.2315e-07 - dense_10_loss: 1.0336e-06 - dense_11_loss: 9.2658e-07 - dense_12_loss: 9.0482e-07 - val_loss: 9.2358e-06 - val_dense_5_loss: 6.5831e-07 - val_dense_6_loss: 2.5299e-06 - val_dense_7_loss: 5.9371e-07 - val_dense_8_loss: 1.5098e-06 - val_dense_9_loss: 9.2659e-07 - val_dense_10_loss: 1.0906e-06 - val_dense_11_loss: 9.1103e-07 - val_dense_12_loss: 1.0157e-06\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0492e-05 - dense_5_loss: 8.8538e-07 - dense_6_loss: 2.5834e-06 - dense_7_loss: 7.4738e-07 - dense_8_loss: 1.6998e-06 - dense_9_loss: 1.0712e-06 - dense_10_loss: 1.2658e-06 - dense_11_loss: 1.0611e-06 - dense_12_loss: 1.1781e-06 - val_loss: 9.2130e-06 - val_dense_5_loss: 7.5424e-07 - val_dense_6_loss: 2.3217e-06 - val_dense_7_loss: 6.3427e-07 - val_dense_8_loss: 1.4233e-06 - val_dense_9_loss: 1.0235e-06 - val_dense_10_loss: 1.1091e-06 - val_dense_11_loss: 9.3839e-07 - val_dense_12_loss: 1.0085e-06\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.2722e-06 - dense_5_loss: 7.2720e-07 - dense_6_loss: 2.2761e-06 - dense_7_loss: 6.6169e-07 - dense_8_loss: 1.5205e-06 - dense_9_loss: 9.8205e-07 - dense_10_loss: 1.1224e-06 - dense_11_loss: 9.8406e-07 - dense_12_loss: 9.9825e-07 - val_loss: 9.7268e-06 - val_dense_5_loss: 7.7737e-07 - val_dense_6_loss: 2.5656e-06 - val_dense_7_loss: 6.4552e-07 - val_dense_8_loss: 1.5964e-06 - val_dense_9_loss: 9.4883e-07 - val_dense_10_loss: 1.1977e-06 - val_dense_11_loss: 9.0230e-07 - val_dense_12_loss: 1.0930e-06\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 8.8410e-06 - dense_5_loss: 7.2115e-07 - dense_6_loss: 2.1694e-06 - dense_7_loss: 6.3645e-07 - dense_8_loss: 1.4006e-06 - dense_9_loss: 9.4156e-07 - dense_10_loss: 1.0562e-06 - dense_11_loss: 9.7204e-07 - dense_12_loss: 9.4357e-07 - val_loss: 8.1096e-06 - val_dense_5_loss: 6.0983e-07 - val_dense_6_loss: 1.9478e-06 - val_dense_7_loss: 5.6028e-07 - val_dense_8_loss: 1.3036e-06 - val_dense_9_loss: 9.1964e-07 - val_dense_10_loss: 9.7252e-07 - val_dense_11_loss: 8.9660e-07 - val_dense_12_loss: 8.9935e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.6176e-06 - dense_5_loss: 5.9917e-07 - dense_6_loss: 1.8757e-06 - dense_7_loss: 5.4956e-07 - dense_8_loss: 1.1776e-06 - dense_9_loss: 8.5908e-07 - dense_10_loss: 8.9582e-07 - dense_11_loss: 8.8035e-07 - dense_12_loss: 7.8028e-07 - val_loss: 7.5401e-06 - val_dense_5_loss: 6.5295e-07 - val_dense_6_loss: 1.7553e-06 - val_dense_7_loss: 5.8408e-07 - val_dense_8_loss: 1.1178e-06 - val_dense_9_loss: 9.1129e-07 - val_dense_10_loss: 8.6496e-07 - val_dense_11_loss: 8.8568e-07 - val_dense_12_loss: 7.6802e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.4911e-06 - dense_5_loss: 6.1047e-07 - dense_6_loss: 1.7946e-06 - dense_7_loss: 5.4964e-07 - dense_8_loss: 1.1455e-06 - dense_9_loss: 8.6069e-07 - dense_10_loss: 8.7905e-07 - dense_11_loss: 8.9184e-07 - dense_12_loss: 7.5927e-07 - val_loss: 7.3454e-06 - val_dense_5_loss: 6.2911e-07 - val_dense_6_loss: 1.6828e-06 - val_dense_7_loss: 5.5465e-07 - val_dense_8_loss: 1.0972e-06 - val_dense_9_loss: 8.9650e-07 - val_dense_10_loss: 8.4649e-07 - val_dense_11_loss: 9.0319e-07 - val_dense_12_loss: 7.3549e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 7.6921e-06 - dense_5_loss: 6.6058e-07 - dense_6_loss: 1.7717e-06 - dense_7_loss: 5.7878e-07 - dense_8_loss: 1.1595e-06 - dense_9_loss: 8.7387e-07 - dense_10_loss: 9.1066e-07 - dense_11_loss: 9.2663e-07 - dense_12_loss: 8.1040e-07 - val_loss: 8.1063e-06 - val_dense_5_loss: 6.9072e-07 - val_dense_6_loss: 1.8798e-06 - val_dense_7_loss: 5.2473e-07 - val_dense_8_loss: 1.2831e-06 - val_dense_9_loss: 9.1527e-07 - val_dense_10_loss: 9.4280e-07 - val_dense_11_loss: 9.5607e-07 - val_dense_12_loss: 9.1381e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.1351e-06 - dense_5_loss: 5.9431e-07 - dense_6_loss: 1.6586e-06 - dense_7_loss: 5.1763e-07 - dense_8_loss: 1.0793e-06 - dense_9_loss: 8.2144e-07 - dense_10_loss: 8.3856e-07 - dense_11_loss: 8.7959e-07 - dense_12_loss: 7.4562e-07 - val_loss: 6.7897e-06 - val_dense_5_loss: 5.5217e-07 - val_dense_6_loss: 1.5538e-06 - val_dense_7_loss: 4.7246e-07 - val_dense_8_loss: 1.0209e-06 - val_dense_9_loss: 8.3385e-07 - val_dense_10_loss: 7.7770e-07 - val_dense_11_loss: 8.4439e-07 - val_dense_12_loss: 7.3447e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 6.6154e-06 - dense_5_loss: 5.5132e-07 - dense_6_loss: 1.4796e-06 - dense_7_loss: 4.8761e-07 - dense_8_loss: 9.9186e-07 - dense_9_loss: 7.9988e-07 - dense_10_loss: 7.6536e-07 - dense_11_loss: 8.5637e-07 - dense_12_loss: 6.8339e-07 - val_loss: 7.4201e-06 - val_dense_5_loss: 6.3671e-07 - val_dense_6_loss: 1.7730e-06 - val_dense_7_loss: 5.2311e-07 - val_dense_8_loss: 1.1711e-06 - val_dense_9_loss: 8.4400e-07 - val_dense_10_loss: 8.6041e-07 - val_dense_11_loss: 8.6513e-07 - val_dense_12_loss: 7.4657e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.5614e-06 - dense_5_loss: 5.5428e-07 - dense_6_loss: 1.4549e-06 - dense_7_loss: 4.8301e-07 - dense_8_loss: 9.7481e-07 - dense_9_loss: 7.9065e-07 - dense_10_loss: 7.5685e-07 - dense_11_loss: 8.6768e-07 - dense_12_loss: 6.7925e-07 - val_loss: 6.9000e-06 - val_dense_5_loss: 6.0500e-07 - val_dense_6_loss: 1.4464e-06 - val_dense_7_loss: 4.6189e-07 - val_dense_8_loss: 1.0452e-06 - val_dense_9_loss: 8.4489e-07 - val_dense_10_loss: 8.4038e-07 - val_dense_11_loss: 8.7342e-07 - val_dense_12_loss: 7.8276e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 6.1879e-06 - dense_5_loss: 4.9625e-07 - dense_6_loss: 1.3631e-06 - dense_7_loss: 4.4421e-07 - dense_8_loss: 9.2997e-07 - dense_9_loss: 7.5607e-07 - dense_10_loss: 7.1519e-07 - dense_11_loss: 8.3546e-07 - dense_12_loss: 6.4760e-07 - val_loss: 6.3157e-06 - val_dense_5_loss: 5.2003e-07 - val_dense_6_loss: 1.3120e-06 - val_dense_7_loss: 4.3548e-07 - val_dense_8_loss: 9.2289e-07 - val_dense_9_loss: 8.3975e-07 - val_dense_10_loss: 7.3316e-07 - val_dense_11_loss: 8.9475e-07 - val_dense_12_loss: 6.5760e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.0061e-06 - dense_5_loss: 4.8100e-07 - dense_6_loss: 1.2893e-06 - dense_7_loss: 4.4432e-07 - dense_8_loss: 8.8530e-07 - dense_9_loss: 7.5385e-07 - dense_10_loss: 6.8698e-07 - dense_11_loss: 8.3779e-07 - dense_12_loss: 6.2762e-07 - val_loss: 5.6971e-06 - val_dense_5_loss: 4.4899e-07 - val_dense_6_loss: 1.1890e-06 - val_dense_7_loss: 4.0220e-07 - val_dense_8_loss: 8.2584e-07 - val_dense_9_loss: 7.7652e-07 - val_dense_10_loss: 6.3195e-07 - val_dense_11_loss: 8.0907e-07 - val_dense_12_loss: 6.1350e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.6593e-06 - dense_5_loss: 4.3744e-07 - dense_6_loss: 1.2200e-06 - dense_7_loss: 3.9716e-07 - dense_8_loss: 8.5006e-07 - dense_9_loss: 7.1153e-07 - dense_10_loss: 6.4793e-07 - dense_11_loss: 7.9793e-07 - dense_12_loss: 5.9724e-07 - val_loss: 5.3847e-06 - val_dense_5_loss: 4.1470e-07 - val_dense_6_loss: 1.1287e-06 - val_dense_7_loss: 3.6523e-07 - val_dense_8_loss: 8.0669e-07 - val_dense_9_loss: 7.2841e-07 - val_dense_10_loss: 5.9984e-07 - val_dense_11_loss: 7.8887e-07 - val_dense_12_loss: 5.5225e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.7585e-06 - dense_5_loss: 4.3300e-07 - dense_6_loss: 1.2466e-06 - dense_7_loss: 3.9439e-07 - dense_8_loss: 8.8575e-07 - dense_9_loss: 7.0875e-07 - dense_10_loss: 6.6335e-07 - dense_11_loss: 8.0427e-07 - dense_12_loss: 6.2240e-07 - val_loss: 5.4043e-06 - val_dense_5_loss: 4.2852e-07 - val_dense_6_loss: 1.0869e-06 - val_dense_7_loss: 3.7254e-07 - val_dense_8_loss: 8.0408e-07 - val_dense_9_loss: 7.5842e-07 - val_dense_10_loss: 5.8653e-07 - val_dense_11_loss: 7.9060e-07 - val_dense_12_loss: 5.7671e-07\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 5.5743e-06 - dense_5_loss: 4.0073e-07 - dense_6_loss: 1.2210e-06 - dense_7_loss: 3.7630e-07 - dense_8_loss: 8.5956e-07 - dense_9_loss: 6.9244e-07 - dense_10_loss: 6.2931e-07 - dense_11_loss: 8.0196e-07 - dense_12_loss: 5.9294e-07 - val_loss: 5.6103e-06 - val_dense_5_loss: 4.1588e-07 - val_dense_6_loss: 1.1092e-06 - val_dense_7_loss: 3.6494e-07 - val_dense_8_loss: 8.3776e-07 - val_dense_9_loss: 8.1618e-07 - val_dense_10_loss: 6.4563e-07 - val_dense_11_loss: 7.9182e-07 - val_dense_12_loss: 6.2889e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.8064e-06 - dense_5_loss: 4.1865e-07 - dense_6_loss: 1.2033e-06 - dense_7_loss: 4.1578e-07 - dense_8_loss: 9.0368e-07 - dense_9_loss: 7.2500e-07 - dense_10_loss: 6.6760e-07 - dense_11_loss: 8.3721e-07 - dense_12_loss: 6.3528e-07 - val_loss: 5.6968e-06 - val_dense_5_loss: 4.5696e-07 - val_dense_6_loss: 1.1134e-06 - val_dense_7_loss: 4.0114e-07 - val_dense_8_loss: 8.5469e-07 - val_dense_9_loss: 7.5993e-07 - val_dense_10_loss: 6.3624e-07 - val_dense_11_loss: 8.2854e-07 - val_dense_12_loss: 6.4587e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 5.2678e-06 - dense_5_loss: 3.6646e-07 - dense_6_loss: 1.1406e-06 - dense_7_loss: 3.5919e-07 - dense_8_loss: 8.2227e-07 - dense_9_loss: 6.5655e-07 - dense_10_loss: 5.8675e-07 - dense_11_loss: 7.7084e-07 - dense_12_loss: 5.6513e-07 - val_loss: 5.8081e-06 - val_dense_5_loss: 3.9365e-07 - val_dense_6_loss: 1.3377e-06 - val_dense_7_loss: 3.4764e-07 - val_dense_8_loss: 9.3185e-07 - val_dense_9_loss: 7.1943e-07 - val_dense_10_loss: 6.8003e-07 - val_dense_11_loss: 7.6570e-07 - val_dense_12_loss: 6.3211e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.5554e-06 - dense_5_loss: 3.9133e-07 - dense_6_loss: 1.1762e-06 - dense_7_loss: 3.7501e-07 - dense_8_loss: 8.7619e-07 - dense_9_loss: 6.8815e-07 - dense_10_loss: 6.4325e-07 - dense_11_loss: 7.8576e-07 - dense_12_loss: 6.1954e-07 - val_loss: 4.9233e-06 - val_dense_5_loss: 3.3144e-07 - val_dense_6_loss: 1.0163e-06 - val_dense_7_loss: 3.2664e-07 - val_dense_8_loss: 7.5704e-07 - val_dense_9_loss: 6.6240e-07 - val_dense_10_loss: 5.5516e-07 - val_dense_11_loss: 7.3035e-07 - val_dense_12_loss: 5.4393e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 5.2011e-06 - dense_5_loss: 3.4333e-07 - dense_6_loss: 1.1168e-06 - dense_7_loss: 3.5723e-07 - dense_8_loss: 8.1796e-07 - dense_9_loss: 6.5515e-07 - dense_10_loss: 5.7274e-07 - dense_11_loss: 7.6968e-07 - dense_12_loss: 5.6822e-07 - val_loss: 5.1712e-06 - val_dense_5_loss: 3.5641e-07 - val_dense_6_loss: 1.0816e-06 - val_dense_7_loss: 3.4864e-07 - val_dense_8_loss: 7.7838e-07 - val_dense_9_loss: 6.9379e-07 - val_dense_10_loss: 5.6726e-07 - val_dense_11_loss: 7.6101e-07 - val_dense_12_loss: 5.8416e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 5.1442e-06 - dense_5_loss: 3.4381e-07 - dense_6_loss: 1.0895e-06 - dense_7_loss: 3.5573e-07 - dense_8_loss: 8.1031e-07 - dense_9_loss: 6.4854e-07 - dense_10_loss: 5.6455e-07 - dense_11_loss: 7.6826e-07 - dense_12_loss: 5.6350e-07 - val_loss: 4.8674e-06 - val_dense_5_loss: 3.2398e-07 - val_dense_6_loss: 9.9708e-07 - val_dense_7_loss: 3.4574e-07 - val_dense_8_loss: 7.3094e-07 - val_dense_9_loss: 6.6470e-07 - val_dense_10_loss: 5.3085e-07 - val_dense_11_loss: 7.5214e-07 - val_dense_12_loss: 5.2200e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.9570e-06 - dense_5_loss: 3.2176e-07 - dense_6_loss: 1.0357e-06 - dense_7_loss: 3.4264e-07 - dense_8_loss: 7.7591e-07 - dense_9_loss: 6.5289e-07 - dense_10_loss: 5.3174e-07 - dense_11_loss: 7.5550e-07 - dense_12_loss: 5.4091e-07 - val_loss: 6.6385e-06 - val_dense_5_loss: 5.2256e-07 - val_dense_6_loss: 1.1502e-06 - val_dense_7_loss: 5.6879e-07 - val_dense_8_loss: 1.0599e-06 - val_dense_9_loss: 8.6373e-07 - val_dense_10_loss: 7.8813e-07 - val_dense_11_loss: 9.4407e-07 - val_dense_12_loss: 7.4119e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.4593e-06 - dense_5_loss: 3.6144e-07 - dense_6_loss: 1.5959e-06 - dense_7_loss: 3.6564e-07 - dense_8_loss: 1.1188e-06 - dense_9_loss: 6.7577e-07 - dense_10_loss: 7.9483e-07 - dense_11_loss: 7.9753e-07 - dense_12_loss: 7.4935e-07 - val_loss: 5.4286e-06 - val_dense_5_loss: 3.8877e-07 - val_dense_6_loss: 9.7430e-07 - val_dense_7_loss: 4.0141e-07 - val_dense_8_loss: 8.4683e-07 - val_dense_9_loss: 7.7364e-07 - val_dense_10_loss: 5.7961e-07 - val_dense_11_loss: 8.6112e-07 - val_dense_12_loss: 6.0294e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.3203e-06 - dense_5_loss: 3.5687e-07 - dense_6_loss: 1.0901e-06 - dense_7_loss: 3.8100e-07 - dense_8_loss: 8.3242e-07 - dense_9_loss: 6.9264e-07 - dense_10_loss: 5.8140e-07 - dense_11_loss: 8.0511e-07 - dense_12_loss: 5.8073e-07 - val_loss: 5.3710e-06 - val_dense_5_loss: 3.6174e-07 - val_dense_6_loss: 1.0965e-06 - val_dense_7_loss: 3.5783e-07 - val_dense_8_loss: 8.7595e-07 - val_dense_9_loss: 6.9196e-07 - val_dense_10_loss: 5.8855e-07 - val_dense_11_loss: 7.7052e-07 - val_dense_12_loss: 6.2789e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.9375e-06 - dense_5_loss: 3.1209e-07 - dense_6_loss: 1.0447e-06 - dense_7_loss: 3.3360e-07 - dense_8_loss: 7.6990e-07 - dense_9_loss: 6.3547e-07 - dense_10_loss: 5.4350e-07 - dense_11_loss: 7.5645e-07 - dense_12_loss: 5.4183e-07 - val_loss: 4.8165e-06 - val_dense_5_loss: 3.0112e-07 - val_dense_6_loss: 1.0004e-06 - val_dense_7_loss: 3.2262e-07 - val_dense_8_loss: 7.3628e-07 - val_dense_9_loss: 6.6725e-07 - val_dense_10_loss: 5.0388e-07 - val_dense_11_loss: 7.6803e-07 - val_dense_12_loss: 5.1684e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7939e-06 - dense_5_loss: 3.0812e-07 - dense_6_loss: 9.8097e-07 - dense_7_loss: 3.3005e-07 - dense_8_loss: 7.3971e-07 - dense_9_loss: 6.3133e-07 - dense_10_loss: 5.1867e-07 - dense_11_loss: 7.5232e-07 - dense_12_loss: 5.3269e-07 - val_loss: 5.3276e-06 - val_dense_5_loss: 3.7599e-07 - val_dense_6_loss: 1.0245e-06 - val_dense_7_loss: 4.0882e-07 - val_dense_8_loss: 8.0964e-07 - val_dense_9_loss: 7.2646e-07 - val_dense_10_loss: 5.9435e-07 - val_dense_11_loss: 8.2122e-07 - val_dense_12_loss: 5.6664e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.8802e-06 - dense_5_loss: 3.0542e-07 - dense_6_loss: 1.0411e-06 - dense_7_loss: 3.2150e-07 - dense_8_loss: 7.5777e-07 - dense_9_loss: 6.2777e-07 - dense_10_loss: 5.4307e-07 - dense_11_loss: 7.4679e-07 - dense_12_loss: 5.3676e-07 - val_loss: 4.9723e-06 - val_dense_5_loss: 3.5105e-07 - val_dense_6_loss: 9.5852e-07 - val_dense_7_loss: 3.5644e-07 - val_dense_8_loss: 7.9661e-07 - val_dense_9_loss: 7.1789e-07 - val_dense_10_loss: 4.8896e-07 - val_dense_11_loss: 7.3582e-07 - val_dense_12_loss: 5.6696e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.8679e-06 - dense_5_loss: 3.2827e-07 - dense_6_loss: 9.9460e-07 - dense_7_loss: 3.4037e-07 - dense_8_loss: 7.3958e-07 - dense_9_loss: 6.5773e-07 - dense_10_loss: 5.1558e-07 - dense_11_loss: 7.5510e-07 - dense_12_loss: 5.3665e-07 - val_loss: 4.6848e-06 - val_dense_5_loss: 2.9251e-07 - val_dense_6_loss: 9.6372e-07 - val_dense_7_loss: 3.1207e-07 - val_dense_8_loss: 7.2983e-07 - val_dense_9_loss: 6.5716e-07 - val_dense_10_loss: 4.8270e-07 - val_dense_11_loss: 7.5788e-07 - val_dense_12_loss: 4.8892e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.0344e-06 - dense_5_loss: 3.1355e-07 - dense_6_loss: 1.0604e-06 - dense_7_loss: 3.4266e-07 - dense_8_loss: 7.9706e-07 - dense_9_loss: 6.4668e-07 - dense_10_loss: 5.6119e-07 - dense_11_loss: 7.5481e-07 - dense_12_loss: 5.5804e-07 - val_loss: 5.1806e-06 - val_dense_5_loss: 3.7555e-07 - val_dense_6_loss: 9.6999e-07 - val_dense_7_loss: 3.9460e-07 - val_dense_8_loss: 7.3704e-07 - val_dense_9_loss: 8.0195e-07 - val_dense_10_loss: 5.2470e-07 - val_dense_11_loss: 8.1976e-07 - val_dense_12_loss: 5.5698e-07\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 10ms/step - loss: 5.2886e-06 - dense_5_loss: 3.3149e-07 - dense_6_loss: 1.1543e-06 - dense_7_loss: 3.4504e-07 - dense_8_loss: 8.2971e-07 - dense_9_loss: 6.6890e-07 - dense_10_loss: 6.0162e-07 - dense_11_loss: 7.7064e-07 - dense_12_loss: 5.8690e-07 - val_loss: 4.4953e-06 - val_dense_5_loss: 2.9257e-07 - val_dense_6_loss: 9.1754e-07 - val_dense_7_loss: 2.9761e-07 - val_dense_8_loss: 6.6279e-07 - val_dense_9_loss: 6.4682e-07 - val_dense_10_loss: 4.6670e-07 - val_dense_11_loss: 7.2411e-07 - val_dense_12_loss: 4.8714e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8895e-06 - dense_5_loss: 3.2776e-07 - dense_6_loss: 1.0004e-06 - dense_7_loss: 3.4189e-07 - dense_8_loss: 7.3062e-07 - dense_9_loss: 6.5964e-07 - dense_10_loss: 5.2527e-07 - dense_11_loss: 7.7175e-07 - dense_12_loss: 5.3208e-07 - val_loss: 4.6969e-06 - val_dense_5_loss: 2.8888e-07 - val_dense_6_loss: 9.5364e-07 - val_dense_7_loss: 3.2970e-07 - val_dense_8_loss: 6.9316e-07 - val_dense_9_loss: 7.3524e-07 - val_dense_10_loss: 4.7798e-07 - val_dense_11_loss: 7.2871e-07 - val_dense_12_loss: 4.8958e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8036e-06 - dense_5_loss: 3.0392e-07 - dense_6_loss: 9.8965e-07 - dense_7_loss: 3.3740e-07 - dense_8_loss: 7.2372e-07 - dense_9_loss: 6.5060e-07 - dense_10_loss: 5.2436e-07 - dense_11_loss: 7.5114e-07 - dense_12_loss: 5.2285e-07 - val_loss: 6.1580e-06 - val_dense_5_loss: 3.8781e-07 - val_dense_6_loss: 1.2479e-06 - val_dense_7_loss: 4.2098e-07 - val_dense_8_loss: 9.9170e-07 - val_dense_9_loss: 7.6031e-07 - val_dense_10_loss: 8.3561e-07 - val_dense_11_loss: 8.4731e-07 - val_dense_12_loss: 6.6642e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.5868e-06 - dense_5_loss: 3.4791e-07 - dense_6_loss: 1.1991e-06 - dense_7_loss: 3.6912e-07 - dense_8_loss: 8.9170e-07 - dense_9_loss: 6.8247e-07 - dense_10_loss: 6.6402e-07 - dense_11_loss: 7.8519e-07 - dense_12_loss: 6.4732e-07 - val_loss: 5.0359e-06 - val_dense_5_loss: 3.5501e-07 - val_dense_6_loss: 1.0088e-06 - val_dense_7_loss: 3.4854e-07 - val_dense_8_loss: 7.6054e-07 - val_dense_9_loss: 7.0286e-07 - val_dense_10_loss: 5.4923e-07 - val_dense_11_loss: 7.6868e-07 - val_dense_12_loss: 5.4221e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.9746e-06 - dense_5_loss: 3.4924e-07 - dense_6_loss: 9.6067e-07 - dense_7_loss: 3.6378e-07 - dense_8_loss: 7.3722e-07 - dense_9_loss: 6.8808e-07 - dense_10_loss: 5.4177e-07 - dense_11_loss: 7.8752e-07 - dense_12_loss: 5.4634e-07 - val_loss: 4.7141e-06 - val_dense_5_loss: 3.1068e-07 - val_dense_6_loss: 9.4641e-07 - val_dense_7_loss: 3.3736e-07 - val_dense_8_loss: 6.9102e-07 - val_dense_9_loss: 6.7371e-07 - val_dense_10_loss: 5.0943e-07 - val_dense_11_loss: 7.2262e-07 - val_dense_12_loss: 5.2293e-07\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.1195e-06 - dense_5_loss: 3.5077e-07 - dense_6_loss: 1.0237e-06 - dense_7_loss: 3.6349e-07 - dense_8_loss: 7.6394e-07 - dense_9_loss: 6.9368e-07 - dense_10_loss: 5.5278e-07 - dense_11_loss: 7.9668e-07 - dense_12_loss: 5.7437e-07 - val_loss: 5.7221e-06 - val_dense_5_loss: 4.6323e-07 - val_dense_6_loss: 1.1162e-06 - val_dense_7_loss: 4.0037e-07 - val_dense_8_loss: 8.7022e-07 - val_dense_9_loss: 7.9510e-07 - val_dense_10_loss: 6.1445e-07 - val_dense_11_loss: 8.5376e-07 - val_dense_12_loss: 6.0873e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.8954e-06 - dense_5_loss: 3.2387e-07 - dense_6_loss: 9.8407e-07 - dense_7_loss: 3.4585e-07 - dense_8_loss: 7.2244e-07 - dense_9_loss: 6.8506e-07 - dense_10_loss: 5.3270e-07 - dense_11_loss: 7.7381e-07 - dense_12_loss: 5.2761e-07 - val_loss: 5.2170e-06 - val_dense_5_loss: 4.2411e-07 - val_dense_6_loss: 9.8723e-07 - val_dense_7_loss: 3.5625e-07 - val_dense_8_loss: 7.2807e-07 - val_dense_9_loss: 7.8527e-07 - val_dense_10_loss: 5.3698e-07 - val_dense_11_loss: 8.2777e-07 - val_dense_12_loss: 5.7135e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.4354e-06 - dense_5_loss: 3.3730e-07 - dense_6_loss: 1.2375e-06 - dense_7_loss: 3.4588e-07 - dense_8_loss: 8.3770e-07 - dense_9_loss: 6.5960e-07 - dense_10_loss: 6.2567e-07 - dense_11_loss: 7.7894e-07 - dense_12_loss: 6.1273e-07 - val_loss: 7.2488e-06 - val_dense_5_loss: 4.8241e-07 - val_dense_6_loss: 1.8554e-06 - val_dense_7_loss: 4.6767e-07 - val_dense_8_loss: 1.1798e-06 - val_dense_9_loss: 7.9809e-07 - val_dense_10_loss: 7.5244e-07 - val_dense_11_loss: 9.1541e-07 - val_dense_12_loss: 7.9760e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.4277e-06 - dense_5_loss: 3.3707e-07 - dense_6_loss: 1.2259e-06 - dense_7_loss: 3.7253e-07 - dense_8_loss: 8.3272e-07 - dense_9_loss: 6.8305e-07 - dense_10_loss: 5.7720e-07 - dense_11_loss: 8.0173e-07 - dense_12_loss: 5.9745e-07 - val_loss: 4.8599e-06 - val_dense_5_loss: 3.2859e-07 - val_dense_6_loss: 9.5217e-07 - val_dense_7_loss: 3.3352e-07 - val_dense_8_loss: 7.0023e-07 - val_dense_9_loss: 6.9483e-07 - val_dense_10_loss: 5.3154e-07 - val_dense_11_loss: 7.8743e-07 - val_dense_12_loss: 5.3157e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.5060e-06 - dense_5_loss: 2.9280e-07 - dense_6_loss: 9.0266e-07 - dense_7_loss: 3.1860e-07 - dense_8_loss: 6.5475e-07 - dense_9_loss: 6.2765e-07 - dense_10_loss: 4.7429e-07 - dense_11_loss: 7.4272e-07 - dense_12_loss: 4.9250e-07 - val_loss: 4.7797e-06 - val_dense_5_loss: 3.3335e-07 - val_dense_6_loss: 8.6770e-07 - val_dense_7_loss: 3.5643e-07 - val_dense_8_loss: 6.5483e-07 - val_dense_9_loss: 7.4576e-07 - val_dense_10_loss: 5.0092e-07 - val_dense_11_loss: 7.6313e-07 - val_dense_12_loss: 5.5759e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.6509e-06 - dense_5_loss: 3.9671e-07 - dense_6_loss: 1.1094e-06 - dense_7_loss: 4.1292e-07 - dense_8_loss: 8.4468e-07 - dense_9_loss: 7.3788e-07 - dense_10_loss: 6.6061e-07 - dense_11_loss: 8.4443e-07 - dense_12_loss: 6.4421e-07 - val_loss: 6.1311e-06 - val_dense_5_loss: 3.3538e-07 - val_dense_6_loss: 1.5144e-06 - val_dense_7_loss: 3.3901e-07 - val_dense_8_loss: 1.0810e-06 - val_dense_9_loss: 6.6911e-07 - val_dense_10_loss: 6.8772e-07 - val_dense_11_loss: 7.6324e-07 - val_dense_12_loss: 7.4122e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.5684e-06 - dense_5_loss: 3.7533e-07 - dense_6_loss: 1.1761e-06 - dense_7_loss: 3.7938e-07 - dense_8_loss: 8.4714e-07 - dense_9_loss: 7.0286e-07 - dense_10_loss: 6.3647e-07 - dense_11_loss: 8.1556e-07 - dense_12_loss: 6.3552e-07 - val_loss: 4.6789e-06 - val_dense_5_loss: 2.8951e-07 - val_dense_6_loss: 9.6334e-07 - val_dense_7_loss: 3.1230e-07 - val_dense_8_loss: 7.0188e-07 - val_dense_9_loss: 6.8171e-07 - val_dense_10_loss: 5.1228e-07 - val_dense_11_loss: 7.1010e-07 - val_dense_12_loss: 5.0775e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7149e-06 - dense_5_loss: 3.1459e-07 - dense_6_loss: 9.1058e-07 - dense_7_loss: 3.4486e-07 - dense_8_loss: 6.7557e-07 - dense_9_loss: 6.7427e-07 - dense_10_loss: 5.0773e-07 - dense_11_loss: 7.6534e-07 - dense_12_loss: 5.2200e-07 - val_loss: 5.0139e-06 - val_dense_5_loss: 2.8893e-07 - val_dense_6_loss: 1.1337e-06 - val_dense_7_loss: 3.4393e-07 - val_dense_8_loss: 7.4957e-07 - val_dense_9_loss: 6.9424e-07 - val_dense_10_loss: 5.3246e-07 - val_dense_11_loss: 7.2930e-07 - val_dense_12_loss: 5.4177e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.7335e-06 - dense_5_loss: 3.2014e-07 - dense_6_loss: 9.4382e-07 - dense_7_loss: 3.3943e-07 - dense_8_loss: 6.8371e-07 - dense_9_loss: 6.5857e-07 - dense_10_loss: 5.1373e-07 - dense_11_loss: 7.5080e-07 - dense_12_loss: 5.2325e-07 - val_loss: 4.4961e-06 - val_dense_5_loss: 3.0571e-07 - val_dense_6_loss: 8.4731e-07 - val_dense_7_loss: 3.1717e-07 - val_dense_8_loss: 6.0899e-07 - val_dense_9_loss: 7.0782e-07 - val_dense_10_loss: 4.8462e-07 - val_dense_11_loss: 7.4996e-07 - val_dense_12_loss: 4.7455e-07\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 7ms/step - loss: 4.5448e-06 - dense_5_loss: 3.0914e-07 - dense_6_loss: 8.8084e-07 - dense_7_loss: 3.3269e-07 - dense_8_loss: 6.4044e-07 - dense_9_loss: 6.5073e-07 - dense_10_loss: 4.8440e-07 - dense_11_loss: 7.4743e-07 - dense_12_loss: 4.9916e-07 - val_loss: 5.8654e-06 - val_dense_5_loss: 3.3708e-07 - val_dense_6_loss: 1.3915e-06 - val_dense_7_loss: 3.6481e-07 - val_dense_8_loss: 8.4260e-07 - val_dense_9_loss: 7.0603e-07 - val_dense_10_loss: 7.6610e-07 - val_dense_11_loss: 8.7021e-07 - val_dense_12_loss: 5.8709e-07\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.8050e-06 - dense_5_loss: 3.2345e-07 - dense_6_loss: 9.6047e-07 - dense_7_loss: 3.4199e-07 - dense_8_loss: 6.8501e-07 - dense_9_loss: 6.6161e-07 - dense_10_loss: 5.3105e-07 - dense_11_loss: 7.7473e-07 - dense_12_loss: 5.2671e-07 - val_loss: 5.1551e-06 - val_dense_5_loss: 4.1357e-07 - val_dense_6_loss: 8.6114e-07 - val_dense_7_loss: 4.0645e-07 - val_dense_8_loss: 7.2153e-07 - val_dense_9_loss: 7.6944e-07 - val_dense_10_loss: 6.0267e-07 - val_dense_11_loss: 8.0525e-07 - val_dense_12_loss: 5.7509e-07\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.1163e-06 - dense_5_loss: 3.4057e-07 - dense_6_loss: 1.0194e-06 - dense_7_loss: 3.7467e-07 - dense_8_loss: 7.4195e-07 - dense_9_loss: 6.9471e-07 - dense_10_loss: 5.7991e-07 - dense_11_loss: 7.9540e-07 - dense_12_loss: 5.6969e-07 - val_loss: 5.2887e-06 - val_dense_5_loss: 3.6737e-07 - val_dense_6_loss: 9.9921e-07 - val_dense_7_loss: 3.4239e-07 - val_dense_8_loss: 7.9773e-07 - val_dense_9_loss: 8.1542e-07 - val_dense_10_loss: 5.6265e-07 - val_dense_11_loss: 8.1919e-07 - val_dense_12_loss: 5.8476e-07\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0182e-06 - dense_5_loss: 3.4869e-07 - dense_6_loss: 9.5420e-07 - dense_7_loss: 3.7655e-07 - dense_8_loss: 7.0266e-07 - dense_9_loss: 7.1238e-07 - dense_10_loss: 5.5335e-07 - dense_11_loss: 8.1410e-07 - dense_12_loss: 5.5628e-07 - val_loss: 4.8439e-06 - val_dense_5_loss: 3.0541e-07 - val_dense_6_loss: 9.6994e-07 - val_dense_7_loss: 3.6898e-07 - val_dense_8_loss: 7.5519e-07 - val_dense_9_loss: 6.8670e-07 - val_dense_10_loss: 4.9015e-07 - val_dense_11_loss: 7.2090e-07 - val_dense_12_loss: 5.4660e-07\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.7980e-06 - dense_5_loss: 3.3983e-07 - dense_6_loss: 9.4071e-07 - dense_7_loss: 3.4573e-07 - dense_8_loss: 6.7421e-07 - dense_9_loss: 6.6605e-07 - dense_10_loss: 5.2358e-07 - dense_11_loss: 7.7479e-07 - dense_12_loss: 5.3307e-07 - val_loss: 5.0964e-06 - val_dense_5_loss: 3.9039e-07 - val_dense_6_loss: 9.1257e-07 - val_dense_7_loss: 3.8009e-07 - val_dense_8_loss: 7.3899e-07 - val_dense_9_loss: 7.7275e-07 - val_dense_10_loss: 5.4452e-07 - val_dense_11_loss: 7.9720e-07 - val_dense_12_loss: 5.5984e-07\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2462e-06 - dense_5_loss: 3.8290e-07 - dense_6_loss: 1.0282e-06 - dense_7_loss: 3.8195e-07 - dense_8_loss: 7.5151e-07 - dense_9_loss: 6.9898e-07 - dense_10_loss: 6.0471e-07 - dense_11_loss: 8.0579e-07 - dense_12_loss: 5.9216e-07 - val_loss: 4.6575e-06 - val_dense_5_loss: 3.3464e-07 - val_dense_6_loss: 8.7466e-07 - val_dense_7_loss: 3.4270e-07 - val_dense_8_loss: 6.8888e-07 - val_dense_9_loss: 6.9869e-07 - val_dense_10_loss: 4.7959e-07 - val_dense_11_loss: 7.2997e-07 - val_dense_12_loss: 5.0834e-07\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.5875e-06 - dense_5_loss: 3.2001e-07 - dense_6_loss: 8.8719e-07 - dense_7_loss: 3.3766e-07 - dense_8_loss: 6.3142e-07 - dense_9_loss: 6.4621e-07 - dense_10_loss: 5.0313e-07 - dense_11_loss: 7.5058e-07 - dense_12_loss: 5.1135e-07 - val_loss: 4.8301e-06 - val_dense_5_loss: 3.3899e-07 - val_dense_6_loss: 9.4246e-07 - val_dense_7_loss: 3.2621e-07 - val_dense_8_loss: 6.8546e-07 - val_dense_9_loss: 7.0753e-07 - val_dense_10_loss: 5.9211e-07 - val_dense_11_loss: 7.2626e-07 - val_dense_12_loss: 5.1111e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00077: early stopping\n",
      "\n",
      "Now training model 2/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 2s 16ms/step - loss: 0.0014 - dense_18_loss: 5.1149e-04 - dense_19_loss: 4.5933e-04 - dense_20_loss: 3.9172e-04 - val_loss: 2.2261e-04 - val_dense_18_loss: 8.7951e-05 - val_dense_19_loss: 5.0740e-05 - val_dense_20_loss: 8.3916e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6873e-04 - dense_18_loss: 7.4315e-05 - dense_19_loss: 3.9669e-05 - dense_20_loss: 5.4748e-05 - val_loss: 9.8797e-05 - val_dense_18_loss: 5.8132e-05 - val_dense_19_loss: 1.9324e-05 - val_dense_20_loss: 2.1342e-05\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.9474e-05 - dense_18_loss: 4.7752e-05 - dense_19_loss: 1.2135e-05 - dense_20_loss: 9.5870e-06 - val_loss: 4.9272e-05 - val_dense_18_loss: 3.7094e-05 - val_dense_19_loss: 7.0238e-06 - val_dense_20_loss: 5.1542e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.0620e-05 - dense_18_loss: 2.8704e-05 - dense_19_loss: 6.1466e-06 - dense_20_loss: 5.7687e-06 - val_loss: 3.0844e-05 - val_dense_18_loss: 1.8669e-05 - val_dense_19_loss: 6.3313e-06 - val_dense_20_loss: 5.8444e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.2974e-05 - dense_18_loss: 1.2286e-05 - dense_19_loss: 5.4312e-06 - dense_20_loss: 5.2569e-06 - val_loss: 1.6023e-05 - val_dense_18_loss: 6.7250e-06 - val_dense_19_loss: 5.3128e-06 - val_dense_20_loss: 3.9848e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1581e-05 - dense_18_loss: 4.2938e-06 - dense_19_loss: 4.2752e-06 - dense_20_loss: 3.0118e-06 - val_loss: 8.6957e-06 - val_dense_18_loss: 2.4447e-06 - val_dense_19_loss: 4.1830e-06 - val_dense_20_loss: 2.0679e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8546e-06 - dense_18_loss: 1.8840e-06 - dense_19_loss: 3.4101e-06 - dense_20_loss: 1.5605e-06 - val_loss: 6.1264e-06 - val_dense_18_loss: 1.4049e-06 - val_dense_19_loss: 3.5543e-06 - val_dense_20_loss: 1.1672e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.1677e-06 - dense_18_loss: 1.2081e-06 - dense_19_loss: 2.9716e-06 - dense_20_loss: 9.8805e-07 - val_loss: 5.5450e-06 - val_dense_18_loss: 1.1419e-06 - val_dense_19_loss: 3.4344e-06 - val_dense_20_loss: 9.6868e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.6311e-06 - dense_18_loss: 1.0024e-06 - dense_19_loss: 2.8506e-06 - dense_20_loss: 7.7804e-07 - val_loss: 4.5312e-06 - val_dense_18_loss: 8.0245e-07 - val_dense_19_loss: 3.0380e-06 - val_dense_20_loss: 6.9081e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.0137e-06 - dense_18_loss: 7.9404e-07 - dense_19_loss: 2.5950e-06 - dense_20_loss: 6.2465e-07 - val_loss: 4.1894e-06 - val_dense_18_loss: 7.2122e-07 - val_dense_19_loss: 2.9041e-06 - val_dense_20_loss: 5.6417e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.7808e-06 - dense_18_loss: 7.1161e-07 - dense_19_loss: 2.5095e-06 - dense_20_loss: 5.5973e-07 - val_loss: 4.0257e-06 - val_dense_18_loss: 6.7131e-07 - val_dense_19_loss: 2.8157e-06 - val_dense_20_loss: 5.3874e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.5201e-06 - dense_18_loss: 6.5362e-07 - dense_19_loss: 2.3552e-06 - dense_20_loss: 5.1129e-07 - val_loss: 3.8849e-06 - val_dense_18_loss: 6.2976e-07 - val_dense_19_loss: 2.6870e-06 - val_dense_20_loss: 5.6814e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.4441e-06 - dense_18_loss: 6.4482e-07 - dense_19_loss: 2.2787e-06 - dense_20_loss: 5.2060e-07 - val_loss: 4.8437e-06 - val_dense_18_loss: 7.6715e-07 - val_dense_19_loss: 3.1008e-06 - val_dense_20_loss: 9.7579e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.7341e-06 - dense_18_loss: 7.3326e-07 - dense_19_loss: 2.3950e-06 - dense_20_loss: 6.0582e-07 - val_loss: 3.7371e-06 - val_dense_18_loss: 6.8439e-07 - val_dense_19_loss: 2.4614e-06 - val_dense_20_loss: 5.9138e-07\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 6ms/step - loss: 3.2477e-06 - dense_18_loss: 6.4942e-07 - dense_19_loss: 2.0771e-06 - dense_20_loss: 5.2117e-07 - val_loss: 3.4464e-06 - val_dense_18_loss: 6.2025e-07 - val_dense_19_loss: 2.3320e-06 - val_dense_20_loss: 4.9422e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.9375e-06 - dense_18_loss: 5.8622e-07 - dense_19_loss: 1.8880e-06 - dense_20_loss: 4.6329e-07 - val_loss: 3.3413e-06 - val_dense_18_loss: 6.3093e-07 - val_dense_19_loss: 2.2218e-06 - val_dense_20_loss: 4.8860e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.9173e-06 - dense_18_loss: 6.1812e-07 - dense_19_loss: 1.8149e-06 - dense_20_loss: 4.8425e-07 - val_loss: 3.2665e-06 - val_dense_18_loss: 6.5914e-07 - val_dense_19_loss: 2.0878e-06 - val_dense_20_loss: 5.1956e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.8679e-06 - dense_18_loss: 6.7724e-07 - dense_19_loss: 1.7020e-06 - dense_20_loss: 4.8866e-07 - val_loss: 3.0861e-06 - val_dense_18_loss: 6.5037e-07 - val_dense_19_loss: 1.9349e-06 - val_dense_20_loss: 5.0084e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.7360e-06 - dense_18_loss: 6.2821e-07 - dense_19_loss: 1.6115e-06 - dense_20_loss: 4.9628e-07 - val_loss: 2.9264e-06 - val_dense_18_loss: 6.2588e-07 - val_dense_19_loss: 1.8404e-06 - val_dense_20_loss: 4.6019e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.7451e-06 - dense_18_loss: 6.9253e-07 - dense_19_loss: 1.5267e-06 - dense_20_loss: 5.2590e-07 - val_loss: 3.1046e-06 - val_dense_18_loss: 8.2258e-07 - val_dense_19_loss: 1.7397e-06 - val_dense_20_loss: 5.4233e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.5033e-06 - dense_18_loss: 6.5014e-07 - dense_19_loss: 1.3849e-06 - dense_20_loss: 4.6824e-07 - val_loss: 2.7316e-06 - val_dense_18_loss: 6.2982e-07 - val_dense_19_loss: 1.5992e-06 - val_dense_20_loss: 5.0256e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.6619e-06 - dense_18_loss: 7.1080e-07 - dense_19_loss: 1.3706e-06 - dense_20_loss: 5.8049e-07 - val_loss: 3.4587e-06 - val_dense_18_loss: 7.1337e-07 - val_dense_19_loss: 2.1598e-06 - val_dense_20_loss: 5.8552e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.5741e-06 - dense_18_loss: 7.0914e-07 - dense_19_loss: 1.2917e-06 - dense_20_loss: 5.7334e-07 - val_loss: 2.9926e-06 - val_dense_18_loss: 6.3040e-07 - val_dense_19_loss: 1.6214e-06 - val_dense_20_loss: 7.4081e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.5348e-06 - dense_18_loss: 6.5621e-07 - dense_19_loss: 1.2454e-06 - dense_20_loss: 6.3318e-07 - val_loss: 2.2823e-06 - val_dense_18_loss: 6.0489e-07 - val_dense_19_loss: 1.2899e-06 - val_dense_20_loss: 3.8750e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.2074e-06 - dense_18_loss: 7.9819e-07 - dense_19_loss: 9.8863e-07 - dense_20_loss: 4.2059e-07 - val_loss: 3.4618e-06 - val_dense_18_loss: 1.4433e-06 - val_dense_19_loss: 1.2592e-06 - val_dense_20_loss: 7.5927e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.3598e-06 - dense_18_loss: 8.9311e-07 - dense_19_loss: 9.8296e-07 - dense_20_loss: 4.8376e-07 - val_loss: 2.4923e-06 - val_dense_18_loss: 6.7503e-07 - val_dense_19_loss: 1.2013e-06 - val_dense_20_loss: 6.1593e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.9392e-06 - dense_18_loss: 6.1735e-07 - dense_19_loss: 8.9613e-07 - dense_20_loss: 4.2572e-07 - val_loss: 2.2969e-06 - val_dense_18_loss: 7.4238e-07 - val_dense_19_loss: 1.0956e-06 - val_dense_20_loss: 4.5899e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.8394e-06 - dense_18_loss: 6.5032e-07 - dense_19_loss: 8.3389e-07 - dense_20_loss: 3.5521e-07 - val_loss: 2.1232e-06 - val_dense_18_loss: 6.9824e-07 - val_dense_19_loss: 1.0214e-06 - val_dense_20_loss: 4.0355e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.5961e-06 - dense_18_loss: 5.5929e-07 - dense_19_loss: 7.1733e-07 - dense_20_loss: 3.1952e-07 - val_loss: 1.9647e-06 - val_dense_18_loss: 6.7830e-07 - val_dense_19_loss: 9.3870e-07 - val_dense_20_loss: 3.4765e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6370e-06 - dense_18_loss: 6.1935e-07 - dense_19_loss: 7.0924e-07 - dense_20_loss: 3.0846e-07 - val_loss: 1.8268e-06 - val_dense_18_loss: 5.0486e-07 - val_dense_19_loss: 9.8440e-07 - val_dense_20_loss: 3.3755e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.5014e-06 - dense_18_loss: 5.1298e-07 - dense_19_loss: 6.7345e-07 - dense_20_loss: 3.1497e-07 - val_loss: 1.7410e-06 - val_dense_18_loss: 5.1088e-07 - val_dense_19_loss: 7.8981e-07 - val_dense_20_loss: 4.4037e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.7602e-06 - dense_18_loss: 7.1831e-07 - dense_19_loss: 6.8754e-07 - dense_20_loss: 3.5434e-07 - val_loss: 1.8286e-06 - val_dense_18_loss: 5.7676e-07 - val_dense_19_loss: 8.1181e-07 - val_dense_20_loss: 4.4007e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.3048e-06 - dense_18_loss: 1.1655e-06 - dense_19_loss: 7.4119e-07 - dense_20_loss: 3.9806e-07 - val_loss: 2.4496e-06 - val_dense_18_loss: 1.1015e-06 - val_dense_19_loss: 9.2386e-07 - val_dense_20_loss: 4.2423e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.0918e-06 - dense_18_loss: 9.6164e-07 - dense_19_loss: 7.1160e-07 - dense_20_loss: 4.1852e-07 - val_loss: 1.7992e-06 - val_dense_18_loss: 6.5533e-07 - val_dense_19_loss: 7.6649e-07 - val_dense_20_loss: 3.7742e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4356e-06 - dense_18_loss: 5.7890e-07 - dense_19_loss: 5.8932e-07 - dense_20_loss: 2.6739e-07 - val_loss: 1.4422e-06 - val_dense_18_loss: 4.5175e-07 - val_dense_19_loss: 6.5181e-07 - val_dense_20_loss: 3.3861e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3556e-06 - dense_18_loss: 5.5072e-07 - dense_19_loss: 5.6101e-07 - dense_20_loss: 2.4391e-07 - val_loss: 1.5967e-06 - val_dense_18_loss: 5.2093e-07 - val_dense_19_loss: 7.4518e-07 - val_dense_20_loss: 3.3060e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1646e-06 - dense_18_loss: 4.2366e-07 - dense_19_loss: 5.2514e-07 - dense_20_loss: 2.1580e-07 - val_loss: 1.3321e-06 - val_dense_18_loss: 5.0440e-07 - val_dense_19_loss: 5.9842e-07 - val_dense_20_loss: 2.2931e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1092e-06 - dense_18_loss: 4.2578e-07 - dense_19_loss: 4.9334e-07 - dense_20_loss: 1.9003e-07 - val_loss: 1.3479e-06 - val_dense_18_loss: 4.1367e-07 - val_dense_19_loss: 7.2021e-07 - val_dense_20_loss: 2.1404e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 25ms/step - loss: 1.1443e-06 - dense_18_loss: 4.2533e-07 - dense_19_loss: 5.1590e-07 - dense_20_loss: 2.0310e-07 - val_loss: 1.4182e-06 - val_dense_18_loss: 5.5633e-07 - val_dense_19_loss: 6.5630e-07 - val_dense_20_loss: 2.0558e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.5246e-06 - dense_18_loss: 5.1726e-07 - dense_19_loss: 6.9853e-07 - dense_20_loss: 3.0884e-07 - val_loss: 1.3711e-06 - val_dense_18_loss: 5.8373e-07 - val_dense_19_loss: 5.9078e-07 - val_dense_20_loss: 1.9661e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1859e-06 - dense_18_loss: 4.3441e-07 - dense_19_loss: 5.2646e-07 - dense_20_loss: 2.2508e-07 - val_loss: 1.1520e-06 - val_dense_18_loss: 3.8449e-07 - val_dense_19_loss: 5.5726e-07 - val_dense_20_loss: 2.1028e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1117e-06 - dense_18_loss: 4.2797e-07 - dense_19_loss: 4.8854e-07 - dense_20_loss: 1.9514e-07 - val_loss: 1.7398e-06 - val_dense_18_loss: 8.2784e-07 - val_dense_19_loss: 6.4324e-07 - val_dense_20_loss: 2.6871e-07\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1605e-06 - dense_18_loss: 4.8396e-07 - dense_19_loss: 4.9899e-07 - dense_20_loss: 1.7750e-07 - val_loss: 1.1849e-06 - val_dense_18_loss: 4.5020e-07 - val_dense_19_loss: 5.3307e-07 - val_dense_20_loss: 2.0165e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1920e-06 - dense_18_loss: 4.4684e-07 - dense_19_loss: 5.3179e-07 - dense_20_loss: 2.1335e-07 - val_loss: 1.8973e-06 - val_dense_18_loss: 8.8181e-07 - val_dense_19_loss: 7.7261e-07 - val_dense_20_loss: 2.4291e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.0588e-06 - dense_18_loss: 9.4903e-07 - dense_19_loss: 7.6145e-07 - dense_20_loss: 3.4830e-07 - val_loss: 1.2206e-06 - val_dense_18_loss: 4.5235e-07 - val_dense_19_loss: 5.7515e-07 - val_dense_20_loss: 1.9305e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1734e-06 - dense_18_loss: 4.5217e-07 - dense_19_loss: 5.1804e-07 - dense_20_loss: 2.0318e-07 - val_loss: 1.0468e-06 - val_dense_18_loss: 3.8239e-07 - val_dense_19_loss: 5.0122e-07 - val_dense_20_loss: 1.6318e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1504e-06 - dense_18_loss: 4.6330e-07 - dense_19_loss: 4.7264e-07 - dense_20_loss: 2.1441e-07 - val_loss: 1.6050e-06 - val_dense_18_loss: 6.2741e-07 - val_dense_19_loss: 6.3599e-07 - val_dense_20_loss: 3.4164e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2430e-06 - dense_18_loss: 5.4056e-07 - dense_19_loss: 4.8134e-07 - dense_20_loss: 2.2110e-07 - val_loss: 1.1177e-06 - val_dense_18_loss: 4.2156e-07 - val_dense_19_loss: 5.1659e-07 - val_dense_20_loss: 1.7950e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1357e-06 - dense_18_loss: 4.5539e-07 - dense_19_loss: 4.6597e-07 - dense_20_loss: 2.1433e-07 - val_loss: 5.1460e-06 - val_dense_18_loss: 2.6308e-06 - val_dense_19_loss: 1.3233e-06 - val_dense_20_loss: 1.1920e-06\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.9466e-06 - dense_18_loss: 1.0086e-06 - dense_19_loss: 6.0401e-07 - dense_20_loss: 3.3394e-07 - val_loss: 1.6068e-06 - val_dense_18_loss: 6.0500e-07 - val_dense_19_loss: 6.1770e-07 - val_dense_20_loss: 3.8413e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.2322e-06 - dense_18_loss: 5.0683e-07 - dense_19_loss: 4.8438e-07 - dense_20_loss: 2.4100e-07 - val_loss: 1.1952e-06 - val_dense_18_loss: 5.0558e-07 - val_dense_19_loss: 4.9230e-07 - val_dense_20_loss: 1.9736e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0223e-06 - dense_18_loss: 4.3246e-07 - dense_19_loss: 4.2528e-07 - dense_20_loss: 1.6451e-07 - val_loss: 1.3428e-06 - val_dense_18_loss: 6.2553e-07 - val_dense_19_loss: 5.1299e-07 - val_dense_20_loss: 2.0431e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0934e-06 - dense_18_loss: 4.3788e-07 - dense_19_loss: 4.5976e-07 - dense_20_loss: 1.9579e-07 - val_loss: 1.4224e-06 - val_dense_18_loss: 5.8058e-07 - val_dense_19_loss: 5.9883e-07 - val_dense_20_loss: 2.4294e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2615e-06 - dense_18_loss: 5.5571e-07 - dense_19_loss: 4.8093e-07 - dense_20_loss: 2.2486e-07 - val_loss: 1.2570e-06 - val_dense_18_loss: 4.1495e-07 - val_dense_19_loss: 5.6914e-07 - val_dense_20_loss: 2.7290e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0078e-06 - dense_18_loss: 4.0666e-07 - dense_19_loss: 4.4132e-07 - dense_20_loss: 1.5977e-07 - val_loss: 1.1354e-06 - val_dense_18_loss: 4.0599e-07 - val_dense_19_loss: 5.2767e-07 - val_dense_20_loss: 2.0171e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0988e-06 - dense_18_loss: 5.0098e-07 - dense_19_loss: 4.3285e-07 - dense_20_loss: 1.6500e-07 - val_loss: 1.1544e-06 - val_dense_18_loss: 4.0202e-07 - val_dense_19_loss: 5.8672e-07 - val_dense_20_loss: 1.6571e-07\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0791e-06 - dense_18_loss: 4.1442e-07 - dense_19_loss: 4.7055e-07 - dense_20_loss: 1.9415e-07 - val_loss: 9.5786e-07 - val_dense_18_loss: 3.4872e-07 - val_dense_19_loss: 4.4091e-07 - val_dense_20_loss: 1.6823e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3891e-06 - dense_18_loss: 4.7649e-07 - dense_19_loss: 6.5754e-07 - dense_20_loss: 2.5503e-07 - val_loss: 1.1110e-06 - val_dense_18_loss: 4.1942e-07 - val_dense_19_loss: 4.8296e-07 - val_dense_20_loss: 2.0864e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1138e-06 - dense_18_loss: 4.4019e-07 - dense_19_loss: 4.6640e-07 - dense_20_loss: 2.0717e-07 - val_loss: 1.1085e-06 - val_dense_18_loss: 4.2903e-07 - val_dense_19_loss: 5.1065e-07 - val_dense_20_loss: 1.6879e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0299e-06 - dense_18_loss: 4.1384e-07 - dense_19_loss: 4.4297e-07 - dense_20_loss: 1.7307e-07 - val_loss: 1.6582e-06 - val_dense_18_loss: 6.8389e-07 - val_dense_19_loss: 6.1880e-07 - val_dense_20_loss: 3.5550e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1062e-06 - dense_18_loss: 4.7800e-07 - dense_19_loss: 4.4021e-07 - dense_20_loss: 1.8800e-07 - val_loss: 1.0344e-06 - val_dense_18_loss: 3.6489e-07 - val_dense_19_loss: 4.4827e-07 - val_dense_20_loss: 2.2123e-07\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1383e-06 - dense_18_loss: 4.3274e-07 - dense_19_loss: 4.6785e-07 - dense_20_loss: 2.3769e-07 - val_loss: 1.1918e-06 - val_dense_18_loss: 5.1227e-07 - val_dense_19_loss: 4.6546e-07 - val_dense_20_loss: 2.1410e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3801e-06 - dense_18_loss: 5.5958e-07 - dense_19_loss: 5.2594e-07 - dense_20_loss: 2.9456e-07 - val_loss: 1.1544e-06 - val_dense_18_loss: 4.3854e-07 - val_dense_19_loss: 5.2861e-07 - val_dense_20_loss: 1.8721e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0744e-06 - dense_18_loss: 4.5525e-07 - dense_19_loss: 4.3196e-07 - dense_20_loss: 1.8713e-07 - val_loss: 9.9974e-07 - val_dense_18_loss: 3.6530e-07 - val_dense_19_loss: 4.6988e-07 - val_dense_20_loss: 1.6456e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.0021e-06 - dense_18_loss: 4.3058e-07 - dense_19_loss: 4.2857e-07 - dense_20_loss: 1.4295e-07 - val_loss: 1.0461e-06 - val_dense_18_loss: 4.2979e-07 - val_dense_19_loss: 4.5927e-07 - val_dense_20_loss: 1.5709e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.2165e-06 - dense_18_loss: 5.2495e-07 - dense_19_loss: 5.1844e-07 - dense_20_loss: 1.7310e-07 - val_loss: 1.4592e-06 - val_dense_18_loss: 7.9614e-07 - val_dense_19_loss: 4.6925e-07 - val_dense_20_loss: 1.9380e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00066: early stopping\n",
      "\n",
      "Now training model 3/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 15ms/step - loss: 0.0022 - dense_26_loss: 8.5264e-04 - dense_27_loss: 7.8830e-04 - dense_28_loss: 5.5814e-04 - val_loss: 2.0964e-04 - val_dense_26_loss: 6.6164e-05 - val_dense_27_loss: 5.8120e-05 - val_dense_28_loss: 8.5355e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1980e-04 - dense_26_loss: 3.1455e-05 - dense_27_loss: 3.0508e-05 - dense_28_loss: 5.7841e-05 - val_loss: 7.2462e-05 - val_dense_26_loss: 1.4577e-05 - val_dense_27_loss: 1.4547e-05 - val_dense_28_loss: 4.3339e-05\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6598e-05 - dense_26_loss: 1.4759e-05 - dense_27_loss: 1.3685e-05 - dense_28_loss: 3.8154e-05 - val_loss: 5.7369e-05 - val_dense_26_loss: 1.1905e-05 - val_dense_27_loss: 1.1780e-05 - val_dense_28_loss: 3.3684e-05\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3084e-05 - dense_26_loss: 1.1879e-05 - dense_27_loss: 1.2328e-05 - dense_28_loss: 2.8877e-05 - val_loss: 4.3510e-05 - val_dense_26_loss: 9.7780e-06 - val_dense_27_loss: 1.0439e-05 - val_dense_28_loss: 2.3293e-05\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 3.6476e-05 - dense_26_loss: 9.6642e-06 - dense_27_loss: 1.0479e-05 - dense_28_loss: 1.6333e-05 - val_loss: 2.5835e-05 - val_dense_26_loss: 7.9566e-06 - val_dense_27_loss: 8.5917e-06 - val_dense_28_loss: 9.2864e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0997e-05 - dense_26_loss: 7.7091e-06 - dense_27_loss: 7.8990e-06 - dense_28_loss: 5.3886e-06 - val_loss: 1.4796e-05 - val_dense_26_loss: 6.2845e-06 - val_dense_27_loss: 5.6851e-06 - val_dense_28_loss: 2.8264e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4804e-05 - dense_26_loss: 6.7552e-06 - dense_27_loss: 5.8989e-06 - dense_28_loss: 2.1495e-06 - val_loss: 1.1807e-05 - val_dense_26_loss: 5.6024e-06 - val_dense_27_loss: 4.5951e-06 - val_dense_28_loss: 1.6099e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2952e-05 - dense_26_loss: 6.2757e-06 - dense_27_loss: 5.2094e-06 - dense_28_loss: 1.4667e-06 - val_loss: 1.1092e-05 - val_dense_26_loss: 5.4346e-06 - val_dense_27_loss: 4.3732e-06 - val_dense_28_loss: 1.2840e-06\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2314e-05 - dense_26_loss: 6.0598e-06 - dense_27_loss: 4.9206e-06 - dense_28_loss: 1.3332e-06 - val_loss: 1.0621e-05 - val_dense_26_loss: 5.2115e-06 - val_dense_27_loss: 4.0899e-06 - val_dense_28_loss: 1.3195e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1779e-05 - dense_26_loss: 5.8591e-06 - dense_27_loss: 4.5718e-06 - dense_28_loss: 1.3476e-06 - val_loss: 1.0031e-05 - val_dense_26_loss: 4.9399e-06 - val_dense_27_loss: 3.7832e-06 - val_dense_28_loss: 1.3077e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0912e-05 - dense_26_loss: 5.4397e-06 - dense_27_loss: 4.0924e-06 - dense_28_loss: 1.3799e-06 - val_loss: 9.4778e-06 - val_dense_26_loss: 4.6155e-06 - val_dense_27_loss: 3.4303e-06 - val_dense_28_loss: 1.4320e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5582e-06 - dense_26_loss: 4.7216e-06 - dense_27_loss: 3.3978e-06 - dense_28_loss: 1.4388e-06 - val_loss: 7.5822e-06 - val_dense_26_loss: 3.6202e-06 - val_dense_27_loss: 2.5798e-06 - val_dense_28_loss: 1.3822e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8094e-06 - dense_26_loss: 3.7663e-06 - dense_27_loss: 2.5835e-06 - dense_28_loss: 1.4596e-06 - val_loss: 5.8564e-06 - val_dense_26_loss: 2.7142e-06 - val_dense_27_loss: 1.8779e-06 - val_dense_28_loss: 1.2644e-06\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.4648e-06 - dense_26_loss: 2.5193e-06 - dense_27_loss: 1.7320e-06 - dense_28_loss: 1.2134e-06 - val_loss: 3.9290e-06 - val_dense_26_loss: 1.7548e-06 - val_dense_27_loss: 1.2007e-06 - val_dense_28_loss: 9.7345e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.6147e-06 - dense_26_loss: 1.5387e-06 - dense_27_loss: 1.1382e-06 - dense_28_loss: 9.3780e-07 - val_loss: 2.9311e-06 - val_dense_26_loss: 1.1624e-06 - val_dense_27_loss: 9.3185e-07 - val_dense_28_loss: 8.3686e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.7695e-06 - dense_26_loss: 1.1124e-06 - dense_27_loss: 8.9019e-07 - dense_28_loss: 7.6692e-07 - val_loss: 2.3534e-06 - val_dense_26_loss: 9.4914e-07 - val_dense_27_loss: 7.1695e-07 - val_dense_28_loss: 6.8735e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1856e-06 - dense_26_loss: 8.7932e-07 - dense_27_loss: 6.6955e-07 - dense_28_loss: 6.3670e-07 - val_loss: 1.9986e-06 - val_dense_26_loss: 7.9270e-07 - val_dense_27_loss: 6.1098e-07 - val_dense_28_loss: 5.9488e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9232e-06 - dense_26_loss: 7.8112e-07 - dense_27_loss: 5.8842e-07 - dense_28_loss: 5.5366e-07 - val_loss: 1.7818e-06 - val_dense_26_loss: 7.4464e-07 - val_dense_27_loss: 5.3737e-07 - val_dense_28_loss: 4.9982e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7101e-06 - dense_26_loss: 7.0215e-07 - dense_27_loss: 5.2975e-07 - dense_28_loss: 4.7824e-07 - val_loss: 1.5817e-06 - val_dense_26_loss: 6.5407e-07 - val_dense_27_loss: 4.9051e-07 - val_dense_28_loss: 4.3716e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5957e-06 - dense_26_loss: 6.6834e-07 - dense_27_loss: 5.1659e-07 - dense_28_loss: 4.1077e-07 - val_loss: 1.7320e-06 - val_dense_26_loss: 7.5340e-07 - val_dense_27_loss: 5.8042e-07 - val_dense_28_loss: 3.9812e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5287e-06 - dense_26_loss: 6.4952e-07 - dense_27_loss: 5.1127e-07 - dense_28_loss: 3.6789e-07 - val_loss: 1.3901e-06 - val_dense_26_loss: 5.8703e-07 - val_dense_27_loss: 4.6797e-07 - val_dense_28_loss: 3.3512e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4767e-06 - dense_26_loss: 6.3761e-07 - dense_27_loss: 5.1279e-07 - dense_28_loss: 3.2631e-07 - val_loss: 1.3065e-06 - val_dense_26_loss: 5.6461e-07 - val_dense_27_loss: 4.5798e-07 - val_dense_28_loss: 2.8396e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3021e-06 - dense_26_loss: 5.6076e-07 - dense_27_loss: 4.6019e-07 - dense_28_loss: 2.8114e-07 - val_loss: 1.3945e-06 - val_dense_26_loss: 6.0723e-07 - val_dense_27_loss: 5.2062e-07 - val_dense_28_loss: 2.6661e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3336e-06 - dense_26_loss: 5.8306e-07 - dense_27_loss: 4.9432e-07 - dense_28_loss: 2.5619e-07 - val_loss: 1.1166e-06 - val_dense_26_loss: 4.8733e-07 - val_dense_27_loss: 4.1342e-07 - val_dense_28_loss: 2.1584e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1332e-06 - dense_26_loss: 4.9397e-07 - dense_27_loss: 4.2834e-07 - dense_28_loss: 2.1094e-07 - val_loss: 1.0924e-06 - val_dense_26_loss: 4.6593e-07 - val_dense_27_loss: 4.2626e-07 - val_dense_28_loss: 2.0018e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1107e-06 - dense_26_loss: 4.8230e-07 - dense_27_loss: 4.4174e-07 - dense_28_loss: 1.8662e-07 - val_loss: 1.0208e-06 - val_dense_26_loss: 4.3941e-07 - val_dense_27_loss: 4.1195e-07 - val_dense_28_loss: 1.6943e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0065e-06 - dense_26_loss: 4.4015e-07 - dense_27_loss: 4.0902e-07 - dense_28_loss: 1.5731e-07 - val_loss: 1.1109e-06 - val_dense_26_loss: 5.1765e-07 - val_dense_27_loss: 4.4217e-07 - val_dense_28_loss: 1.5105e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1180e-06 - dense_26_loss: 4.9276e-07 - dense_27_loss: 4.7473e-07 - dense_28_loss: 1.5050e-07 - val_loss: 1.3224e-06 - val_dense_26_loss: 5.6116e-07 - val_dense_27_loss: 5.5101e-07 - val_dense_28_loss: 2.1026e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0411e-06 - dense_26_loss: 4.5966e-07 - dense_27_loss: 4.3795e-07 - dense_28_loss: 1.4348e-07 - val_loss: 8.4426e-07 - val_dense_26_loss: 3.5848e-07 - val_dense_27_loss: 3.6249e-07 - val_dense_28_loss: 1.2329e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6890e-07 - dense_26_loss: 3.7461e-07 - dense_27_loss: 3.6936e-07 - dense_28_loss: 1.2494e-07 - val_loss: 9.1300e-07 - val_dense_26_loss: 3.7806e-07 - val_dense_27_loss: 4.0734e-07 - val_dense_28_loss: 1.2760e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4676e-07 - dense_26_loss: 3.7030e-07 - dense_27_loss: 3.6332e-07 - dense_28_loss: 1.1315e-07 - val_loss: 8.4091e-07 - val_dense_26_loss: 3.8244e-07 - val_dense_27_loss: 3.5449e-07 - val_dense_28_loss: 1.0397e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5580e-07 - dense_26_loss: 3.7393e-07 - dense_27_loss: 3.7556e-07 - dense_28_loss: 1.0631e-07 - val_loss: 9.3968e-07 - val_dense_26_loss: 4.0612e-07 - val_dense_27_loss: 4.0447e-07 - val_dense_28_loss: 1.2908e-07\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1551e-07 - dense_26_loss: 3.5734e-07 - dense_27_loss: 3.6192e-07 - dense_28_loss: 9.6254e-08 - val_loss: 8.8505e-07 - val_dense_26_loss: 3.5063e-07 - val_dense_27_loss: 3.9024e-07 - val_dense_28_loss: 1.4418e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0095e-06 - dense_26_loss: 4.3827e-07 - dense_27_loss: 4.4562e-07 - dense_28_loss: 1.2566e-07 - val_loss: 1.0415e-06 - val_dense_26_loss: 4.6795e-07 - val_dense_27_loss: 4.6421e-07 - val_dense_28_loss: 1.0937e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2912e-06 - dense_26_loss: 5.8642e-07 - dense_27_loss: 5.6606e-07 - dense_28_loss: 1.3876e-07 - val_loss: 1.3606e-06 - val_dense_26_loss: 5.7663e-07 - val_dense_27_loss: 5.8507e-07 - val_dense_28_loss: 1.9886e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0261e-06 - dense_26_loss: 4.5816e-07 - dense_27_loss: 4.5780e-07 - dense_28_loss: 1.1018e-07 - val_loss: 7.4265e-07 - val_dense_26_loss: 3.1018e-07 - val_dense_27_loss: 3.3183e-07 - val_dense_28_loss: 1.0064e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2346e-07 - dense_26_loss: 3.6334e-07 - dense_27_loss: 3.7335e-07 - dense_28_loss: 8.6766e-08 - val_loss: 7.7424e-07 - val_dense_26_loss: 3.3507e-07 - val_dense_27_loss: 3.5567e-07 - val_dense_28_loss: 8.3502e-08\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9127e-07 - dense_26_loss: 3.4807e-07 - dense_27_loss: 3.6067e-07 - dense_28_loss: 8.2528e-08 - val_loss: 9.5065e-07 - val_dense_26_loss: 4.4041e-07 - val_dense_27_loss: 4.2577e-07 - val_dense_28_loss: 8.4469e-08\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1923e-07 - dense_26_loss: 3.1386e-07 - dense_27_loss: 3.3151e-07 - dense_28_loss: 7.3863e-08 - val_loss: 7.5506e-07 - val_dense_26_loss: 3.0986e-07 - val_dense_27_loss: 3.6141e-07 - val_dense_28_loss: 8.3794e-08\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0571e-07 - dense_26_loss: 3.0806e-07 - dense_27_loss: 3.2813e-07 - dense_28_loss: 6.9521e-08 - val_loss: 7.2872e-07 - val_dense_26_loss: 3.1737e-07 - val_dense_27_loss: 3.3444e-07 - val_dense_28_loss: 7.6920e-08\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7294e-07 - dense_26_loss: 2.9705e-07 - dense_27_loss: 3.1087e-07 - dense_28_loss: 6.5009e-08 - val_loss: 7.7217e-07 - val_dense_26_loss: 3.2481e-07 - val_dense_27_loss: 3.6643e-07 - val_dense_28_loss: 8.0921e-08\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0328e-07 - dense_26_loss: 3.0417e-07 - dense_27_loss: 3.2689e-07 - dense_28_loss: 7.2216e-08 - val_loss: 7.3871e-07 - val_dense_26_loss: 3.2097e-07 - val_dense_27_loss: 3.3559e-07 - val_dense_28_loss: 8.2145e-08\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9728e-07 - dense_26_loss: 3.0825e-07 - dense_27_loss: 3.2415e-07 - dense_28_loss: 6.4879e-08 - val_loss: 7.8157e-07 - val_dense_26_loss: 3.3496e-07 - val_dense_27_loss: 3.5752e-07 - val_dense_28_loss: 8.9098e-08\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3835e-07 - dense_26_loss: 3.2923e-07 - dense_27_loss: 3.4136e-07 - dense_28_loss: 6.7761e-08 - val_loss: 7.7591e-07 - val_dense_26_loss: 3.3866e-07 - val_dense_27_loss: 3.6081e-07 - val_dense_28_loss: 7.6442e-08\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9344e-07 - dense_26_loss: 3.0576e-07 - dense_27_loss: 3.2481e-07 - dense_28_loss: 6.2864e-08 - val_loss: 6.8720e-07 - val_dense_26_loss: 2.9102e-07 - val_dense_27_loss: 3.3468e-07 - val_dense_28_loss: 6.1501e-08\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6134e-07 - dense_26_loss: 2.8955e-07 - dense_27_loss: 3.1142e-07 - dense_28_loss: 6.0379e-08 - val_loss: 6.6164e-07 - val_dense_26_loss: 2.8447e-07 - val_dense_27_loss: 3.1701e-07 - val_dense_28_loss: 6.0158e-08\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7481e-07 - dense_26_loss: 2.9920e-07 - dense_27_loss: 3.1673e-07 - dense_28_loss: 5.8886e-08 - val_loss: 7.4787e-07 - val_dense_26_loss: 3.2373e-07 - val_dense_27_loss: 3.5145e-07 - val_dense_28_loss: 7.2685e-08\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7646e-07 - dense_26_loss: 4.5148e-07 - dense_27_loss: 4.4799e-07 - dense_28_loss: 7.6995e-08 - val_loss: 1.8848e-06 - val_dense_26_loss: 9.4966e-07 - val_dense_27_loss: 8.1338e-07 - val_dense_28_loss: 1.2177e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6813e-07 - dense_26_loss: 3.8934e-07 - dense_27_loss: 4.0445e-07 - dense_28_loss: 7.4332e-08 - val_loss: 9.6796e-07 - val_dense_26_loss: 4.1413e-07 - val_dense_27_loss: 4.7231e-07 - val_dense_28_loss: 8.1523e-08\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0550e-06 - dense_26_loss: 4.8669e-07 - dense_27_loss: 4.8175e-07 - dense_28_loss: 8.6546e-08 - val_loss: 7.0336e-07 - val_dense_26_loss: 2.9703e-07 - val_dense_27_loss: 3.3082e-07 - val_dense_28_loss: 7.5511e-08\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9125e-07 - dense_26_loss: 3.0376e-07 - dense_27_loss: 3.2072e-07 - dense_28_loss: 6.6764e-08 - val_loss: 6.9591e-07 - val_dense_26_loss: 3.0576e-07 - val_dense_27_loss: 3.2525e-07 - val_dense_28_loss: 6.4898e-08\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8701e-07 - dense_26_loss: 3.0282e-07 - dense_27_loss: 3.2442e-07 - dense_28_loss: 5.9777e-08 - val_loss: 7.1536e-07 - val_dense_26_loss: 3.0926e-07 - val_dense_27_loss: 3.3643e-07 - val_dense_28_loss: 6.9671e-08\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0288e-07 - dense_26_loss: 3.1201e-07 - dense_27_loss: 3.2729e-07 - dense_28_loss: 6.3581e-08 - val_loss: 8.5710e-07 - val_dense_26_loss: 3.9646e-07 - val_dense_27_loss: 3.8553e-07 - val_dense_28_loss: 7.5108e-08\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8356e-07 - dense_26_loss: 3.5137e-07 - dense_27_loss: 3.5844e-07 - dense_28_loss: 7.3751e-08 - val_loss: 7.4289e-07 - val_dense_26_loss: 3.3450e-07 - val_dense_27_loss: 3.4443e-07 - val_dense_28_loss: 6.3969e-08\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2925e-07 - dense_26_loss: 3.2339e-07 - dense_27_loss: 3.4145e-07 - dense_28_loss: 6.4406e-08 - val_loss: 6.9026e-07 - val_dense_26_loss: 3.0014e-07 - val_dense_27_loss: 3.2748e-07 - val_dense_28_loss: 6.2634e-08\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.8072e-07 - dense_26_loss: 3.0377e-07 - dense_27_loss: 3.1733e-07 - dense_28_loss: 5.9623e-08 - val_loss: 7.4120e-07 - val_dense_26_loss: 3.1717e-07 - val_dense_27_loss: 3.5822e-07 - val_dense_28_loss: 6.5806e-08\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00056: early stopping\n",
      "\n",
      "Now training model 4/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 15ms/step - loss: 0.0017 - dense_34_loss: 6.9748e-04 - dense_35_loss: 6.2841e-04 - dense_36_loss: 4.2195e-04 - val_loss: 1.5897e-04 - val_dense_34_loss: 5.2640e-05 - val_dense_35_loss: 5.1493e-05 - val_dense_36_loss: 5.4837e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1976e-04 - dense_34_loss: 4.3860e-05 - dense_35_loss: 3.6065e-05 - dense_36_loss: 3.9833e-05 - val_loss: 7.9470e-05 - val_dense_34_loss: 2.6429e-05 - val_dense_35_loss: 2.4080e-05 - val_dense_36_loss: 2.8961e-05\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9402e-05 - dense_34_loss: 2.2791e-05 - dense_35_loss: 2.2168e-05 - dense_36_loss: 2.4443e-05 - val_loss: 6.2928e-05 - val_dense_34_loss: 1.9658e-05 - val_dense_35_loss: 1.9861e-05 - val_dense_36_loss: 2.3409e-05\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9099e-05 - dense_34_loss: 1.8277e-05 - dense_35_loss: 1.8482e-05 - dense_36_loss: 2.2340e-05 - val_loss: 5.2843e-05 - val_dense_34_loss: 1.5745e-05 - val_dense_35_loss: 1.6071e-05 - val_dense_36_loss: 2.1027e-05\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 4.4871e-05 - dense_34_loss: 1.3485e-05 - dense_35_loss: 1.3224e-05 - dense_36_loss: 1.8162e-05 - val_loss: 3.2904e-05 - val_dense_34_loss: 9.4295e-06 - val_dense_35_loss: 8.8415e-06 - val_dense_36_loss: 1.4633e-05\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1681e-05 - dense_34_loss: 6.3089e-06 - dense_35_loss: 5.6225e-06 - dense_36_loss: 9.7497e-06 - val_loss: 9.9486e-06 - val_dense_34_loss: 3.1088e-06 - val_dense_35_loss: 2.5931e-06 - val_dense_36_loss: 4.2467e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2796e-06 - dense_34_loss: 1.8276e-06 - dense_35_loss: 1.5442e-06 - dense_36_loss: 1.9078e-06 - val_loss: 2.3706e-06 - val_dense_34_loss: 8.7619e-07 - val_dense_35_loss: 7.2958e-07 - val_dense_36_loss: 7.6482e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0219e-06 - dense_34_loss: 7.2897e-07 - dense_35_loss: 6.0523e-07 - dense_36_loss: 6.8772e-07 - val_loss: 1.7359e-06 - val_dense_34_loss: 6.4105e-07 - val_dense_35_loss: 5.2304e-07 - val_dense_36_loss: 5.7179e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7452e-06 - dense_34_loss: 6.3788e-07 - dense_35_loss: 5.1885e-07 - dense_36_loss: 5.8847e-07 - val_loss: 1.7490e-06 - val_dense_34_loss: 6.3049e-07 - val_dense_35_loss: 5.2105e-07 - val_dense_36_loss: 5.9749e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7312e-06 - dense_34_loss: 6.3104e-07 - dense_35_loss: 5.2024e-07 - dense_36_loss: 5.7993e-07 - val_loss: 1.6828e-06 - val_dense_34_loss: 6.2670e-07 - val_dense_35_loss: 5.1830e-07 - val_dense_36_loss: 5.3778e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7139e-06 - dense_34_loss: 6.2212e-07 - dense_35_loss: 5.1094e-07 - dense_36_loss: 5.8088e-07 - val_loss: 1.6620e-06 - val_dense_34_loss: 6.0765e-07 - val_dense_35_loss: 4.9226e-07 - val_dense_36_loss: 5.6210e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7178e-06 - dense_34_loss: 6.2046e-07 - dense_35_loss: 5.0656e-07 - dense_36_loss: 5.9083e-07 - val_loss: 1.9274e-06 - val_dense_34_loss: 7.4587e-07 - val_dense_35_loss: 6.3575e-07 - val_dense_36_loss: 5.4580e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7491e-06 - dense_34_loss: 6.2856e-07 - dense_35_loss: 5.1735e-07 - dense_36_loss: 6.0322e-07 - val_loss: 1.6643e-06 - val_dense_34_loss: 6.0571e-07 - val_dense_35_loss: 4.9916e-07 - val_dense_36_loss: 5.5944e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6988e-06 - dense_34_loss: 6.1427e-07 - dense_35_loss: 4.9830e-07 - dense_36_loss: 5.8627e-07 - val_loss: 1.6265e-06 - val_dense_34_loss: 5.9463e-07 - val_dense_35_loss: 4.7986e-07 - val_dense_36_loss: 5.5199e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6825e-06 - dense_34_loss: 6.0150e-07 - dense_35_loss: 4.8865e-07 - dense_36_loss: 5.9233e-07 - val_loss: 1.6736e-06 - val_dense_34_loss: 6.0714e-07 - val_dense_35_loss: 4.9724e-07 - val_dense_36_loss: 5.6925e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7281e-06 - dense_34_loss: 6.1151e-07 - dense_35_loss: 4.9387e-07 - dense_36_loss: 6.2275e-07 - val_loss: 1.7116e-06 - val_dense_34_loss: 5.9908e-07 - val_dense_35_loss: 4.7879e-07 - val_dense_36_loss: 6.3370e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7150e-06 - dense_34_loss: 6.0955e-07 - dense_35_loss: 4.8880e-07 - dense_36_loss: 6.1667e-07 - val_loss: 1.6623e-06 - val_dense_34_loss: 6.0592e-07 - val_dense_35_loss: 4.8791e-07 - val_dense_36_loss: 5.6845e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7179e-06 - dense_34_loss: 6.0737e-07 - dense_35_loss: 4.8894e-07 - dense_36_loss: 6.2161e-07 - val_loss: 1.6546e-06 - val_dense_34_loss: 6.0087e-07 - val_dense_35_loss: 4.8454e-07 - val_dense_36_loss: 5.6923e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6863e-06 - dense_34_loss: 5.9559e-07 - dense_35_loss: 4.8021e-07 - dense_36_loss: 6.1052e-07 - val_loss: 1.6691e-06 - val_dense_34_loss: 6.0630e-07 - val_dense_35_loss: 4.9042e-07 - val_dense_36_loss: 5.7235e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6806e-06 - dense_34_loss: 5.9629e-07 - dense_35_loss: 4.7654e-07 - dense_36_loss: 6.0776e-07 - val_loss: 1.6396e-06 - val_dense_34_loss: 5.9777e-07 - val_dense_35_loss: 4.6620e-07 - val_dense_36_loss: 5.7568e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6830e-06 - dense_34_loss: 5.8769e-07 - dense_35_loss: 4.7859e-07 - dense_36_loss: 6.1673e-07 - val_loss: 1.7172e-06 - val_dense_34_loss: 6.3121e-07 - val_dense_35_loss: 4.9862e-07 - val_dense_36_loss: 5.8737e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7311e-06 - dense_34_loss: 6.0232e-07 - dense_35_loss: 4.8511e-07 - dense_36_loss: 6.4370e-07 - val_loss: 1.7604e-06 - val_dense_34_loss: 5.9682e-07 - val_dense_35_loss: 5.6212e-07 - val_dense_36_loss: 6.0142e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7710e-06 - dense_34_loss: 5.9918e-07 - dense_35_loss: 5.1224e-07 - dense_36_loss: 6.5957e-07 - val_loss: 1.6594e-06 - val_dense_34_loss: 5.8856e-07 - val_dense_35_loss: 4.6793e-07 - val_dense_36_loss: 6.0290e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7494e-06 - dense_34_loss: 5.9493e-07 - dense_35_loss: 4.8878e-07 - dense_36_loss: 6.6571e-07 - val_loss: 1.7055e-06 - val_dense_34_loss: 5.9287e-07 - val_dense_35_loss: 5.0928e-07 - val_dense_36_loss: 6.0336e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7301e-06 - dense_34_loss: 6.0253e-07 - dense_35_loss: 4.9391e-07 - dense_36_loss: 6.3368e-07 - val_loss: 1.6543e-06 - val_dense_34_loss: 5.7467e-07 - val_dense_35_loss: 4.5955e-07 - val_dense_36_loss: 6.2011e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6713e-06 - dense_34_loss: 5.7816e-07 - dense_35_loss: 4.5959e-07 - dense_36_loss: 6.3358e-07 - val_loss: 1.6222e-06 - val_dense_34_loss: 5.7720e-07 - val_dense_35_loss: 4.5674e-07 - val_dense_36_loss: 5.8822e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6539e-06 - dense_34_loss: 5.6809e-07 - dense_35_loss: 4.6114e-07 - dense_36_loss: 6.2466e-07 - val_loss: 1.6814e-06 - val_dense_34_loss: 5.8820e-07 - val_dense_35_loss: 4.8390e-07 - val_dense_36_loss: 6.0927e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6627e-06 - dense_34_loss: 5.6841e-07 - dense_35_loss: 4.6297e-07 - dense_36_loss: 6.3127e-07 - val_loss: 1.5688e-06 - val_dense_34_loss: 5.5391e-07 - val_dense_35_loss: 4.3613e-07 - val_dense_36_loss: 5.7876e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6448e-06 - dense_34_loss: 5.6361e-07 - dense_35_loss: 4.5819e-07 - dense_36_loss: 6.2299e-07 - val_loss: 1.7914e-06 - val_dense_34_loss: 6.5475e-07 - val_dense_35_loss: 5.1567e-07 - val_dense_36_loss: 6.2101e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6937e-06 - dense_34_loss: 5.7888e-07 - dense_35_loss: 4.7739e-07 - dense_36_loss: 6.3746e-07 - val_loss: 1.6529e-06 - val_dense_34_loss: 6.0056e-07 - val_dense_35_loss: 4.6308e-07 - val_dense_36_loss: 5.8930e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6568e-06 - dense_34_loss: 5.6083e-07 - dense_35_loss: 4.5783e-07 - dense_36_loss: 6.3818e-07 - val_loss: 1.6204e-06 - val_dense_34_loss: 5.6446e-07 - val_dense_35_loss: 4.7272e-07 - val_dense_36_loss: 5.8323e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6507e-06 - dense_34_loss: 5.6159e-07 - dense_35_loss: 4.6057e-07 - dense_36_loss: 6.2853e-07 - val_loss: 1.7056e-06 - val_dense_34_loss: 5.7075e-07 - val_dense_35_loss: 4.5269e-07 - val_dense_36_loss: 6.8213e-07\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6842e-06 - dense_34_loss: 5.7340e-07 - dense_35_loss: 4.7355e-07 - dense_36_loss: 6.3724e-07 - val_loss: 1.6185e-06 - val_dense_34_loss: 5.7471e-07 - val_dense_35_loss: 4.4555e-07 - val_dense_36_loss: 5.9820e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6242e-06 - dense_34_loss: 5.5686e-07 - dense_35_loss: 4.4746e-07 - dense_36_loss: 6.1986e-07 - val_loss: 1.5966e-06 - val_dense_34_loss: 5.4860e-07 - val_dense_35_loss: 4.5009e-07 - val_dense_36_loss: 5.9792e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Now training model 5/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 15ms/step - loss: 0.0017 - dense_42_loss: 6.5258e-04 - dense_43_loss: 6.1402e-04 - dense_44_loss: 3.9095e-04 - val_loss: 1.4559e-04 - val_dense_42_loss: 4.3178e-05 - val_dense_43_loss: 2.9954e-05 - val_dense_44_loss: 7.2459e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0964e-04 - dense_42_loss: 2.7026e-05 - dense_43_loss: 2.2420e-05 - dense_44_loss: 6.0193e-05 - val_loss: 7.5044e-05 - val_dense_42_loss: 1.4106e-05 - val_dense_43_loss: 1.6102e-05 - val_dense_44_loss: 4.4836e-05\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0759e-05 - dense_42_loss: 1.2172e-05 - dense_43_loss: 1.2197e-05 - dense_44_loss: 3.6390e-05 - val_loss: 4.5615e-05 - val_dense_42_loss: 9.8266e-06 - val_dense_43_loss: 1.0154e-05 - val_dense_44_loss: 2.5634e-05\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.0758e-05 - dense_42_loss: 6.6658e-06 - dense_43_loss: 7.7280e-06 - dense_44_loss: 1.6364e-05 - val_loss: 1.4759e-05 - val_dense_42_loss: 3.5775e-06 - val_dense_43_loss: 4.3066e-06 - val_dense_44_loss: 6.8749e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0231e-06 - dense_42_loss: 1.9775e-06 - dense_43_loss: 2.1874e-06 - dense_44_loss: 2.8582e-06 - val_loss: 2.6201e-06 - val_dense_42_loss: 8.5602e-07 - val_dense_43_loss: 9.9720e-07 - val_dense_44_loss: 7.6687e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1900e-06 - dense_42_loss: 7.4293e-07 - dense_43_loss: 8.3210e-07 - dense_44_loss: 6.1495e-07 - val_loss: 1.8370e-06 - val_dense_42_loss: 6.5536e-07 - val_dense_43_loss: 7.0718e-07 - val_dense_44_loss: 4.7448e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9149e-06 - dense_42_loss: 6.7577e-07 - dense_43_loss: 7.3449e-07 - dense_44_loss: 5.0467e-07 - val_loss: 1.7558e-06 - val_dense_42_loss: 6.2925e-07 - val_dense_43_loss: 6.9174e-07 - val_dense_44_loss: 4.3479e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8783e-06 - dense_42_loss: 6.6478e-07 - dense_43_loss: 7.2494e-07 - dense_44_loss: 4.8856e-07 - val_loss: 1.7660e-06 - val_dense_42_loss: 6.3063e-07 - val_dense_43_loss: 6.9573e-07 - val_dense_44_loss: 4.3966e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8599e-06 - dense_42_loss: 6.6249e-07 - dense_43_loss: 7.1973e-07 - dense_44_loss: 4.7770e-07 - val_loss: 1.7361e-06 - val_dense_42_loss: 6.2282e-07 - val_dense_43_loss: 6.8573e-07 - val_dense_44_loss: 4.2752e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8648e-06 - dense_42_loss: 6.6367e-07 - dense_43_loss: 7.2161e-07 - dense_44_loss: 4.7947e-07 - val_loss: 1.8043e-06 - val_dense_42_loss: 6.3916e-07 - val_dense_43_loss: 7.2491e-07 - val_dense_44_loss: 4.4019e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8927e-06 - dense_42_loss: 6.6543e-07 - dense_43_loss: 7.3099e-07 - dense_44_loss: 4.9633e-07 - val_loss: 1.7876e-06 - val_dense_42_loss: 6.5188e-07 - val_dense_43_loss: 6.9600e-07 - val_dense_44_loss: 4.3970e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8928e-06 - dense_42_loss: 6.7578e-07 - dense_43_loss: 7.2639e-07 - dense_44_loss: 4.9059e-07 - val_loss: 1.7786e-06 - val_dense_42_loss: 6.2977e-07 - val_dense_43_loss: 6.9751e-07 - val_dense_44_loss: 4.5132e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8786e-06 - dense_42_loss: 6.6490e-07 - dense_43_loss: 7.2183e-07 - dense_44_loss: 4.9190e-07 - val_loss: 1.7473e-06 - val_dense_42_loss: 6.3225e-07 - val_dense_43_loss: 6.9341e-07 - val_dense_44_loss: 4.2160e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8594e-06 - dense_42_loss: 6.6498e-07 - dense_43_loss: 7.1839e-07 - dense_44_loss: 4.7605e-07 - val_loss: 1.8254e-06 - val_dense_42_loss: 6.5851e-07 - val_dense_43_loss: 6.9997e-07 - val_dense_44_loss: 4.6687e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8658e-06 - dense_42_loss: 6.6659e-07 - dense_43_loss: 7.1675e-07 - dense_44_loss: 4.8251e-07 - val_loss: 1.7310e-06 - val_dense_42_loss: 6.1767e-07 - val_dense_43_loss: 6.8991e-07 - val_dense_44_loss: 4.2343e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8554e-06 - dense_42_loss: 6.6053e-07 - dense_43_loss: 7.0902e-07 - dense_44_loss: 4.8589e-07 - val_loss: 1.7206e-06 - val_dense_42_loss: 6.0969e-07 - val_dense_43_loss: 6.7946e-07 - val_dense_44_loss: 4.3146e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8663e-06 - dense_42_loss: 6.6010e-07 - dense_43_loss: 7.1152e-07 - dense_44_loss: 4.9468e-07 - val_loss: 1.7307e-06 - val_dense_42_loss: 6.2482e-07 - val_dense_43_loss: 6.7566e-07 - val_dense_44_loss: 4.3027e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8603e-06 - dense_42_loss: 6.5922e-07 - dense_43_loss: 7.0786e-07 - dense_44_loss: 4.9320e-07 - val_loss: 1.7160e-06 - val_dense_42_loss: 6.1566e-07 - val_dense_43_loss: 6.6707e-07 - val_dense_44_loss: 4.3327e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8455e-06 - dense_42_loss: 6.5214e-07 - dense_43_loss: 7.0499e-07 - dense_44_loss: 4.8833e-07 - val_loss: 1.7747e-06 - val_dense_42_loss: 6.2390e-07 - val_dense_43_loss: 7.0555e-07 - val_dense_44_loss: 4.4524e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8300e-06 - dense_42_loss: 6.4702e-07 - dense_43_loss: 6.9846e-07 - dense_44_loss: 4.8452e-07 - val_loss: 1.7199e-06 - val_dense_42_loss: 6.2299e-07 - val_dense_43_loss: 6.6821e-07 - val_dense_44_loss: 4.2866e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8589e-06 - dense_42_loss: 6.5857e-07 - dense_43_loss: 7.0655e-07 - dense_44_loss: 4.9376e-07 - val_loss: 1.7585e-06 - val_dense_42_loss: 6.3136e-07 - val_dense_43_loss: 6.6905e-07 - val_dense_44_loss: 4.5812e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8710e-06 - dense_42_loss: 6.6710e-07 - dense_43_loss: 6.9930e-07 - dense_44_loss: 5.0460e-07 - val_loss: 1.7653e-06 - val_dense_42_loss: 6.2638e-07 - val_dense_43_loss: 6.8792e-07 - val_dense_44_loss: 4.5104e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8395e-06 - dense_42_loss: 6.4954e-07 - dense_43_loss: 6.8967e-07 - dense_44_loss: 5.0033e-07 - val_loss: 1.8428e-06 - val_dense_42_loss: 7.0279e-07 - val_dense_43_loss: 6.9111e-07 - val_dense_44_loss: 4.4891e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8731e-06 - dense_42_loss: 6.6661e-07 - dense_43_loss: 6.9964e-07 - dense_44_loss: 5.0687e-07 - val_loss: 1.7859e-06 - val_dense_42_loss: 6.4496e-07 - val_dense_43_loss: 7.0558e-07 - val_dense_44_loss: 4.3534e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8631e-06 - dense_42_loss: 6.5897e-07 - dense_43_loss: 6.9999e-07 - dense_44_loss: 5.0413e-07 - val_loss: 1.7798e-06 - val_dense_42_loss: 6.3191e-07 - val_dense_43_loss: 6.5580e-07 - val_dense_44_loss: 4.9211e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8774e-06 - dense_42_loss: 6.7001e-07 - dense_43_loss: 7.0383e-07 - dense_44_loss: 5.0358e-07 - val_loss: 1.7351e-06 - val_dense_42_loss: 6.2354e-07 - val_dense_43_loss: 6.5997e-07 - val_dense_44_loss: 4.5159e-07\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8586e-06 - dense_42_loss: 6.6545e-07 - dense_43_loss: 6.9959e-07 - dense_44_loss: 4.9352e-07 - val_loss: 1.7603e-06 - val_dense_42_loss: 6.1703e-07 - val_dense_43_loss: 6.7454e-07 - val_dense_44_loss: 4.6874e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8373e-06 - dense_42_loss: 6.5143e-07 - dense_43_loss: 6.8441e-07 - dense_44_loss: 5.0145e-07 - val_loss: 1.7408e-06 - val_dense_42_loss: 6.2262e-07 - val_dense_43_loss: 6.7664e-07 - val_dense_44_loss: 4.4150e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8023e-06 - dense_42_loss: 6.4107e-07 - dense_43_loss: 6.7638e-07 - dense_44_loss: 4.8485e-07 - val_loss: 1.8079e-06 - val_dense_42_loss: 6.4213e-07 - val_dense_43_loss: 6.6125e-07 - val_dense_44_loss: 5.0447e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "\n",
      "Now training model 6/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 13ms/step - loss: 8.4093e-04 - dense_50_loss: 5.3288e-04 - dense_51_loss: 3.0806e-04 - val_loss: 4.3909e-05 - val_dense_50_loss: 2.0881e-05 - val_dense_51_loss: 2.3029e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.5617e-05 - dense_50_loss: 1.9432e-05 - dense_51_loss: 1.6184e-05 - val_loss: 1.6005e-05 - val_dense_50_loss: 1.0805e-05 - val_dense_51_loss: 5.1994e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2058e-05 - dense_50_loss: 9.8576e-06 - dense_51_loss: 2.2000e-06 - val_loss: 7.4005e-06 - val_dense_50_loss: 6.4223e-06 - val_dense_51_loss: 9.7824e-07\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1588e-06 - dense_50_loss: 8.2573e-06 - dense_51_loss: 9.0155e-07 - val_loss: 6.8719e-06 - val_dense_50_loss: 6.0692e-06 - val_dense_51_loss: 8.0271e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6677e-06 - dense_50_loss: 7.8487e-06 - dense_51_loss: 8.1899e-07 - val_loss: 6.6536e-06 - val_dense_50_loss: 5.8893e-06 - val_dense_51_loss: 7.6427e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4416e-06 - dense_50_loss: 7.6180e-06 - dense_51_loss: 8.2362e-07 - val_loss: 6.5178e-06 - val_dense_50_loss: 5.6864e-06 - val_dense_51_loss: 8.3142e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1033e-06 - dense_50_loss: 7.2292e-06 - dense_51_loss: 8.7409e-07 - val_loss: 6.5105e-06 - val_dense_50_loss: 5.6481e-06 - val_dense_51_loss: 8.6240e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8431e-06 - dense_50_loss: 6.8756e-06 - dense_51_loss: 9.6752e-07 - val_loss: 5.7915e-06 - val_dense_50_loss: 4.9291e-06 - val_dense_51_loss: 8.6239e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.0105e-06 - dense_50_loss: 6.0295e-06 - dense_51_loss: 9.8101e-07 - val_loss: 5.2558e-06 - val_dense_50_loss: 4.2456e-06 - val_dense_51_loss: 1.0102e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.2530e-06 - dense_50_loss: 5.1353e-06 - dense_51_loss: 1.1178e-06 - val_loss: 4.7057e-06 - val_dense_50_loss: 3.6369e-06 - val_dense_51_loss: 1.0688e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2838e-06 - dense_50_loss: 4.0958e-06 - dense_51_loss: 1.1880e-06 - val_loss: 3.8302e-06 - val_dense_50_loss: 2.7685e-06 - val_dense_51_loss: 1.0617e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.2436e-06 - dense_50_loss: 2.9996e-06 - dense_51_loss: 1.2440e-06 - val_loss: 2.9480e-06 - val_dense_50_loss: 1.8886e-06 - val_dense_51_loss: 1.0594e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.1409e-06 - dense_50_loss: 1.9769e-06 - dense_51_loss: 1.1640e-06 - val_loss: 2.2042e-06 - val_dense_50_loss: 1.2550e-06 - val_dense_51_loss: 9.4923e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2096e-06 - dense_50_loss: 1.2293e-06 - dense_51_loss: 9.8036e-07 - val_loss: 1.7285e-06 - val_dense_50_loss: 8.7275e-07 - val_dense_51_loss: 8.5579e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5178e-06 - dense_50_loss: 7.5497e-07 - dense_51_loss: 7.6279e-07 - val_loss: 1.1802e-06 - val_dense_50_loss: 5.5404e-07 - val_dense_51_loss: 6.2614e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1557e-06 - dense_50_loss: 5.4636e-07 - dense_51_loss: 6.0936e-07 - val_loss: 1.0287e-06 - val_dense_50_loss: 4.5879e-07 - val_dense_51_loss: 5.6987e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8143e-07 - dense_50_loss: 4.4828e-07 - dense_51_loss: 5.3315e-07 - val_loss: 9.3241e-07 - val_dense_50_loss: 4.0248e-07 - val_dense_51_loss: 5.2993e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.3734e-07 - dense_50_loss: 4.2277e-07 - dense_51_loss: 5.1458e-07 - val_loss: 1.1043e-06 - val_dense_50_loss: 5.4223e-07 - val_dense_51_loss: 5.6211e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6324e-07 - dense_50_loss: 4.5112e-07 - dense_51_loss: 5.1212e-07 - val_loss: 8.9821e-07 - val_dense_50_loss: 3.9352e-07 - val_dense_51_loss: 5.0468e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9354e-07 - dense_50_loss: 4.0831e-07 - dense_51_loss: 4.8523e-07 - val_loss: 9.1863e-07 - val_dense_50_loss: 4.0315e-07 - val_dense_51_loss: 5.1548e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8885e-07 - dense_50_loss: 4.1009e-07 - dense_51_loss: 4.7875e-07 - val_loss: 9.4155e-07 - val_dense_50_loss: 4.1212e-07 - val_dense_51_loss: 5.2943e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1917e-07 - dense_50_loss: 4.0935e-07 - dense_51_loss: 5.0982e-07 - val_loss: 1.1936e-06 - val_dense_50_loss: 5.3673e-07 - val_dense_51_loss: 6.5686e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0036e-06 - dense_50_loss: 4.6355e-07 - dense_51_loss: 5.4009e-07 - val_loss: 9.2429e-07 - val_dense_50_loss: 3.7499e-07 - val_dense_51_loss: 5.4930e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9313e-07 - dense_50_loss: 4.1183e-07 - dense_51_loss: 4.8130e-07 - val_loss: 9.6480e-07 - val_dense_50_loss: 3.9569e-07 - val_dense_51_loss: 5.6911e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7640e-07 - dense_50_loss: 3.9210e-07 - dense_51_loss: 4.8430e-07 - val_loss: 8.8545e-07 - val_dense_50_loss: 3.8680e-07 - val_dense_51_loss: 4.9864e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7568e-07 - dense_50_loss: 3.9815e-07 - dense_51_loss: 4.7753e-07 - val_loss: 8.9126e-07 - val_dense_50_loss: 3.8674e-07 - val_dense_51_loss: 5.0452e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7612e-07 - dense_50_loss: 3.9530e-07 - dense_51_loss: 4.8082e-07 - val_loss: 9.6450e-07 - val_dense_50_loss: 4.1996e-07 - val_dense_51_loss: 5.4454e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.3863e-07 - dense_50_loss: 4.2144e-07 - dense_51_loss: 5.1719e-07 - val_loss: 9.4600e-07 - val_dense_50_loss: 4.3110e-07 - val_dense_51_loss: 5.1490e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8484e-07 - dense_50_loss: 4.1082e-07 - dense_51_loss: 4.7402e-07 - val_loss: 1.0200e-06 - val_dense_50_loss: 5.0171e-07 - val_dense_51_loss: 5.1830e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5120e-07 - dense_50_loss: 4.2992e-07 - dense_51_loss: 5.2127e-07 - val_loss: 9.9945e-07 - val_dense_50_loss: 4.8635e-07 - val_dense_51_loss: 5.1310e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2408e-07 - dense_50_loss: 4.5519e-07 - dense_51_loss: 4.6889e-07 - val_loss: 8.8975e-07 - val_dense_50_loss: 3.9366e-07 - val_dense_51_loss: 4.9609e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.6648e-07 - dense_50_loss: 3.9983e-07 - dense_51_loss: 4.6665e-07 - val_loss: 1.0117e-06 - val_dense_50_loss: 5.1354e-07 - val_dense_51_loss: 4.9819e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9452e-07 - dense_50_loss: 4.3048e-07 - dense_51_loss: 4.6405e-07 - val_loss: 9.8704e-07 - val_dense_50_loss: 5.0024e-07 - val_dense_51_loss: 4.8680e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8311e-07 - dense_50_loss: 4.3242e-07 - dense_51_loss: 4.5070e-07 - val_loss: 9.6428e-07 - val_dense_50_loss: 5.0525e-07 - val_dense_51_loss: 4.5904e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4725e-07 - dense_50_loss: 4.0704e-07 - dense_51_loss: 4.4021e-07 - val_loss: 1.0852e-06 - val_dense_50_loss: 6.1099e-07 - val_dense_51_loss: 4.7421e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7396e-07 - dense_50_loss: 4.3009e-07 - dense_51_loss: 4.4387e-07 - val_loss: 8.7179e-07 - val_dense_50_loss: 4.1654e-07 - val_dense_51_loss: 4.5525e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2401e-07 - dense_50_loss: 3.9010e-07 - dense_51_loss: 4.3391e-07 - val_loss: 9.2410e-07 - val_dense_50_loss: 4.2567e-07 - val_dense_51_loss: 4.9843e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.3441e-07 - dense_50_loss: 3.8947e-07 - dense_51_loss: 4.4494e-07 - val_loss: 8.8660e-07 - val_dense_50_loss: 4.2094e-07 - val_dense_51_loss: 4.6566e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3425e-07 - dense_50_loss: 4.0954e-07 - dense_51_loss: 4.2471e-07 - val_loss: 9.0092e-07 - val_dense_50_loss: 3.9743e-07 - val_dense_51_loss: 5.0349e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "\n",
      "Now training model 7/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 0.0010 - dense_57_loss: 6.7940e-04 - dense_58_loss: 3.6458e-04 - val_loss: 6.9996e-05 - val_dense_57_loss: 4.1444e-05 - val_dense_58_loss: 2.8552e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.3638e-05 - dense_57_loss: 2.4129e-05 - dense_58_loss: 1.9510e-05 - val_loss: 1.5454e-05 - val_dense_57_loss: 9.7323e-06 - val_dense_58_loss: 5.7212e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2767e-05 - dense_57_loss: 1.0128e-05 - dense_58_loss: 2.6389e-06 - val_loss: 8.5553e-06 - val_dense_57_loss: 6.9929e-06 - val_dense_58_loss: 1.5624e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7724e-06 - dense_57_loss: 8.8116e-06 - dense_58_loss: 9.6078e-07 - val_loss: 7.5071e-06 - val_dense_57_loss: 6.7678e-06 - val_dense_58_loss: 7.3930e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3565e-06 - dense_57_loss: 8.6205e-06 - dense_58_loss: 7.3601e-07 - val_loss: 7.0547e-06 - val_dense_57_loss: 6.3568e-06 - val_dense_58_loss: 6.9789e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9927e-06 - dense_57_loss: 8.2716e-06 - dense_58_loss: 7.2110e-07 - val_loss: 6.9643e-06 - val_dense_57_loss: 6.2762e-06 - val_dense_58_loss: 6.8815e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7969e-06 - dense_57_loss: 8.0554e-06 - dense_58_loss: 7.4149e-07 - val_loss: 6.7744e-06 - val_dense_57_loss: 6.0566e-06 - val_dense_58_loss: 7.1777e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5425e-06 - dense_57_loss: 7.7830e-06 - dense_58_loss: 7.5948e-07 - val_loss: 6.4703e-06 - val_dense_57_loss: 5.7130e-06 - val_dense_58_loss: 7.5728e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1152e-06 - dense_57_loss: 7.3085e-06 - dense_58_loss: 8.0670e-07 - val_loss: 6.2552e-06 - val_dense_57_loss: 5.4460e-06 - val_dense_58_loss: 8.0924e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.6770e-06 - dense_57_loss: 6.7951e-06 - dense_58_loss: 8.8191e-07 - val_loss: 5.5621e-06 - val_dense_57_loss: 4.7604e-06 - val_dense_58_loss: 8.0169e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.6901e-06 - dense_57_loss: 5.8287e-06 - dense_58_loss: 8.6145e-07 - val_loss: 4.9807e-06 - val_dense_57_loss: 4.0654e-06 - val_dense_58_loss: 9.1537e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8786e-06 - dense_57_loss: 4.9108e-06 - dense_58_loss: 9.6787e-07 - val_loss: 4.0511e-06 - val_dense_57_loss: 3.1477e-06 - val_dense_58_loss: 9.0340e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.5874e-06 - dense_57_loss: 3.6035e-06 - dense_58_loss: 9.8395e-07 - val_loss: 3.1891e-06 - val_dense_57_loss: 2.2786e-06 - val_dense_58_loss: 9.1043e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.2784e-06 - dense_57_loss: 2.3453e-06 - dense_58_loss: 9.3312e-07 - val_loss: 2.1658e-06 - val_dense_57_loss: 1.3667e-06 - val_dense_58_loss: 7.9901e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1293e-06 - dense_57_loss: 1.3184e-06 - dense_58_loss: 8.1090e-07 - val_loss: 1.5466e-06 - val_dense_57_loss: 8.4561e-07 - val_dense_58_loss: 7.0095e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4183e-06 - dense_57_loss: 7.3937e-07 - dense_58_loss: 6.7892e-07 - val_loss: 1.1009e-06 - val_dense_57_loss: 5.0132e-07 - val_dense_58_loss: 5.9960e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0342e-06 - dense_57_loss: 4.7062e-07 - dense_58_loss: 5.6358e-07 - val_loss: 9.4551e-07 - val_dense_57_loss: 3.9800e-07 - val_dense_58_loss: 5.4751e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7419e-07 - dense_57_loss: 3.7307e-07 - dense_58_loss: 5.0112e-07 - val_loss: 8.6717e-07 - val_dense_57_loss: 3.5393e-07 - val_dense_58_loss: 5.1324e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.0892e-07 - dense_57_loss: 3.3801e-07 - dense_58_loss: 4.7092e-07 - val_loss: 8.5046e-07 - val_dense_57_loss: 3.3542e-07 - val_dense_58_loss: 5.1505e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1763e-07 - dense_57_loss: 3.3252e-07 - dense_58_loss: 4.8511e-07 - val_loss: 8.6963e-07 - val_dense_57_loss: 3.4135e-07 - val_dense_58_loss: 5.2829e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1781e-07 - dense_57_loss: 3.3400e-07 - dense_58_loss: 4.8381e-07 - val_loss: 8.3804e-07 - val_dense_57_loss: 3.4076e-07 - val_dense_58_loss: 4.9728e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.9765e-07 - dense_57_loss: 3.3227e-07 - dense_58_loss: 4.6538e-07 - val_loss: 8.3496e-07 - val_dense_57_loss: 3.4545e-07 - val_dense_58_loss: 4.8951e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8349e-07 - dense_57_loss: 3.2702e-07 - dense_58_loss: 4.5647e-07 - val_loss: 8.1815e-07 - val_dense_57_loss: 3.3406e-07 - val_dense_58_loss: 4.8410e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.7484e-07 - dense_57_loss: 3.2500e-07 - dense_58_loss: 4.4984e-07 - val_loss: 8.4538e-07 - val_dense_57_loss: 3.4471e-07 - val_dense_58_loss: 5.0067e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9576e-07 - dense_57_loss: 3.3204e-07 - dense_58_loss: 4.6372e-07 - val_loss: 8.1730e-07 - val_dense_57_loss: 3.3261e-07 - val_dense_58_loss: 4.8469e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6143e-07 - dense_57_loss: 3.2004e-07 - dense_58_loss: 4.4139e-07 - val_loss: 8.3213e-07 - val_dense_57_loss: 3.3685e-07 - val_dense_58_loss: 4.9528e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6790e-07 - dense_57_loss: 3.2486e-07 - dense_58_loss: 4.4305e-07 - val_loss: 8.0225e-07 - val_dense_57_loss: 3.3213e-07 - val_dense_58_loss: 4.7012e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.5827e-07 - dense_57_loss: 3.2160e-07 - dense_58_loss: 4.3667e-07 - val_loss: 8.1703e-07 - val_dense_57_loss: 3.4944e-07 - val_dense_58_loss: 4.6759e-07\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6675e-07 - dense_57_loss: 3.2922e-07 - dense_58_loss: 4.3753e-07 - val_loss: 8.0698e-07 - val_dense_57_loss: 3.3520e-07 - val_dense_58_loss: 4.7179e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8376e-07 - dense_57_loss: 3.3096e-07 - dense_58_loss: 4.5280e-07 - val_loss: 9.3587e-07 - val_dense_57_loss: 3.4259e-07 - val_dense_58_loss: 5.9328e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1373e-07 - dense_57_loss: 3.4436e-07 - dense_58_loss: 4.6937e-07 - val_loss: 8.0862e-07 - val_dense_57_loss: 3.4181e-07 - val_dense_58_loss: 4.6680e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6377e-07 - dense_57_loss: 3.3362e-07 - dense_58_loss: 4.3016e-07 - val_loss: 8.2169e-07 - val_dense_57_loss: 3.4508e-07 - val_dense_58_loss: 4.7661e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.8779e-07 - dense_57_loss: 3.5003e-07 - dense_58_loss: 4.3776e-07 - val_loss: 8.1747e-07 - val_dense_57_loss: 3.5143e-07 - val_dense_58_loss: 4.6604e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5533e-07 - dense_57_loss: 3.3402e-07 - dense_58_loss: 4.2131e-07 - val_loss: 7.9199e-07 - val_dense_57_loss: 3.3995e-07 - val_dense_58_loss: 4.5204e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3818e-07 - dense_57_loss: 3.2183e-07 - dense_58_loss: 4.1635e-07 - val_loss: 8.0215e-07 - val_dense_57_loss: 3.3898e-07 - val_dense_58_loss: 4.6318e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6131e-07 - dense_57_loss: 3.2785e-07 - dense_58_loss: 4.3347e-07 - val_loss: 8.2154e-07 - val_dense_57_loss: 3.5388e-07 - val_dense_58_loss: 4.6766e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5584e-07 - dense_57_loss: 3.3681e-07 - dense_58_loss: 4.1904e-07 - val_loss: 8.2183e-07 - val_dense_57_loss: 3.6628e-07 - val_dense_58_loss: 4.5555e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5869e-07 - dense_57_loss: 3.3819e-07 - dense_58_loss: 4.2050e-07 - val_loss: 9.0955e-07 - val_dense_57_loss: 3.8614e-07 - val_dense_58_loss: 5.2341e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4239e-07 - dense_57_loss: 3.6956e-07 - dense_58_loss: 4.7284e-07 - val_loss: 8.4607e-07 - val_dense_57_loss: 3.6387e-07 - val_dense_58_loss: 4.8220e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6436e-07 - dense_57_loss: 3.3668e-07 - dense_58_loss: 4.2768e-07 - val_loss: 7.7598e-07 - val_dense_57_loss: 3.4328e-07 - val_dense_58_loss: 4.3270e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5195e-07 - dense_57_loss: 3.3809e-07 - dense_58_loss: 4.1386e-07 - val_loss: 8.8116e-07 - val_dense_57_loss: 4.3113e-07 - val_dense_58_loss: 4.5004e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "\n",
      "Now training model 8/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 0.0011 - dense_64_loss: 7.1259e-04 - dense_65_loss: 3.5679e-04 - val_loss: 8.4425e-05 - val_dense_64_loss: 3.6160e-05 - val_dense_65_loss: 4.8265e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.9248e-05 - dense_64_loss: 2.2040e-05 - dense_65_loss: 1.7208e-05 - val_loss: 1.2941e-05 - val_dense_64_loss: 8.4584e-06 - val_dense_65_loss: 4.4824e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0859e-05 - dense_64_loss: 8.2880e-06 - dense_65_loss: 2.5706e-06 - val_loss: 6.5881e-06 - val_dense_64_loss: 5.3608e-06 - val_dense_65_loss: 1.2273e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6967e-06 - dense_64_loss: 6.7155e-06 - dense_65_loss: 9.8118e-07 - val_loss: 5.7815e-06 - val_dense_64_loss: 5.0250e-06 - val_dense_65_loss: 7.5658e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1914e-06 - dense_64_loss: 6.4272e-06 - dense_65_loss: 7.6417e-07 - val_loss: 5.6831e-06 - val_dense_64_loss: 4.9423e-06 - val_dense_65_loss: 7.4084e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0846e-06 - dense_64_loss: 6.3241e-06 - dense_65_loss: 7.6053e-07 - val_loss: 5.6204e-06 - val_dense_64_loss: 4.8808e-06 - val_dense_65_loss: 7.3965e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.9753e-06 - dense_64_loss: 6.2034e-06 - dense_65_loss: 7.7188e-07 - val_loss: 5.5390e-06 - val_dense_64_loss: 4.7648e-06 - val_dense_65_loss: 7.7421e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8847e-06 - dense_64_loss: 6.1014e-06 - dense_65_loss: 7.8327e-07 - val_loss: 5.4496e-06 - val_dense_64_loss: 4.6769e-06 - val_dense_65_loss: 7.7275e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7635e-06 - dense_64_loss: 5.9553e-06 - dense_65_loss: 8.0819e-07 - val_loss: 5.3512e-06 - val_dense_64_loss: 4.5745e-06 - val_dense_65_loss: 7.7674e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6070e-06 - dense_64_loss: 5.7745e-06 - dense_65_loss: 8.3254e-07 - val_loss: 5.4052e-06 - val_dense_64_loss: 4.6027e-06 - val_dense_65_loss: 8.0254e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.4508e-06 - dense_64_loss: 5.5284e-06 - dense_65_loss: 9.2248e-07 - val_loss: 4.9420e-06 - val_dense_64_loss: 4.0824e-06 - val_dense_65_loss: 8.5959e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0684e-06 - dense_64_loss: 5.1114e-06 - dense_65_loss: 9.5698e-07 - val_loss: 4.6930e-06 - val_dense_64_loss: 3.7978e-06 - val_dense_65_loss: 8.9521e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5703e-06 - dense_64_loss: 4.5929e-06 - dense_65_loss: 9.7744e-07 - val_loss: 4.2576e-06 - val_dense_64_loss: 3.3418e-06 - val_dense_65_loss: 9.1574e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0204e-06 - dense_64_loss: 4.0055e-06 - dense_65_loss: 1.0150e-06 - val_loss: 3.7931e-06 - val_dense_64_loss: 2.8597e-06 - val_dense_65_loss: 9.3334e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.4458e-06 - dense_64_loss: 3.3563e-06 - dense_65_loss: 1.0895e-06 - val_loss: 3.6693e-06 - val_dense_64_loss: 2.4719e-06 - val_dense_65_loss: 1.1974e-06\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.7020e-06 - dense_64_loss: 2.5599e-06 - dense_65_loss: 1.1421e-06 - val_loss: 2.7098e-06 - val_dense_64_loss: 1.7296e-06 - val_dense_65_loss: 9.8022e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.7630e-06 - dense_64_loss: 1.7513e-06 - dense_65_loss: 1.0117e-06 - val_loss: 2.1746e-06 - val_dense_64_loss: 1.2991e-06 - val_dense_65_loss: 8.7550e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9634e-06 - dense_64_loss: 1.0847e-06 - dense_65_loss: 8.7877e-07 - val_loss: 1.5003e-06 - val_dense_64_loss: 7.4222e-07 - val_dense_65_loss: 7.5805e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4333e-06 - dense_64_loss: 6.7565e-07 - dense_65_loss: 7.5760e-07 - val_loss: 1.2378e-06 - val_dense_64_loss: 5.3785e-07 - val_dense_65_loss: 6.9994e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1602e-06 - dense_64_loss: 5.0134e-07 - dense_65_loss: 6.5887e-07 - val_loss: 1.1208e-06 - val_dense_64_loss: 4.8428e-07 - val_dense_65_loss: 6.3657e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0730e-06 - dense_64_loss: 4.5965e-07 - dense_65_loss: 6.1338e-07 - val_loss: 1.0677e-06 - val_dense_64_loss: 4.5104e-07 - val_dense_65_loss: 6.1666e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0410e-06 - dense_64_loss: 4.5556e-07 - dense_65_loss: 5.8545e-07 - val_loss: 1.0448e-06 - val_dense_64_loss: 4.4694e-07 - val_dense_65_loss: 5.9782e-07\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8408e-07 - dense_64_loss: 4.2092e-07 - dense_65_loss: 5.6316e-07 - val_loss: 1.0535e-06 - val_dense_64_loss: 4.4715e-07 - val_dense_65_loss: 6.0637e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0198e-06 - dense_64_loss: 4.3905e-07 - dense_65_loss: 5.8073e-07 - val_loss: 1.0067e-06 - val_dense_64_loss: 4.2342e-07 - val_dense_65_loss: 5.8329e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7970e-07 - dense_64_loss: 4.1683e-07 - dense_65_loss: 5.6287e-07 - val_loss: 1.0613e-06 - val_dense_64_loss: 4.4429e-07 - val_dense_65_loss: 6.1704e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8038e-07 - dense_64_loss: 4.2257e-07 - dense_65_loss: 5.5781e-07 - val_loss: 1.0257e-06 - val_dense_64_loss: 4.4042e-07 - val_dense_65_loss: 5.8527e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.7487e-07 - dense_64_loss: 4.1861e-07 - dense_65_loss: 5.5625e-07 - val_loss: 1.0573e-06 - val_dense_64_loss: 4.8223e-07 - val_dense_65_loss: 5.7504e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6431e-07 - dense_64_loss: 4.2330e-07 - dense_65_loss: 5.4100e-07 - val_loss: 1.0490e-06 - val_dense_64_loss: 4.8418e-07 - val_dense_65_loss: 5.6481e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5628e-07 - dense_64_loss: 4.2186e-07 - dense_65_loss: 5.3442e-07 - val_loss: 1.0401e-06 - val_dense_64_loss: 4.1802e-07 - val_dense_65_loss: 6.2205e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7357e-07 - dense_64_loss: 4.2063e-07 - dense_65_loss: 5.5293e-07 - val_loss: 1.0278e-06 - val_dense_64_loss: 4.5220e-07 - val_dense_65_loss: 5.7555e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.4017e-07 - dense_64_loss: 4.1162e-07 - dense_65_loss: 5.2855e-07 - val_loss: 1.0809e-06 - val_dense_64_loss: 4.5266e-07 - val_dense_65_loss: 6.2827e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7942e-07 - dense_64_loss: 4.2878e-07 - dense_65_loss: 5.5064e-07 - val_loss: 9.8280e-07 - val_dense_64_loss: 4.3670e-07 - val_dense_65_loss: 5.4609e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3999e-07 - dense_64_loss: 4.1587e-07 - dense_65_loss: 5.2412e-07 - val_loss: 1.0037e-06 - val_dense_64_loss: 4.4269e-07 - val_dense_65_loss: 5.6097e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.2131e-07 - dense_64_loss: 4.1390e-07 - dense_65_loss: 5.0741e-07 - val_loss: 1.0503e-06 - val_dense_64_loss: 4.5485e-07 - val_dense_65_loss: 5.9540e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2637e-07 - dense_64_loss: 4.1460e-07 - dense_65_loss: 5.1177e-07 - val_loss: 1.2470e-06 - val_dense_64_loss: 4.3174e-07 - val_dense_65_loss: 8.1526e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0414e-06 - dense_64_loss: 4.5365e-07 - dense_65_loss: 5.8778e-07 - val_loss: 1.1331e-06 - val_dense_64_loss: 5.7206e-07 - val_dense_65_loss: 5.6100e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3155e-07 - dense_64_loss: 4.3514e-07 - dense_65_loss: 4.9640e-07 - val_loss: 9.5635e-07 - val_dense_64_loss: 4.4144e-07 - val_dense_65_loss: 5.1491e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.0270e-07 - dense_64_loss: 4.2253e-07 - dense_65_loss: 4.8018e-07 - val_loss: 9.7204e-07 - val_dense_64_loss: 4.6142e-07 - val_dense_65_loss: 5.1063e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.0740e-07 - dense_64_loss: 4.1856e-07 - dense_65_loss: 4.8884e-07 - val_loss: 1.0021e-06 - val_dense_64_loss: 4.6173e-07 - val_dense_65_loss: 5.4038e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3091e-07 - dense_64_loss: 4.3539e-07 - dense_65_loss: 4.9552e-07 - val_loss: 9.9149e-07 - val_dense_64_loss: 4.6679e-07 - val_dense_65_loss: 5.2470e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1960e-07 - dense_64_loss: 4.2414e-07 - dense_65_loss: 4.9546e-07 - val_loss: 1.0692e-06 - val_dense_64_loss: 4.7976e-07 - val_dense_65_loss: 5.8943e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.1436e-07 - dense_64_loss: 4.2452e-07 - dense_65_loss: 4.8984e-07 - val_loss: 9.7022e-07 - val_dense_64_loss: 4.3756e-07 - val_dense_65_loss: 5.3266e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.6777e-07 - dense_64_loss: 4.1962e-07 - dense_65_loss: 4.4815e-07 - val_loss: 1.0657e-06 - val_dense_64_loss: 5.1102e-07 - val_dense_65_loss: 5.5467e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9176e-07 - dense_64_loss: 4.4036e-07 - dense_65_loss: 4.5139e-07 - val_loss: 9.2145e-07 - val_dense_64_loss: 4.3316e-07 - val_dense_65_loss: 4.8828e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "\n",
      "Now training model 9/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 8.3614e-04 - dense_71_loss: 5.6165e-04 - dense_72_loss: 2.7449e-04 - val_loss: 5.3576e-05 - val_dense_71_loss: 2.1133e-05 - val_dense_72_loss: 3.2443e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.3307e-05 - dense_71_loss: 1.9442e-05 - dense_72_loss: 1.3865e-05 - val_loss: 1.0659e-05 - val_dense_71_loss: 7.2843e-06 - val_dense_72_loss: 3.3743e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0087e-06 - dense_71_loss: 7.0084e-06 - dense_72_loss: 2.0003e-06 - val_loss: 5.8839e-06 - val_dense_71_loss: 4.7616e-06 - val_dense_72_loss: 1.1223e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6773e-06 - dense_71_loss: 5.7523e-06 - dense_72_loss: 9.2501e-07 - val_loss: 5.0354e-06 - val_dense_71_loss: 4.2489e-06 - val_dense_72_loss: 7.8645e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3252e-06 - dense_71_loss: 5.5236e-06 - dense_72_loss: 8.0162e-07 - val_loss: 4.8820e-06 - val_dense_71_loss: 4.1403e-06 - val_dense_72_loss: 7.4176e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2061e-06 - dense_71_loss: 5.4022e-06 - dense_72_loss: 8.0398e-07 - val_loss: 4.8060e-06 - val_dense_71_loss: 3.9955e-06 - val_dense_72_loss: 8.1041e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9810e-06 - dense_71_loss: 5.1600e-06 - dense_72_loss: 8.2093e-07 - val_loss: 4.6208e-06 - val_dense_71_loss: 3.8573e-06 - val_dense_72_loss: 7.6347e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7179e-06 - dense_71_loss: 4.8867e-06 - dense_72_loss: 8.3121e-07 - val_loss: 4.3951e-06 - val_dense_71_loss: 3.5874e-06 - val_dense_72_loss: 8.0777e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.4231e-06 - dense_71_loss: 4.5250e-06 - dense_72_loss: 8.9813e-07 - val_loss: 4.2789e-06 - val_dense_71_loss: 3.3417e-06 - val_dense_72_loss: 9.3723e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9963e-06 - dense_71_loss: 4.0236e-06 - dense_72_loss: 9.7272e-07 - val_loss: 3.6260e-06 - val_dense_71_loss: 2.7727e-06 - val_dense_72_loss: 8.5337e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.2893e-06 - dense_71_loss: 3.2681e-06 - dense_72_loss: 1.0213e-06 - val_loss: 3.1865e-06 - val_dense_71_loss: 2.2673e-06 - val_dense_72_loss: 9.1921e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.5807e-06 - dense_71_loss: 2.5414e-06 - dense_72_loss: 1.0393e-06 - val_loss: 2.5741e-06 - val_dense_71_loss: 1.6589e-06 - val_dense_72_loss: 9.1523e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.9121e-06 - dense_71_loss: 1.8455e-06 - dense_72_loss: 1.0666e-06 - val_loss: 2.1795e-06 - val_dense_71_loss: 1.2693e-06 - val_dense_72_loss: 9.1024e-07\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2209e-06 - dense_71_loss: 1.2126e-06 - dense_72_loss: 1.0083e-06 - val_loss: 1.6998e-06 - val_dense_71_loss: 8.2694e-07 - val_dense_72_loss: 8.7290e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6760e-06 - dense_71_loss: 8.0397e-07 - dense_72_loss: 8.7201e-07 - val_loss: 1.3371e-06 - val_dense_71_loss: 5.8862e-07 - val_dense_72_loss: 7.4853e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3081e-06 - dense_71_loss: 5.8017e-07 - dense_72_loss: 7.2791e-07 - val_loss: 1.1195e-06 - val_dense_71_loss: 4.8583e-07 - val_dense_72_loss: 6.3366e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0986e-06 - dense_71_loss: 4.8307e-07 - dense_72_loss: 6.1554e-07 - val_loss: 1.0459e-06 - val_dense_71_loss: 4.4441e-07 - val_dense_72_loss: 6.0151e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0189e-06 - dense_71_loss: 4.3772e-07 - dense_72_loss: 5.8114e-07 - val_loss: 9.7995e-07 - val_dense_71_loss: 4.2888e-07 - val_dense_72_loss: 5.5107e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.3437e-07 - dense_71_loss: 4.1500e-07 - dense_72_loss: 5.1937e-07 - val_loss: 9.3936e-07 - val_dense_71_loss: 4.0582e-07 - val_dense_72_loss: 5.3354e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.0718e-07 - dense_71_loss: 4.0410e-07 - dense_72_loss: 5.0308e-07 - val_loss: 1.0083e-06 - val_dense_71_loss: 4.8503e-07 - val_dense_72_loss: 5.2331e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1069e-07 - dense_71_loss: 4.1814e-07 - dense_72_loss: 4.9255e-07 - val_loss: 1.0341e-06 - val_dense_71_loss: 4.4600e-07 - val_dense_72_loss: 5.8807e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5121e-07 - dense_71_loss: 4.2578e-07 - dense_72_loss: 5.2543e-07 - val_loss: 9.6487e-07 - val_dense_71_loss: 4.1795e-07 - val_dense_72_loss: 5.4692e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.9168e-07 - dense_71_loss: 3.9292e-07 - dense_72_loss: 4.9876e-07 - val_loss: 9.6546e-07 - val_dense_71_loss: 4.3556e-07 - val_dense_72_loss: 5.2990e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9850e-07 - dense_71_loss: 4.1476e-07 - dense_72_loss: 4.8374e-07 - val_loss: 9.5303e-07 - val_dense_71_loss: 4.1610e-07 - val_dense_72_loss: 5.3694e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2423e-07 - dense_71_loss: 4.3084e-07 - dense_72_loss: 4.9339e-07 - val_loss: 9.3369e-07 - val_dense_71_loss: 4.1165e-07 - val_dense_72_loss: 5.2204e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8608e-07 - dense_71_loss: 4.0554e-07 - dense_72_loss: 4.8055e-07 - val_loss: 8.8583e-07 - val_dense_71_loss: 3.9404e-07 - val_dense_72_loss: 4.9179e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.4344e-07 - dense_71_loss: 3.8545e-07 - dense_72_loss: 4.5799e-07 - val_loss: 9.9198e-07 - val_dense_71_loss: 4.5828e-07 - val_dense_72_loss: 5.3369e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.9923e-07 - dense_71_loss: 4.2177e-07 - dense_72_loss: 4.7746e-07 - val_loss: 9.0396e-07 - val_dense_71_loss: 4.1211e-07 - val_dense_72_loss: 4.9185e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3737e-07 - dense_71_loss: 3.8580e-07 - dense_72_loss: 4.5157e-07 - val_loss: 8.9129e-07 - val_dense_71_loss: 4.1432e-07 - val_dense_72_loss: 4.7697e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.3952e-07 - dense_71_loss: 3.8724e-07 - dense_72_loss: 4.5228e-07 - val_loss: 9.2157e-07 - val_dense_71_loss: 4.4233e-07 - val_dense_72_loss: 4.7924e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.2685e-07 - dense_71_loss: 3.9164e-07 - dense_72_loss: 4.3522e-07 - val_loss: 9.5975e-07 - val_dense_71_loss: 4.0240e-07 - val_dense_72_loss: 5.5735e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.5005e-07 - dense_71_loss: 4.0167e-07 - dense_72_loss: 4.4838e-07 - val_loss: 9.0379e-07 - val_dense_71_loss: 4.1221e-07 - val_dense_72_loss: 4.9159e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2029e-07 - dense_71_loss: 3.8547e-07 - dense_72_loss: 4.3482e-07 - val_loss: 8.8435e-07 - val_dense_71_loss: 4.0984e-07 - val_dense_72_loss: 4.7452e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.1566e-07 - dense_71_loss: 3.8984e-07 - dense_72_loss: 4.2581e-07 - val_loss: 9.1240e-07 - val_dense_71_loss: 4.7490e-07 - val_dense_72_loss: 4.3750e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.1577e-07 - dense_71_loss: 4.0242e-07 - dense_72_loss: 4.1336e-07 - val_loss: 9.2611e-07 - val_dense_71_loss: 4.7161e-07 - val_dense_72_loss: 4.5450e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.0660e-07 - dense_71_loss: 3.8977e-07 - dense_72_loss: 4.1683e-07 - val_loss: 8.6044e-07 - val_dense_71_loss: 4.1897e-07 - val_dense_72_loss: 4.4146e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9289e-07 - dense_71_loss: 3.9224e-07 - dense_72_loss: 4.0064e-07 - val_loss: 8.5261e-07 - val_dense_71_loss: 4.0493e-07 - val_dense_72_loss: 4.4768e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.4860e-07 - dense_71_loss: 4.5199e-07 - dense_72_loss: 3.9661e-07 - val_loss: 9.5872e-07 - val_dense_71_loss: 4.7243e-07 - val_dense_72_loss: 4.8629e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6103e-07 - dense_71_loss: 5.4532e-07 - dense_72_loss: 4.1571e-07 - val_loss: 1.0313e-06 - val_dense_71_loss: 4.3286e-07 - val_dense_72_loss: 5.9843e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4098e-07 - dense_71_loss: 4.1159e-07 - dense_72_loss: 4.2939e-07 - val_loss: 8.5322e-07 - val_dense_71_loss: 4.3908e-07 - val_dense_72_loss: 4.1414e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6743e-07 - dense_71_loss: 3.9238e-07 - dense_72_loss: 3.7505e-07 - val_loss: 7.6029e-07 - val_dense_71_loss: 3.7248e-07 - val_dense_72_loss: 3.8781e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.3263e-07 - dense_71_loss: 3.7285e-07 - dense_72_loss: 3.5977e-07 - val_loss: 1.0207e-06 - val_dense_71_loss: 4.6130e-07 - val_dense_72_loss: 5.5944e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.8352e-07 - dense_71_loss: 4.0513e-07 - dense_72_loss: 3.7839e-07 - val_loss: 9.6239e-07 - val_dense_71_loss: 4.6054e-07 - val_dense_72_loss: 5.0185e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.3967e-07 - dense_71_loss: 4.6059e-07 - dense_72_loss: 3.7908e-07 - val_loss: 7.9894e-07 - val_dense_71_loss: 4.3079e-07 - val_dense_72_loss: 3.6815e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5026e-07 - dense_71_loss: 4.1528e-07 - dense_72_loss: 3.3499e-07 - val_loss: 9.0834e-07 - val_dense_71_loss: 4.7071e-07 - val_dense_72_loss: 4.3763e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9050e-07 - dense_71_loss: 4.5375e-07 - dense_72_loss: 3.3676e-07 - val_loss: 7.5282e-07 - val_dense_71_loss: 3.8194e-07 - val_dense_72_loss: 3.7088e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.6683e-07 - dense_71_loss: 3.5557e-07 - dense_72_loss: 3.1126e-07 - val_loss: 9.2815e-07 - val_dense_71_loss: 3.9724e-07 - val_dense_72_loss: 5.3090e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.3027e-07 - dense_71_loss: 4.8005e-07 - dense_72_loss: 3.5022e-07 - val_loss: 8.0026e-07 - val_dense_71_loss: 4.4908e-07 - val_dense_72_loss: 3.5117e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5773e-07 - dense_71_loss: 4.4379e-07 - dense_72_loss: 3.1394e-07 - val_loss: 7.7411e-07 - val_dense_71_loss: 4.2813e-07 - val_dense_72_loss: 3.4598e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1880e-07 - dense_71_loss: 4.1710e-07 - dense_72_loss: 3.0170e-07 - val_loss: 9.8541e-07 - val_dense_71_loss: 6.1812e-07 - val_dense_72_loss: 3.6729e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2700e-07 - dense_71_loss: 4.2724e-07 - dense_72_loss: 2.9976e-07 - val_loss: 7.6038e-07 - val_dense_71_loss: 4.2340e-07 - val_dense_72_loss: 3.3699e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7331e-07 - dense_71_loss: 3.9101e-07 - dense_72_loss: 2.8230e-07 - val_loss: 9.2520e-07 - val_dense_71_loss: 5.1747e-07 - val_dense_72_loss: 4.0773e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3773e-07 - dense_71_loss: 4.5809e-07 - dense_72_loss: 2.7964e-07 - val_loss: 8.1557e-07 - val_dense_71_loss: 4.8223e-07 - val_dense_72_loss: 3.3334e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9182e-07 - dense_71_loss: 4.0939e-07 - dense_72_loss: 2.8244e-07 - val_loss: 7.3878e-07 - val_dense_71_loss: 4.4219e-07 - val_dense_72_loss: 2.9659e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4924e-07 - dense_71_loss: 3.8589e-07 - dense_72_loss: 2.6335e-07 - val_loss: 6.5877e-07 - val_dense_71_loss: 3.8876e-07 - val_dense_72_loss: 2.7001e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1785e-07 - dense_71_loss: 3.6921e-07 - dense_72_loss: 2.4864e-07 - val_loss: 7.3429e-07 - val_dense_71_loss: 4.1814e-07 - val_dense_72_loss: 3.1616e-07\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1659e-07 - dense_71_loss: 3.6673e-07 - dense_72_loss: 2.4986e-07 - val_loss: 6.9539e-07 - val_dense_71_loss: 3.8108e-07 - val_dense_72_loss: 3.1431e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.6598e-07 - dense_71_loss: 3.4326e-07 - dense_72_loss: 2.2272e-07 - val_loss: 6.4551e-07 - val_dense_71_loss: 3.7755e-07 - val_dense_72_loss: 2.6796e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6591e-07 - dense_71_loss: 3.4320e-07 - dense_72_loss: 2.2271e-07 - val_loss: 6.2365e-07 - val_dense_71_loss: 3.6260e-07 - val_dense_72_loss: 2.6106e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.0390e-07 - dense_71_loss: 3.7197e-07 - dense_72_loss: 2.3193e-07 - val_loss: 1.1480e-06 - val_dense_71_loss: 5.1548e-07 - val_dense_72_loss: 6.3251e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5963e-07 - dense_71_loss: 5.5036e-07 - dense_72_loss: 3.0927e-07 - val_loss: 7.5313e-07 - val_dense_71_loss: 4.5651e-07 - val_dense_72_loss: 2.9662e-07\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1199e-07 - dense_71_loss: 3.7158e-07 - dense_72_loss: 2.4041e-07 - val_loss: 7.6222e-07 - val_dense_71_loss: 4.3831e-07 - val_dense_72_loss: 3.2391e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9451e-07 - dense_71_loss: 3.7056e-07 - dense_72_loss: 2.2394e-07 - val_loss: 7.4993e-07 - val_dense_71_loss: 3.9281e-07 - val_dense_72_loss: 3.5711e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.8061e-07 - dense_71_loss: 3.8538e-07 - dense_72_loss: 1.9523e-07 - val_loss: 6.1969e-07 - val_dense_71_loss: 4.1935e-07 - val_dense_72_loss: 2.0034e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1845e-07 - dense_71_loss: 3.8867e-07 - dense_72_loss: 2.2978e-07 - val_loss: 6.5630e-07 - val_dense_71_loss: 4.4909e-07 - val_dense_72_loss: 2.0721e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3829e-07 - dense_71_loss: 3.5244e-07 - dense_72_loss: 1.8586e-07 - val_loss: 9.9798e-07 - val_dense_71_loss: 4.5784e-07 - val_dense_72_loss: 5.4014e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9374e-07 - dense_71_loss: 4.3085e-07 - dense_72_loss: 2.6289e-07 - val_loss: 5.8116e-07 - val_dense_71_loss: 3.8632e-07 - val_dense_72_loss: 1.9484e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.3703e-07 - dense_71_loss: 3.5334e-07 - dense_72_loss: 1.8369e-07 - val_loss: 5.7854e-07 - val_dense_71_loss: 4.0089e-07 - val_dense_72_loss: 1.7765e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5628e-07 - dense_71_loss: 3.6126e-07 - dense_72_loss: 1.9501e-07 - val_loss: 8.1486e-07 - val_dense_71_loss: 5.0232e-07 - val_dense_72_loss: 3.1254e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0301e-07 - dense_71_loss: 4.0289e-07 - dense_72_loss: 2.0012e-07 - val_loss: 5.5342e-07 - val_dense_71_loss: 4.0064e-07 - val_dense_72_loss: 1.5278e-07\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2829e-07 - dense_71_loss: 3.7883e-07 - dense_72_loss: 1.4946e-07 - val_loss: 6.1712e-07 - val_dense_71_loss: 4.5066e-07 - val_dense_72_loss: 1.6646e-07\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7893e-07 - dense_71_loss: 3.4275e-07 - dense_72_loss: 1.3618e-07 - val_loss: 8.9422e-07 - val_dense_71_loss: 3.9431e-07 - val_dense_72_loss: 4.9992e-07\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5892e-07 - dense_71_loss: 4.2023e-07 - dense_72_loss: 2.3869e-07 - val_loss: 5.7391e-07 - val_dense_71_loss: 4.1768e-07 - val_dense_72_loss: 1.5624e-07\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9530e-07 - dense_71_loss: 3.4887e-07 - dense_72_loss: 1.4643e-07 - val_loss: 5.7621e-07 - val_dense_71_loss: 3.4677e-07 - val_dense_72_loss: 2.2943e-07\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2582e-07 - dense_71_loss: 3.5654e-07 - dense_72_loss: 1.6928e-07 - val_loss: 6.0772e-07 - val_dense_71_loss: 4.3846e-07 - val_dense_72_loss: 1.6926e-07\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7184e-07 - dense_71_loss: 3.3987e-07 - dense_72_loss: 1.3197e-07 - val_loss: 5.2229e-07 - val_dense_71_loss: 3.7107e-07 - val_dense_72_loss: 1.5122e-07\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6624e-07 - dense_71_loss: 3.3276e-07 - dense_72_loss: 1.3348e-07 - val_loss: 6.7851e-07 - val_dense_71_loss: 5.4546e-07 - val_dense_72_loss: 1.3306e-07\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.4051e-07 - dense_71_loss: 4.0568e-07 - dense_72_loss: 1.3483e-07 - val_loss: 5.4015e-07 - val_dense_71_loss: 3.6360e-07 - val_dense_72_loss: 1.7655e-07\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3146e-07 - dense_71_loss: 3.8989e-07 - dense_72_loss: 1.4157e-07 - val_loss: 6.0106e-07 - val_dense_71_loss: 4.2508e-07 - val_dense_72_loss: 1.7599e-07\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0108e-07 - dense_71_loss: 3.5554e-07 - dense_72_loss: 1.4554e-07 - val_loss: 5.3703e-07 - val_dense_71_loss: 4.2233e-07 - val_dense_72_loss: 1.1470e-07\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5886e-07 - dense_71_loss: 3.9176e-07 - dense_72_loss: 1.6710e-07 - val_loss: 8.0597e-07 - val_dense_71_loss: 4.7401e-07 - val_dense_72_loss: 3.3196e-07\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1031e-07 - dense_71_loss: 4.5025e-07 - dense_72_loss: 1.6006e-07 - val_loss: 5.0534e-07 - val_dense_71_loss: 3.8310e-07 - val_dense_72_loss: 1.2224e-07\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.8242e-07 - dense_71_loss: 3.5374e-07 - dense_72_loss: 1.2868e-07 - val_loss: 5.1652e-07 - val_dense_71_loss: 3.9155e-07 - val_dense_72_loss: 1.2497e-07\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6722e-07 - dense_71_loss: 3.4633e-07 - dense_72_loss: 1.2089e-07 - val_loss: 4.9768e-07 - val_dense_71_loss: 3.7966e-07 - val_dense_72_loss: 1.1802e-07\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6517e-07 - dense_71_loss: 3.4268e-07 - dense_72_loss: 1.2249e-07 - val_loss: 5.6167e-07 - val_dense_71_loss: 3.9250e-07 - val_dense_72_loss: 1.6918e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4733e-07 - dense_71_loss: 3.2866e-07 - dense_72_loss: 1.1867e-07 - val_loss: 5.1328e-07 - val_dense_71_loss: 3.7106e-07 - val_dense_72_loss: 1.4222e-07\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0556e-07 - dense_71_loss: 3.7461e-07 - dense_72_loss: 2.3095e-07 - val_loss: 6.4152e-07 - val_dense_71_loss: 4.7288e-07 - val_dense_72_loss: 1.6863e-07\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0249e-07 - dense_71_loss: 3.7970e-07 - dense_72_loss: 1.2279e-07 - val_loss: 6.0631e-07 - val_dense_71_loss: 4.1691e-07 - val_dense_72_loss: 1.8940e-07\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9662e-07 - dense_71_loss: 3.3924e-07 - dense_72_loss: 1.5738e-07 - val_loss: 5.3031e-07 - val_dense_71_loss: 3.9019e-07 - val_dense_72_loss: 1.4012e-07\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4562e-07 - dense_71_loss: 3.3714e-07 - dense_72_loss: 1.0848e-07 - val_loss: 5.2470e-07 - val_dense_71_loss: 3.9531e-07 - val_dense_72_loss: 1.2939e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "\n",
      "Now training model 10/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 7.7081e-04 - dense_78_loss: 4.8223e-04 - dense_79_loss: 2.8858e-04 - val_loss: 6.3947e-05 - val_dense_78_loss: 2.5519e-05 - val_dense_79_loss: 3.8428e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.4222e-05 - dense_78_loss: 1.6498e-05 - dense_79_loss: 1.7724e-05 - val_loss: 1.2131e-05 - val_dense_78_loss: 8.4155e-06 - val_dense_79_loss: 3.7154e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4012e-06 - dense_78_loss: 6.3065e-06 - dense_79_loss: 2.0948e-06 - val_loss: 5.4914e-06 - val_dense_78_loss: 4.2465e-06 - val_dense_79_loss: 1.2449e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7943e-06 - dense_78_loss: 4.9188e-06 - dense_79_loss: 8.7554e-07 - val_loss: 4.3768e-06 - val_dense_78_loss: 3.6504e-06 - val_dense_79_loss: 7.2636e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3764e-06 - dense_78_loss: 4.6688e-06 - dense_79_loss: 7.0760e-07 - val_loss: 4.6650e-06 - val_dense_78_loss: 3.9639e-06 - val_dense_79_loss: 7.0109e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3608e-06 - dense_78_loss: 4.6399e-06 - dense_79_loss: 7.2087e-07 - val_loss: 4.4816e-06 - val_dense_78_loss: 3.7424e-06 - val_dense_79_loss: 7.3918e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2722e-06 - dense_78_loss: 4.5449e-06 - dense_79_loss: 7.2727e-07 - val_loss: 4.2504e-06 - val_dense_78_loss: 3.5145e-06 - val_dense_79_loss: 7.3585e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.2542e-06 - dense_78_loss: 4.4980e-06 - dense_79_loss: 7.5613e-07 - val_loss: 4.0619e-06 - val_dense_78_loss: 3.3445e-06 - val_dense_79_loss: 7.1742e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0436e-06 - dense_78_loss: 4.3296e-06 - dense_79_loss: 7.1400e-07 - val_loss: 3.9715e-06 - val_dense_78_loss: 3.2327e-06 - val_dense_79_loss: 7.3883e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9155e-06 - dense_78_loss: 4.1868e-06 - dense_79_loss: 7.2870e-07 - val_loss: 3.9237e-06 - val_dense_78_loss: 3.1929e-06 - val_dense_79_loss: 7.3078e-07\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.8271e-06 - dense_78_loss: 4.0814e-06 - dense_79_loss: 7.4571e-07 - val_loss: 3.8064e-06 - val_dense_78_loss: 3.0462e-06 - val_dense_79_loss: 7.6023e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6910e-06 - dense_78_loss: 3.9184e-06 - dense_79_loss: 7.7260e-07 - val_loss: 4.6780e-06 - val_dense_78_loss: 3.8460e-06 - val_dense_79_loss: 8.3199e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.1615e-06 - dense_78_loss: 4.1532e-06 - dense_79_loss: 1.0083e-06 - val_loss: 3.6217e-06 - val_dense_78_loss: 2.7959e-06 - val_dense_79_loss: 8.2577e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.2533e-06 - dense_78_loss: 3.4077e-06 - dense_79_loss: 8.4555e-07 - val_loss: 3.4235e-06 - val_dense_78_loss: 2.6184e-06 - val_dense_79_loss: 8.0506e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.9267e-06 - dense_78_loss: 3.0778e-06 - dense_79_loss: 8.4889e-07 - val_loss: 3.0649e-06 - val_dense_78_loss: 2.2510e-06 - val_dense_79_loss: 8.1389e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.5468e-06 - dense_78_loss: 2.7181e-06 - dense_79_loss: 8.2871e-07 - val_loss: 2.7531e-06 - val_dense_78_loss: 1.9589e-06 - val_dense_79_loss: 7.9422e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.1514e-06 - dense_78_loss: 2.3181e-06 - dense_79_loss: 8.3323e-07 - val_loss: 2.6348e-06 - val_dense_78_loss: 1.8145e-06 - val_dense_79_loss: 8.2027e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.8515e-06 - dense_78_loss: 2.0014e-06 - dense_79_loss: 8.5012e-07 - val_loss: 2.5188e-06 - val_dense_78_loss: 1.7116e-06 - val_dense_79_loss: 8.0729e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.5261e-06 - dense_78_loss: 1.6574e-06 - dense_79_loss: 8.6868e-07 - val_loss: 2.1465e-06 - val_dense_78_loss: 1.2621e-06 - val_dense_79_loss: 8.8434e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1285e-06 - dense_78_loss: 1.2860e-06 - dense_79_loss: 8.4250e-07 - val_loss: 1.8354e-06 - val_dense_78_loss: 1.0726e-06 - val_dense_79_loss: 7.6287e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8105e-06 - dense_78_loss: 1.0463e-06 - dense_79_loss: 7.6422e-07 - val_loss: 1.5607e-06 - val_dense_78_loss: 8.3587e-07 - val_dense_79_loss: 7.2485e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5010e-06 - dense_78_loss: 8.0601e-07 - dense_79_loss: 6.9498e-07 - val_loss: 1.3964e-06 - val_dense_78_loss: 7.1284e-07 - val_dense_79_loss: 6.8352e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3659e-06 - dense_78_loss: 6.9390e-07 - dense_79_loss: 6.7204e-07 - val_loss: 1.2922e-06 - val_dense_78_loss: 6.5636e-07 - val_dense_79_loss: 6.3585e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2254e-06 - dense_78_loss: 6.0532e-07 - dense_79_loss: 6.2013e-07 - val_loss: 1.2185e-06 - val_dense_78_loss: 6.0676e-07 - val_dense_79_loss: 6.1176e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1397e-06 - dense_78_loss: 5.5971e-07 - dense_79_loss: 5.8000e-07 - val_loss: 1.1536e-06 - val_dense_78_loss: 5.5424e-07 - val_dense_79_loss: 5.9937e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1296e-06 - dense_78_loss: 5.4087e-07 - dense_79_loss: 5.8877e-07 - val_loss: 1.2156e-06 - val_dense_78_loss: 5.6158e-07 - val_dense_79_loss: 6.5403e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0970e-06 - dense_78_loss: 5.3687e-07 - dense_79_loss: 5.6013e-07 - val_loss: 1.1640e-06 - val_dense_78_loss: 5.8389e-07 - val_dense_79_loss: 5.8013e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0657e-06 - dense_78_loss: 5.2365e-07 - dense_79_loss: 5.4203e-07 - val_loss: 1.1658e-06 - val_dense_78_loss: 5.7743e-07 - val_dense_79_loss: 5.8835e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0977e-06 - dense_78_loss: 5.2928e-07 - dense_79_loss: 5.6840e-07 - val_loss: 1.1595e-06 - val_dense_78_loss: 5.5677e-07 - val_dense_79_loss: 6.0276e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0712e-06 - dense_78_loss: 5.3178e-07 - dense_79_loss: 5.3942e-07 - val_loss: 1.1715e-06 - val_dense_78_loss: 6.0894e-07 - val_dense_79_loss: 5.6256e-07\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0595e-06 - dense_78_loss: 5.1849e-07 - dense_79_loss: 5.4098e-07 - val_loss: 1.1270e-06 - val_dense_78_loss: 5.6624e-07 - val_dense_79_loss: 5.6079e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0512e-06 - dense_78_loss: 5.1985e-07 - dense_79_loss: 5.3133e-07 - val_loss: 1.1123e-06 - val_dense_78_loss: 5.4327e-07 - val_dense_79_loss: 5.6904e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0533e-06 - dense_78_loss: 5.0888e-07 - dense_79_loss: 5.4445e-07 - val_loss: 1.1374e-06 - val_dense_78_loss: 5.6086e-07 - val_dense_79_loss: 5.7657e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0457e-06 - dense_78_loss: 5.1313e-07 - dense_79_loss: 5.3257e-07 - val_loss: 1.1311e-06 - val_dense_78_loss: 5.7497e-07 - val_dense_79_loss: 5.5615e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0412e-06 - dense_78_loss: 5.1604e-07 - dense_79_loss: 5.2519e-07 - val_loss: 1.0467e-06 - val_dense_78_loss: 5.0536e-07 - val_dense_79_loss: 5.4136e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0115e-06 - dense_78_loss: 4.9818e-07 - dense_79_loss: 5.1329e-07 - val_loss: 1.2505e-06 - val_dense_78_loss: 6.8551e-07 - val_dense_79_loss: 5.6496e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0575e-06 - dense_78_loss: 5.3442e-07 - dense_79_loss: 5.2312e-07 - val_loss: 1.0591e-06 - val_dense_78_loss: 5.1508e-07 - val_dense_79_loss: 5.4403e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.9271e-07 - dense_78_loss: 4.9407e-07 - dense_79_loss: 4.9864e-07 - val_loss: 1.1223e-06 - val_dense_78_loss: 5.2771e-07 - val_dense_79_loss: 5.9459e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0389e-06 - dense_78_loss: 5.1947e-07 - dense_79_loss: 5.1938e-07 - val_loss: 1.0831e-06 - val_dense_78_loss: 5.3347e-07 - val_dense_79_loss: 5.4966e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0207e-06 - dense_78_loss: 5.0727e-07 - dense_79_loss: 5.1344e-07 - val_loss: 1.2660e-06 - val_dense_78_loss: 6.7711e-07 - val_dense_79_loss: 5.8884e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1224e-06 - dense_78_loss: 5.8538e-07 - dense_79_loss: 5.3698e-07 - val_loss: 1.1699e-06 - val_dense_78_loss: 5.8328e-07 - val_dense_79_loss: 5.8664e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0141e-06 - dense_78_loss: 5.0597e-07 - dense_79_loss: 5.0814e-07 - val_loss: 1.0846e-06 - val_dense_78_loss: 5.3908e-07 - val_dense_79_loss: 5.4550e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0422e-06 - dense_78_loss: 5.2054e-07 - dense_79_loss: 5.2163e-07 - val_loss: 1.1228e-06 - val_dense_78_loss: 5.6980e-07 - val_dense_79_loss: 5.5299e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0419e-06 - dense_78_loss: 5.2317e-07 - dense_79_loss: 5.1869e-07 - val_loss: 1.0494e-06 - val_dense_78_loss: 5.4391e-07 - val_dense_79_loss: 5.0554e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0490e-06 - dense_78_loss: 5.2749e-07 - dense_79_loss: 5.2153e-07 - val_loss: 1.1519e-06 - val_dense_78_loss: 5.4937e-07 - val_dense_79_loss: 6.0249e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0393e-06 - dense_78_loss: 5.2809e-07 - dense_79_loss: 5.1122e-07 - val_loss: 1.2005e-06 - val_dense_78_loss: 6.6258e-07 - val_dense_79_loss: 5.3794e-07\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0570e-06 - dense_78_loss: 5.6155e-07 - dense_79_loss: 4.9542e-07 - val_loss: 1.0803e-06 - val_dense_78_loss: 5.2734e-07 - val_dense_79_loss: 5.5295e-07\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0033e-06 - dense_78_loss: 4.9695e-07 - dense_79_loss: 5.0637e-07 - val_loss: 1.0642e-06 - val_dense_78_loss: 5.4887e-07 - val_dense_79_loss: 5.1534e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1131e-06 - dense_78_loss: 6.1774e-07 - dense_79_loss: 4.9539e-07 - val_loss: 1.0946e-06 - val_dense_78_loss: 5.5142e-07 - val_dense_79_loss: 5.4313e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0401e-06 - dense_78_loss: 5.4274e-07 - dense_79_loss: 4.9740e-07 - val_loss: 1.0412e-06 - val_dense_78_loss: 5.4159e-07 - val_dense_79_loss: 4.9963e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0654e-06 - dense_78_loss: 5.8591e-07 - dense_79_loss: 4.7945e-07 - val_loss: 1.0394e-06 - val_dense_78_loss: 5.4460e-07 - val_dense_79_loss: 4.9481e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.8117e-07 - dense_78_loss: 5.2130e-07 - dense_79_loss: 4.5987e-07 - val_loss: 1.0197e-06 - val_dense_78_loss: 5.4308e-07 - val_dense_79_loss: 4.7665e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0889e-06 - dense_78_loss: 6.1960e-07 - dense_79_loss: 4.6932e-07 - val_loss: 1.0261e-06 - val_dense_78_loss: 5.5488e-07 - val_dense_79_loss: 4.7127e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.8068e-07 - dense_78_loss: 5.3527e-07 - dense_79_loss: 4.4542e-07 - val_loss: 9.9786e-07 - val_dense_78_loss: 5.3150e-07 - val_dense_79_loss: 4.6637e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0308e-06 - dense_78_loss: 5.6693e-07 - dense_79_loss: 4.6382e-07 - val_loss: 1.0183e-06 - val_dense_78_loss: 5.3733e-07 - val_dense_79_loss: 4.8095e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "\n",
      "Now training model 11/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 13ms/step - loss: 0.0010 - dense_85_loss: 6.6840e-04 - dense_86_loss: 3.5846e-04 - val_loss: 7.4287e-05 - val_dense_85_loss: 3.5893e-05 - val_dense_86_loss: 3.8393e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.8479e-05 - dense_85_loss: 2.1629e-05 - dense_86_loss: 1.6850e-05 - val_loss: 1.1988e-05 - val_dense_85_loss: 6.3794e-06 - val_dense_86_loss: 5.6083e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3563e-06 - dense_85_loss: 6.6685e-06 - dense_86_loss: 2.6878e-06 - val_loss: 5.2591e-06 - val_dense_85_loss: 4.1262e-06 - val_dense_86_loss: 1.1329e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.1366e-06 - dense_85_loss: 5.2314e-06 - dense_86_loss: 9.0516e-07 - val_loss: 4.5633e-06 - val_dense_85_loss: 3.8486e-06 - val_dense_86_loss: 7.1471e-07\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7307e-06 - dense_85_loss: 5.0236e-06 - dense_86_loss: 7.0715e-07 - val_loss: 4.4255e-06 - val_dense_85_loss: 3.7463e-06 - val_dense_86_loss: 6.7911e-07\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5685e-06 - dense_85_loss: 4.9035e-06 - dense_86_loss: 6.6498e-07 - val_loss: 4.4533e-06 - val_dense_85_loss: 3.7672e-06 - val_dense_86_loss: 6.8615e-07\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6229e-06 - dense_85_loss: 4.9233e-06 - dense_86_loss: 6.9964e-07 - val_loss: 4.3116e-06 - val_dense_85_loss: 3.6497e-06 - val_dense_86_loss: 6.6191e-07\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4690e-06 - dense_85_loss: 4.7948e-06 - dense_86_loss: 6.7416e-07 - val_loss: 4.2654e-06 - val_dense_85_loss: 3.6074e-06 - val_dense_86_loss: 6.5800e-07\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.3780e-06 - dense_85_loss: 4.7098e-06 - dense_86_loss: 6.6824e-07 - val_loss: 4.2520e-06 - val_dense_85_loss: 3.5574e-06 - val_dense_86_loss: 6.9455e-07\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3841e-06 - dense_85_loss: 4.6921e-06 - dense_86_loss: 6.9195e-07 - val_loss: 4.2702e-06 - val_dense_85_loss: 3.5860e-06 - val_dense_86_loss: 6.8417e-07\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3129e-06 - dense_85_loss: 4.6089e-06 - dense_86_loss: 7.0395e-07 - val_loss: 4.1736e-06 - val_dense_85_loss: 3.4958e-06 - val_dense_86_loss: 6.7778e-07\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.1526e-06 - dense_85_loss: 4.4501e-06 - dense_86_loss: 7.0242e-07 - val_loss: 3.9804e-06 - val_dense_85_loss: 3.3177e-06 - val_dense_86_loss: 6.6266e-07\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0025e-06 - dense_85_loss: 4.3020e-06 - dense_86_loss: 7.0055e-07 - val_loss: 3.9503e-06 - val_dense_85_loss: 3.2415e-06 - val_dense_86_loss: 7.0871e-07\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8772e-06 - dense_85_loss: 4.1578e-06 - dense_86_loss: 7.1931e-07 - val_loss: 3.9626e-06 - val_dense_85_loss: 3.2483e-06 - val_dense_86_loss: 7.1431e-07\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6473e-06 - dense_85_loss: 3.9312e-06 - dense_86_loss: 7.1608e-07 - val_loss: 3.5791e-06 - val_dense_85_loss: 2.9085e-06 - val_dense_86_loss: 6.7061e-07\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.3951e-06 - dense_85_loss: 3.6708e-06 - dense_86_loss: 7.2428e-07 - val_loss: 3.4285e-06 - val_dense_85_loss: 2.7072e-06 - val_dense_86_loss: 7.2130e-07\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.0996e-06 - dense_85_loss: 3.3515e-06 - dense_86_loss: 7.4809e-07 - val_loss: 3.1190e-06 - val_dense_85_loss: 2.4346e-06 - val_dense_86_loss: 6.8441e-07\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.7214e-06 - dense_85_loss: 2.9702e-06 - dense_86_loss: 7.5116e-07 - val_loss: 2.9569e-06 - val_dense_85_loss: 2.2276e-06 - val_dense_86_loss: 7.2927e-07\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.2424e-06 - dense_85_loss: 2.4843e-06 - dense_86_loss: 7.5809e-07 - val_loss: 2.7423e-06 - val_dense_85_loss: 1.9983e-06 - val_dense_86_loss: 7.4400e-07\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.8157e-06 - dense_85_loss: 2.0037e-06 - dense_86_loss: 8.1196e-07 - val_loss: 2.1710e-06 - val_dense_85_loss: 1.4193e-06 - val_dense_86_loss: 7.5163e-07\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.2647e-06 - dense_85_loss: 1.5033e-06 - dense_86_loss: 7.6136e-07 - val_loss: 1.8186e-06 - val_dense_85_loss: 1.0869e-06 - val_dense_86_loss: 7.3173e-07\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8486e-06 - dense_85_loss: 1.1029e-06 - dense_86_loss: 7.4570e-07 - val_loss: 1.7827e-06 - val_dense_85_loss: 1.0585e-06 - val_dense_86_loss: 7.2418e-07\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5332e-06 - dense_85_loss: 8.5350e-07 - dense_86_loss: 6.7975e-07 - val_loss: 1.3174e-06 - val_dense_85_loss: 6.8319e-07 - val_dense_86_loss: 6.3424e-07\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2918e-06 - dense_85_loss: 6.7283e-07 - dense_86_loss: 6.1898e-07 - val_loss: 1.1883e-06 - val_dense_85_loss: 6.0535e-07 - val_dense_86_loss: 5.8295e-07\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1549e-06 - dense_85_loss: 5.8722e-07 - dense_86_loss: 5.6770e-07 - val_loss: 1.1172e-06 - val_dense_85_loss: 5.5383e-07 - val_dense_86_loss: 5.6340e-07\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0758e-06 - dense_85_loss: 5.5377e-07 - dense_86_loss: 5.2201e-07 - val_loss: 1.0703e-06 - val_dense_85_loss: 5.3984e-07 - val_dense_86_loss: 5.3051e-07\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0310e-06 - dense_85_loss: 5.2701e-07 - dense_86_loss: 5.0397e-07 - val_loss: 1.1323e-06 - val_dense_85_loss: 5.3838e-07 - val_dense_86_loss: 5.9387e-07\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0443e-06 - dense_85_loss: 5.3496e-07 - dense_86_loss: 5.0937e-07 - val_loss: 1.0826e-06 - val_dense_85_loss: 5.2823e-07 - val_dense_86_loss: 5.5440e-07\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0278e-06 - dense_85_loss: 5.3374e-07 - dense_86_loss: 4.9405e-07 - val_loss: 1.0682e-06 - val_dense_85_loss: 5.3704e-07 - val_dense_86_loss: 5.3114e-07\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0091e-06 - dense_85_loss: 5.2490e-07 - dense_86_loss: 4.8419e-07 - val_loss: 1.1346e-06 - val_dense_85_loss: 5.5772e-07 - val_dense_86_loss: 5.7693e-07\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0639e-06 - dense_85_loss: 5.4807e-07 - dense_86_loss: 5.1586e-07 - val_loss: 1.0319e-06 - val_dense_85_loss: 5.1476e-07 - val_dense_86_loss: 5.1712e-07\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0073e-06 - dense_85_loss: 5.2153e-07 - dense_86_loss: 4.8579e-07 - val_loss: 1.2594e-06 - val_dense_85_loss: 6.1682e-07 - val_dense_86_loss: 6.4256e-07\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0465e-06 - dense_85_loss: 5.5031e-07 - dense_86_loss: 4.9615e-07 - val_loss: 1.0902e-06 - val_dense_85_loss: 5.7714e-07 - val_dense_86_loss: 5.1301e-07\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.9223e-07 - dense_85_loss: 5.2055e-07 - dense_86_loss: 4.7168e-07 - val_loss: 1.0507e-06 - val_dense_85_loss: 5.3910e-07 - val_dense_86_loss: 5.1156e-07\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0002e-06 - dense_85_loss: 5.1807e-07 - dense_86_loss: 4.8212e-07 - val_loss: 1.0941e-06 - val_dense_85_loss: 5.8141e-07 - val_dense_86_loss: 5.1268e-07\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0050e-06 - dense_85_loss: 5.3856e-07 - dense_86_loss: 4.6641e-07 - val_loss: 1.1065e-06 - val_dense_85_loss: 6.0945e-07 - val_dense_86_loss: 4.9702e-07\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0151e-06 - dense_85_loss: 5.4190e-07 - dense_86_loss: 4.7318e-07 - val_loss: 1.1127e-06 - val_dense_85_loss: 5.5458e-07 - val_dense_86_loss: 5.5812e-07\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0036e-06 - dense_85_loss: 5.1762e-07 - dense_86_loss: 4.8601e-07 - val_loss: 1.0612e-06 - val_dense_85_loss: 5.5393e-07 - val_dense_86_loss: 5.0729e-07\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.8836e-07 - dense_85_loss: 5.3406e-07 - dense_86_loss: 4.5430e-07 - val_loss: 1.0125e-06 - val_dense_85_loss: 5.2161e-07 - val_dense_86_loss: 4.9090e-07\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6626e-07 - dense_85_loss: 5.1732e-07 - dense_86_loss: 4.4894e-07 - val_loss: 9.8685e-07 - val_dense_85_loss: 5.0724e-07 - val_dense_86_loss: 4.7961e-07\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4620e-07 - dense_85_loss: 5.0173e-07 - dense_86_loss: 4.4447e-07 - val_loss: 9.8431e-07 - val_dense_85_loss: 5.1516e-07 - val_dense_86_loss: 4.6915e-07\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.4845e-07 - dense_85_loss: 5.0826e-07 - dense_86_loss: 4.4019e-07 - val_loss: 9.9402e-07 - val_dense_85_loss: 5.2066e-07 - val_dense_86_loss: 4.7336e-07\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.4264e-07 - dense_85_loss: 5.0333e-07 - dense_86_loss: 4.3931e-07 - val_loss: 9.8380e-07 - val_dense_85_loss: 5.2400e-07 - val_dense_86_loss: 4.5980e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4788e-07 - dense_85_loss: 5.1557e-07 - dense_86_loss: 4.3232e-07 - val_loss: 1.0845e-06 - val_dense_85_loss: 5.9018e-07 - val_dense_86_loss: 4.9428e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.7970e-07 - dense_85_loss: 5.3015e-07 - dense_86_loss: 4.4955e-07 - val_loss: 1.0326e-06 - val_dense_85_loss: 5.4899e-07 - val_dense_86_loss: 4.8357e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.4854e-07 - dense_85_loss: 5.0726e-07 - dense_86_loss: 4.4128e-07 - val_loss: 9.7511e-07 - val_dense_85_loss: 5.1626e-07 - val_dense_86_loss: 4.5885e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "\n",
      "Now training model 12/12\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 3s 26ms/step - loss: 0.0081 - dense_92_loss: 7.6162e-04 - dense_93_loss: 0.0013 - dense_94_loss: 9.1983e-04 - dense_95_loss: 8.9084e-04 - dense_96_loss: 8.2416e-04 - dense_97_loss: 0.0013 - dense_98_loss: 9.1338e-04 - dense_99_loss: 0.0012 - val_loss: 6.4378e-04 - val_dense_92_loss: 6.6534e-05 - val_dense_93_loss: 5.2024e-05 - val_dense_94_loss: 1.2014e-04 - val_dense_95_loss: 6.4262e-05 - val_dense_96_loss: 8.5596e-05 - val_dense_97_loss: 9.3443e-05 - val_dense_98_loss: 8.0144e-05 - val_dense_99_loss: 8.1634e-05\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.5204e-04 - dense_92_loss: 2.4375e-05 - dense_93_loss: 3.3790e-05 - dense_94_loss: 4.4809e-05 - dense_95_loss: 3.1508e-05 - dense_96_loss: 2.8923e-05 - dense_97_loss: 3.0784e-05 - dense_98_loss: 2.9672e-05 - dense_99_loss: 2.8177e-05 - val_loss: 6.9278e-05 - val_dense_92_loss: 5.1009e-06 - val_dense_93_loss: 1.1086e-05 - val_dense_94_loss: 1.1164e-05 - val_dense_95_loss: 1.1637e-05 - val_dense_96_loss: 5.8659e-06 - val_dense_97_loss: 8.2994e-06 - val_dense_98_loss: 9.0880e-06 - val_dense_99_loss: 7.0359e-06\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 3.7504e-05 - dense_92_loss: 2.4186e-06 - dense_93_loss: 7.3421e-06 - dense_94_loss: 4.4536e-06 - dense_95_loss: 5.5078e-06 - dense_96_loss: 3.4104e-06 - dense_97_loss: 5.3328e-06 - dense_98_loss: 4.3405e-06 - dense_99_loss: 4.6984e-06 - val_loss: 1.6960e-05 - val_dense_92_loss: 1.1318e-06 - val_dense_93_loss: 4.0414e-06 - val_dense_94_loss: 1.2426e-06 - val_dense_95_loss: 2.7562e-06 - val_dense_96_loss: 1.4846e-06 - val_dense_97_loss: 2.5461e-06 - val_dense_98_loss: 1.7592e-06 - val_dense_99_loss: 1.9978e-06\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.4517e-05 - dense_92_loss: 7.7494e-07 - dense_93_loss: 3.8040e-06 - dense_94_loss: 9.0768e-07 - dense_95_loss: 2.5120e-06 - dense_96_loss: 1.2057e-06 - dense_97_loss: 2.1124e-06 - dense_98_loss: 1.4338e-06 - dense_99_loss: 1.7661e-06 - val_loss: 1.1899e-05 - val_dense_92_loss: 5.2157e-07 - val_dense_93_loss: 3.3484e-06 - val_dense_94_loss: 5.5786e-07 - val_dense_95_loss: 2.1733e-06 - val_dense_96_loss: 1.0129e-06 - val_dense_97_loss: 1.7545e-06 - val_dense_98_loss: 1.0971e-06 - val_dense_99_loss: 1.4338e-06\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1838e-05 - dense_92_loss: 4.8532e-07 - dense_93_loss: 3.4468e-06 - dense_94_loss: 5.2679e-07 - dense_95_loss: 2.2583e-06 - dense_96_loss: 9.5373e-07 - dense_97_loss: 1.6528e-06 - dense_98_loss: 1.0551e-06 - dense_99_loss: 1.4594e-06 - val_loss: 1.1068e-05 - val_dense_92_loss: 4.3690e-07 - val_dense_93_loss: 3.2370e-06 - val_dense_94_loss: 4.8703e-07 - val_dense_95_loss: 2.0895e-06 - val_dense_96_loss: 9.2306e-07 - val_dense_97_loss: 1.5244e-06 - val_dense_98_loss: 1.0223e-06 - val_dense_99_loss: 1.3477e-06\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1418e-05 - dense_92_loss: 4.5173e-07 - dense_93_loss: 3.3627e-06 - dense_94_loss: 4.8166e-07 - dense_95_loss: 2.2077e-06 - dense_96_loss: 9.2622e-07 - dense_97_loss: 1.5555e-06 - dense_98_loss: 1.0104e-06 - dense_99_loss: 1.4219e-06 - val_loss: 1.0982e-05 - val_dense_92_loss: 4.4260e-07 - val_dense_93_loss: 3.2101e-06 - val_dense_94_loss: 4.7863e-07 - val_dense_95_loss: 2.0895e-06 - val_dense_96_loss: 9.1728e-07 - val_dense_97_loss: 1.4826e-06 - val_dense_98_loss: 1.0105e-06 - val_dense_99_loss: 1.3513e-06\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1408e-05 - dense_92_loss: 4.5162e-07 - dense_93_loss: 3.3651e-06 - dense_94_loss: 4.7388e-07 - dense_95_loss: 2.2349e-06 - dense_96_loss: 9.2481e-07 - dense_97_loss: 1.5261e-06 - dense_98_loss: 1.0070e-06 - dense_99_loss: 1.4246e-06 - val_loss: 1.0921e-05 - val_dense_92_loss: 4.2259e-07 - val_dense_93_loss: 3.1848e-06 - val_dense_94_loss: 4.6940e-07 - val_dense_95_loss: 2.0841e-06 - val_dense_96_loss: 9.1345e-07 - val_dense_97_loss: 1.4835e-06 - val_dense_98_loss: 1.0100e-06 - val_dense_99_loss: 1.3536e-06\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1337e-05 - dense_92_loss: 4.5145e-07 - dense_93_loss: 3.3289e-06 - dense_94_loss: 4.7453e-07 - dense_95_loss: 2.2045e-06 - dense_96_loss: 9.2753e-07 - dense_97_loss: 1.5248e-06 - dense_98_loss: 1.0097e-06 - dense_99_loss: 1.4159e-06 - val_loss: 1.0927e-05 - val_dense_92_loss: 4.4577e-07 - val_dense_93_loss: 3.1511e-06 - val_dense_94_loss: 4.7401e-07 - val_dense_95_loss: 2.0727e-06 - val_dense_96_loss: 9.4185e-07 - val_dense_97_loss: 1.4586e-06 - val_dense_98_loss: 1.0344e-06 - val_dense_99_loss: 1.3488e-06\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1265e-05 - dense_92_loss: 4.5154e-07 - dense_93_loss: 3.3020e-06 - dense_94_loss: 4.7350e-07 - dense_95_loss: 2.1796e-06 - dense_96_loss: 9.3105e-07 - dense_97_loss: 1.5073e-06 - dense_98_loss: 1.0165e-06 - dense_99_loss: 1.4035e-06 - val_loss: 1.0817e-05 - val_dense_92_loss: 4.4710e-07 - val_dense_93_loss: 3.1208e-06 - val_dense_94_loss: 4.7637e-07 - val_dense_95_loss: 2.0316e-06 - val_dense_96_loss: 9.5410e-07 - val_dense_97_loss: 1.4459e-06 - val_dense_98_loss: 1.0167e-06 - val_dense_99_loss: 1.3246e-06\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1147e-05 - dense_92_loss: 4.5466e-07 - dense_93_loss: 3.2523e-06 - dense_94_loss: 4.7606e-07 - dense_95_loss: 2.1437e-06 - dense_96_loss: 9.3018e-07 - dense_97_loss: 1.4851e-06 - dense_98_loss: 1.0187e-06 - dense_99_loss: 1.3867e-06 - val_loss: 1.1277e-05 - val_dense_92_loss: 4.8909e-07 - val_dense_93_loss: 3.1395e-06 - val_dense_94_loss: 5.3057e-07 - val_dense_95_loss: 2.0947e-06 - val_dense_96_loss: 1.0092e-06 - val_dense_97_loss: 1.5038e-06 - val_dense_98_loss: 1.1058e-06 - val_dense_99_loss: 1.4041e-06\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1664e-05 - dense_92_loss: 5.1648e-07 - dense_93_loss: 3.2880e-06 - dense_94_loss: 5.3411e-07 - dense_95_loss: 2.2215e-06 - dense_96_loss: 1.0115e-06 - dense_97_loss: 1.5480e-06 - dense_98_loss: 1.0888e-06 - dense_99_loss: 1.4558e-06 - val_loss: 1.2202e-05 - val_dense_92_loss: 6.0059e-07 - val_dense_93_loss: 3.2092e-06 - val_dense_94_loss: 6.5041e-07 - val_dense_95_loss: 2.1945e-06 - val_dense_96_loss: 1.1685e-06 - val_dense_97_loss: 1.6503e-06 - val_dense_98_loss: 1.1887e-06 - val_dense_99_loss: 1.5402e-06\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1508e-05 - dense_92_loss: 5.1099e-07 - dense_93_loss: 3.2658e-06 - dense_94_loss: 5.2130e-07 - dense_95_loss: 2.1771e-06 - dense_96_loss: 1.0005e-06 - dense_97_loss: 1.5174e-06 - dense_98_loss: 1.0790e-06 - dense_99_loss: 1.4360e-06 - val_loss: 1.0812e-05 - val_dense_92_loss: 4.5545e-07 - val_dense_93_loss: 3.0807e-06 - val_dense_94_loss: 4.9513e-07 - val_dense_95_loss: 1.9931e-06 - val_dense_96_loss: 9.6273e-07 - val_dense_97_loss: 1.4549e-06 - val_dense_98_loss: 1.0377e-06 - val_dense_99_loss: 1.3325e-06\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1253e-05 - dense_92_loss: 4.8692e-07 - dense_93_loss: 3.2147e-06 - dense_94_loss: 4.9741e-07 - dense_95_loss: 2.1431e-06 - dense_96_loss: 9.7647e-07 - dense_97_loss: 1.4937e-06 - dense_98_loss: 1.0457e-06 - dense_99_loss: 1.3952e-06 - val_loss: 1.0955e-05 - val_dense_92_loss: 4.8815e-07 - val_dense_93_loss: 3.0534e-06 - val_dense_94_loss: 5.2288e-07 - val_dense_95_loss: 2.0014e-06 - val_dense_96_loss: 9.9181e-07 - val_dense_97_loss: 1.4754e-06 - val_dense_98_loss: 1.0817e-06 - val_dense_99_loss: 1.3400e-06\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1209e-05 - dense_92_loss: 4.8740e-07 - dense_93_loss: 3.1749e-06 - dense_94_loss: 4.9902e-07 - dense_95_loss: 2.1308e-06 - dense_96_loss: 9.7298e-07 - dense_97_loss: 1.4949e-06 - dense_98_loss: 1.0534e-06 - dense_99_loss: 1.3956e-06 - val_loss: 1.1109e-05 - val_dense_92_loss: 4.7811e-07 - val_dense_93_loss: 3.1265e-06 - val_dense_94_loss: 5.0885e-07 - val_dense_95_loss: 2.0758e-06 - val_dense_96_loss: 9.7039e-07 - val_dense_97_loss: 1.4954e-06 - val_dense_98_loss: 1.0795e-06 - val_dense_99_loss: 1.3740e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1217e-05 - dense_92_loss: 4.9721e-07 - dense_93_loss: 3.1575e-06 - dense_94_loss: 5.1280e-07 - dense_95_loss: 2.1369e-06 - dense_96_loss: 9.8035e-07 - dense_97_loss: 1.4748e-06 - dense_98_loss: 1.0595e-06 - dense_99_loss: 1.3977e-06 - val_loss: 1.0785e-05 - val_dense_92_loss: 4.7533e-07 - val_dense_93_loss: 3.0245e-06 - val_dense_94_loss: 5.0212e-07 - val_dense_95_loss: 1.9872e-06 - val_dense_96_loss: 9.5947e-07 - val_dense_97_loss: 1.4110e-06 - val_dense_98_loss: 1.0703e-06 - val_dense_99_loss: 1.3550e-06\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1156e-05 - dense_92_loss: 5.0958e-07 - dense_93_loss: 3.1150e-06 - dense_94_loss: 5.1098e-07 - dense_95_loss: 2.0973e-06 - dense_96_loss: 9.9614e-07 - dense_97_loss: 1.4752e-06 - dense_98_loss: 1.0616e-06 - dense_99_loss: 1.3905e-06 - val_loss: 1.0747e-05 - val_dense_92_loss: 4.6364e-07 - val_dense_93_loss: 3.0324e-06 - val_dense_94_loss: 4.8569e-07 - val_dense_95_loss: 2.0001e-06 - val_dense_96_loss: 9.6879e-07 - val_dense_97_loss: 1.4362e-06 - val_dense_98_loss: 1.0553e-06 - val_dense_99_loss: 1.3045e-06\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0943e-05 - dense_92_loss: 4.9473e-07 - dense_93_loss: 3.0645e-06 - dense_94_loss: 4.9945e-07 - dense_95_loss: 2.0486e-06 - dense_96_loss: 9.7427e-07 - dense_97_loss: 1.4495e-06 - dense_98_loss: 1.0487e-06 - dense_99_loss: 1.3635e-06 - val_loss: 1.0580e-05 - val_dense_92_loss: 4.7171e-07 - val_dense_93_loss: 2.9196e-06 - val_dense_94_loss: 5.0202e-07 - val_dense_95_loss: 1.9448e-06 - val_dense_96_loss: 9.6649e-07 - val_dense_97_loss: 1.4064e-06 - val_dense_98_loss: 1.0382e-06 - val_dense_99_loss: 1.3305e-06\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0926e-05 - dense_92_loss: 5.0651e-07 - dense_93_loss: 3.0316e-06 - dense_94_loss: 5.0726e-07 - dense_95_loss: 2.0283e-06 - dense_96_loss: 9.9214e-07 - dense_97_loss: 1.4412e-06 - dense_98_loss: 1.0572e-06 - dense_99_loss: 1.3617e-06 - val_loss: 1.0479e-05 - val_dense_92_loss: 4.7010e-07 - val_dense_93_loss: 2.8870e-06 - val_dense_94_loss: 4.9597e-07 - val_dense_95_loss: 1.9122e-06 - val_dense_96_loss: 9.6885e-07 - val_dense_97_loss: 1.3869e-06 - val_dense_98_loss: 1.0625e-06 - val_dense_99_loss: 1.2952e-06\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1518e-05 - dense_92_loss: 5.7664e-07 - dense_93_loss: 3.0407e-06 - dense_94_loss: 5.7100e-07 - dense_95_loss: 2.1182e-06 - dense_96_loss: 1.0886e-06 - dense_97_loss: 1.5174e-06 - dense_98_loss: 1.1492e-06 - dense_99_loss: 1.4558e-06 - val_loss: 1.0976e-05 - val_dense_92_loss: 5.4171e-07 - val_dense_93_loss: 2.9245e-06 - val_dense_94_loss: 5.1733e-07 - val_dense_95_loss: 2.0500e-06 - val_dense_96_loss: 9.8764e-07 - val_dense_97_loss: 1.4145e-06 - val_dense_98_loss: 1.1548e-06 - val_dense_99_loss: 1.3854e-06\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1069e-05 - dense_92_loss: 5.4494e-07 - dense_93_loss: 2.9522e-06 - dense_94_loss: 5.3877e-07 - dense_95_loss: 2.0396e-06 - dense_96_loss: 1.0418e-06 - dense_97_loss: 1.4527e-06 - dense_98_loss: 1.0912e-06 - dense_99_loss: 1.4073e-06 - val_loss: 1.1512e-05 - val_dense_92_loss: 6.5521e-07 - val_dense_93_loss: 2.8615e-06 - val_dense_94_loss: 6.2731e-07 - val_dense_95_loss: 2.0270e-06 - val_dense_96_loss: 1.1994e-06 - val_dense_97_loss: 1.4724e-06 - val_dense_98_loss: 1.2313e-06 - val_dense_99_loss: 1.4375e-06\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2698e-05 - dense_92_loss: 7.3582e-07 - dense_93_loss: 3.0636e-06 - dense_94_loss: 7.0024e-07 - dense_95_loss: 2.2979e-06 - dense_96_loss: 1.2812e-06 - dense_97_loss: 1.6856e-06 - dense_98_loss: 1.2979e-06 - dense_99_loss: 1.6358e-06 - val_loss: 1.0370e-05 - val_dense_92_loss: 4.8865e-07 - val_dense_93_loss: 2.8118e-06 - val_dense_94_loss: 5.0132e-07 - val_dense_95_loss: 1.8846e-06 - val_dense_96_loss: 9.7325e-07 - val_dense_97_loss: 1.3551e-06 - val_dense_98_loss: 1.0604e-06 - val_dense_99_loss: 1.2942e-06\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0473e-05 - dense_92_loss: 5.1265e-07 - dense_93_loss: 2.8053e-06 - dense_94_loss: 5.0518e-07 - dense_95_loss: 1.9015e-06 - dense_96_loss: 9.9336e-07 - dense_97_loss: 1.3839e-06 - dense_98_loss: 1.0519e-06 - dense_99_loss: 1.3187e-06 - val_loss: 1.0364e-05 - val_dense_92_loss: 5.4079e-07 - val_dense_93_loss: 2.6384e-06 - val_dense_94_loss: 5.3874e-07 - val_dense_95_loss: 1.7823e-06 - val_dense_96_loss: 1.0825e-06 - val_dense_97_loss: 1.3682e-06 - val_dense_98_loss: 1.1453e-06 - val_dense_99_loss: 1.2673e-06\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0450e-05 - dense_92_loss: 5.3274e-07 - dense_93_loss: 2.7457e-06 - dense_94_loss: 5.1050e-07 - dense_95_loss: 1.8774e-06 - dense_96_loss: 1.0101e-06 - dense_97_loss: 1.3786e-06 - dense_98_loss: 1.0704e-06 - dense_99_loss: 1.3246e-06 - val_loss: 1.0112e-05 - val_dense_92_loss: 4.9870e-07 - val_dense_93_loss: 2.5854e-06 - val_dense_94_loss: 5.0932e-07 - val_dense_95_loss: 1.7495e-06 - val_dense_96_loss: 1.0102e-06 - val_dense_97_loss: 1.3277e-06 - val_dense_98_loss: 1.1594e-06 - val_dense_99_loss: 1.2720e-06\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1798e-05 - dense_92_loss: 6.8910e-07 - dense_93_loss: 2.8495e-06 - dense_94_loss: 6.4499e-07 - dense_95_loss: 2.1080e-06 - dense_96_loss: 1.1904e-06 - dense_97_loss: 1.5680e-06 - dense_98_loss: 1.2342e-06 - dense_99_loss: 1.5142e-06 - val_loss: 9.7775e-06 - val_dense_92_loss: 5.0481e-07 - val_dense_93_loss: 2.4868e-06 - val_dense_94_loss: 5.1389e-07 - val_dense_95_loss: 1.6920e-06 - val_dense_96_loss: 9.6811e-07 - val_dense_97_loss: 1.3139e-06 - val_dense_98_loss: 1.0735e-06 - val_dense_99_loss: 1.2244e-06\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0220e-05 - dense_92_loss: 5.5936e-07 - dense_93_loss: 2.5901e-06 - dense_94_loss: 5.2114e-07 - dense_95_loss: 1.7867e-06 - dense_96_loss: 1.0163e-06 - dense_97_loss: 1.3633e-06 - dense_98_loss: 1.0755e-06 - dense_99_loss: 1.3080e-06 - val_loss: 1.1024e-05 - val_dense_92_loss: 6.7159e-07 - val_dense_93_loss: 2.6135e-06 - val_dense_94_loss: 6.3861e-07 - val_dense_95_loss: 1.7250e-06 - val_dense_96_loss: 1.1887e-06 - val_dense_97_loss: 1.4963e-06 - val_dense_98_loss: 1.3096e-06 - val_dense_99_loss: 1.3805e-06\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0554e-05 - dense_92_loss: 6.0672e-07 - dense_93_loss: 2.5900e-06 - dense_94_loss: 5.6372e-07 - dense_95_loss: 1.8230e-06 - dense_96_loss: 1.0627e-06 - dense_97_loss: 1.4140e-06 - dense_98_loss: 1.1163e-06 - dense_99_loss: 1.3779e-06 - val_loss: 1.0628e-05 - val_dense_92_loss: 6.3186e-07 - val_dense_93_loss: 2.4805e-06 - val_dense_94_loss: 5.8057e-07 - val_dense_95_loss: 1.8627e-06 - val_dense_96_loss: 1.1353e-06 - val_dense_97_loss: 1.3764e-06 - val_dense_98_loss: 1.1443e-06 - val_dense_99_loss: 1.4163e-06\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1968e-05 - dense_92_loss: 7.9932e-07 - dense_93_loss: 2.6258e-06 - dense_94_loss: 7.1390e-07 - dense_95_loss: 2.0437e-06 - dense_96_loss: 1.3192e-06 - dense_97_loss: 1.5883e-06 - dense_98_loss: 1.3051e-06 - dense_99_loss: 1.5727e-06 - val_loss: 1.0850e-05 - val_dense_92_loss: 6.3759e-07 - val_dense_93_loss: 2.6941e-06 - val_dense_94_loss: 6.0268e-07 - val_dense_95_loss: 1.8812e-06 - val_dense_96_loss: 1.0977e-06 - val_dense_97_loss: 1.4471e-06 - val_dense_98_loss: 1.1742e-06 - val_dense_99_loss: 1.3156e-06\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0553e-05 - dense_92_loss: 6.4404e-07 - dense_93_loss: 2.5007e-06 - dense_94_loss: 5.7276e-07 - dense_95_loss: 1.8114e-06 - dense_96_loss: 1.1050e-06 - dense_97_loss: 1.4082e-06 - dense_98_loss: 1.1488e-06 - dense_99_loss: 1.3622e-06 - val_loss: 9.4990e-06 - val_dense_92_loss: 5.6657e-07 - val_dense_93_loss: 2.1796e-06 - val_dense_94_loss: 5.6006e-07 - val_dense_95_loss: 1.5371e-06 - val_dense_96_loss: 1.0801e-06 - val_dense_97_loss: 1.2702e-06 - val_dense_98_loss: 1.1116e-06 - val_dense_99_loss: 1.1937e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.5938e-06 - dense_92_loss: 5.8470e-07 - dense_93_loss: 2.2436e-06 - dense_94_loss: 5.3280e-07 - dense_95_loss: 1.5822e-06 - dense_96_loss: 1.0257e-06 - dense_97_loss: 1.2836e-06 - dense_98_loss: 1.0901e-06 - dense_99_loss: 1.2512e-06 - val_loss: 9.1003e-06 - val_dense_92_loss: 5.3906e-07 - val_dense_93_loss: 2.0744e-06 - val_dense_94_loss: 5.3208e-07 - val_dense_95_loss: 1.4591e-06 - val_dense_96_loss: 9.7307e-07 - val_dense_97_loss: 1.2393e-06 - val_dense_98_loss: 1.0798e-06 - val_dense_99_loss: 1.2036e-06\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 9.3139e-06 - dense_92_loss: 5.7931e-07 - dense_93_loss: 2.1064e-06 - dense_94_loss: 5.2689e-07 - dense_95_loss: 1.5385e-06 - dense_96_loss: 1.0136e-06 - dense_97_loss: 1.2517e-06 - dense_98_loss: 1.0705e-06 - dense_99_loss: 1.2269e-06 - val_loss: 9.6972e-06 - val_dense_92_loss: 5.9482e-07 - val_dense_93_loss: 2.1752e-06 - val_dense_94_loss: 5.6023e-07 - val_dense_95_loss: 1.5668e-06 - val_dense_96_loss: 1.0909e-06 - val_dense_97_loss: 1.2965e-06 - val_dense_98_loss: 1.1725e-06 - val_dense_99_loss: 1.2404e-06\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.0672e-06 - dense_92_loss: 5.8780e-07 - dense_93_loss: 1.9950e-06 - dense_94_loss: 5.2929e-07 - dense_95_loss: 1.4552e-06 - dense_96_loss: 1.0075e-06 - dense_97_loss: 1.2216e-06 - dense_98_loss: 1.0677e-06 - dense_99_loss: 1.2032e-06 - val_loss: 9.1195e-06 - val_dense_92_loss: 5.7374e-07 - val_dense_93_loss: 1.9633e-06 - val_dense_94_loss: 5.3621e-07 - val_dense_95_loss: 1.5007e-06 - val_dense_96_loss: 1.0205e-06 - val_dense_97_loss: 1.2033e-06 - val_dense_98_loss: 1.0952e-06 - val_dense_99_loss: 1.2266e-06\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.1588e-06 - dense_92_loss: 6.1678e-07 - dense_93_loss: 1.9105e-06 - dense_94_loss: 5.4558e-07 - dense_95_loss: 1.4556e-06 - dense_96_loss: 1.0460e-06 - dense_97_loss: 1.2538e-06 - dense_98_loss: 1.0908e-06 - dense_99_loss: 1.2397e-06 - val_loss: 8.4233e-06 - val_dense_92_loss: 5.4694e-07 - val_dense_93_loss: 1.7899e-06 - val_dense_94_loss: 4.9908e-07 - val_dense_95_loss: 1.2856e-06 - val_dense_96_loss: 9.7141e-07 - val_dense_97_loss: 1.1360e-06 - val_dense_98_loss: 1.0590e-06 - val_dense_99_loss: 1.1354e-06\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.8794e-06 - dense_92_loss: 6.2684e-07 - dense_93_loss: 1.7875e-06 - dense_94_loss: 5.4932e-07 - dense_95_loss: 1.3587e-06 - dense_96_loss: 1.0452e-06 - dense_97_loss: 1.2045e-06 - dense_98_loss: 1.1005e-06 - dense_99_loss: 1.2068e-06 - val_loss: 9.3550e-06 - val_dense_92_loss: 6.4170e-07 - val_dense_93_loss: 1.7317e-06 - val_dense_94_loss: 5.8091e-07 - val_dense_95_loss: 1.5198e-06 - val_dense_96_loss: 1.1295e-06 - val_dense_97_loss: 1.2469e-06 - val_dense_98_loss: 1.1993e-06 - val_dense_99_loss: 1.3052e-06\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.2553e-06 - dense_92_loss: 6.6014e-07 - dense_93_loss: 1.7796e-06 - dense_94_loss: 5.8704e-07 - dense_95_loss: 1.4410e-06 - dense_96_loss: 1.0954e-06 - dense_97_loss: 1.2784e-06 - dense_98_loss: 1.1269e-06 - dense_99_loss: 1.2869e-06 - val_loss: 8.6753e-06 - val_dense_92_loss: 6.3147e-07 - val_dense_93_loss: 1.6481e-06 - val_dense_94_loss: 5.4534e-07 - val_dense_95_loss: 1.2395e-06 - val_dense_96_loss: 1.0151e-06 - val_dense_97_loss: 1.2906e-06 - val_dense_98_loss: 1.1410e-06 - val_dense_99_loss: 1.1642e-06\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.8493e-06 - dense_92_loss: 6.2540e-07 - dense_93_loss: 1.6882e-06 - dense_94_loss: 5.5641e-07 - dense_95_loss: 1.3731e-06 - dense_96_loss: 1.0261e-06 - dense_97_loss: 1.2430e-06 - dense_98_loss: 1.0981e-06 - dense_99_loss: 1.2390e-06 - val_loss: 7.9012e-06 - val_dense_92_loss: 5.4264e-07 - val_dense_93_loss: 1.4491e-06 - val_dense_94_loss: 5.2835e-07 - val_dense_95_loss: 1.1699e-06 - val_dense_96_loss: 9.6387e-07 - val_dense_97_loss: 1.0868e-06 - val_dense_98_loss: 1.0440e-06 - val_dense_99_loss: 1.1165e-06\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.1488e-06 - dense_92_loss: 5.5848e-07 - dense_93_loss: 1.5250e-06 - dense_94_loss: 5.1549e-07 - dense_95_loss: 1.2343e-06 - dense_96_loss: 9.6987e-07 - dense_97_loss: 1.1495e-06 - dense_98_loss: 1.0282e-06 - dense_99_loss: 1.1680e-06 - val_loss: 7.4490e-06 - val_dense_92_loss: 5.1265e-07 - val_dense_93_loss: 1.3368e-06 - val_dense_94_loss: 4.8586e-07 - val_dense_95_loss: 1.0444e-06 - val_dense_96_loss: 9.1992e-07 - val_dense_97_loss: 1.0584e-06 - val_dense_98_loss: 1.0218e-06 - val_dense_99_loss: 1.0692e-06\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 8.0154e-06 - dense_92_loss: 5.5530e-07 - dense_93_loss: 1.4427e-06 - dense_94_loss: 5.2004e-07 - dense_95_loss: 1.1968e-06 - dense_96_loss: 9.6709e-07 - dense_97_loss: 1.1357e-06 - dense_98_loss: 1.0435e-06 - dense_99_loss: 1.1542e-06 - val_loss: 7.2158e-06 - val_dense_92_loss: 4.9875e-07 - val_dense_93_loss: 1.2716e-06 - val_dense_94_loss: 4.7862e-07 - val_dense_95_loss: 1.0073e-06 - val_dense_96_loss: 9.1268e-07 - val_dense_97_loss: 1.0012e-06 - val_dense_98_loss: 1.0198e-06 - val_dense_99_loss: 1.0259e-06\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.3218e-06 - dense_92_loss: 5.1409e-07 - dense_93_loss: 1.2628e-06 - dense_94_loss: 4.8358e-07 - dense_95_loss: 1.0513e-06 - dense_96_loss: 9.1865e-07 - dense_97_loss: 1.0227e-06 - dense_98_loss: 1.0071e-06 - dense_99_loss: 1.0615e-06 - val_loss: 7.5435e-06 - val_dense_92_loss: 5.4841e-07 - val_dense_93_loss: 1.2874e-06 - val_dense_94_loss: 4.9792e-07 - val_dense_95_loss: 1.0658e-06 - val_dense_96_loss: 9.4211e-07 - val_dense_97_loss: 1.0388e-06 - val_dense_98_loss: 1.0639e-06 - val_dense_99_loss: 1.0992e-06\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4652e-06 - dense_92_loss: 5.3644e-07 - dense_93_loss: 1.2272e-06 - dense_94_loss: 5.0958e-07 - dense_95_loss: 1.0811e-06 - dense_96_loss: 9.4889e-07 - dense_97_loss: 1.0484e-06 - dense_98_loss: 1.0172e-06 - dense_99_loss: 1.0965e-06 - val_loss: 7.3405e-06 - val_dense_92_loss: 5.1571e-07 - val_dense_93_loss: 1.1605e-06 - val_dense_94_loss: 5.0513e-07 - val_dense_95_loss: 1.0231e-06 - val_dense_96_loss: 9.4773e-07 - val_dense_97_loss: 1.0809e-06 - val_dense_98_loss: 1.0591e-06 - val_dense_99_loss: 1.0484e-06\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.8784e-06 - dense_92_loss: 5.6740e-07 - dense_93_loss: 1.2773e-06 - dense_94_loss: 5.4679e-07 - dense_95_loss: 1.1513e-06 - dense_96_loss: 9.9148e-07 - dense_97_loss: 1.1306e-06 - dense_98_loss: 1.0647e-06 - dense_99_loss: 1.1488e-06 - val_loss: 7.7934e-06 - val_dense_92_loss: 4.5835e-07 - val_dense_93_loss: 1.4081e-06 - val_dense_94_loss: 4.5802e-07 - val_dense_95_loss: 1.3461e-06 - val_dense_96_loss: 8.7040e-07 - val_dense_97_loss: 1.1305e-06 - val_dense_98_loss: 9.8931e-07 - val_dense_99_loss: 1.1327e-06\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.2205e-06 - dense_92_loss: 5.0092e-07 - dense_93_loss: 1.1842e-06 - dense_94_loss: 4.8972e-07 - dense_95_loss: 1.0473e-06 - dense_96_loss: 9.1620e-07 - dense_97_loss: 1.0368e-06 - dense_98_loss: 9.9741e-07 - dense_99_loss: 1.0479e-06 - val_loss: 6.8267e-06 - val_dense_92_loss: 4.5691e-07 - val_dense_93_loss: 1.0307e-06 - val_dense_94_loss: 4.8448e-07 - val_dense_95_loss: 9.5489e-07 - val_dense_96_loss: 8.9776e-07 - val_dense_97_loss: 9.5707e-07 - val_dense_98_loss: 1.0205e-06 - val_dense_99_loss: 1.0244e-06\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.4670e-06 - dense_92_loss: 5.2177e-07 - dense_93_loss: 1.1472e-06 - dense_94_loss: 5.2219e-07 - dense_95_loss: 1.1169e-06 - dense_96_loss: 9.5675e-07 - dense_97_loss: 1.0721e-06 - dense_98_loss: 1.0239e-06 - dense_99_loss: 1.1062e-06 - val_loss: 6.7235e-06 - val_dense_92_loss: 4.2543e-07 - val_dense_93_loss: 1.1066e-06 - val_dense_94_loss: 4.5234e-07 - val_dense_95_loss: 1.0187e-06 - val_dense_96_loss: 8.3643e-07 - val_dense_97_loss: 9.4559e-07 - val_dense_98_loss: 9.6215e-07 - val_dense_99_loss: 9.7633e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6584e-06 - dense_92_loss: 4.4994e-07 - dense_93_loss: 1.0158e-06 - dense_94_loss: 4.5658e-07 - dense_95_loss: 9.5293e-07 - dense_96_loss: 8.7350e-07 - dense_97_loss: 9.4752e-07 - dense_98_loss: 9.6177e-07 - dense_99_loss: 1.0004e-06 - val_loss: 6.9707e-06 - val_dense_92_loss: 5.2189e-07 - val_dense_93_loss: 1.0131e-06 - val_dense_94_loss: 5.2271e-07 - val_dense_95_loss: 9.0833e-07 - val_dense_96_loss: 9.3086e-07 - val_dense_97_loss: 1.0006e-06 - val_dense_98_loss: 1.0754e-06 - val_dense_99_loss: 9.9782e-07\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.6948e-06 - dense_92_loss: 4.6391e-07 - dense_93_loss: 1.0089e-06 - dense_94_loss: 4.8280e-07 - dense_95_loss: 9.3807e-07 - dense_96_loss: 8.8175e-07 - dense_97_loss: 9.4441e-07 - dense_98_loss: 9.7747e-07 - dense_99_loss: 9.9748e-07 - val_loss: 6.3383e-06 - val_dense_92_loss: 4.3611e-07 - val_dense_93_loss: 8.8727e-07 - val_dense_94_loss: 4.3467e-07 - val_dense_95_loss: 8.5109e-07 - val_dense_96_loss: 8.8751e-07 - val_dense_97_loss: 8.9660e-07 - val_dense_98_loss: 9.9138e-07 - val_dense_99_loss: 9.5369e-07\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.2267e-06 - dense_92_loss: 4.3341e-07 - dense_93_loss: 8.7103e-07 - dense_94_loss: 4.4766e-07 - dense_95_loss: 8.5412e-07 - dense_96_loss: 8.5117e-07 - dense_97_loss: 8.8648e-07 - dense_98_loss: 9.4590e-07 - dense_99_loss: 9.3695e-07 - val_loss: 6.1656e-06 - val_dense_92_loss: 3.8128e-07 - val_dense_93_loss: 8.7774e-07 - val_dense_94_loss: 4.2493e-07 - val_dense_95_loss: 8.7363e-07 - val_dense_96_loss: 8.2050e-07 - val_dense_97_loss: 9.1610e-07 - val_dense_98_loss: 9.1745e-07 - val_dense_99_loss: 9.5397e-07\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.8958e-06 - dense_92_loss: 4.5704e-07 - dense_93_loss: 1.0548e-06 - dense_94_loss: 4.7356e-07 - dense_95_loss: 1.0300e-06 - dense_96_loss: 8.9252e-07 - dense_97_loss: 9.7439e-07 - dense_98_loss: 9.7899e-07 - dense_99_loss: 1.0345e-06 - val_loss: 7.2013e-06 - val_dense_92_loss: 4.8047e-07 - val_dense_93_loss: 1.0470e-06 - val_dense_94_loss: 5.0790e-07 - val_dense_95_loss: 1.0479e-06 - val_dense_96_loss: 9.4585e-07 - val_dense_97_loss: 1.0572e-06 - val_dense_98_loss: 1.0358e-06 - val_dense_99_loss: 1.0791e-06\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.8539e-06 - dense_92_loss: 4.5601e-07 - dense_93_loss: 9.9525e-07 - dense_94_loss: 4.7605e-07 - dense_95_loss: 1.0319e-06 - dense_96_loss: 9.0160e-07 - dense_97_loss: 9.8323e-07 - dense_98_loss: 9.7718e-07 - dense_99_loss: 1.0328e-06 - val_loss: 6.8753e-06 - val_dense_92_loss: 4.4817e-07 - val_dense_93_loss: 9.7309e-07 - val_dense_94_loss: 5.1485e-07 - val_dense_95_loss: 1.0256e-06 - val_dense_96_loss: 8.9315e-07 - val_dense_97_loss: 9.3671e-07 - val_dense_98_loss: 9.9183e-07 - val_dense_99_loss: 1.0919e-06\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.4932e-06 - dense_92_loss: 4.3729e-07 - dense_93_loss: 9.0932e-07 - dense_94_loss: 4.6201e-07 - dense_95_loss: 9.3301e-07 - dense_96_loss: 8.6856e-07 - dense_97_loss: 9.3733e-07 - dense_98_loss: 9.5611e-07 - dense_99_loss: 9.8958e-07 - val_loss: 6.1482e-06 - val_dense_92_loss: 4.3158e-07 - val_dense_93_loss: 7.6378e-07 - val_dense_94_loss: 4.5416e-07 - val_dense_95_loss: 8.3250e-07 - val_dense_96_loss: 9.0832e-07 - val_dense_97_loss: 9.0689e-07 - val_dense_98_loss: 9.4843e-07 - val_dense_99_loss: 9.0256e-07\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.0564e-06 - dense_92_loss: 3.9857e-07 - dense_93_loss: 8.3193e-07 - dense_94_loss: 4.3531e-07 - dense_95_loss: 8.4488e-07 - dense_96_loss: 8.3913e-07 - dense_97_loss: 8.6582e-07 - dense_98_loss: 9.2075e-07 - dense_99_loss: 9.1998e-07 - val_loss: 6.2035e-06 - val_dense_92_loss: 3.9474e-07 - val_dense_93_loss: 8.6258e-07 - val_dense_94_loss: 4.4291e-07 - val_dense_95_loss: 8.7246e-07 - val_dense_96_loss: 8.3910e-07 - val_dense_97_loss: 9.1967e-07 - val_dense_98_loss: 9.5174e-07 - val_dense_99_loss: 9.2026e-07\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1267e-06 - dense_92_loss: 4.0661e-07 - dense_93_loss: 8.0084e-07 - dense_94_loss: 4.4270e-07 - dense_95_loss: 8.5601e-07 - dense_96_loss: 8.4778e-07 - dense_97_loss: 8.9245e-07 - dense_98_loss: 9.3869e-07 - dense_99_loss: 9.4167e-07 - val_loss: 6.5500e-06 - val_dense_92_loss: 4.0770e-07 - val_dense_93_loss: 9.3451e-07 - val_dense_94_loss: 4.2918e-07 - val_dense_95_loss: 1.0055e-06 - val_dense_96_loss: 8.7257e-07 - val_dense_97_loss: 9.7573e-07 - val_dense_98_loss: 9.4180e-07 - val_dense_99_loss: 9.8302e-07\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.2049e-06 - dense_92_loss: 4.0967e-07 - dense_93_loss: 8.0696e-07 - dense_94_loss: 4.4251e-07 - dense_95_loss: 9.0436e-07 - dense_96_loss: 8.5903e-07 - dense_97_loss: 8.9821e-07 - dense_98_loss: 9.4240e-07 - dense_99_loss: 9.4171e-07 - val_loss: 5.8729e-06 - val_dense_92_loss: 3.4715e-07 - val_dense_93_loss: 7.8255e-07 - val_dense_94_loss: 4.0709e-07 - val_dense_95_loss: 8.5274e-07 - val_dense_96_loss: 8.1600e-07 - val_dense_97_loss: 8.3607e-07 - val_dense_98_loss: 9.3644e-07 - val_dense_99_loss: 8.9485e-07\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.7076e-06 - dense_92_loss: 3.7241e-07 - dense_93_loss: 7.3030e-07 - dense_94_loss: 4.0356e-07 - dense_95_loss: 7.7338e-07 - dense_96_loss: 8.2181e-07 - dense_97_loss: 8.1668e-07 - dense_98_loss: 9.1004e-07 - dense_99_loss: 8.7941e-07 - val_loss: 5.7870e-06 - val_dense_92_loss: 3.4381e-07 - val_dense_93_loss: 7.7070e-07 - val_dense_94_loss: 4.2561e-07 - val_dense_95_loss: 8.1981e-07 - val_dense_96_loss: 8.3115e-07 - val_dense_97_loss: 7.8226e-07 - val_dense_98_loss: 8.9573e-07 - val_dense_99_loss: 9.1787e-07\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.7988e-06 - dense_92_loss: 3.8837e-07 - dense_93_loss: 7.5193e-07 - dense_94_loss: 4.1262e-07 - dense_95_loss: 7.9776e-07 - dense_96_loss: 8.2463e-07 - dense_97_loss: 8.2097e-07 - dense_98_loss: 9.0471e-07 - dense_99_loss: 8.9777e-07 - val_loss: 5.5748e-06 - val_dense_92_loss: 3.5438e-07 - val_dense_93_loss: 6.8783e-07 - val_dense_94_loss: 3.9863e-07 - val_dense_95_loss: 7.2535e-07 - val_dense_96_loss: 8.5760e-07 - val_dense_97_loss: 7.8899e-07 - val_dense_98_loss: 9.0435e-07 - val_dense_99_loss: 8.5770e-07\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.9477e-06 - dense_92_loss: 3.9204e-07 - dense_93_loss: 7.5779e-07 - dense_94_loss: 4.2123e-07 - dense_95_loss: 8.3856e-07 - dense_96_loss: 8.4953e-07 - dense_97_loss: 8.5955e-07 - dense_98_loss: 9.0699e-07 - dense_99_loss: 9.2202e-07 - val_loss: 5.9935e-06 - val_dense_92_loss: 3.4107e-07 - val_dense_93_loss: 8.7416e-07 - val_dense_94_loss: 4.0743e-07 - val_dense_95_loss: 8.6223e-07 - val_dense_96_loss: 8.2024e-07 - val_dense_97_loss: 8.4121e-07 - val_dense_98_loss: 9.1679e-07 - val_dense_99_loss: 9.3033e-07\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.6898e-06 - dense_92_loss: 3.7842e-07 - dense_93_loss: 7.0489e-07 - dense_94_loss: 4.1430e-07 - dense_95_loss: 7.8397e-07 - dense_96_loss: 8.2120e-07 - dense_97_loss: 8.1658e-07 - dense_98_loss: 8.9527e-07 - dense_99_loss: 8.7520e-07 - val_loss: 5.6457e-06 - val_dense_92_loss: 3.5949e-07 - val_dense_93_loss: 6.9225e-07 - val_dense_94_loss: 4.1560e-07 - val_dense_95_loss: 7.4482e-07 - val_dense_96_loss: 8.2925e-07 - val_dense_97_loss: 7.8860e-07 - val_dense_98_loss: 9.3460e-07 - val_dense_99_loss: 8.8104e-07\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.5636e-06 - dense_92_loss: 3.6195e-07 - dense_93_loss: 6.9012e-07 - dense_94_loss: 4.0240e-07 - dense_95_loss: 7.6067e-07 - dense_96_loss: 7.9558e-07 - dense_97_loss: 7.9999e-07 - dense_98_loss: 8.8955e-07 - dense_99_loss: 8.6333e-07 - val_loss: 5.8993e-06 - val_dense_92_loss: 3.9606e-07 - val_dense_93_loss: 7.1085e-07 - val_dense_94_loss: 4.3974e-07 - val_dense_95_loss: 7.7475e-07 - val_dense_96_loss: 8.4641e-07 - val_dense_97_loss: 8.4795e-07 - val_dense_98_loss: 9.7298e-07 - val_dense_99_loss: 9.1056e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.6671e-06 - dense_92_loss: 4.4270e-07 - dense_93_loss: 9.0119e-07 - dense_94_loss: 4.7293e-07 - dense_95_loss: 9.8600e-07 - dense_96_loss: 9.2147e-07 - dense_97_loss: 9.5911e-07 - dense_98_loss: 9.7678e-07 - dense_99_loss: 1.0069e-06 - val_loss: 5.8014e-06 - val_dense_92_loss: 3.3899e-07 - val_dense_93_loss: 8.2451e-07 - val_dense_94_loss: 3.8372e-07 - val_dense_95_loss: 8.0344e-07 - val_dense_96_loss: 8.1432e-07 - val_dense_97_loss: 8.1020e-07 - val_dense_98_loss: 9.1192e-07 - val_dense_99_loss: 9.1431e-07\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.8786e-06 - dense_92_loss: 3.9490e-07 - dense_93_loss: 7.4798e-07 - dense_94_loss: 4.2181e-07 - dense_95_loss: 8.0006e-07 - dense_96_loss: 8.5537e-07 - dense_97_loss: 8.3590e-07 - dense_98_loss: 9.1431e-07 - dense_99_loss: 9.0825e-07 - val_loss: 6.8876e-06 - val_dense_92_loss: 4.5814e-07 - val_dense_93_loss: 8.6586e-07 - val_dense_94_loss: 4.6738e-07 - val_dense_95_loss: 1.0325e-06 - val_dense_96_loss: 1.0232e-06 - val_dense_97_loss: 1.0006e-06 - val_dense_98_loss: 1.0492e-06 - val_dense_99_loss: 9.9064e-07\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.4719e-06 - dense_92_loss: 4.1301e-07 - dense_93_loss: 8.8763e-07 - dense_94_loss: 4.4922e-07 - dense_95_loss: 9.8159e-07 - dense_96_loss: 8.6699e-07 - dense_97_loss: 9.5746e-07 - dense_98_loss: 9.5322e-07 - dense_99_loss: 9.6274e-07 - val_loss: 6.2744e-06 - val_dense_92_loss: 3.7339e-07 - val_dense_93_loss: 7.7282e-07 - val_dense_94_loss: 4.8831e-07 - val_dense_95_loss: 8.5115e-07 - val_dense_96_loss: 8.8498e-07 - val_dense_97_loss: 9.2879e-07 - val_dense_98_loss: 9.9430e-07 - val_dense_99_loss: 9.8062e-07\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.8198e-06 - dense_92_loss: 3.8835e-07 - dense_93_loss: 7.1206e-07 - dense_94_loss: 4.2643e-07 - dense_95_loss: 7.9243e-07 - dense_96_loss: 8.4333e-07 - dense_97_loss: 8.3985e-07 - dense_98_loss: 9.1600e-07 - dense_99_loss: 9.0134e-07 - val_loss: 5.8115e-06 - val_dense_92_loss: 3.5009e-07 - val_dense_93_loss: 7.8708e-07 - val_dense_94_loss: 3.9964e-07 - val_dense_95_loss: 8.6654e-07 - val_dense_96_loss: 8.1141e-07 - val_dense_97_loss: 8.3034e-07 - val_dense_98_loss: 9.0686e-07 - val_dense_99_loss: 8.5957e-07\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5755e-06 - dense_92_loss: 3.6519e-07 - dense_93_loss: 6.8900e-07 - dense_94_loss: 4.0693e-07 - dense_95_loss: 7.5626e-07 - dense_96_loss: 8.1782e-07 - dense_97_loss: 7.8918e-07 - dense_98_loss: 8.9551e-07 - dense_99_loss: 8.5556e-07 - val_loss: 5.5460e-06 - val_dense_92_loss: 3.3659e-07 - val_dense_93_loss: 7.3232e-07 - val_dense_94_loss: 3.8237e-07 - val_dense_95_loss: 7.3014e-07 - val_dense_96_loss: 8.0659e-07 - val_dense_97_loss: 8.0234e-07 - val_dense_98_loss: 9.0884e-07 - val_dense_99_loss: 8.4681e-07\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6556e-06 - dense_92_loss: 3.6190e-07 - dense_93_loss: 7.0853e-07 - dense_94_loss: 4.0782e-07 - dense_95_loss: 7.7110e-07 - dense_96_loss: 8.2065e-07 - dense_97_loss: 8.0069e-07 - dense_98_loss: 9.1648e-07 - dense_99_loss: 8.6848e-07 - val_loss: 5.6835e-06 - val_dense_92_loss: 3.5080e-07 - val_dense_93_loss: 6.7723e-07 - val_dense_94_loss: 3.8952e-07 - val_dense_95_loss: 7.5575e-07 - val_dense_96_loss: 8.2244e-07 - val_dense_97_loss: 8.2872e-07 - val_dense_98_loss: 9.7312e-07 - val_dense_99_loss: 8.8594e-07\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.6096e-06 - dense_92_loss: 3.7170e-07 - dense_93_loss: 6.9166e-07 - dense_94_loss: 4.0149e-07 - dense_95_loss: 7.4307e-07 - dense_96_loss: 8.1199e-07 - dense_97_loss: 8.1955e-07 - dense_98_loss: 9.0346e-07 - dense_99_loss: 8.6664e-07 - val_loss: 5.6278e-06 - val_dense_92_loss: 3.6746e-07 - val_dense_93_loss: 6.8191e-07 - val_dense_94_loss: 4.1390e-07 - val_dense_95_loss: 6.9557e-07 - val_dense_96_loss: 8.7198e-07 - val_dense_97_loss: 8.2369e-07 - val_dense_98_loss: 9.2651e-07 - val_dense_99_loss: 8.4677e-07\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4668e-06 - dense_92_loss: 3.5902e-07 - dense_93_loss: 6.5870e-07 - dense_94_loss: 3.9910e-07 - dense_95_loss: 7.2283e-07 - dense_96_loss: 8.1466e-07 - dense_97_loss: 7.8471e-07 - dense_98_loss: 8.9101e-07 - dense_99_loss: 8.3675e-07 - val_loss: 5.5564e-06 - val_dense_92_loss: 3.5592e-07 - val_dense_93_loss: 6.8756e-07 - val_dense_94_loss: 4.0112e-07 - val_dense_95_loss: 7.2554e-07 - val_dense_96_loss: 8.4003e-07 - val_dense_97_loss: 7.8189e-07 - val_dense_98_loss: 9.0457e-07 - val_dense_99_loss: 8.5980e-07\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 7.8676e-06 - dense_92_loss: 5.0194e-07 - dense_93_loss: 1.1558e-06 - dense_94_loss: 5.2752e-07 - dense_95_loss: 1.2771e-06 - dense_96_loss: 1.0008e-06 - dense_97_loss: 1.1585e-06 - dense_98_loss: 1.0650e-06 - dense_99_loss: 1.1809e-06 - val_loss: 6.1611e-06 - val_dense_92_loss: 4.0885e-07 - val_dense_93_loss: 8.0363e-07 - val_dense_94_loss: 4.4704e-07 - val_dense_95_loss: 8.6277e-07 - val_dense_96_loss: 8.6601e-07 - val_dense_97_loss: 8.8841e-07 - val_dense_98_loss: 9.4250e-07 - val_dense_99_loss: 9.4188e-07\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.4810e-06 - dense_92_loss: 3.6167e-07 - dense_93_loss: 6.5888e-07 - dense_94_loss: 3.9464e-07 - dense_95_loss: 7.2076e-07 - dense_96_loss: 8.1768e-07 - dense_97_loss: 7.8559e-07 - dense_98_loss: 8.9236e-07 - dense_99_loss: 8.4939e-07 - val_loss: 5.4706e-06 - val_dense_92_loss: 3.4338e-07 - val_dense_93_loss: 6.3663e-07 - val_dense_94_loss: 3.9633e-07 - val_dense_95_loss: 7.1625e-07 - val_dense_96_loss: 8.4083e-07 - val_dense_97_loss: 7.8815e-07 - val_dense_98_loss: 9.2518e-07 - val_dense_99_loss: 8.2388e-07\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3595e-06 - dense_92_loss: 3.5464e-07 - dense_93_loss: 6.2696e-07 - dense_94_loss: 3.8998e-07 - dense_95_loss: 7.0232e-07 - dense_96_loss: 8.0946e-07 - dense_97_loss: 7.5849e-07 - dense_98_loss: 8.9345e-07 - dense_99_loss: 8.2418e-07 - val_loss: 5.4398e-06 - val_dense_92_loss: 3.2674e-07 - val_dense_93_loss: 6.5160e-07 - val_dense_94_loss: 3.8093e-07 - val_dense_95_loss: 7.1115e-07 - val_dense_96_loss: 8.2635e-07 - val_dense_97_loss: 7.5784e-07 - val_dense_98_loss: 9.4661e-07 - val_dense_99_loss: 8.3860e-07\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.4246e-06 - dense_92_loss: 3.6175e-07 - dense_93_loss: 6.4425e-07 - dense_94_loss: 3.9828e-07 - dense_95_loss: 7.3251e-07 - dense_96_loss: 7.9539e-07 - dense_97_loss: 7.6602e-07 - dense_98_loss: 8.8812e-07 - dense_99_loss: 8.3830e-07 - val_loss: 5.6267e-06 - val_dense_92_loss: 3.7991e-07 - val_dense_93_loss: 6.8259e-07 - val_dense_94_loss: 4.4345e-07 - val_dense_95_loss: 6.8031e-07 - val_dense_96_loss: 8.4804e-07 - val_dense_97_loss: 8.1380e-07 - val_dense_98_loss: 9.4675e-07 - val_dense_99_loss: 8.3190e-07\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.5952e-06 - dense_92_loss: 3.7184e-07 - dense_93_loss: 6.9113e-07 - dense_94_loss: 4.0875e-07 - dense_95_loss: 7.2882e-07 - dense_96_loss: 8.2736e-07 - dense_97_loss: 8.0380e-07 - dense_98_loss: 9.0578e-07 - dense_99_loss: 8.5770e-07 - val_loss: 6.3593e-06 - val_dense_92_loss: 4.4885e-07 - val_dense_93_loss: 7.1522e-07 - val_dense_94_loss: 4.7580e-07 - val_dense_95_loss: 8.0814e-07 - val_dense_96_loss: 9.7996e-07 - val_dense_97_loss: 9.0789e-07 - val_dense_98_loss: 1.0693e-06 - val_dense_99_loss: 9.5411e-07\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.5253e-06 - dense_92_loss: 3.7552e-07 - dense_93_loss: 6.5653e-07 - dense_94_loss: 4.0535e-07 - dense_95_loss: 7.1175e-07 - dense_96_loss: 8.3174e-07 - dense_97_loss: 7.8484e-07 - dense_98_loss: 9.0729e-07 - dense_99_loss: 8.5226e-07 - val_loss: 6.4796e-06 - val_dense_92_loss: 3.9662e-07 - val_dense_93_loss: 1.0272e-06 - val_dense_94_loss: 4.1072e-07 - val_dense_95_loss: 1.0563e-06 - val_dense_96_loss: 8.3978e-07 - val_dense_97_loss: 8.3207e-07 - val_dense_98_loss: 9.2856e-07 - val_dense_99_loss: 9.8833e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.9628e-06 - dense_92_loss: 3.9396e-07 - dense_93_loss: 7.7333e-07 - dense_94_loss: 4.1732e-07 - dense_95_loss: 8.3585e-07 - dense_96_loss: 8.4518e-07 - dense_97_loss: 8.5494e-07 - dense_98_loss: 9.2209e-07 - dense_99_loss: 9.2016e-07 - val_loss: 6.5082e-06 - val_dense_92_loss: 4.1971e-07 - val_dense_93_loss: 7.8393e-07 - val_dense_94_loss: 4.9062e-07 - val_dense_95_loss: 8.9659e-07 - val_dense_96_loss: 9.0866e-07 - val_dense_97_loss: 9.9732e-07 - val_dense_98_loss: 9.8632e-07 - val_dense_99_loss: 1.0250e-06\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5918e-06 - dense_92_loss: 3.8625e-07 - dense_93_loss: 6.7422e-07 - dense_94_loss: 4.0105e-07 - dense_95_loss: 7.4206e-07 - dense_96_loss: 8.3266e-07 - dense_97_loss: 7.8624e-07 - dense_98_loss: 8.9129e-07 - dense_99_loss: 8.7805e-07 - val_loss: 5.5667e-06 - val_dense_92_loss: 3.7479e-07 - val_dense_93_loss: 7.0720e-07 - val_dense_94_loss: 4.0878e-07 - val_dense_95_loss: 7.4203e-07 - val_dense_96_loss: 8.0821e-07 - val_dense_97_loss: 8.0302e-07 - val_dense_98_loss: 8.8500e-07 - val_dense_99_loss: 8.3767e-07\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4480e-06 - dense_92_loss: 3.6911e-07 - dense_93_loss: 6.4484e-07 - dense_94_loss: 4.0876e-07 - dense_95_loss: 7.0582e-07 - dense_96_loss: 8.2455e-07 - dense_97_loss: 7.7463e-07 - dense_98_loss: 8.8343e-07 - dense_99_loss: 8.3685e-07 - val_loss: 6.4975e-06 - val_dense_92_loss: 4.4081e-07 - val_dense_93_loss: 7.4810e-07 - val_dense_94_loss: 4.9672e-07 - val_dense_95_loss: 8.2520e-07 - val_dense_96_loss: 1.0051e-06 - val_dense_97_loss: 9.4834e-07 - val_dense_98_loss: 9.9424e-07 - val_dense_99_loss: 1.0390e-06\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.4537e-06 - dense_92_loss: 4.1794e-07 - dense_93_loss: 8.6559e-07 - dense_94_loss: 4.5053e-07 - dense_95_loss: 9.4058e-07 - dense_96_loss: 8.9915e-07 - dense_97_loss: 9.3510e-07 - dense_98_loss: 9.4921e-07 - dense_99_loss: 9.9560e-07 - val_loss: 6.2041e-06 - val_dense_92_loss: 3.6817e-07 - val_dense_93_loss: 8.5704e-07 - val_dense_94_loss: 4.5386e-07 - val_dense_95_loss: 9.0854e-07 - val_dense_96_loss: 8.8620e-07 - val_dense_97_loss: 8.7774e-07 - val_dense_98_loss: 9.5768e-07 - val_dense_99_loss: 8.9493e-07\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.8740e-06 - dense_92_loss: 3.9268e-07 - dense_93_loss: 7.3269e-07 - dense_94_loss: 4.3381e-07 - dense_95_loss: 7.9288e-07 - dense_96_loss: 8.5415e-07 - dense_97_loss: 8.5145e-07 - dense_98_loss: 9.1660e-07 - dense_99_loss: 8.9971e-07 - val_loss: 6.0066e-06 - val_dense_92_loss: 3.9435e-07 - val_dense_93_loss: 8.3477e-07 - val_dense_94_loss: 4.0373e-07 - val_dense_95_loss: 8.5341e-07 - val_dense_96_loss: 8.7999e-07 - val_dense_97_loss: 7.8595e-07 - val_dense_98_loss: 9.5004e-07 - val_dense_99_loss: 9.0434e-07\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6152e-06 - dense_92_loss: 3.9114e-07 - dense_93_loss: 6.6044e-07 - dense_94_loss: 4.2387e-07 - dense_95_loss: 7.2401e-07 - dense_96_loss: 8.5035e-07 - dense_97_loss: 7.9557e-07 - dense_98_loss: 9.1741e-07 - dense_99_loss: 8.5239e-07 - val_loss: 5.7920e-06 - val_dense_92_loss: 3.6786e-07 - val_dense_93_loss: 6.9264e-07 - val_dense_94_loss: 4.0962e-07 - val_dense_95_loss: 7.1071e-07 - val_dense_96_loss: 9.6601e-07 - val_dense_97_loss: 8.0304e-07 - val_dense_98_loss: 9.7649e-07 - val_dense_99_loss: 8.6562e-07\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4848e-06 - dense_92_loss: 3.7419e-07 - dense_93_loss: 6.4057e-07 - dense_94_loss: 4.1536e-07 - dense_95_loss: 6.9976e-07 - dense_96_loss: 8.4435e-07 - dense_97_loss: 7.7404e-07 - dense_98_loss: 9.0322e-07 - dense_99_loss: 8.3335e-07 - val_loss: 5.7247e-06 - val_dense_92_loss: 3.6768e-07 - val_dense_93_loss: 7.4445e-07 - val_dense_94_loss: 4.2899e-07 - val_dense_95_loss: 7.5986e-07 - val_dense_96_loss: 8.4055e-07 - val_dense_97_loss: 8.2757e-07 - val_dense_98_loss: 8.9671e-07 - val_dense_99_loss: 8.5885e-07\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.5405e-06 - dense_92_loss: 3.7902e-07 - dense_93_loss: 6.4517e-07 - dense_94_loss: 4.0850e-07 - dense_95_loss: 7.2304e-07 - dense_96_loss: 8.3122e-07 - dense_97_loss: 7.9762e-07 - dense_98_loss: 9.0067e-07 - dense_99_loss: 8.5523e-07 - val_loss: 5.9636e-06 - val_dense_92_loss: 3.6796e-07 - val_dense_93_loss: 7.6157e-07 - val_dense_94_loss: 4.2121e-07 - val_dense_95_loss: 8.2900e-07 - val_dense_96_loss: 8.2452e-07 - val_dense_97_loss: 9.4579e-07 - val_dense_98_loss: 8.7735e-07 - val_dense_99_loss: 9.3620e-07\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.5262e-06 - dense_92_loss: 3.8506e-07 - dense_93_loss: 6.4707e-07 - dense_94_loss: 4.0845e-07 - dense_95_loss: 7.1151e-07 - dense_96_loss: 8.2639e-07 - dense_97_loss: 7.8491e-07 - dense_98_loss: 9.0969e-07 - dense_99_loss: 8.5316e-07 - val_loss: 5.3056e-06 - val_dense_92_loss: 3.7315e-07 - val_dense_93_loss: 6.3784e-07 - val_dense_94_loss: 4.1890e-07 - val_dense_95_loss: 6.4023e-07 - val_dense_96_loss: 8.1108e-07 - val_dense_97_loss: 7.1239e-07 - val_dense_98_loss: 9.0401e-07 - val_dense_99_loss: 8.0801e-07\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.3633e-06 - dense_92_loss: 3.7405e-07 - dense_93_loss: 6.2708e-07 - dense_94_loss: 4.1078e-07 - dense_95_loss: 6.7818e-07 - dense_96_loss: 8.0939e-07 - dense_97_loss: 7.4155e-07 - dense_98_loss: 9.0362e-07 - dense_99_loss: 8.1863e-07 - val_loss: 6.2113e-06 - val_dense_92_loss: 4.0465e-07 - val_dense_93_loss: 8.9948e-07 - val_dense_94_loss: 4.3952e-07 - val_dense_95_loss: 7.7716e-07 - val_dense_96_loss: 8.5558e-07 - val_dense_97_loss: 8.5471e-07 - val_dense_98_loss: 1.0412e-06 - val_dense_99_loss: 9.3905e-07\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.8315e-06 - dense_92_loss: 4.1457e-07 - dense_93_loss: 7.0028e-07 - dense_94_loss: 4.3766e-07 - dense_95_loss: 7.4988e-07 - dense_96_loss: 8.6668e-07 - dense_97_loss: 8.2389e-07 - dense_98_loss: 9.6037e-07 - dense_99_loss: 8.7816e-07 - val_loss: 7.0437e-06 - val_dense_92_loss: 5.0571e-07 - val_dense_93_loss: 9.1272e-07 - val_dense_94_loss: 5.4279e-07 - val_dense_95_loss: 9.4056e-07 - val_dense_96_loss: 1.0209e-06 - val_dense_97_loss: 9.9771e-07 - val_dense_98_loss: 1.1296e-06 - val_dense_99_loss: 9.9366e-07\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6973e-06 - dense_92_loss: 4.1041e-07 - dense_93_loss: 6.6164e-07 - dense_94_loss: 4.4024e-07 - dense_95_loss: 7.2498e-07 - dense_96_loss: 8.5039e-07 - dense_97_loss: 8.0080e-07 - dense_98_loss: 9.5201e-07 - dense_99_loss: 8.5682e-07 - val_loss: 5.7154e-06 - val_dense_92_loss: 4.2091e-07 - val_dense_93_loss: 6.5947e-07 - val_dense_94_loss: 4.7946e-07 - val_dense_95_loss: 6.4858e-07 - val_dense_96_loss: 9.0318e-07 - val_dense_97_loss: 8.0462e-07 - val_dense_98_loss: 9.4934e-07 - val_dense_99_loss: 8.4988e-07\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6224e-06 - dense_92_loss: 4.0132e-07 - dense_93_loss: 6.6590e-07 - dense_94_loss: 4.2949e-07 - dense_95_loss: 7.0397e-07 - dense_96_loss: 8.5656e-07 - dense_97_loss: 7.8733e-07 - dense_98_loss: 9.2734e-07 - dense_99_loss: 8.5047e-07 - val_loss: 6.1351e-06 - val_dense_92_loss: 3.9515e-07 - val_dense_93_loss: 7.2164e-07 - val_dense_94_loss: 4.4879e-07 - val_dense_95_loss: 7.6570e-07 - val_dense_96_loss: 9.2404e-07 - val_dense_97_loss: 9.1241e-07 - val_dense_98_loss: 1.0124e-06 - val_dense_99_loss: 9.5499e-07\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.7698e-06 - dense_92_loss: 4.1596e-07 - dense_93_loss: 6.5290e-07 - dense_94_loss: 4.3971e-07 - dense_95_loss: 7.2921e-07 - dense_96_loss: 8.8623e-07 - dense_97_loss: 8.2447e-07 - dense_98_loss: 9.4416e-07 - dense_99_loss: 8.7711e-07 - val_loss: 6.3091e-06 - val_dense_92_loss: 4.7751e-07 - val_dense_93_loss: 6.4228e-07 - val_dense_94_loss: 5.0299e-07 - val_dense_95_loss: 8.1057e-07 - val_dense_96_loss: 1.0370e-06 - val_dense_97_loss: 9.2323e-07 - val_dense_98_loss: 1.0313e-06 - val_dense_99_loss: 8.8420e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5563e-06 - dense_92_loss: 3.8869e-07 - dense_93_loss: 6.3983e-07 - dense_94_loss: 4.2318e-07 - dense_95_loss: 7.0241e-07 - dense_96_loss: 8.4692e-07 - dense_97_loss: 7.8539e-07 - dense_98_loss: 9.2303e-07 - dense_99_loss: 8.4689e-07 - val_loss: 5.7114e-06 - val_dense_92_loss: 3.4234e-07 - val_dense_93_loss: 6.8195e-07 - val_dense_94_loss: 3.9789e-07 - val_dense_95_loss: 7.8185e-07 - val_dense_96_loss: 8.2596e-07 - val_dense_97_loss: 8.4588e-07 - val_dense_98_loss: 9.2927e-07 - val_dense_99_loss: 9.0628e-07\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.9165e-06 - dense_92_loss: 4.0425e-07 - dense_93_loss: 7.5623e-07 - dense_94_loss: 4.2983e-07 - dense_95_loss: 7.9100e-07 - dense_96_loss: 8.7055e-07 - dense_97_loss: 8.4137e-07 - dense_98_loss: 9.3601e-07 - dense_99_loss: 8.8730e-07 - val_loss: 1.1879e-05 - val_dense_92_loss: 6.7232e-07 - val_dense_93_loss: 2.1021e-06 - val_dense_94_loss: 6.5417e-07 - val_dense_95_loss: 2.2246e-06 - val_dense_96_loss: 1.1954e-06 - val_dense_97_loss: 1.9935e-06 - val_dense_98_loss: 1.4348e-06 - val_dense_99_loss: 1.6027e-06\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.4618e-06 - dense_92_loss: 4.7269e-07 - dense_93_loss: 1.0992e-06 - dense_94_loss: 4.9139e-07 - dense_95_loss: 1.1675e-06 - dense_96_loss: 9.6952e-07 - dense_97_loss: 1.0855e-06 - dense_98_loss: 1.0428e-06 - dense_99_loss: 1.1332e-06 - val_loss: 6.2096e-06 - val_dense_92_loss: 4.1595e-07 - val_dense_93_loss: 8.0436e-07 - val_dense_94_loss: 4.9540e-07 - val_dense_95_loss: 8.0376e-07 - val_dense_96_loss: 8.9036e-07 - val_dense_97_loss: 8.0410e-07 - val_dense_98_loss: 1.0473e-06 - val_dense_99_loss: 9.4836e-07\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6310e-06 - dense_92_loss: 4.1048e-07 - dense_93_loss: 6.0672e-07 - dense_94_loss: 4.4543e-07 - dense_95_loss: 7.1063e-07 - dense_96_loss: 8.5035e-07 - dense_97_loss: 7.8786e-07 - dense_98_loss: 9.3587e-07 - dense_99_loss: 8.8364e-07 - val_loss: 5.8341e-06 - val_dense_92_loss: 3.7390e-07 - val_dense_93_loss: 7.0527e-07 - val_dense_94_loss: 4.1216e-07 - val_dense_95_loss: 7.4834e-07 - val_dense_96_loss: 8.7500e-07 - val_dense_97_loss: 8.3419e-07 - val_dense_98_loss: 9.9497e-07 - val_dense_99_loss: 8.9029e-07\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5705e-06 - dense_92_loss: 3.9403e-07 - dense_93_loss: 6.2367e-07 - dense_94_loss: 4.2803e-07 - dense_95_loss: 6.8512e-07 - dense_96_loss: 8.4068e-07 - dense_97_loss: 7.9900e-07 - dense_98_loss: 9.3659e-07 - dense_99_loss: 8.6333e-07 - val_loss: 5.7963e-06 - val_dense_92_loss: 4.5511e-07 - val_dense_93_loss: 7.0922e-07 - val_dense_94_loss: 4.3034e-07 - val_dense_95_loss: 6.9687e-07 - val_dense_96_loss: 8.5892e-07 - val_dense_97_loss: 7.7566e-07 - val_dense_98_loss: 9.5984e-07 - val_dense_99_loss: 9.1035e-07\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3527e-06 - dense_92_loss: 3.9326e-07 - dense_93_loss: 5.6861e-07 - dense_94_loss: 4.1381e-07 - dense_95_loss: 6.4907e-07 - dense_96_loss: 8.3464e-07 - dense_97_loss: 7.4571e-07 - dense_98_loss: 9.2245e-07 - dense_99_loss: 8.2517e-07 - val_loss: 5.1949e-06 - val_dense_92_loss: 3.8195e-07 - val_dense_93_loss: 5.2744e-07 - val_dense_94_loss: 3.9833e-07 - val_dense_95_loss: 5.7062e-07 - val_dense_96_loss: 8.3539e-07 - val_dense_97_loss: 7.4215e-07 - val_dense_98_loss: 9.2855e-07 - val_dense_99_loss: 8.1045e-07\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2251e-06 - dense_92_loss: 3.8298e-07 - dense_93_loss: 5.4792e-07 - dense_94_loss: 4.1098e-07 - dense_95_loss: 6.1848e-07 - dense_96_loss: 8.2530e-07 - dense_97_loss: 7.3720e-07 - dense_98_loss: 9.0398e-07 - dense_99_loss: 7.9830e-07 - val_loss: 5.6692e-06 - val_dense_92_loss: 4.3456e-07 - val_dense_93_loss: 5.7945e-07 - val_dense_94_loss: 4.5515e-07 - val_dense_95_loss: 6.1223e-07 - val_dense_96_loss: 9.1258e-07 - val_dense_97_loss: 8.2670e-07 - val_dense_98_loss: 9.6265e-07 - val_dense_99_loss: 8.8592e-07\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.3753e-06 - dense_92_loss: 3.8392e-07 - dense_93_loss: 5.8098e-07 - dense_94_loss: 4.3711e-07 - dense_95_loss: 6.3251e-07 - dense_96_loss: 8.4848e-07 - dense_97_loss: 7.5255e-07 - dense_98_loss: 9.2282e-07 - dense_99_loss: 8.1692e-07 - val_loss: 5.4790e-06 - val_dense_92_loss: 3.5594e-07 - val_dense_93_loss: 6.9874e-07 - val_dense_94_loss: 4.1375e-07 - val_dense_95_loss: 6.8462e-07 - val_dense_96_loss: 8.5133e-07 - val_dense_97_loss: 7.1658e-07 - val_dense_98_loss: 9.6275e-07 - val_dense_99_loss: 7.9533e-07\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.3204e-06 - dense_92_loss: 3.8529e-07 - dense_93_loss: 5.5977e-07 - dense_94_loss: 4.1544e-07 - dense_95_loss: 6.3932e-07 - dense_96_loss: 8.3386e-07 - dense_97_loss: 7.4485e-07 - dense_98_loss: 9.2028e-07 - dense_99_loss: 8.2162e-07 - val_loss: 5.1185e-06 - val_dense_92_loss: 3.7081e-07 - val_dense_93_loss: 5.2860e-07 - val_dense_94_loss: 4.2101e-07 - val_dense_95_loss: 5.6891e-07 - val_dense_96_loss: 8.4555e-07 - val_dense_97_loss: 7.1776e-07 - val_dense_98_loss: 9.1055e-07 - val_dense_99_loss: 7.5531e-07\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2612e-06 - dense_92_loss: 3.7789e-07 - dense_93_loss: 5.5329e-07 - dense_94_loss: 4.1512e-07 - dense_95_loss: 6.2011e-07 - dense_96_loss: 8.4237e-07 - dense_97_loss: 7.3512e-07 - dense_98_loss: 9.0608e-07 - dense_99_loss: 8.1126e-07 - val_loss: 5.8224e-06 - val_dense_92_loss: 4.0036e-07 - val_dense_93_loss: 6.5097e-07 - val_dense_94_loss: 4.5371e-07 - val_dense_95_loss: 7.3809e-07 - val_dense_96_loss: 8.8958e-07 - val_dense_97_loss: 8.3240e-07 - val_dense_98_loss: 9.8411e-07 - val_dense_99_loss: 8.7314e-07\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.7743e-06 - dense_92_loss: 4.1238e-07 - dense_93_loss: 7.0700e-07 - dense_94_loss: 4.4054e-07 - dense_95_loss: 7.3069e-07 - dense_96_loss: 8.7516e-07 - dense_97_loss: 8.0017e-07 - dense_98_loss: 9.3956e-07 - dense_99_loss: 8.6879e-07 - val_loss: 5.7744e-06 - val_dense_92_loss: 4.0024e-07 - val_dense_93_loss: 6.0614e-07 - val_dense_94_loss: 4.4829e-07 - val_dense_95_loss: 6.1344e-07 - val_dense_96_loss: 9.8325e-07 - val_dense_97_loss: 7.9478e-07 - val_dense_98_loss: 1.0530e-06 - val_dense_99_loss: 8.7522e-07\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4773e-06 - dense_92_loss: 4.0118e-07 - dense_93_loss: 5.9079e-07 - dense_94_loss: 4.3069e-07 - dense_95_loss: 6.4630e-07 - dense_96_loss: 8.7720e-07 - dense_97_loss: 7.5887e-07 - dense_98_loss: 9.4086e-07 - dense_99_loss: 8.3138e-07 - val_loss: 5.7134e-06 - val_dense_92_loss: 4.1162e-07 - val_dense_93_loss: 6.2120e-07 - val_dense_94_loss: 4.7366e-07 - val_dense_95_loss: 6.1673e-07 - val_dense_96_loss: 9.1139e-07 - val_dense_97_loss: 7.9406e-07 - val_dense_98_loss: 9.8622e-07 - val_dense_99_loss: 8.9852e-07\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4638e-06 - dense_92_loss: 4.1751e-07 - dense_93_loss: 5.7221e-07 - dense_94_loss: 4.4500e-07 - dense_95_loss: 6.3023e-07 - dense_96_loss: 8.7081e-07 - dense_97_loss: 7.4251e-07 - dense_98_loss: 9.3734e-07 - dense_99_loss: 8.4819e-07 - val_loss: 5.7732e-06 - val_dense_92_loss: 4.2757e-07 - val_dense_93_loss: 6.1541e-07 - val_dense_94_loss: 4.5526e-07 - val_dense_95_loss: 6.6225e-07 - val_dense_96_loss: 9.2944e-07 - val_dense_97_loss: 7.8716e-07 - val_dense_98_loss: 9.9340e-07 - val_dense_99_loss: 9.0274e-07\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3750e-06 - dense_92_loss: 4.0030e-07 - dense_93_loss: 5.3895e-07 - dense_94_loss: 4.3076e-07 - dense_95_loss: 6.2427e-07 - dense_96_loss: 8.6673e-07 - dense_97_loss: 7.5000e-07 - dense_98_loss: 9.3847e-07 - dense_99_loss: 8.2549e-07 - val_loss: 5.1555e-06 - val_dense_92_loss: 3.6214e-07 - val_dense_93_loss: 5.5942e-07 - val_dense_94_loss: 4.2407e-07 - val_dense_95_loss: 5.5911e-07 - val_dense_96_loss: 8.3315e-07 - val_dense_97_loss: 7.1413e-07 - val_dense_98_loss: 9.3933e-07 - val_dense_99_loss: 7.6418e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5129e-06 - dense_92_loss: 4.0409e-07 - dense_93_loss: 5.8990e-07 - dense_94_loss: 4.3911e-07 - dense_95_loss: 6.5150e-07 - dense_96_loss: 8.6429e-07 - dense_97_loss: 7.5924e-07 - dense_98_loss: 9.4476e-07 - dense_99_loss: 8.6007e-07 - val_loss: 5.2955e-06 - val_dense_92_loss: 3.7874e-07 - val_dense_93_loss: 4.2525e-07 - val_dense_94_loss: 4.5952e-07 - val_dense_95_loss: 5.3546e-07 - val_dense_96_loss: 8.7850e-07 - val_dense_97_loss: 6.7655e-07 - val_dense_98_loss: 1.1039e-06 - val_dense_99_loss: 8.3761e-07\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.1688e-06 - dense_92_loss: 3.9155e-07 - dense_93_loss: 4.8604e-07 - dense_94_loss: 4.3203e-07 - dense_95_loss: 5.6450e-07 - dense_96_loss: 8.5186e-07 - dense_97_loss: 6.8547e-07 - dense_98_loss: 9.6704e-07 - dense_99_loss: 7.9032e-07 - val_loss: 7.8654e-06 - val_dense_92_loss: 5.3830e-07 - val_dense_93_loss: 1.2320e-06 - val_dense_94_loss: 4.9146e-07 - val_dense_95_loss: 1.2237e-06 - val_dense_96_loss: 1.0144e-06 - val_dense_97_loss: 1.0468e-06 - val_dense_98_loss: 1.0575e-06 - val_dense_99_loss: 1.2612e-06\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.7855e-06 - dense_92_loss: 4.1813e-07 - dense_93_loss: 6.9626e-07 - dense_94_loss: 4.5161e-07 - dense_95_loss: 7.1892e-07 - dense_96_loss: 8.7303e-07 - dense_97_loss: 7.9712e-07 - dense_98_loss: 9.4176e-07 - dense_99_loss: 8.8869e-07 - val_loss: 5.4565e-06 - val_dense_92_loss: 4.0672e-07 - val_dense_93_loss: 5.4053e-07 - val_dense_94_loss: 4.7752e-07 - val_dense_95_loss: 6.0173e-07 - val_dense_96_loss: 8.7690e-07 - val_dense_97_loss: 7.6235e-07 - val_dense_98_loss: 9.4098e-07 - val_dense_99_loss: 8.4980e-07\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.1323e-06 - dense_92_loss: 3.9513e-07 - dense_93_loss: 5.1463e-07 - dense_94_loss: 4.2555e-07 - dense_95_loss: 5.5055e-07 - dense_96_loss: 8.5227e-07 - dense_97_loss: 6.9920e-07 - dense_98_loss: 9.0622e-07 - dense_99_loss: 7.8880e-07 - val_loss: 5.2524e-06 - val_dense_92_loss: 3.6436e-07 - val_dense_93_loss: 5.3160e-07 - val_dense_94_loss: 3.9950e-07 - val_dense_95_loss: 5.4656e-07 - val_dense_96_loss: 8.7231e-07 - val_dense_97_loss: 7.3455e-07 - val_dense_98_loss: 9.5595e-07 - val_dense_99_loss: 8.4761e-07\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0904e-06 - dense_92_loss: 4.0671e-07 - dense_93_loss: 4.7462e-07 - dense_94_loss: 4.2571e-07 - dense_95_loss: 5.2746e-07 - dense_96_loss: 8.5596e-07 - dense_97_loss: 6.9068e-07 - dense_98_loss: 9.3029e-07 - dense_99_loss: 7.7901e-07 - val_loss: 5.1358e-06 - val_dense_92_loss: 4.4637e-07 - val_dense_93_loss: 4.4917e-07 - val_dense_94_loss: 4.4743e-07 - val_dense_95_loss: 5.2014e-07 - val_dense_96_loss: 8.9456e-07 - val_dense_97_loss: 6.7550e-07 - val_dense_98_loss: 9.2934e-07 - val_dense_99_loss: 7.7326e-07\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.9344e-06 - dense_92_loss: 3.9613e-07 - dense_93_loss: 4.4317e-07 - dense_94_loss: 4.2058e-07 - dense_95_loss: 4.9595e-07 - dense_96_loss: 8.4620e-07 - dense_97_loss: 6.5286e-07 - dense_98_loss: 9.2248e-07 - dense_99_loss: 7.5707e-07 - val_loss: 5.0379e-06 - val_dense_92_loss: 3.6707e-07 - val_dense_93_loss: 5.2527e-07 - val_dense_94_loss: 4.2623e-07 - val_dense_95_loss: 4.8434e-07 - val_dense_96_loss: 8.7025e-07 - val_dense_97_loss: 6.3521e-07 - val_dense_98_loss: 9.8302e-07 - val_dense_99_loss: 7.4648e-07\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.0646e-06 - dense_92_loss: 3.9554e-07 - dense_93_loss: 4.7787e-07 - dense_94_loss: 4.2920e-07 - dense_95_loss: 5.2909e-07 - dense_96_loss: 8.5435e-07 - dense_97_loss: 6.7670e-07 - dense_98_loss: 9.3052e-07 - dense_99_loss: 7.7130e-07 - val_loss: 5.2591e-06 - val_dense_92_loss: 3.7477e-07 - val_dense_93_loss: 5.5409e-07 - val_dense_94_loss: 4.4332e-07 - val_dense_95_loss: 5.0568e-07 - val_dense_96_loss: 9.8022e-07 - val_dense_97_loss: 6.7492e-07 - val_dense_98_loss: 9.5430e-07 - val_dense_99_loss: 7.7178e-07\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2380e-06 - dense_92_loss: 4.1875e-07 - dense_93_loss: 4.9486e-07 - dense_94_loss: 4.4850e-07 - dense_95_loss: 5.4969e-07 - dense_96_loss: 8.8465e-07 - dense_97_loss: 6.9943e-07 - dense_98_loss: 9.4244e-07 - dense_99_loss: 7.9964e-07 - val_loss: 5.2071e-06 - val_dense_92_loss: 4.1112e-07 - val_dense_93_loss: 5.1026e-07 - val_dense_94_loss: 4.2373e-07 - val_dense_95_loss: 5.2667e-07 - val_dense_96_loss: 8.9552e-07 - val_dense_97_loss: 6.8711e-07 - val_dense_98_loss: 9.9280e-07 - val_dense_99_loss: 7.5985e-07\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0846e-06 - dense_92_loss: 4.0611e-07 - dense_93_loss: 5.0679e-07 - dense_94_loss: 4.3245e-07 - dense_95_loss: 5.2752e-07 - dense_96_loss: 8.5733e-07 - dense_97_loss: 6.6026e-07 - dense_98_loss: 9.2398e-07 - dense_99_loss: 7.7014e-07 - val_loss: 5.9047e-06 - val_dense_92_loss: 4.0732e-07 - val_dense_93_loss: 6.8229e-07 - val_dense_94_loss: 4.6706e-07 - val_dense_95_loss: 7.4141e-07 - val_dense_96_loss: 8.9946e-07 - val_dense_97_loss: 7.8696e-07 - val_dense_98_loss: 1.0003e-06 - val_dense_99_loss: 9.1990e-07\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.1948e-06 - dense_92_loss: 4.0895e-07 - dense_93_loss: 5.1985e-07 - dense_94_loss: 4.5235e-07 - dense_95_loss: 5.4265e-07 - dense_96_loss: 8.7574e-07 - dense_97_loss: 6.6988e-07 - dense_98_loss: 9.4229e-07 - dense_99_loss: 7.8306e-07 - val_loss: 5.7580e-06 - val_dense_92_loss: 4.3557e-07 - val_dense_93_loss: 6.7903e-07 - val_dense_94_loss: 4.7674e-07 - val_dense_95_loss: 6.6725e-07 - val_dense_96_loss: 8.6499e-07 - val_dense_97_loss: 7.5412e-07 - val_dense_98_loss: 1.0151e-06 - val_dense_99_loss: 8.6525e-07\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0213e-06 - dense_92_loss: 4.0084e-07 - dense_93_loss: 4.4831e-07 - dense_94_loss: 4.5432e-07 - dense_95_loss: 5.0309e-07 - dense_96_loss: 8.4717e-07 - dense_97_loss: 6.5955e-07 - dense_98_loss: 9.3222e-07 - dense_99_loss: 7.7580e-07 - val_loss: 5.2130e-06 - val_dense_92_loss: 4.2028e-07 - val_dense_93_loss: 4.4433e-07 - val_dense_94_loss: 4.6122e-07 - val_dense_95_loss: 5.2842e-07 - val_dense_96_loss: 8.9531e-07 - val_dense_97_loss: 6.6587e-07 - val_dense_98_loss: 9.5803e-07 - val_dense_99_loss: 8.3959e-07\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.2569e-06 - dense_92_loss: 4.0272e-07 - dense_93_loss: 5.3656e-07 - dense_94_loss: 4.4705e-07 - dense_95_loss: 5.7101e-07 - dense_96_loss: 8.6109e-07 - dense_97_loss: 6.9657e-07 - dense_98_loss: 9.4483e-07 - dense_99_loss: 7.9711e-07 - val_loss: 4.9621e-06 - val_dense_92_loss: 4.2247e-07 - val_dense_93_loss: 3.9133e-07 - val_dense_94_loss: 4.1418e-07 - val_dense_95_loss: 4.0072e-07 - val_dense_96_loss: 8.7635e-07 - val_dense_97_loss: 6.8670e-07 - val_dense_98_loss: 1.0268e-06 - val_dense_99_loss: 7.4359e-07\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.8313e-06 - dense_92_loss: 4.0593e-07 - dense_93_loss: 4.0920e-07 - dense_94_loss: 4.4215e-07 - dense_95_loss: 4.3909e-07 - dense_96_loss: 8.3589e-07 - dense_97_loss: 6.2772e-07 - dense_98_loss: 9.4190e-07 - dense_99_loss: 7.2939e-07 - val_loss: 4.8944e-06 - val_dense_92_loss: 4.0021e-07 - val_dense_93_loss: 3.7606e-07 - val_dense_94_loss: 4.7245e-07 - val_dense_95_loss: 3.9523e-07 - val_dense_96_loss: 8.7641e-07 - val_dense_97_loss: 6.1417e-07 - val_dense_98_loss: 9.6200e-07 - val_dense_99_loss: 7.9784e-07\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.8261e-06 - dense_92_loss: 3.9214e-07 - dense_93_loss: 4.2559e-07 - dense_94_loss: 4.3684e-07 - dense_95_loss: 4.5983e-07 - dense_96_loss: 8.4051e-07 - dense_97_loss: 6.2791e-07 - dense_98_loss: 9.0591e-07 - dense_99_loss: 7.3736e-07 - val_loss: 6.5750e-06 - val_dense_92_loss: 5.3104e-07 - val_dense_93_loss: 6.9154e-07 - val_dense_94_loss: 5.5907e-07 - val_dense_95_loss: 8.1340e-07 - val_dense_96_loss: 1.0700e-06 - val_dense_97_loss: 9.6577e-07 - val_dense_98_loss: 9.7194e-07 - val_dense_99_loss: 9.7226e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.9417e-06 - dense_92_loss: 4.6258e-07 - dense_93_loss: 6.7559e-07 - dense_94_loss: 4.8836e-07 - dense_95_loss: 6.8916e-07 - dense_96_loss: 9.5502e-07 - dense_97_loss: 7.9938e-07 - dense_98_loss: 9.8939e-07 - dense_99_loss: 8.8226e-07 - val_loss: 5.7707e-06 - val_dense_92_loss: 3.9808e-07 - val_dense_93_loss: 6.2846e-07 - val_dense_94_loss: 5.1430e-07 - val_dense_95_loss: 6.6999e-07 - val_dense_96_loss: 9.2238e-07 - val_dense_97_loss: 7.1056e-07 - val_dense_98_loss: 1.0017e-06 - val_dense_99_loss: 9.2519e-07\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0072e-06 - dense_92_loss: 4.0418e-07 - dense_93_loss: 4.7253e-07 - dense_94_loss: 4.4453e-07 - dense_95_loss: 4.8879e-07 - dense_96_loss: 8.5492e-07 - dense_97_loss: 6.6385e-07 - dense_98_loss: 9.4346e-07 - dense_99_loss: 7.3497e-07 - val_loss: 5.0844e-06 - val_dense_92_loss: 3.6202e-07 - val_dense_93_loss: 4.5202e-07 - val_dense_94_loss: 5.0044e-07 - val_dense_95_loss: 5.0356e-07 - val_dense_96_loss: 9.0980e-07 - val_dense_97_loss: 6.7511e-07 - val_dense_98_loss: 9.1207e-07 - val_dense_99_loss: 7.6941e-07\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.8393e-06 - dense_92_loss: 3.8058e-07 - dense_93_loss: 4.5300e-07 - dense_94_loss: 4.2553e-07 - dense_95_loss: 4.7248e-07 - dense_96_loss: 8.3318e-07 - dense_97_loss: 6.2685e-07 - dense_98_loss: 9.2775e-07 - dense_99_loss: 7.1991e-07 - val_loss: 5.3267e-06 - val_dense_92_loss: 3.6864e-07 - val_dense_93_loss: 4.8976e-07 - val_dense_94_loss: 4.9091e-07 - val_dense_95_loss: 5.2933e-07 - val_dense_96_loss: 8.5843e-07 - val_dense_97_loss: 8.1568e-07 - val_dense_98_loss: 9.6382e-07 - val_dense_99_loss: 8.1008e-07\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6029e-06 - dense_92_loss: 4.1580e-07 - dense_93_loss: 6.6382e-07 - dense_94_loss: 4.6989e-07 - dense_95_loss: 6.5156e-07 - dense_96_loss: 9.0137e-07 - dense_97_loss: 7.6739e-07 - dense_98_loss: 9.3503e-07 - dense_99_loss: 7.9799e-07 - val_loss: 4.8708e-06 - val_dense_92_loss: 3.6071e-07 - val_dense_93_loss: 4.1647e-07 - val_dense_94_loss: 4.0554e-07 - val_dense_95_loss: 4.4714e-07 - val_dense_96_loss: 9.0147e-07 - val_dense_97_loss: 6.1702e-07 - val_dense_98_loss: 1.0112e-06 - val_dense_99_loss: 7.1127e-07\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.1069e-06 - dense_92_loss: 4.1212e-07 - dense_93_loss: 4.8241e-07 - dense_94_loss: 4.5090e-07 - dense_95_loss: 4.9645e-07 - dense_96_loss: 8.8309e-07 - dense_97_loss: 6.6760e-07 - dense_98_loss: 9.6268e-07 - dense_99_loss: 7.5171e-07 - val_loss: 4.9776e-06 - val_dense_92_loss: 3.9731e-07 - val_dense_93_loss: 4.2061e-07 - val_dense_94_loss: 4.1489e-07 - val_dense_95_loss: 4.4826e-07 - val_dense_96_loss: 8.4795e-07 - val_dense_97_loss: 7.1687e-07 - val_dense_98_loss: 9.9545e-07 - val_dense_99_loss: 7.3630e-07\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.7566e-06 - dense_92_loss: 3.8815e-07 - dense_93_loss: 4.2158e-07 - dense_94_loss: 4.2824e-07 - dense_95_loss: 4.2848e-07 - dense_96_loss: 8.4513e-07 - dense_97_loss: 6.2284e-07 - dense_98_loss: 9.1964e-07 - dense_99_loss: 7.0258e-07 - val_loss: 5.4736e-06 - val_dense_92_loss: 4.0864e-07 - val_dense_93_loss: 5.2643e-07 - val_dense_94_loss: 4.6345e-07 - val_dense_95_loss: 5.4543e-07 - val_dense_96_loss: 9.0425e-07 - val_dense_97_loss: 7.9781e-07 - val_dense_98_loss: 1.0199e-06 - val_dense_99_loss: 8.0770e-07\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.8805e-06 - dense_92_loss: 3.9599e-07 - dense_93_loss: 4.5453e-07 - dense_94_loss: 4.3135e-07 - dense_95_loss: 4.6869e-07 - dense_96_loss: 8.3824e-07 - dense_97_loss: 6.4036e-07 - dense_98_loss: 9.3170e-07 - dense_99_loss: 7.1963e-07 - val_loss: 4.4603e-06 - val_dense_92_loss: 3.5737e-07 - val_dense_93_loss: 2.9685e-07 - val_dense_94_loss: 4.2587e-07 - val_dense_95_loss: 3.2055e-07 - val_dense_96_loss: 8.9680e-07 - val_dense_97_loss: 5.9908e-07 - val_dense_98_loss: 8.9579e-07 - val_dense_99_loss: 6.6800e-07\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.4153e-06 - dense_92_loss: 3.7221e-07 - dense_93_loss: 3.2936e-07 - dense_94_loss: 4.0635e-07 - dense_95_loss: 3.5400e-07 - dense_96_loss: 8.4708e-07 - dense_97_loss: 5.6256e-07 - dense_98_loss: 8.8239e-07 - dense_99_loss: 6.6130e-07 - val_loss: 5.6315e-06 - val_dense_92_loss: 3.9057e-07 - val_dense_93_loss: 6.2299e-07 - val_dense_94_loss: 4.3394e-07 - val_dense_95_loss: 5.6109e-07 - val_dense_96_loss: 9.1264e-07 - val_dense_97_loss: 8.7271e-07 - val_dense_98_loss: 1.0163e-06 - val_dense_99_loss: 8.2127e-07\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.8850e-06 - dense_92_loss: 3.8895e-07 - dense_93_loss: 4.5670e-07 - dense_94_loss: 4.2294e-07 - dense_95_loss: 4.6522e-07 - dense_96_loss: 8.4902e-07 - dense_97_loss: 6.4951e-07 - dense_98_loss: 9.2090e-07 - dense_99_loss: 7.3174e-07 - val_loss: 5.2423e-06 - val_dense_92_loss: 4.0959e-07 - val_dense_93_loss: 4.0700e-07 - val_dense_94_loss: 4.3899e-07 - val_dense_95_loss: 5.1037e-07 - val_dense_96_loss: 9.6683e-07 - val_dense_97_loss: 7.3566e-07 - val_dense_98_loss: 9.9540e-07 - val_dense_99_loss: 7.7848e-07\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.8219e-06 - dense_92_loss: 3.9317e-07 - dense_93_loss: 4.4489e-07 - dense_94_loss: 4.2801e-07 - dense_95_loss: 4.3884e-07 - dense_96_loss: 8.6478e-07 - dense_97_loss: 6.2722e-07 - dense_98_loss: 9.2011e-07 - dense_99_loss: 7.0487e-07 - val_loss: 4.5184e-06 - val_dense_92_loss: 3.5946e-07 - val_dense_93_loss: 3.3093e-07 - val_dense_94_loss: 4.2798e-07 - val_dense_95_loss: 3.7725e-07 - val_dense_96_loss: 8.5859e-07 - val_dense_97_loss: 5.7121e-07 - val_dense_98_loss: 9.4006e-07 - val_dense_99_loss: 6.5293e-07\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.2768e-06 - dense_92_loss: 3.6269e-07 - dense_93_loss: 2.9288e-07 - dense_94_loss: 4.0189e-07 - dense_95_loss: 3.2507e-07 - dense_96_loss: 8.0656e-07 - dense_97_loss: 5.4188e-07 - dense_98_loss: 9.1237e-07 - dense_99_loss: 6.3350e-07 - val_loss: 4.4692e-06 - val_dense_92_loss: 3.4384e-07 - val_dense_93_loss: 3.3094e-07 - val_dense_94_loss: 4.1225e-07 - val_dense_95_loss: 4.0713e-07 - val_dense_96_loss: 8.5572e-07 - val_dense_97_loss: 5.4908e-07 - val_dense_98_loss: 9.0901e-07 - val_dense_99_loss: 6.6127e-07\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.8797e-06 - dense_92_loss: 3.9651e-07 - dense_93_loss: 4.7472e-07 - dense_94_loss: 4.3376e-07 - dense_95_loss: 4.7858e-07 - dense_96_loss: 8.3058e-07 - dense_97_loss: 6.3678e-07 - dense_98_loss: 9.1452e-07 - dense_99_loss: 7.1428e-07 - val_loss: 4.3607e-06 - val_dense_92_loss: 3.5942e-07 - val_dense_93_loss: 2.5962e-07 - val_dense_94_loss: 4.0546e-07 - val_dense_95_loss: 3.2926e-07 - val_dense_96_loss: 8.8258e-07 - val_dense_97_loss: 5.7716e-07 - val_dense_98_loss: 9.4270e-07 - val_dense_99_loss: 6.0447e-07\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5214e-06 - dense_92_loss: 3.8096e-07 - dense_93_loss: 3.6406e-07 - dense_94_loss: 4.1212e-07 - dense_95_loss: 3.8349e-07 - dense_96_loss: 8.2596e-07 - dense_97_loss: 5.8369e-07 - dense_98_loss: 9.1145e-07 - dense_99_loss: 6.5967e-07 - val_loss: 5.7536e-06 - val_dense_92_loss: 3.7596e-07 - val_dense_93_loss: 7.8707e-07 - val_dense_94_loss: 4.4463e-07 - val_dense_95_loss: 5.7724e-07 - val_dense_96_loss: 9.5195e-07 - val_dense_97_loss: 8.1506e-07 - val_dense_98_loss: 9.2615e-07 - val_dense_99_loss: 8.7551e-07\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.9675e-06 - dense_92_loss: 3.9971e-07 - dense_93_loss: 5.0777e-07 - dense_94_loss: 4.3745e-07 - dense_95_loss: 4.7674e-07 - dense_96_loss: 8.5265e-07 - dense_97_loss: 6.5586e-07 - dense_98_loss: 9.0538e-07 - dense_99_loss: 7.3193e-07 - val_loss: 4.4332e-06 - val_dense_92_loss: 3.6635e-07 - val_dense_93_loss: 3.2037e-07 - val_dense_94_loss: 4.1379e-07 - val_dense_95_loss: 3.1688e-07 - val_dense_96_loss: 8.1703e-07 - val_dense_97_loss: 6.3338e-07 - val_dense_98_loss: 8.9951e-07 - val_dense_99_loss: 6.6587e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.3797e-06 - dense_92_loss: 3.6051e-07 - dense_93_loss: 3.4952e-07 - dense_94_loss: 4.0761e-07 - dense_95_loss: 3.5330e-07 - dense_96_loss: 7.9594e-07 - dense_97_loss: 5.8546e-07 - dense_98_loss: 8.7982e-07 - dense_99_loss: 6.4758e-07 - val_loss: 5.1020e-06 - val_dense_92_loss: 3.6728e-07 - val_dense_93_loss: 6.0986e-07 - val_dense_94_loss: 3.9556e-07 - val_dense_95_loss: 5.0466e-07 - val_dense_96_loss: 8.4779e-07 - val_dense_97_loss: 6.6480e-07 - val_dense_98_loss: 9.1497e-07 - val_dense_99_loss: 7.9711e-07\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.7354e-06 - dense_92_loss: 3.8107e-07 - dense_93_loss: 4.7198e-07 - dense_94_loss: 4.1403e-07 - dense_95_loss: 4.6832e-07 - dense_96_loss: 7.9802e-07 - dense_97_loss: 6.2065e-07 - dense_98_loss: 8.8652e-07 - dense_99_loss: 6.9481e-07 - val_loss: 4.5325e-06 - val_dense_92_loss: 3.6010e-07 - val_dense_93_loss: 2.9664e-07 - val_dense_94_loss: 4.1136e-07 - val_dense_95_loss: 3.2074e-07 - val_dense_96_loss: 9.2770e-07 - val_dense_97_loss: 5.7974e-07 - val_dense_98_loss: 9.3477e-07 - val_dense_99_loss: 7.0143e-07\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2493e-06 - dense_92_loss: 3.6387e-07 - dense_93_loss: 2.8898e-07 - dense_94_loss: 4.0438e-07 - dense_95_loss: 3.1161e-07 - dense_96_loss: 8.3344e-07 - dense_97_loss: 5.4325e-07 - dense_98_loss: 8.8302e-07 - dense_99_loss: 6.2078e-07 - val_loss: 4.4989e-06 - val_dense_92_loss: 3.4784e-07 - val_dense_93_loss: 3.0290e-07 - val_dense_94_loss: 4.3653e-07 - val_dense_95_loss: 2.9115e-07 - val_dense_96_loss: 9.0519e-07 - val_dense_97_loss: 5.7493e-07 - val_dense_98_loss: 1.0071e-06 - val_dense_99_loss: 6.3324e-07\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.8111e-06 - dense_92_loss: 3.8675e-07 - dense_93_loss: 4.5805e-07 - dense_94_loss: 4.2571e-07 - dense_95_loss: 4.4309e-07 - dense_96_loss: 8.5991e-07 - dense_97_loss: 6.2361e-07 - dense_98_loss: 9.1941e-07 - dense_99_loss: 6.9452e-07 - val_loss: 5.0085e-06 - val_dense_92_loss: 3.9697e-07 - val_dense_93_loss: 5.4673e-07 - val_dense_94_loss: 4.7900e-07 - val_dense_95_loss: 3.8051e-07 - val_dense_96_loss: 8.3432e-07 - val_dense_97_loss: 7.2754e-07 - val_dense_98_loss: 9.0857e-07 - val_dense_99_loss: 7.3485e-07\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.5781e-06 - dense_92_loss: 3.7530e-07 - dense_93_loss: 4.0013e-07 - dense_94_loss: 4.1180e-07 - dense_95_loss: 4.0482e-07 - dense_96_loss: 8.2280e-07 - dense_97_loss: 5.9307e-07 - dense_98_loss: 8.9546e-07 - dense_99_loss: 6.7468e-07 - val_loss: 4.3004e-06 - val_dense_92_loss: 3.4394e-07 - val_dense_93_loss: 2.7538e-07 - val_dense_94_loss: 4.1733e-07 - val_dense_95_loss: 3.2754e-07 - val_dense_96_loss: 8.0014e-07 - val_dense_97_loss: 5.4473e-07 - val_dense_98_loss: 9.6781e-07 - val_dense_99_loss: 6.2355e-07\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5081e-06 - dense_92_loss: 3.7784e-07 - dense_93_loss: 3.6657e-07 - dense_94_loss: 4.1052e-07 - dense_95_loss: 3.7958e-07 - dense_96_loss: 8.2992e-07 - dense_97_loss: 6.0591e-07 - dense_98_loss: 8.9017e-07 - dense_99_loss: 6.4762e-07 - val_loss: 4.2340e-06 - val_dense_92_loss: 3.6613e-07 - val_dense_93_loss: 2.3192e-07 - val_dense_94_loss: 4.1368e-07 - val_dense_95_loss: 2.9338e-07 - val_dense_96_loss: 8.4554e-07 - val_dense_97_loss: 5.5114e-07 - val_dense_98_loss: 9.2395e-07 - val_dense_99_loss: 6.0824e-07\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.6202e-06 - dense_92_loss: 3.8197e-07 - dense_93_loss: 4.0868e-07 - dense_94_loss: 4.1756e-07 - dense_95_loss: 4.1076e-07 - dense_96_loss: 8.4494e-07 - dense_97_loss: 5.9604e-07 - dense_98_loss: 9.0461e-07 - dense_99_loss: 6.5561e-07 - val_loss: 4.5657e-06 - val_dense_92_loss: 3.5973e-07 - val_dense_93_loss: 3.3721e-07 - val_dense_94_loss: 4.6697e-07 - val_dense_95_loss: 3.4972e-07 - val_dense_96_loss: 8.2777e-07 - val_dense_97_loss: 5.9605e-07 - val_dense_98_loss: 9.1460e-07 - val_dense_99_loss: 7.1363e-07\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.5798e-06 - dense_92_loss: 3.8902e-07 - dense_93_loss: 3.6717e-07 - dense_94_loss: 4.2705e-07 - dense_95_loss: 3.9074e-07 - dense_96_loss: 8.2247e-07 - dense_97_loss: 5.9916e-07 - dense_98_loss: 9.1103e-07 - dense_99_loss: 6.7321e-07 - val_loss: 4.5702e-06 - val_dense_92_loss: 3.6159e-07 - val_dense_93_loss: 3.8263e-07 - val_dense_94_loss: 4.3800e-07 - val_dense_95_loss: 3.4987e-07 - val_dense_96_loss: 8.2129e-07 - val_dense_97_loss: 5.9454e-07 - val_dense_98_loss: 9.6294e-07 - val_dense_99_loss: 6.5938e-07\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.4777e-06 - dense_92_loss: 3.7135e-07 - dense_93_loss: 3.6009e-07 - dense_94_loss: 4.2013e-07 - dense_95_loss: 3.8000e-07 - dense_96_loss: 8.1909e-07 - dense_97_loss: 5.7627e-07 - dense_98_loss: 9.0251e-07 - dense_99_loss: 6.4829e-07 - val_loss: 4.3353e-06 - val_dense_92_loss: 3.9451e-07 - val_dense_93_loss: 2.8611e-07 - val_dense_94_loss: 4.2269e-07 - val_dense_95_loss: 2.5396e-07 - val_dense_96_loss: 8.8352e-07 - val_dense_97_loss: 5.2700e-07 - val_dense_98_loss: 9.5810e-07 - val_dense_99_loss: 6.0945e-07\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.3741e-06 - dense_92_loss: 3.8738e-07 - dense_93_loss: 3.2053e-07 - dense_94_loss: 4.1171e-07 - dense_95_loss: 3.3336e-07 - dense_96_loss: 8.2919e-07 - dense_97_loss: 5.5562e-07 - dense_98_loss: 9.0404e-07 - dense_99_loss: 6.3226e-07 - val_loss: 4.3622e-06 - val_dense_92_loss: 3.7270e-07 - val_dense_93_loss: 2.7814e-07 - val_dense_94_loss: 4.2917e-07 - val_dense_95_loss: 2.5696e-07 - val_dense_96_loss: 8.3018e-07 - val_dense_97_loss: 5.5235e-07 - val_dense_98_loss: 9.7592e-07 - val_dense_99_loss: 6.6679e-07\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.2951e-06 - dense_92_loss: 3.7751e-07 - dense_93_loss: 3.0589e-07 - dense_94_loss: 4.0924e-07 - dense_95_loss: 3.1387e-07 - dense_96_loss: 8.1447e-07 - dense_97_loss: 5.4198e-07 - dense_98_loss: 9.0164e-07 - dense_99_loss: 6.3047e-07 - val_loss: 4.7037e-06 - val_dense_92_loss: 3.5448e-07 - val_dense_93_loss: 4.3178e-07 - val_dense_94_loss: 4.4614e-07 - val_dense_95_loss: 3.7541e-07 - val_dense_96_loss: 8.2672e-07 - val_dense_97_loss: 6.3775e-07 - val_dense_98_loss: 9.2815e-07 - val_dense_99_loss: 7.0332e-07\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.3870e-06 - dense_92_loss: 3.7061e-07 - dense_93_loss: 3.4613e-07 - dense_94_loss: 4.1190e-07 - dense_95_loss: 3.3924e-07 - dense_96_loss: 8.1300e-07 - dense_97_loss: 5.6785e-07 - dense_98_loss: 8.8758e-07 - dense_99_loss: 6.5064e-07 - val_loss: 4.6624e-06 - val_dense_92_loss: 4.1981e-07 - val_dense_93_loss: 3.9011e-07 - val_dense_94_loss: 4.4018e-07 - val_dense_95_loss: 2.9766e-07 - val_dense_96_loss: 9.2527e-07 - val_dense_97_loss: 6.2337e-07 - val_dense_98_loss: 9.5415e-07 - val_dense_99_loss: 6.1189e-07\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.4199e-06 - dense_92_loss: 3.7587e-07 - dense_93_loss: 3.5796e-07 - dense_94_loss: 4.0890e-07 - dense_95_loss: 3.5941e-07 - dense_96_loss: 8.2893e-07 - dense_97_loss: 5.7303e-07 - dense_98_loss: 8.8632e-07 - dense_99_loss: 6.2952e-07 - val_loss: 5.2777e-06 - val_dense_92_loss: 4.5481e-07 - val_dense_93_loss: 3.7916e-07 - val_dense_94_loss: 4.8055e-07 - val_dense_95_loss: 5.0326e-07 - val_dense_96_loss: 9.7049e-07 - val_dense_97_loss: 7.5778e-07 - val_dense_98_loss: 1.0245e-06 - val_dense_99_loss: 7.0708e-07\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.5364e-06 - dense_92_loss: 4.0300e-07 - dense_93_loss: 3.4638e-07 - dense_94_loss: 4.1226e-07 - dense_95_loss: 3.6614e-07 - dense_96_loss: 8.4301e-07 - dense_97_loss: 5.9490e-07 - dense_98_loss: 9.0802e-07 - dense_99_loss: 6.6274e-07 - val_loss: 4.6047e-06 - val_dense_92_loss: 3.7913e-07 - val_dense_93_loss: 3.0989e-07 - val_dense_94_loss: 4.1925e-07 - val_dense_95_loss: 3.4153e-07 - val_dense_96_loss: 8.7284e-07 - val_dense_97_loss: 6.5426e-07 - val_dense_98_loss: 9.7974e-07 - val_dense_99_loss: 6.4806e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.2007e-06 - dense_92_loss: 3.6598e-07 - dense_93_loss: 2.7313e-07 - dense_94_loss: 4.0733e-07 - dense_95_loss: 2.8500e-07 - dense_96_loss: 8.1058e-07 - dense_97_loss: 5.5698e-07 - dense_98_loss: 9.0238e-07 - dense_99_loss: 5.9934e-07 - val_loss: 4.5000e-06 - val_dense_92_loss: 3.6254e-07 - val_dense_93_loss: 2.6236e-07 - val_dense_94_loss: 4.2482e-07 - val_dense_95_loss: 3.2480e-07 - val_dense_96_loss: 9.8387e-07 - val_dense_97_loss: 5.7699e-07 - val_dense_98_loss: 9.2536e-07 - val_dense_99_loss: 6.3923e-07\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.2391e-06 - dense_92_loss: 3.5850e-07 - dense_93_loss: 2.9573e-07 - dense_94_loss: 4.0827e-07 - dense_95_loss: 3.1376e-07 - dense_96_loss: 8.1745e-07 - dense_97_loss: 5.5735e-07 - dense_98_loss: 8.8087e-07 - dense_99_loss: 6.0712e-07 - val_loss: 4.5952e-06 - val_dense_92_loss: 3.7986e-07 - val_dense_93_loss: 2.6846e-07 - val_dense_94_loss: 4.4726e-07 - val_dense_95_loss: 3.8026e-07 - val_dense_96_loss: 9.3205e-07 - val_dense_97_loss: 5.9115e-07 - val_dense_98_loss: 9.4978e-07 - val_dense_99_loss: 6.4641e-07\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.3246e-06 - dense_92_loss: 3.8192e-07 - dense_93_loss: 2.8619e-07 - dense_94_loss: 4.2076e-07 - dense_95_loss: 3.0462e-07 - dense_96_loss: 8.3494e-07 - dense_97_loss: 5.7244e-07 - dense_98_loss: 9.1432e-07 - dense_99_loss: 6.0941e-07 - val_loss: 4.7908e-06 - val_dense_92_loss: 4.6934e-07 - val_dense_93_loss: 2.4721e-07 - val_dense_94_loss: 4.9544e-07 - val_dense_95_loss: 3.0214e-07 - val_dense_96_loss: 9.4346e-07 - val_dense_97_loss: 6.2690e-07 - val_dense_98_loss: 1.0178e-06 - val_dense_99_loss: 6.8852e-07\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.0438e-06 - dense_92_loss: 4.0927e-07 - dense_93_loss: 4.8770e-07 - dense_94_loss: 4.3553e-07 - dense_95_loss: 4.7803e-07 - dense_96_loss: 9.0476e-07 - dense_97_loss: 6.5753e-07 - dense_98_loss: 9.5269e-07 - dense_99_loss: 7.1825e-07 - val_loss: 4.6150e-06 - val_dense_92_loss: 3.7468e-07 - val_dense_93_loss: 2.6645e-07 - val_dense_94_loss: 4.4906e-07 - val_dense_95_loss: 3.2364e-07 - val_dense_96_loss: 9.4227e-07 - val_dense_97_loss: 6.2793e-07 - val_dense_98_loss: 9.9542e-07 - val_dense_99_loss: 6.3556e-07\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2993e-06 - dense_92_loss: 3.6649e-07 - dense_93_loss: 2.8301e-07 - dense_94_loss: 4.0911e-07 - dense_95_loss: 3.0461e-07 - dense_96_loss: 8.3122e-07 - dense_97_loss: 5.5927e-07 - dense_98_loss: 9.2824e-07 - dense_99_loss: 6.1740e-07 - val_loss: 4.4060e-06 - val_dense_92_loss: 3.6749e-07 - val_dense_93_loss: 2.7205e-07 - val_dense_94_loss: 4.5682e-07 - val_dense_95_loss: 2.8744e-07 - val_dense_96_loss: 8.2132e-07 - val_dense_97_loss: 6.1437e-07 - val_dense_98_loss: 9.6721e-07 - val_dense_99_loss: 6.1934e-07\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2701e-06 - dense_92_loss: 3.7192e-07 - dense_93_loss: 2.9316e-07 - dense_94_loss: 4.0648e-07 - dense_95_loss: 3.0563e-07 - dense_96_loss: 8.1676e-07 - dense_97_loss: 5.6499e-07 - dense_98_loss: 8.9237e-07 - dense_99_loss: 6.1883e-07 - val_loss: 4.5969e-06 - val_dense_92_loss: 3.7829e-07 - val_dense_93_loss: 2.8574e-07 - val_dense_94_loss: 4.2836e-07 - val_dense_95_loss: 3.0067e-07 - val_dense_96_loss: 8.9865e-07 - val_dense_97_loss: 6.7047e-07 - val_dense_98_loss: 9.5203e-07 - val_dense_99_loss: 6.8269e-07\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.3577e-06 - dense_92_loss: 3.7332e-07 - dense_93_loss: 3.1534e-07 - dense_94_loss: 4.0686e-07 - dense_95_loss: 3.4154e-07 - dense_96_loss: 8.1130e-07 - dense_97_loss: 5.6060e-07 - dense_98_loss: 9.0550e-07 - dense_99_loss: 6.4324e-07 - val_loss: 4.8666e-06 - val_dense_92_loss: 3.9144e-07 - val_dense_93_loss: 3.5794e-07 - val_dense_94_loss: 4.3635e-07 - val_dense_95_loss: 3.7623e-07 - val_dense_96_loss: 8.8813e-07 - val_dense_97_loss: 6.3736e-07 - val_dense_98_loss: 1.1176e-06 - val_dense_99_loss: 6.6149e-07\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.5369e-06 - dense_92_loss: 3.7944e-07 - dense_93_loss: 3.8824e-07 - dense_94_loss: 4.0828e-07 - dense_95_loss: 3.8959e-07 - dense_96_loss: 8.1320e-07 - dense_97_loss: 5.8166e-07 - dense_98_loss: 9.1052e-07 - dense_99_loss: 6.6596e-07 - val_loss: 4.5957e-06 - val_dense_92_loss: 3.9687e-07 - val_dense_93_loss: 2.4515e-07 - val_dense_94_loss: 4.5092e-07 - val_dense_95_loss: 3.2298e-07 - val_dense_96_loss: 8.7734e-07 - val_dense_97_loss: 6.1910e-07 - val_dense_98_loss: 1.0195e-06 - val_dense_99_loss: 6.6381e-07\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.1668e-06 - dense_92_loss: 4.2909e-07 - dense_93_loss: 5.2402e-07 - dense_94_loss: 4.5562e-07 - dense_95_loss: 4.9172e-07 - dense_96_loss: 8.7184e-07 - dense_97_loss: 6.9671e-07 - dense_98_loss: 9.6561e-07 - dense_99_loss: 7.3219e-07 - val_loss: 4.4926e-06 - val_dense_92_loss: 3.9634e-07 - val_dense_93_loss: 3.1160e-07 - val_dense_94_loss: 4.5972e-07 - val_dense_95_loss: 2.9032e-07 - val_dense_96_loss: 8.7396e-07 - val_dense_97_loss: 5.7293e-07 - val_dense_98_loss: 9.2600e-07 - val_dense_99_loss: 6.6171e-07\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.4310e-06 - dense_92_loss: 3.8426e-07 - dense_93_loss: 3.3676e-07 - dense_94_loss: 4.2382e-07 - dense_95_loss: 3.4875e-07 - dense_96_loss: 8.2442e-07 - dense_97_loss: 5.7190e-07 - dense_98_loss: 9.0115e-07 - dense_99_loss: 6.3992e-07 - val_loss: 4.7730e-06 - val_dense_92_loss: 4.4478e-07 - val_dense_93_loss: 3.7278e-07 - val_dense_94_loss: 4.2081e-07 - val_dense_95_loss: 3.7061e-07 - val_dense_96_loss: 8.8561e-07 - val_dense_97_loss: 6.0162e-07 - val_dense_98_loss: 9.8485e-07 - val_dense_99_loss: 6.9196e-07\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.2051e-06 - dense_92_loss: 3.7576e-07 - dense_93_loss: 2.6567e-07 - dense_94_loss: 3.9850e-07 - dense_95_loss: 2.8421e-07 - dense_96_loss: 8.3536e-07 - dense_97_loss: 5.2497e-07 - dense_98_loss: 9.1692e-07 - dense_99_loss: 6.0373e-07 - val_loss: 4.5612e-06 - val_dense_92_loss: 3.6863e-07 - val_dense_93_loss: 3.3469e-07 - val_dense_94_loss: 4.0868e-07 - val_dense_95_loss: 3.6425e-07 - val_dense_96_loss: 9.1467e-07 - val_dense_97_loss: 5.6559e-07 - val_dense_98_loss: 9.7112e-07 - val_dense_99_loss: 6.3353e-07\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00151: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1167afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        print('evaluating model for '+histgroup[0])\n",
    "        print(histstruct.evaluate_classifier(histgroup)[0].shape)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    print('Found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "            thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "            mse_good.append( thismse )\n",
    "            print(run)\n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    print('Found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        print('Found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34546ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model for NormalizedHitResiduals_TIB__Layer__1\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_1\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_2\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_3\n",
      "(2831,)\n",
      "evaluating model for chargeInner_PXLayer_4\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+1\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-1\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+2\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-2\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_+3\n",
      "(2831,)\n",
      "evaluating model for charge_PXDisk_-3\n",
      "(2831,)\n",
      "evaluating model for NormalizedHitResiduals_TOB__Layer__1\n",
      "(2831,)\n",
      "Found mse array for training set of following shape: (1678, 40)\n",
      "Found mse array for good set of following shape: (1537, 40)\n",
      "Found mse array for bad set of following shape: (44, 40)\n",
      "Found mse array for bad set of following shape: (35, 40)\n",
      "Found mse array for bad set of following shape: (46, 40)\n",
      "Found mse array for bad set of following shape: (19, 40)\n",
      "Found mse array for bad set of following shape: (22, 40)\n",
      "Found mse array for bad set of following shape: (28, 40)\n",
      "Found mse array for bad set of following shape: (12, 40)\n",
      "Found mse array for bad set of following shape: (32, 40)\n"
     ]
    }
   ],
   "source": [
    "(mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7105b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct, mse_train):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    for dims in dimslist:\n",
    "        thismse = mse_train[:,dims]\n",
    "        if training_mode=='global': \n",
    "            fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "            #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "            #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "            #                                                    'up')\n",
    "        else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "        #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "        #                onlycontour=False, xlims=30, ylims=30, \n",
    "        #                onlypositive=True, transparency=0.5,\n",
    "        #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "        #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "        #                title='density fit of lumisection MSE')\n",
    "        ##plt.close('all') # release plot memory\n",
    "        fitfunclist.append(fitfunc)\n",
    "     \n",
    "        \n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4988fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = fit_mse_distribution(histstruct, mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7437c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    print('--- good lumesections ---')\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    print('length of log prob array: '+str(len(logprob_good)))\n",
    "    print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "    #print(sorted(logprob_good))\n",
    "    \n",
    "    print('--- bad lumisections ---')\n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "    \n",
    "    print('length of log prob array: '+str(len(logprob_bad)))\n",
    "    print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "    #print(sorted(logprob_good))\n",
    "    #print(sorted(logprob_bad))\n",
    "    #print(logprob_bad)\n",
    "    \n",
    "    return [logprob_good, logprob_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a8ed5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- good lumesections ---\n",
      "length of log prob array: 1537\n",
      "minimum of log prob: 370.82188385506277\n",
      "--- bad lumisections ---\n",
      "length of log prob array: 238\n",
      "maximum of log prob: 410.0235904340274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_317647/688802665.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    }
   ],
   "source": [
    "(logprob_good, logprob_bad) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b777c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoder_individual(histstruct):\n",
    "    \n",
    "    msewps = []\n",
    "    for histname in histstruct.histnames:\n",
    "        \n",
    "        # Get histograms from histstruct\n",
    "        X_test_good = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'good']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        X_test_bad = X_test_bad = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'bad']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        # Get each model from the histstruct\n",
    "        autoencoder = histstruct.get_classifier(histname)\n",
    "        \n",
    "        # Getting evaluation criteria\n",
    "        prediction_test_good = autoencoder.reconstruct(X_test_good)\n",
    "        mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "        prediction_test_bad = autoencoder.reconstruct(X_test_bad)\n",
    "        mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "        \n",
    "        if userfriendly:\n",
    "            print('Average MSE on good set: ' + str(np.mean(mse_test_good)))\n",
    "            print('Average MSE on bad set: ' + str(np.mean(mse_test_bad)))\n",
    "        \n",
    "        if createPlots:\n",
    "            # Number of plots of each type to generate per model (so nplot * 2 * len(model))\n",
    "            nplot = 3\n",
    "            \n",
    "            # Good examples\n",
    "            print('Examples of good histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "            for i in randint: \n",
    "                histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "            \n",
    "            # Bad examples\n",
    "            print('Examples of bad histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "            for i in randint:\n",
    "                histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "        \n",
    "        # Attaching the bad histograms as a new set of rows under the good histograms\n",
    "        validation_data = np.vstack((X_test_good, X_test_bad))\n",
    "        validation_preds = np.vstack((prediction_test_good, prediction_test_bad))\n",
    "        # Creating labels to differentiate the data when we go to compare predictions\n",
    "        #     with actual label\n",
    "        labels = np.hstack((np.zeros(len(X_test_good)), np.ones(len(X_test_bad))))\n",
    "        \n",
    "        # Pick a working point to see \n",
    "        msewp = 0.5*(np.mean(mse_test_bad) - np.mean(mse_test_good))\n",
    "        print(\"Selected working point: \" + str(msewp))\n",
    "        \n",
    "        # Get data to pick a good working point for future evaluation\n",
    "        scores = aeu.mseTop10Raw(validation_data, validation_preds)\n",
    "        nsig = np.sum(labels)\n",
    "        nback = np.sum(1-labels)\n",
    "        \n",
    "        # Get some metrics for the user\n",
    "        tp = np.sum(np.where((labels==1) & (scores>msewp),1,0))/nsig\n",
    "        fp = np.sum(np.where((labels==0) & (scores>msewp),1,0))/nback\n",
    "        tn = 1-fp\n",
    "        fn = 1-tp\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2*precision*recall) / (precision + recall)\n",
    "        \n",
    "        if userfriendly:\n",
    "            print(accuracy)\n",
    "            print(precision)\n",
    "            print(recall)\n",
    "            print(f1)\n",
    "        \n",
    "    return msewps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "891a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad, biasFactor):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    badMin = min(np.where(logprob_bad != -np.inf, logprob_bad, np.inf))\n",
    "    goodMax = max(np.where(logprob_good != np.inf, logprob_good, -np.inf))\n",
    "    \n",
    "    # Getting rid of infinities\n",
    "    logprob_good[logprob_good > 500] = goodMax\n",
    "    logprob_bad[logprob_bad < 0] = badMin\n",
    "    # These only take effect if a histogram is grossly misclassified\n",
    "    logprob_good[logprob_good < badMin] = badMin\n",
    "    logprob_bad[logprob_bad > goodMax] = goodMax\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                       bcklabel='good', bckcolor='g', \n",
    "                       nbins=200, normalize=True,\n",
    "                       xaxtitle='negative logarithmic probability',\n",
    "                       yaxtitle='number of lumisections (normalized)')\n",
    "      \n",
    "    # Plot ROC curve for analysis\n",
    "    auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    # Average is biased towards better recall per user specifications\n",
    "    logprob_threshold = (1/(biasFactor + 1)) * (biasFactor*np.mean(logprob_good) + np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "    # logprob_threshold = 424\n",
    "    (_, _, _, tp, fp, tn, fn) = aeu.get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    print('Selected logprob threshold of ' + str(logprob_threshold))\n",
    "    \n",
    "    # Get metrics for analysis\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = (1 + biasFactor * biasFactor) * ((precision * recall) / ((biasFactor * biasFactor * precision) + recall)) \n",
    "    \n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('F-Measure: ' + str(f_measure))\n",
    "    \n",
    "    return logprob_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bbddf8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate_autoencoders_combined() missing 1 required positional argument: 'biasFactor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_317647/1609964662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogprob_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_autoencoders_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprob_good\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprob_bad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_autoencoders_combined() missing 1 required positional argument: 'biasFactor'"
     ]
    }
   ],
   "source": [
    "logprob_threshold = evaluate_autoencoders_combined(logprob_good, logprob_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msewps = evaluate_autoencoder_individual(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "356f7ddc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
