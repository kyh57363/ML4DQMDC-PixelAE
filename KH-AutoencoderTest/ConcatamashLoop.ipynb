{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba412492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 20:38:24.462231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.1-8d929/x86_64-centos7-gcc8-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.1-f3599/x86_64-centos7-gcc8-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/8u222-884d8/x86_64-centos7-gcc8-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.30-e5b21/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/3.6.3-dfb24/x86_64-centos7-gcc8-opt/lib64/R/library/readr/rcon\n",
      "2022-06-16 20:38:24.462265: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import SubHistStruct\n",
    "importlib.reload(SubHistStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed Controls and Run Mode\n",
    "\n",
    "# Disables all plots for large datasets where speed is more important\n",
    "createPlots = True\n",
    "\n",
    "# Control for the notebook - turn off user-friendly mode to enable faster runtimes\n",
    "userfriendly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4590f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = '../data/'\n",
    "\n",
    "# Select a list of good runs to train on in development training_mode\n",
    "# Should be validated by eye\n",
    "trainrunsls = [\n",
    "                    {\"297057\":[[-1]]}, \n",
    "#                    {\"297099\":[[-1]]}, \n",
    "                    {\"297101\":[[-1]]},\n",
    "                    {\"297113\":[[-1]]}, \n",
    "                    {\"297114\":[[-1]]}, \n",
    "                    {\"297175\":[[-1]]},\n",
    "                    {\"297177\":[[-1]]},\n",
    "                    {\"297179\":[[-1]]}, \n",
    "                    {\"297215\":[[-1]]},\n",
    "#                    {\"297218\":[[-1]]},\n",
    "                    {\"297225\":[[-1]]},\n",
    "                    {\"297296\":[[-1]]}, \n",
    "                    {\"297411\":[[-1]]},\n",
    "                    {\"297426\":[[-1]]},\n",
    "                    {\"297431\":[[-1]]},\n",
    "                    {\"297434\":[[-1]]},\n",
    "                    {\"297468\":[[-1]]},\n",
    "                    {\"297483\":[[-1]]},\n",
    "                    {\"297486\":[[-1]]},\n",
    "                    {\"297503\":[[-1]]},\n",
    "                    {\"297557\":[[-1]]},\n",
    "                    {\"297598\":[[-1]]},\n",
    "                    {\"297604\":[[-1]]},\n",
    "                    {\"297620\":[[-1]]}, \n",
    "                    {\"297659\":[[-1]]},\n",
    "                    {\"297670\":[[-1]]},\n",
    "                    {\"297674\":[[-1]]},\n",
    "                    {\"297678\":[[-1]]}, \n",
    "                    {\"297722\":[[-1]]},\n",
    "                    {\"298997\":[[-1]]},\n",
    "                    {\"299061\":[[-1]]},\n",
    "                    {\"299065\":[[-1]]}, \n",
    "                    {\"299067\":[[-1]]},\n",
    "                    {\"299096\":[[-1]]},\n",
    "                    {\"299149\":[[-1]]},\n",
    "                    {\"299178\":[[-1]]}, \n",
    "                    {\"299184\":[[-1]]},\n",
    "                    {\"299185\":[[-1]]},\n",
    "                    {\"299327\":[[-1]]},\n",
    "                    {\"299329\":[[-1]]}, \n",
    "                    {\"299480\":[[-1]]} \n",
    "]\n",
    "              \n",
    "\n",
    "# Select a list of good runs to test on in development training_mode\n",
    "# Should be validated by eye\n",
    "goodrunsls = {'2017':{\n",
    "                    \"297057\":[[-1]], \n",
    "                    \"297099\":[[-1]], \n",
    "                    \"297101\":[[-1]],\n",
    "                    \"297113\":[[-1]], \n",
    "                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],\n",
    "                    \"297177\":[[-1]],\n",
    "                    \"297179\":[[-1]], \n",
    "                    \"297215\":[[-1]],\n",
    "                    \"297218\":[[-1]],\n",
    "                    \"297225\":[[-1]],\n",
    "                    \"297296\":[[-1]], \n",
    "                    \"297411\":[[-1]],\n",
    "                    \"297426\":[[-1]],\n",
    "                    \"297431\":[[-1]],\n",
    "                    \"297434\":[[-1]],\n",
    "                    \"297468\":[[-1]],\n",
    "                    \"297483\":[[-1]],\n",
    "                    \"297486\":[[-1]],\n",
    "                    \"297503\":[[-1]],\n",
    "                    \"297557\":[[-1]],\n",
    "                    \"297598\":[[-1]],\n",
    "                    \"297604\":[[-1]],\n",
    "                    \"297620\":[[-1]], \n",
    "                    \"297659\":[[-1]],\n",
    "                    \"297670\":[[-1]],\n",
    "                    \"297674\":[[-1]],\n",
    "                    \"297678\":[[-1]], \n",
    "                    \"297722\":[[-1]],\n",
    "                    \"298997\":[[-1]],\n",
    "                    \"299061\":[[-1]],\n",
    "                    \"299065\":[[-1]], \n",
    "                    \"299067\":[[-1]],\n",
    "                    \"299096\":[[-1]],\n",
    "                    \"299149\":[[-1]],\n",
    "                    \"299178\":[[-1]], \n",
    "                    \"299184\":[[-1]],\n",
    "                    \"299185\":[[-1]],\n",
    "                    \"299327\":[[-1]],\n",
    "                    \"299329\":[[-1]], \n",
    "                    \"299480\":[[-1]]\n",
    "              }\n",
    "              \n",
    "}\n",
    "\n",
    "\n",
    "badrunsls = {'2017':\n",
    "                {\n",
    "                    #\"297048\":[[-1]],\n",
    "                    #\"297282\":[[-1]],\n",
    "                    #\"297283\":[[-1]],\n",
    "                    #\"297284\":[[-1]],\n",
    "                    #\"297287\":[[-1]],\n",
    "                    #\"297288\":[[-1]],\n",
    "                    #\"297289\":[[-1]],\n",
    "                    \"299316\":[[-1]],\n",
    "                    \"299317\":[[-1]],\n",
    "                    \"299318\":[[-1]],\n",
    "                    \"299324\":[[-1]],\n",
    "                    \"299326\":[[-1]],\n",
    "                    #\"301086\":[[88,126]],\n",
    "                    #\"301086\":[[89,89]],\n",
    "                    #\"303948\":[[1710,1710]],\n",
    "                    \"297047\":[[-1]], #close but, true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297211\":[[-1]], #Reconstructs well\n",
    "#                   \"299325\":[[-1]], #Reconstructs well\n",
    "                    \"297664\":[[-1]], #true bad for all 8\n",
    "                    \"299317\":[[-1]], #true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                    \"297502\":[[-1]]\n",
    "                },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "\n",
    "# The year and eras being used\n",
    "year = '2017'\n",
    "eras = ['B']\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = [\n",
    "    ['NormalizedHitResiduals_TIB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1', 'NormalizedHitResiduals_TIB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2',\n",
    "     'NormalizedHitResiduals_TIB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3' , 'NormalizedHitResiduals_TIB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4'],\n",
    "    ['chargeInner_PXLayer_1', 'chargeOuter_PXLayer_1', 'adc_PXLayer_1'],\n",
    "    ['chargeInner_PXLayer_2', 'chargeOuter_PXLayer_2', 'adc_PXLayer_2'],\n",
    "    ['chargeInner_PXLayer_3', 'chargeOuter_PXLayer_3', 'adc_PXLayer_3'],\n",
    "    ['chargeInner_PXLayer_4', 'chargeOuter_PXLayer_4', 'adc_PXLayer_4'],\n",
    "    ['charge_PXDisk_+1', 'adc_PXDisk_+1'],\n",
    "    ['charge_PXDisk_-1', 'adc_PXDisk_-1'],\n",
    "    ['charge_PXDisk_+2', 'adc_PXDisk_+2'],\n",
    "    ['charge_PXDisk_-2', 'adc_PXDisk_-2'],\n",
    "    ['charge_PXDisk_+3', 'adc_PXDisk_+3'],\n",
    "    ['charge_PXDisk_-3', 'adc_PXDisk_-3'],\n",
    "    ['NormalizedHitResiduals_TOB__Layer__1', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__1', 'NormalizedHitResiduals_TOB__Layer__2', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__2',\n",
    "     'NormalizedHitResiduals_TOB__Layer__3', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__3' , 'NormalizedHitResiduals_TOB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__4']\n",
    "]\n",
    "\n",
    "# Read new data or use previously saved data & should data be saved\n",
    "readnew = True\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ffebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Set whether to train globally or locally or in a development/testing mode\n",
    "training_mode = 'development'\n",
    "\n",
    "# Selects whether to create a new histstruct or use a saved one\n",
    "readnew = True\n",
    "\n",
    "# Select whether to save a new histstruct\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6394238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames\n",
    "\n",
    "# Evaluate models seperately, as an ensemble, both, or neither\n",
    "individualEval = True\n",
    "ensembleEval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_combined_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            ## Model parameters\n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(256, activation=\"tanh\")(conc_layer)\n",
    "            encoder = Dense(128, activation='relu')(encoder)\n",
    "            \n",
    "            encoder = Dense(64, activation='relu')(encoder)\n",
    "            \n",
    "            decoder = Dense(128, activation=\"relu\")(encoder)\n",
    "            decoder = Dense(256, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_combined_autoencoder(histslist, vallist, autoencoders):\n",
    "    \n",
    "    # Iterate through the training data to train corresponding autoencoders\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        if userfriendly: print('\\nNow training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 200\n",
    "        batch_size = 100\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=0,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                            epochs=nb_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                            verbose=0,\n",
    "                                callbacks= [earlystop] \n",
    "                            )\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1167afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        histstruct.evaluate_classifier(histgroup)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "            thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "            mse_good.append( thismse )\n",
    "            \n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7105b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    for dims in dimslist:\n",
    "        thismse = mse_train[:,dims]\n",
    "        if training_mode=='global': \n",
    "            fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "            #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "            #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "            #                                                    'up')\n",
    "        else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "        #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "        #                onlycontour=False, xlims=30, ylims=30, \n",
    "        #                onlypositive=True, transparency=0.5,\n",
    "        #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "        #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "        #                title='density fit of lumisection MSE')\n",
    "        ##plt.close('all') # release plot memory\n",
    "        fitfunclist.append(fitfunc)\n",
    "     \n",
    "        \n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7437c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    #print(sorted(logprob_good))\n",
    "    \n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "    \n",
    "    return [logprob_good, logprob_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09b777c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoder_individual(histstruct):\n",
    "    \n",
    "    msewps = []\n",
    "    for histname in histstruct.histnames:\n",
    "        \n",
    "        # Get histograms from histstruct\n",
    "        X_test_good = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'good']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        X_test_bad = X_test_bad = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'bad']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "        \n",
    "        # Get each model from the histstruct\n",
    "        autoencoder = histstruct.get_classifier(histname)\n",
    "        \n",
    "        # Getting evaluation criteria\n",
    "        prediction_test_good = autoencoder.reconstruct(X_test_good)\n",
    "        mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "        prediction_test_bad = autoencoder.reconstruct(X_test_bad)\n",
    "        mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "        \n",
    "        \n",
    "        if createPlots:\n",
    "            # Number of plots of each type to generate per model (so nplot * 2 * len(model))\n",
    "            nplot = 3\n",
    "            \n",
    "            # Good examples\n",
    "            print('Examples of good histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "            for i in randint: \n",
    "                histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "            \n",
    "            # Bad examples\n",
    "            print('Examples of bad histograms and reconstruction:')\n",
    "            randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "            for i in randint:\n",
    "                histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "                labellist = ['data','reconstruction']\n",
    "                colorlist = ['black','blue']\n",
    "                pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "                plt.show()\n",
    "        \n",
    "        # Attaching the bad histograms as a new set of rows under the good histograms\n",
    "        validation_data = np.vstack((X_test_good, X_test_bad))\n",
    "        validation_preds = np.vstack((prediction_test_good, prediction_test_bad))\n",
    "        # Creating labels to differentiate the data when we go to compare predictions\n",
    "        #     with actual label\n",
    "        labels = np.hstack((np.zeros(len(X_test_good)), np.ones(len(X_test_bad))))\n",
    "        \n",
    "        # Pick a working point to see \n",
    "        msewp = 0.5*(np.mean(mse_test_bad) - np.mean(mse_test_good))\n",
    "        print(\"Selected working point: \" + str(msewp))\n",
    "        \n",
    "        # Get data to pick a good working point for future evaluation\n",
    "        scores = aeu.mseTop10Raw(validation_data, validation_preds)\n",
    "        nsig = np.sum(labels)\n",
    "        nback = np.sum(1-labels)\n",
    "        \n",
    "        # Get some metrics for the user\n",
    "        tp = np.sum(np.where((labels==1) & (scores>msewp),1,0))/nsig\n",
    "        fp = np.sum(np.where((labels==0) & (scores>msewp),1,0))/nback\n",
    "        tn = 1-fp\n",
    "        fn = 1-tp\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2*precision*recall) / (precision + recall)\n",
    "        \n",
    "        if userfriendly:\n",
    "            print(accuracy)\n",
    "            print(precision)\n",
    "            print(recall)\n",
    "            print(f1)\n",
    "        \n",
    "    return msewps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "891a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    #pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "    #                   bcklabel='good', bckcolor='g', \n",
    "    #                   nbins=200, normalize=True,\n",
    "    #                   xaxtitle='negative logarithmic probability',\n",
    "    #                   yaxtitle='number of lumisections (normalized)')\n",
    "    \n",
    "    logprob_good[logprob_good > 500] = -500\n",
    "    logprob_bad[logprob_bad < 0] = 0\n",
    "    logprob_good[logprob_good < 0] = 0\n",
    "    logprob_bad[logprob_bad > 500] = 500\n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    logprob_threshold = 0.5 * (np.mean(logprob_good) - np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "\n",
    "    # Get metrics for analysis\n",
    "    (tp, fp, tn, fn) = get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_measure = (2 * precision * recall) / (precision + recall)\n",
    "    print('Selected logprob threshold of ' + str(logprob_threshold))\n",
    "\n",
    "    \n",
    "    return [accuracy, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bbddf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(scores, labels, wp):\n",
    "    nsig = np.sum(labels)\n",
    "    nback = np.sum(1-labels)\n",
    "\n",
    "    # get confusion matrix entries\n",
    "    tp = np.sum(np.where((labels==1) & (scores>wp),1,0))/nsig\n",
    "    fp = np.sum(np.where((labels==0) & (scores>wp),1,0))/nback\n",
    "    tn = 1-fp\n",
    "    fn = 1-tp\n",
    "    cmat = np.array([[tp,fn],[fp,tn]])\n",
    "    \n",
    "    return(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4051dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: {'297057': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to 332.8092645409154\n",
      "Selected logprob threshold of 51.32703952568024\n",
      "Accuracy: 0.6319083368403904\n",
      "Recall: 0.9831932773109243\n",
      "New Best Run: {'297057': [[-1]]}\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297101': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to 325.8558775083542\n",
      "Selected logprob threshold of 51.43129552378572\n",
      "Accuracy: 0.6187263273645485\n",
      "Recall: 0.9747899159663865\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297113': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to 314.6045211277915\n",
      "Selected logprob threshold of 51.67749567363141\n",
      "Accuracy: 0.6218826787580944\n",
      "Recall: 0.9831932773109243\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297114': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to 254.20540281353072\n",
      "Selected logprob threshold of 44.853195794229826\n",
      "Accuracy: 0.6147011308562197\n",
      "Recall: 1.0\n",
      "New Best Run: {'297114': [[-1]]}\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297175': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to 280.6836887252706\n",
      "Selected logprob threshold of 44.505501549360915\n",
      "Accuracy: 0.616269124774304\n",
      "Recall: 1.0\n",
      "New Best Run: {'297175': [[-1]]}\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297177': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to 287.18131048713843\n",
      "Selected logprob threshold of 23.981865214226175\n",
      "Accuracy: 0.6088737595199631\n",
      "Recall: 0.9873949579831933\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297179': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to 306.53050024603476\n",
      "Selected logprob threshold of 1.8597102130534784\n",
      "Accuracy: 0.5130462524266572\n",
      "Recall: 0.9915966386554622\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297215': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71773/3406801837.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
      "/tmp/ipykernel_71773/3406801837.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
      "/tmp/ipykernel_71773/2997766680.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: scores of +inf were reset to -380.6419637566345\n",
      "Selected logprob threshold of 1.3607534727319832\n",
      "Accuracy: 0.5\n",
      "Recall: 0.0\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Run: {'297225': [[-1]]}\n",
      "\n",
      "Training models...\n",
      "\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "24-th leading minor of the array is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_71773/3583989559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mmse_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_good_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_bad_eval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_models_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiststruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mfitfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_mse_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiststruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mlogprob_good\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprob_bad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiststruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_good_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_bad_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_autoencoders_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprob_good\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprob_bad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_71773/3362655799.py\u001b[0m in \u001b[0;36mfit_mse_distribution\u001b[0;34m(histstruct)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mfitfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeminormalFitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeminormalFitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfitfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianKdeFitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianKdeFitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfitfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/cloudfitters/GaussianKdeFitter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, points, bw_method, bw_scott_factor)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mscott_bw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mbw_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_scott_factor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscott_bw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n\u001b[0m\u001b[1;32m     89\u001b[0m                          check_finite=check_finite)\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n\u001b[0m\u001b[1;32m     38\u001b[0m                           \"definite\" % info)\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 24-th leading minor of the array is not positive definite"
     ]
    }
   ],
   "source": [
    "bestRun = [{}, 0, 0]\n",
    "for i, run in enumerate(trainrunsls):\n",
    "    \n",
    "    print('Run: {}'.format(run))\n",
    "    \n",
    "    # Select runs to be used in training from the user-defined list\n",
    "    runsls_training = run\n",
    "    # Select bad runs to test on in the user-defined list\n",
    "    runsls_bad = badrunsls['2017']\n",
    "    # Select good runs to test on in the user-defined list\n",
    "    runsls_good = goodrunsls['2017']\n",
    "        \n",
    "    \n",
    "    # Initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = SubHistStruct.SubHistStruct()\n",
    "\n",
    "    save_stdout = sys.stdout\n",
    "    sys.stdout = open('trash', 'w')\n",
    "    histstruct.reset_histlist(histnames)\n",
    "    sys.stdout = save_stdout\n",
    "    \n",
    "    # Unpack histnames and add every histogram individually\n",
    "    for histnamegroup in histnames:\n",
    "        for histname in histnamegroup:\n",
    "            \n",
    "            # Bring the histograms into memory from storage for later use\n",
    "            filename = '../data/DF'+year+'B_'+histname+'.csv'\n",
    "            df = dloader.get_dataframe_from_file( filename )\n",
    "            \n",
    "            # In case of local training, we can remove most of the histograms\n",
    "            if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "                runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "                df = dfu.select_runsls( df, runsls_total )\n",
    "                \n",
    "            # Store the data in the histstruct object managing this whole thing\n",
    "            save_stdout = sys.stdout\n",
    "            sys.stdout = open('trash', 'w')\n",
    "            histstruct.add_dataframe( df, rebinningfactor = 3 )\n",
    "            sys.stdout = save_stdout\n",
    "            \n",
    "    # Add masks\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat' )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=100 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    (histslist, vallist, autoencoders, train_normhist) = define_combined_autoencoder(histstruct)\n",
    "    \n",
    "    print('\\nTraining models...\\n')\n",
    "    save_stdout = sys.stdout\n",
    "    sys.stdout = open('trash', 'w')\n",
    "    train_combined_autoencoder(histslist, vallist, autoencoders)\n",
    "    sys.stdout = save_stdout\n",
    "    (mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)\n",
    "    fitfunc = fit_mse_distribution(histstruct)\n",
    "    (logprob_good, logprob_bad) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)\n",
    "    (accuracy, recall) = evaluate_autoencoders_combined(logprob_good, logprob_bad)\n",
    "    \n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Recall: ' + str(recall))\n",
    "    \n",
    "    if recall > bestRun[1]:\n",
    "        bestRun[0] = run\n",
    "        bestRun[1] = recall\n",
    "        bestRun[2] = accuracy\n",
    "        print('New Best Run: {}'.format(run))\n",
    "    elif recall == bestRun[1]:\n",
    "        if accuracy > bestRun[2]:\n",
    "            bestRun[0] = run\n",
    "            bestRun[1] = recall\n",
    "            bestRun[2] = accuracy\n",
    "            print('New Best Run: {}'.format(run))\n",
    "    \n",
    "    print('\\n--------------------------------------\\n')\n",
    "\n",
    "print('Best Run: ' + bestRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "356f7ddc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
