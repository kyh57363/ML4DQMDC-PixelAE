{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba645803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'HistStruct' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/HistStruct.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211c7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Data Controls\n",
    "\n",
    "# Select all available histograms automatically or user selection\n",
    "automatic_histnames = True\n",
    "\n",
    "year = '2017' # Data-taking year\n",
    "eras = ['B'] # List of eras\n",
    "dim = 1 # Dimension of histograms (1D or 2D)\n",
    "# May need alteration later, but this is the only data directory I have perms for\n",
    "datadir = '../data/'\n",
    "outputdir = '../data/Norms'\n",
    "\n",
    "histnames = []\n",
    "# Case user wants to select histnames manually\n",
    "if not automatic_histnames:\n",
    "    # Manual selector for histograms\n",
    "    histnames = ([\n",
    "        'NormalizedHitResiduals_TIB__Layer__1',\n",
    "        'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1',\n",
    "        'NormalizedHitResiduals_TIB__Layer__2',\n",
    "        'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2',\n",
    "        'NormalizedHitResiduals_TIB__Layer__3',\n",
    "        'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3',\n",
    "        'NormalizedHitResiduals_TIB__Layer__4',\n",
    "        'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4',\n",
    "        'NormalizedHitResiduals_TIB__Layer__5',\n",
    "        'Summary_ClusterStoNCorr__OnTrack__TIB__layer__5',\n",
    "        'NormalizedHitResiduals_TIB__Layer__6',\n",
    "        'Summary_ClusterStoNCorr__OnTrack__TIB__layer__6',\n",
    "        'chargeInner_PXLayer_1',\n",
    "        'chargeInner_PXLayer_2',\n",
    "        'chargeInner_PXLayer_3',\n",
    "        'chargeInner_PXLayer_4',\n",
    "        'chargeOuter_PXLayer_1',\n",
    "        'chargeOuter_PXLayer_2',\n",
    "        'chargeOuter_PXLayer_3',\n",
    "        'chargeOuter_PXLayer_4',\n",
    "        \n",
    "    ])\n",
    "\n",
    "    print('Histograms to process: ' + str(len(histnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d909992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin processing for era B\n",
      "WARNING: in DataLoader.get_csv_files: something went wrong in numerical sorting the filenames, maybe the format of the filenames is not as expected? the returned list of files should be complete, but they might not be sorted correctly.\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "Exists\n",
      "WARNING: in DataLoader.get_csv_files: something went wrong in numerical sorting the filenames, maybe the format of the filenames is not as expected? the returned list of files should be complete, but they might not be sorted correctly.\n"
     ]
    }
   ],
   "source": [
    "### Read and Format CSV Files\n",
    "# CSV files are formatted into CSvs with the same name, but normalized\n",
    "\n",
    "# Loop over eras\n",
    "for era in eras:\n",
    "    print('\\nBegin processing for era ' + era)\n",
    "    \n",
    "    # Create a DataLoader instance\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    \n",
    "    # Pull in all csv files from the data directory\n",
    "    csvfiles = dloader.get_csv_files_in_dirs([datadir])\n",
    "    \n",
    "    for csv in csvfiles:\n",
    "        df = dloader.get_dataframe_from_files([csv])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea676be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
