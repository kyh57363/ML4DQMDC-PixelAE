{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f6f0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 21:13:11.136346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.1-8d929/x86_64-centos7-gcc8-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.1-f3599/x86_64-centos7-gcc8-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/8u222-884d8/x86_64-centos7-gcc8-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.30-e5b21/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/3.6.3-dfb24/x86_64-centos7-gcc8-opt/lib64/R/library/readr/rcon\n",
      "2022-07-08 21:13:11.136396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-k/khowey/SWAN_projects/ML4DQMDC-PixelAE/KH-AutoencoderTest/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import gc\n",
    "from os.path import exists\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "from sys import getsizeof\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import FlexiStruct\n",
    "importlib.reload(FlexiStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d16d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2017'\n",
    "era = 'E'\n",
    "\n",
    "datadir = '../data/' + year + era + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e93aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk1Vars = ['chargeInner', 'chargeOuter', 'adc', 'size']\n",
    "blk2Vars = ['NormalizedHitResiduals', \n",
    "            'Summary_ClusterStoNCorr__OnTrack_',\n",
    "            #'Summary_TotalNumberOfDigis_'\n",
    "           ]\n",
    "blk3Vars = [\n",
    "    #'NumberOfTracks', \n",
    "    'NumberOfRecHitsPerTrack', \n",
    "    'Chi2oNDF',\n",
    "    'goodvtxNbr'] \n",
    "miscVars = [\n",
    "    #'NumberOfClustersInPixel', \n",
    "    'num_clusters_ontrack_PXBarrel', \n",
    "    'num_clusters_ontrack_PXForward', \n",
    "    #'NumberOfClustersInStrip'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0517e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the different permutations for block 1\n",
    "combosBlk1 = []\n",
    "histcount = 0\n",
    "modelcount = 0\n",
    "for size in range(1, len(blk1Vars) + 1):\n",
    "    # Get every combination of given size\n",
    "    thisList = list(itertools.combinations(blk1Vars, size))\n",
    "    \n",
    "    \n",
    "    ## Applying rules\n",
    "    for item in thisList:\n",
    "        \n",
    "        if 'chargeInner' not in item: continue\n",
    "        \n",
    "        subList = []\n",
    "        subListPX = []\n",
    "        subListDSP = []\n",
    "        subListDSN = []\n",
    "        # Getting individual histograms to set appropriate names\n",
    "        for element in item:\n",
    "            \n",
    "            # Need to treat chargeInner the same as 'charge' for disks\n",
    "            if element == 'chargeInner':\n",
    "                for i in range(1, 4):\n",
    "                    subListDSP.append('charge_PXDisk_+' + str(i))\n",
    "                    subListDSN.append('charge_PXDisk_-' + str(i))\n",
    "                    \n",
    "            elif element != 'chargeOuter':\n",
    "                for i in range(1, 4):\n",
    "                    subListDSP.append(element + '_PXDisk_+' + str(i))\n",
    "                    subListDSN.append(element + '_PXDisk_-' + str(i))\n",
    "            # PXlayers\n",
    "            for i in range(1, 5):\n",
    "                subListPX.append(element + '_PXLayer_' + str(i))\n",
    "        \n",
    "        subList.append(subListPX)\n",
    "        subList.append(subListDSP)\n",
    "        subList.append(subListDSN)\n",
    "        \n",
    "        combosBlk1.append(subList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66dce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Permutations for block 2\n",
    "combosBlk2 = []\n",
    "for size in range(1, len(blk2Vars) + 1):\n",
    "    # Get every combination of given size\n",
    "    thisList = list(itertools.combinations(blk2Vars, size))\n",
    "    \n",
    "    \n",
    "    ## Applying rules\n",
    "    for item in thisList:\n",
    "        if 'Summary_ClusterStoNCorr__OnTrack_' not in item: continue\n",
    "            \n",
    "        subList = []\n",
    "        subTIB = []\n",
    "        subTOB = []\n",
    "        subTIDP = []\n",
    "        subTIDN = []\n",
    "        subTECP = []\n",
    "        subTECN = []\n",
    "        \n",
    "        # Getting individual histograms to set appropriate names\n",
    "        for element in item:\n",
    "            \n",
    "            # Special case\n",
    "            if element != 'NormalizedHitResiduals':\n",
    "                for i in range(1, 10):\n",
    "                    subTECN.append(element + '_TEC__MINUS__wheel__' + str(i))\n",
    "                    subTECP.append(element + '_TEC__PLUS__wheel__' + str(i))\n",
    "                    \n",
    "                for i in range(1, 4):\n",
    "                    subTIDN.append(element + '_TID__MINUS__wheel__' + str(i))\n",
    "                    subTIDP.append(element + '_TID__PLUS__wheel__' + str(i))\n",
    "                    \n",
    "                for i in range(1, 5):\n",
    "                    subTIB.append(element + '_TIB__layer__' + str(i))\n",
    "            \n",
    "                for i in range(1, 7):\n",
    "                    subTOB.append(element + '_TOB__layer__' + str(i))\n",
    "                    \n",
    "            else: \n",
    "                for i  in range(1, 10):\n",
    "                    subTECN.append(element + '_TEC__wheel__' + str(i))\n",
    "                    \n",
    "                for i in range(1, 4):\n",
    "                    subTIDN.append(element + '_TID__wheel__' + str(i))\n",
    "                    \n",
    "                for i in range(1, 5):\n",
    "                    subTIB.append(element + '_TIB__Layer__' + str(i))\n",
    "            \n",
    "                for i in range(1, 7):\n",
    "                    subTOB.append(element + '_TOB__Layer__' + str(i))\n",
    "\n",
    "        subList.append(subTIB)\n",
    "        subList.append(subTOB)\n",
    "        if len(subTIDP) > 0:\n",
    "            subList.append(subTIDP)\n",
    "        subList.append(subTIDN)\n",
    "        if len(subTECP) > 0:\n",
    "            subList.append(subTECP)\n",
    "        subList.append(subTECN)\n",
    "        combosBlk2.append(subList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044be4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Permutations for block 3\n",
    "combosBlk3 = []\n",
    "\n",
    "for size in range(1, len(blk3Vars) + 1):\n",
    "    # Get every combination of given size\n",
    "    thisList = list(itertools.combinations(blk3Vars, size))\n",
    "    \n",
    "    ## Applying rules\n",
    "    for item in thisList:\n",
    "        if 'NumberOfRecHitsPerTrack' not in item: continue\n",
    "         \n",
    "        subList = []\n",
    "        for element in item:\n",
    "            if element !='goodvtxNbr':\n",
    "                subList.append(element + '_lumiFlag_GenTk')\n",
    "            else:\n",
    "                subList.append(element)\n",
    "        \n",
    "        combosBlk3.append([subList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6052c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Permutations for block 4\n",
    "combosBlk4 = []\n",
    "\n",
    "for size in range(0, len(miscVars) + 1):\n",
    "    # Get every combination of given size\n",
    "    thisList = list(itertools.combinations(miscVars, size))\n",
    "    \n",
    "    ## Applying rules\n",
    "    for item in thisList:\n",
    "        subList = []\n",
    "        subSubList = []\n",
    "        for element in item:\n",
    "            subSubList.append(element)\n",
    "    \n",
    "        subList.append(subSubList)\n",
    "        combosBlk4.append(subList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3335f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to Train:\n",
      " - Concatamash: 2752\n",
      " - Combined: 17920\n",
      "\n",
      "Training Sets: 256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Parsing combinations to create histlists\n",
    "histlists = []\n",
    "conmodelcount = 0\n",
    "combmodelcount = 0\n",
    "for combo1 in combosBlk1:\n",
    "    for combo2 in combosBlk2:\n",
    "        for combo3 in combosBlk3:\n",
    "            for combo4 in combosBlk4:\n",
    "                curList = []\n",
    "                for element in combo1:\n",
    "                    curList.append(element)\n",
    "                for element in combo2:\n",
    "                    curList.append(element)\n",
    "                for element in combo3:\n",
    "                    curList.append(element)\n",
    "                for element in combo4:\n",
    "                    if len(element) > 0:\n",
    "                        curList.append(element)\n",
    "                \n",
    "                # Sanity check that all files exist\n",
    "                for histgroup in curList:\n",
    "                    for hist in histgroup:\n",
    "                        filename = 'DF' + year + era + '_' + hist +'.csv'\n",
    "                        path = datadir + filename\n",
    "                        if not os.path.exists(path):\n",
    "                            raise Exception('Histogram {} does not exist!'.format(hist))\n",
    "                histlists.append(curList)\n",
    "                \n",
    "for histlist in histlists:\n",
    "    for histgroup in histlist:\n",
    "        conmodelcount = conmodelcount + 1\n",
    "        for hist in histgroup:\n",
    "            combmodelcount = combmodelcount + 1\n",
    "            \n",
    "print('Models to Train:')\n",
    "print(' - Concatamash: ' + str(conmodelcount))\n",
    "print(' - Combined: ' + str(combmodelcount))\n",
    "\n",
    "print('\\nTraining Sets: ' + str(len(histlists)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b82dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = '../data/'\n",
    "\n",
    "# Select a list of good runs to train on in development training_mode\n",
    "# Should be validated by eye\n",
    "trainrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                   \"297598\":[[-1]],\n",
    "#                   \"297604\":[[-1]],   # A decently clean histogram\n",
    "                   \"297620\":[[-1]],   # A decently clean histogram\n",
    "                   \"297659\":[[-1]],   # An okay histogram\n",
    "                   \"297670\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                   \"299065\":[[-1]],   # A decently clean histogram\n",
    "                   \"299067\":[[-1]],   # A decently clean histogram\n",
    "                   \"299096\":[[-1]],\n",
    "                   \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "#                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "#                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "                   '2017C': {\n",
    "                      \"299370\":[[-1]],\n",
    "                      \"299394\":[[-1]],\n",
    "                      \"299420\":[[-1]],\n",
    "                      \"299477\":[[-1]],\n",
    "                      \"299593\":[[-1]],\n",
    "                      \"299597\":[[-1]],\n",
    "                      \"299617\":[[-1]],\n",
    "                      \"300018\":[[-1]],\n",
    "                      \"300105\":[[-1]],\n",
    "                      \"300117\":[[-1]],\n",
    "                      \"300124\":[[-1]],\n",
    "                      \"300234\":[[-1]],\n",
    "                      \"300237\":[[-1]],\n",
    "                      \"300240\":[[-1]],\n",
    "                      \"300370\":[[-1]],\n",
    "                      \"300157\":[[-1]],\n",
    "                      \"300373\":[[-1]],\n",
    "                      \"300392\":[[-1]],\n",
    "                      \"300395\":[[-1]],\n",
    "                      \"300401\":[[-1]],\n",
    "                      \"300462\":[[-1]],\n",
    "                      \"300466\":[[-1]],\n",
    "#                      \"300514\":[[-1]],\n",
    "#                      \"300517\":[[-1]],\n",
    "#                      \"300538\":[[-1]],\n",
    "#                      \"300539\":[[-1]],\n",
    "#                      \"300364\":[[-1]],\n",
    "                       },'2017E':{\n",
    "                            \"303819\":[[-1]],\n",
    "                            \"303999\":[[-1]],\n",
    "                            \"304119\":[[-1]],\n",
    "                            \"304120\":[[-1]],\n",
    "                            \"304197\":[[-1]],\n",
    "                            \"304505\":[[-1]],\n",
    "                            \"304198\":[[-1]],\n",
    "                          #\"304199\":[[-1]],\n",
    "                          #\"304209\":[[-1]],\n",
    "                          #\"304333\":[[-1]],\n",
    "                          #\"304446\":[[-1]],\n",
    "                          #\"304449\":[[-1]],\n",
    "                            \"304452\":[[-1]],\n",
    "                            \"304508\":[[-1]],\n",
    "                            \"304625\":[[-1]],\n",
    "                            \"304655\":[[-1]],\n",
    "                            \"304737\":[[-1]],\n",
    "                            \"304778\":[[-1]],\n",
    "                            \"306459\":[[-1]],\n",
    "                            \"304196\":[[-1]],\n",
    "                 },'2017F':{\n",
    "#                      \"305310\":[[-1]],\n",
    "#                      \"305040\":[[-1]],\n",
    "#                      \"305043\":[[-1]],\n",
    "#                      \"305185\":[[-1]],\n",
    "#                      \"305204\":[[-1]],\n",
    "                      \"305234\":[[-1]],\n",
    "                      \"305247\":[[-1]],\n",
    "                      \"305313\":[[-1]],\n",
    "                      \"305338\":[[-1]],\n",
    "                      \"305350\":[[-1]],\n",
    "                      \"305364\":[[-1]],\n",
    "                      \"305376\":[[-1]],\n",
    "                      \"306042\":[[-1]],\n",
    "                      \"306051\":[[-1]],\n",
    "                      \"305406\":[[-1]],\n",
    "                      \"306122\":[[-1]],\n",
    "                      \"306134\":[[-1]],\n",
    "                      \"306137\":[[-1]],\n",
    "                      \"306154\":[[-1]],\n",
    "                      \"306170\":[[-1]],\n",
    "                      \"306417\":[[-1]],\n",
    "                      \"306432\":[[-1]],\n",
    "                      \"306456\":[[-1]],\n",
    "                      \"305516\":[[-1]],\n",
    "                      \"305586\":[[-1]],\n",
    "                      \"305588\":[[-1]],\n",
    "                      \"305590\":[[-1]],\n",
    "                      \"305809\":[[-1]],\n",
    "                      \"305832\":[[-1]],\n",
    "                      \"305840\":[[-1]],\n",
    "                      \"305898\":[[-1]],\n",
    "                      \"306029\":[[-1]],\n",
    "                      \"306037\":[[-1]],\n",
    "                      \"306095\":[[-1]],\n",
    "                },\n",
    "                '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "# Select a list of good runs to test on in development training_mode\n",
    "# Should be validated by eye\n",
    "goodrunsls = {'2017B':{\n",
    "#                    \"297057\":[[-1]], \n",
    "#                    \"297099\":[[-1]], \n",
    "#                    \"297101\":[[-1]],\n",
    "#                    \"297113\":[[-1]], \n",
    "#                    \"297114\":[[-1]], \n",
    "                    \"297175\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297177\":[[-1]],\n",
    "#                    \"297179\":[[-1]], \n",
    "#                    \"297215\":[[-1]],\n",
    "#                    \"297218\":[[-1]],\n",
    "#                    \"297225\":[[-1]],\n",
    "#                    \"297296\":[[-1]], \n",
    "#                    \"297411\":[[-1]],\n",
    "#                    \"297426\":[[-1]],  \n",
    "#                    \"297431\":[[-1]],\n",
    "#                    \"297434\":[[-1]], \n",
    "#                    \"297468\":[[-1]],\n",
    "#                    \"297483\":[[-1]],\n",
    "#                    \"297486\":[[-1]],\n",
    "#                    \"297503\":[[-1]],\n",
    "#                    \"297557\":[[-1]],\n",
    "#                    \"297598\":[[-1]],\n",
    "#                    \"297604\":[[-1]],   # A decently clean histogram\n",
    "#                    \"297620\":[[-1]],   # A decently clean histogram\n",
    "                    \"297659\":[[-1]],   # An okay histogram\n",
    "                    \"297670\":[[-1]],   # A decently clean histogram\n",
    "                    \"297674\":[[-1]],\n",
    "#                    \"297678\":[[-1]],   # A particularly messy histogram\n",
    "                    \"297722\":[[-1]],   # A decently clean histogram\n",
    "#                    \"298997\":[[-1]],\n",
    "#                    \"299061\":[[-1]],\n",
    "                    \"299065\":[[-1]],   # A decently clean histogram\n",
    "                    \"299067\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299096\":[[-1]],\n",
    "#                    \"299149\":[[-1]],\n",
    "#                    \"299178\":[[-1]],   # A decently clean histogram\n",
    "#                    \"299184\":[[-1]],   # A particularly messy histogram\n",
    "                    \"299185\":[[-1]],   # A decently clean histogram\n",
    "                    \"299327\":[[-1]],\n",
    "#                    \"299329\":[[-1]], \n",
    "                    \"299480\":[[-1]]    # A decently clean histogram\n",
    "                    },\n",
    "                '2017C':{\n",
    "#                      \"299370\":[[-1]],\n",
    "#                      \"299394\":[[-1]],\n",
    "#                      \"299420\":[[-1]],\n",
    "#                      \"299477\":[[-1]],\n",
    "#                      \"299593\":[[-1]],\n",
    "#                      \"299597\":[[-1]],\n",
    "#                      \"299617\":[[-1]],\n",
    "#                      \"300018\":[[-1]],\n",
    "#                      \"300105\":[[-1]],\n",
    "#                      \"300117\":[[-1]],\n",
    "#                      \"300124\":[[-1]],\n",
    "#                      \"300234\":[[-1]],\n",
    "#                      \"300237\":[[-1]],\n",
    "#                      \"300240\":[[-1]],\n",
    "#                      \"300370\":[[-1]],\n",
    "#                      \"300157\":[[-1]],\n",
    "#                      \"300373\":[[-1]],\n",
    "#                      \"300392\":[[-1]],\n",
    "#                      \"300395\":[[-1]],\n",
    "#                      \"300401\":[[-1]],\n",
    "#                      \"300462\":[[-1]],\n",
    "#                      \"300466\":[[-1]],\n",
    "                      \"300514\":[[-1]],\n",
    "                      \"300517\":[[-1]],\n",
    "                      \"300538\":[[-1]],\n",
    "                      \"300539\":[[-1]],\n",
    "                      \"300364\":[[-1]],\n",
    "                },'2017E':{\n",
    "            #         \"303819\":[[-1]],\n",
    "#                    \"303999\":[[-1]],\n",
    "#                    \"304119\":[[-1]],\n",
    "#                    \"304120\":[[-1]],\n",
    "#                    \"304197\":[[-1]],\n",
    "#                    \"304505\":[[-1]],\n",
    "#                    \"304198\":[[-1]],\n",
    "                    \"304199\":[[-1]],\n",
    "                    \"304209\":[[-1]],\n",
    "                    \"304333\":[[-1]],\n",
    "                    \"304446\":[[-1]],\n",
    "                    \"304449\":[[-1]],\n",
    "#                    \"304452\":[[-1]],\n",
    "#                    \"304508\":[[-1]],\n",
    "#                    \"304625\":[[-1]],\n",
    "#                    \"304655\":[[-1]],\n",
    "#                    \"304737\":[[-1]],\n",
    "#                    \"304778\":[[-1]],\n",
    "#                    \"306459\":[[-1]],\n",
    "#                    \"304196\":[[-1]],\n",
    "                },'2017F':{\n",
    "                      \"305310\":[[-1]],\n",
    "                      \"305040\":[[-1]],\n",
    "                      \"305043\":[[-1]],\n",
    "                      \"305185\":[[-1]],\n",
    "                      \"305204\":[[-1]],\n",
    "#                      \"305234\":[[-1]],\n",
    "#                      \"305247\":[[-1]],\n",
    "#                      \"305313\":[[-1]],\n",
    "#                      \"305338\":[[-1]],\n",
    "#                      \"305350\":[[-1]],\n",
    "#                      \"305364\":[[-1]],\n",
    "#                      \"305376\":[[-1]],\n",
    "#                      \"306042\":[[-1]],\n",
    "#                      \"306051\":[[-1]],\n",
    "#                      \"305406\":[[-1]],\n",
    "#                      \"306122\":[[-1]],\n",
    "#                      \"306134\":[[-1]],\n",
    "#                      \"306137\":[[-1]],\n",
    "#                      \"306154\":[[-1]],\n",
    "#                      \"306170\":[[-1]],\n",
    "#                      \"306417\":[[-1]],\n",
    "#                      \"306432\":[[-1]],\n",
    "#                      \"306456\":[[-1]],\n",
    "#                      \"305516\":[[-1]],\n",
    "#                      \"305586\":[[-1]],\n",
    "#                      \"305588\":[[-1]],\n",
    "#                      \"305590\":[[-1]],\n",
    "#                      \"305809\":[[-1]],\n",
    "#                      \"305832\":[[-1]],\n",
    "#                      \"305840\":[[-1]],\n",
    "#                      \"305898\":[[-1]],\n",
    "#                      \"306029\":[[-1]],\n",
    "#                      \"306037\":[[-1]],\n",
    "#                      \"306095\":[[-1]],\n",
    "                },\n",
    "                '2018':{ # needs to be re-checked, not guaranteed to be fully correct or representative.   \n",
    "                  \"315267\":[[-1]] \n",
    "              }\n",
    "}\n",
    "\n",
    "\n",
    "badrunsls = {'2017B':\n",
    "                {\n",
    "                    #\"297048\":[[-1]],\n",
    "                    #\"297282\":[[-1]],\n",
    "                    #\"297283\":[[-1]],\n",
    "                    #\"297284\":[[-1]],\n",
    "                    #\"297287\":[[-1]],\n",
    "                    #\"297288\":[[-1]],\n",
    "                    #\"297289\":[[-1]],\n",
    "                    \"299316\":[[-1]],\n",
    "                    \"299317\":[[-1]],\n",
    "                    \"299318\":[[-1]],\n",
    "                    \"299324\":[[-1]],\n",
    "                    \"299326\":[[-1]],\n",
    "                    #\"301086\":[[88,126]],\n",
    "                    #\"301086\":[[89,89]],\n",
    "                    #\"303948\":[[1710,1710]],\n",
    "                    \"297047\":[[-1]], #close but, true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297211\":[[-1]], #Reconstructs well\n",
    "#                   \"299325\":[[-1]], #Reconstructs well\n",
    "                    \"297664\":[[-1]], #true bad for all 8\n",
    "                    \"299317\":[[-1]], #true bad for all 8\n",
    "                    \"297169\":[[-1]], #true bad for all 8\n",
    "#                   \"297502\":[[-1]]\n",
    "                },\n",
    "             '2017C':{\n",
    "                \"300079\":[[-1]],\n",
    "                \"300282\":[[-1]],\n",
    "                \"300389\":[[-1]],\n",
    "                \"300398\":[[-1]],\n",
    "                 \n",
    "                 \n",
    "#                 \"300781\":[[-1]], # bad for tracking (pixels were excluded.\n",
    "#                 \"300079\":[[-1]], # is bad for strips and then also for tracking\n",
    "#                 \"302029\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good \n",
    "#                 \"300576\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"300574\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"300282\":[[-1]], # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "#                 \"301912\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "#                 \"301086\":[[-1]], # Half bad for pixels (lost HV or readout card)  \n",
    "#                 \"300283\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "#                 \"300282\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "#                 \"300281\":[[-1]], # Half bad for pixels (lost HV or readout card) \n",
    "#                 \"300239\":[[-1]], # Half bad for pixels (lost HV or readout card)\n",
    "#                 \"301394\":[[-1]], # Marginal for pixels\n",
    "#                 \"301183\":[[-1]], # Marginal for pixels\n",
    "#                 \"300398\":[[-1]], # Marginal for pixels\n",
    "#                 \"300389\":[[-1]], # Marginal for pixels\n",
    "#                 \"300365\":[[-1]]  # Marginal for pixels\n",
    "              },\n",
    "             '2017E':{\n",
    "                 \"304740\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304776\":[[-1]], # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 \"304506\":[[-1]], # Portcard problem for pixels\n",
    "                 \"304507\":[[-1]], # Portcard problem for pixels \n",
    "                 \"303989\":[[-1]], # Bad for pixels, power supply died\n",
    "                 \"303824\":[[-1]]  # Partly bad for strips due to a test\n",
    "             },\n",
    "             '2017F':{\n",
    "                 \"306422\":[[-1]], # Partly bad for strips - 2 data readouts failed \n",
    "#                 \"306423\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "#                 \"306425\":[[-1]], # Partly bad for strips - 2 data readouts failed\n",
    "#                 \"305440\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "#                 \"305441\":[[-1]], # Partly bad for strips - 1 data readout failed\n",
    "                 \"305249\":[[-1]], # Bad for pixels - half of disk failed \n",
    "                 \"305250\":[[-1]], # Bad for pixels - half of disk failed\n",
    "#                 \"305064\":[[-1]], # Marginal for pixels - some readout failed\n",
    "             },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = histlists[255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585330ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Select whether to save a new histstruct\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3148531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames\n",
    "\n",
    "# Bias Factors\n",
    "fmBiasFactor = 2\n",
    "wpBiasFactor = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ccbedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on a user-defined subset of runs\n",
    "    \n",
    "# Select runs to be used in training from the user-defined list\n",
    "runsls_training = trainrunsls[year + era]\n",
    "# Select bad runs to test on in the user-defined list\n",
    "runsls_bad = badrunsls[year + era]\n",
    "# Select good runs to test on in the user-defined list\n",
    "runsls_good = goodrunsls[year + era]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b5b458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Classifiers and masks cleared to preserve consistency\n"
     ]
    }
   ],
   "source": [
    "# Initializations\n",
    "dloader = DataLoader.DataLoader()\n",
    "histstruct = FlexiStruct.FlexiStruct()\n",
    "histstruct.reset_histlist(histnames)\n",
    "failedruns = {}\n",
    "failedls ={}\n",
    "# Unpack histnames and add every histogram individually\n",
    "consistent = True\n",
    "for histnamegroup in histnames:\n",
    "    for histname in histnamegroup:\n",
    "        \n",
    "        # Bring the histograms into memory from storage for later use\n",
    "        filename = datadir + year + era + '/DF' + year + era + '_' + histname + '.csv'\n",
    "        df = dloader.get_dataframe_from_file( filename )\n",
    "        \n",
    "        # In case of local training, we can remove most of the histograms\n",
    "        if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "            runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "            df = dfu.select_runsls( df, runsls_total )\n",
    "        \n",
    "        df = dfu.rm_duplicates(df)\n",
    "        \n",
    "        try:\n",
    "            # Store the data in the histstruct object managing this whole thing\n",
    "            histstruct.add_dataframe( df, rebinningfactor = 1, standardbincount = 102 )\n",
    "        except:\n",
    "            print(\"WARNING: Could not add \" + histname, file=sys.stderr)\n",
    "            failedruns[histname] = dfu.get_runs(df)\n",
    "            failedls[histname] = dfu.get_ls(df)\n",
    "            consistent = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edf2ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "inconsistentRuns = {}\n",
    "if not consistent:\n",
    "    for histname in failedruns:\n",
    "        inconsistentRuns[histname] = {}\n",
    "        for run in runsls_total:\n",
    "            if int(run) not in failedruns[histname]:\n",
    "                runls = {}\n",
    "                runls[run] = [[-1]]\n",
    "                inconsistentRuns[histname].update(runls)\n",
    "    print(inconsistentRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b24bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Masks to Data\n",
    "def assignMasks(histstruct, runsls_training, runsls_good, runsls_bad):\n",
    "\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat', entries_to_bins_ratio=0)\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=0)\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    if save:\n",
    "        histstruct.save('test.pk1')\n",
    "    return histstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f3bc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_concatamash_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            # Half the total bin count\n",
    "            arch = 51 * len(histnamegroup)\n",
    "            \n",
    "            ## Model parameters\n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(arch * 2, activation=\"tanh\")(conc_layer)\n",
    "            encoder = Dense(arch, activation='relu')(encoder)\n",
    "            \n",
    "            encoder = Dense(arch/2, activation='relu')(encoder)\n",
    "            \n",
    "            decoder = Dense(arch, activation=\"relu\")(encoder)\n",
    "            decoder = Dense(arch * 2, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d62f4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders):\n",
    "    \n",
    "    # Iterate through the training data to train corresponding autoencoders\n",
    "    autoencodersTrain = []\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        sys.stdout.write('\\rNow training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 500\n",
    "        batch_size = 1000\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=0,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                            epochs=nb_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                            verbose=0,\n",
    "                            callbacks= [earlystop],    \n",
    "                            )\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier) \n",
    "        autoencodersTrain.append(classifier)\n",
    "        K.clear_session()\n",
    "        del(autoencoder, classifier)\n",
    "    return autoencodersTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "463440b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        histstruct.evaluate_classifier(histgroup)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histgroup in histnames:\n",
    "            for histname in histgroup:\n",
    "                mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histgroup in histnames:\n",
    "            for histname in histgroup:\n",
    "                hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "                thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "                mse_good.append( thismse )\n",
    "                print(run)\n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    nbadruns = len([name for name in runsls_bad])\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8afd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct, mse_train):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    #for dims in dimslist:\n",
    "    #    thismse = mse_train[:,dims]\n",
    "    #    if training_mode=='global': \n",
    "    #        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "    #        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "    #        #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "    #        #                                                    'up')\n",
    "    #    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    #    #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "    #    #                onlycontour=False, xlims=30, ylims=30, \n",
    "    #    #                onlypositive=True, transparency=0.5,\n",
    "    #    #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "    #    #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "    #    #                title='density fit of lumisection MSE')\n",
    "    #    ##plt.close('all') # release plot memory\n",
    "    #    fitfunclist.append(fitfunc)\n",
    "    # \n",
    "    #    \n",
    "    fitfunc = GaussianKdeFitter.GaussianKdeFitter()\n",
    "    fitfunc.fit(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f3e2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    #print(sorted(logprob_good))\n",
    "\n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "\n",
    "    #print(sorted(logprob_good))\n",
    "    #print(sorted(logprob_bad))\n",
    "    #print(logprob_bad)\n",
    "    \n",
    "    sep = np.min(logprob_good) - np.max(logprob_bad)\n",
    "    \n",
    "    return [logprob_good, logprob_bad, sep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc19ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad, fmBiasFactor, wpBiasFactor):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    badMin = min(np.where(logprob_bad != -np.inf, logprob_bad, -1))\n",
    "    goodMax = max(np.where(logprob_good != np.inf, logprob_good, 10001))\n",
    "    \n",
    "    logprob_good = np.where(logprob_good != np.inf, logprob_good, goodMax)\n",
    "    logprob_bad = np.where(logprob_bad != -np.inf, logprob_bad, badMin)\n",
    "    \n",
    "    # These only take effect if a histogram is grossly misclassified\n",
    "    logprob_good[logprob_good == -np.inf] = badMin\n",
    "    logprob_bad[logprob_bad == np.inf] = goodMax\n",
    "    \n",
    "    avSep = np.mean(logprob_good) - np.mean(logprob_bad)\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    # Average is biased towards better recall per user specifications\n",
    "    logprob_threshold = (1/(wpBiasFactor + 1)) * (wpBiasFactor*np.mean(logprob_good) + np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "    # logprob_threshold = 424\n",
    "    \n",
    "    (tp, fp, tn, fn) = get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    \n",
    "    # Get metrics for analysis\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = (1 + fmBiasFactor * fmBiasFactor) * ((precision * recall) / ((fmBiasFactor * fmBiasFactor * precision) + recall)) \n",
    "    \n",
    "    return [logprob_threshold, f_measure, avSep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6329ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(scores, labels, wp='maxauc', plotwp=True,\n",
    "                          true_positive_label='Good', true_negative_label='Anomalous',\n",
    "                          pred_positive_label='Predicted good', pred_negative_label='Predicted anomalous',\n",
    "                          xaxlabelsize=None, yaxlabelsize=None, textsize=None,\n",
    "                          colormap='Blues', colortitle=None):\n",
    "    ### plot a confusion matrix\n",
    "    # input arguments:\n",
    "    # - scores and labels: defined in the same way as for get_roc\n",
    "    # - wp: the chosen working point \n",
    "    #       (i.e. any score above wp is flagged as signal, any below is flagged as background)\n",
    "    #       note: wp can be a integer or float, in which case that value will be used directly,\n",
    "    #             or it can be a string in which case it will be used as the 'method' argument in get_wp!\n",
    "    # - plotwp: only relevant if wp is a string (see above), in which case plotwp will be used as the 'doplot' argument in get_wp\n",
    "    \n",
    "    if isinstance(wp,str): wp = get_wp(scores, labels, method=wp, doplot=plotwp)\n",
    "\n",
    "    nsig = np.sum(labels)\n",
    "    nback = np.sum(1-labels)\n",
    "\n",
    "    # get confusion matrix entries\n",
    "    tp = np.sum(np.where((labels==1) & (scores>wp),1,0))/nsig\n",
    "    fp = np.sum(np.where((labels==0) & (scores>wp),1,0))/nback\n",
    "    tn = 1-fp\n",
    "    fn = 1-tp\n",
    "    cmat = np.array([[tp,fn],[fp,tn]])\n",
    "    \n",
    "    # old plotting method with seaborn\n",
    "    #df_cm = pd.DataFrame(cmat, index = [true_negative_label,true_positive_label],\n",
    "    #              columns = [predicted_negative_label,predicted_positive_label])\n",
    "    #fig,ax = plt.subplots()\n",
    "    #sn.heatmap(df_cm, annot=True, cmap=plt.cm.Blues)\n",
    "    \n",
    "    # new plotting method with pyplot\n",
    "\n",
    "    # printouts for testing\n",
    "    #print('working point: {}'.format(wp))\n",
    "    #print('nsig: {}'.format(nsig))\n",
    "    #print('nback: {}'.format(nback))\n",
    "    #print('true positive / nsig: {}'.format(tp))\n",
    "    #print('false positive / nback: {}'.format(fp))\n",
    "\n",
    "    # return the working point (for later use if it was automatically calculated)\n",
    "    return (tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "847fca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to print memory information for debugging memory leaks\n",
    "import linecache\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=3):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e3526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop it Fxn\n",
    "def masterLoop(top50, numModels, histnames, histstruct):\n",
    "    percComp = (numModels/conmodelcount)*100\n",
    "    print('Running Job {}/'.format(i+1) + str(len(histlists)) + ' - {:.2f}% Complete'.format(percComp))\n",
    "    \n",
    "    # Update histlist to reflect new data\n",
    "    histstruct.reset_histlist(histnames, suppress=True)\n",
    "    assignMasks(histstruct, runsls_training, runsls_good, runsls_bad)\n",
    "    \n",
    "    # Build autoencoders based on new data\n",
    "    (histslist, vallist, autoencoders, train_normhist) = define_concatamash_autoencoder(histstruct)\n",
    "    \n",
    "    # Train autoencoders based on current histlist and record speed\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Suppres Unhelpful Error Messages\n",
    "    orig_out = sys.stderr\n",
    "    sys.stderr = open('trash', 'w')\n",
    "    autoencoders = train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders)\n",
    "    sys.stderr = orig_out\n",
    "    \n",
    "    numModels += len(autoencoders)\n",
    "    \n",
    "    stop = time.perf_counter()\n",
    "    trainTime = stop - start\n",
    "    \n",
    "    sys.stdout.write('\\rTraining complete in ' + str(trainTime) + ' seconds')\n",
    "    sys.stdout.flush()\n",
    "    print()\n",
    "    \n",
    "    for j, autoencoder in enumerate(autoencoders):\n",
    "        autoencoder.save('../SavedModels/Permutations/Job' + str(i + 1) + '/AE' + str(j))\n",
    "    del(autoencoders)\n",
    "    \n",
    "    # Evaluate models\n",
    "    (mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)\n",
    "    fitfunc = fit_mse_distribution(histstruct, mse_train)\n",
    "    \n",
    "    orig_out = sys.stderr\n",
    "    sys.stderr = open('trash', 'w')\n",
    "    (logprob_good, logprob_bad, sep) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)\n",
    "    sys.stderr = orig_out\n",
    "    \n",
    "    (logprob_threshold, f_measure, avSep) = evaluate_autoencoders_combined(logprob_good, logprob_bad, fmBiasFactor, wpBiasFactor)\n",
    "    \n",
    "    # Adding a penalty for unseparable autoencoders\n",
    "    if(sep <= 0): sepFactor = 0.7\n",
    "    else: sepFactor = 1\n",
    "    \n",
    "    # Metric to determine how separable our dataset is\n",
    "    separability = sepFactor*avSep\n",
    "    \n",
    "    # Empty list\n",
    "    dataPackage = [histnames, i + 1, trainTime, separability, sep, f_measure, logprob_threshold]\n",
    "    if len(top50) < 1:\n",
    "        top50.append(dataPackage)\n",
    "        print('New Best Model:')\n",
    "        print(' - Train Time: ' + str(trainTime))\n",
    "        print(' - Separability: ' + str(separability))\n",
    "        print(' - F{}-Measure: '.format(fmBiasFactor) + str(f_measure))\n",
    "        \n",
    "    # Partly full list\n",
    "    elif len(top50) < 50:\n",
    "        for j in range(len(top50) - 1, -1, -1):\n",
    "            if separability < top50[j][3]:\n",
    "                top50.insert(j+1, dataPackage)\n",
    "                break\n",
    "            # Reached end of list\n",
    "            if j == 0:\n",
    "                top50.insert(j, dataPackage)\n",
    "                print('New Best Model:')\n",
    "                print(' - Train Time: ' + str(trainTime))\n",
    "                print(' - Separability: ' + str(separability))\n",
    "                print(' - F{}-Measure: '.format(fmBiasFactor) + str(f_measure))\n",
    "               \n",
    "    # Full list\n",
    "    elif separability > top50[49][3]:\n",
    "        for j in range(49, -1, -1):\n",
    "            if separability < top50[j][3]:\n",
    "                top50.insert(j+1, dataPackage)\n",
    "                break\n",
    "                \n",
    "            # Reached end of list\n",
    "            if j == 0:\n",
    "                top50.insert(j, dataPackage)\n",
    "                print('New Best Model:')\n",
    "                print(' - Train Time: ' + str(trainTime))\n",
    "                print(' - Separability: ' + str(separability))\n",
    "                print(' - F{}-Measure: '.format(fmBiasFactor) + str(f_measure))\n",
    "            \n",
    "            \n",
    "        del top50[-1]\n",
    "    \n",
    "    print()\n",
    "    return [top50, numModels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53dfe472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Job 1/256 - 0.00% Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 21:18:41.307081: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.1-8d929/x86_64-centos7-gcc8-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.1-f3599/x86_64-centos7-gcc8-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/8u222-884d8/x86_64-centos7-gcc8-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/8.3.0-cebb0/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.30-e5b21/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/3.6.3-dfb24/x86_64-centos7-gcc8-opt/lib64/R/library/readr/rcon\n",
      "2022-07-08 21:18:41.307139: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-08 21:18:41.307199: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cae770548b47): /proc/driver/nvidia/version does not exist\n",
      "2022-07-08 21:18:41.308990: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Now training model 1/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 21:18:44.990534: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-07-08 21:18:44.991877: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400105000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 521.8528596907854 seconds\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe328912c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe328912c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3085851f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3085851f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 21:27:28.949841: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE0/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3b03355e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3b03355e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE1/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe378309ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe378309ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30ba00670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30ba00670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE2/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe308356160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe308356160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE3/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe3b03355e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe3b03355e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3b00ac790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3b00ac790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE4/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe378309ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe378309ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe303fccee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe303fccee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE5/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3281cec10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe3281cec10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE6/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe3b03355e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe3b03355e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30ba005e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30ba005e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE7/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe378309ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe378309ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30844adc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30844adc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE8/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe402fae9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30baaaca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe30baaaca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ../SavedModels/Permutations/Job1/AE9/assets\n",
      "NOTE: scores of +inf were reset to 80.96783857819379\n",
      "New Best Model:\n",
      " - Train Time: 521.8528596907854\n",
      " - Separability: inf\n",
      " - F2-Measure: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2068/3492871561.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 lines\n",
      "#1: framework/constant_op.py:98: 127175.0 KiB\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "#2: internal/python_message.py:1503: 14498.1 KiB\n",
      "    self._parent_message_weakref = weakref.proxy(parent_message)\n",
      "#3: framework/ops.py:1095: 11477.4 KiB\n",
      "    return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr\n",
      "3993 other: 100189.5 KiB\n",
      "Total allocated size: 253340.1 KiB\n",
      "\n",
      "Running Job 2/256 - 0.36% Complete\n",
      "Now training model 4/11"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2068/2387031561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtracemalloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistnames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistlists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mtop50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumModels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasterLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumModels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiststruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msnapshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracemalloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdisplay_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2068/1827682841.py\u001b[0m in \u001b[0;36mmasterLoop\u001b[0;34m(top50, numModels, histnames, histstruct)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0morig_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mautoencoders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_concatamash_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiststruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistslist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvallist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2068/1456183151.py\u001b[0m in \u001b[0;36mtrain_concatamash_autoencoder\u001b[0;34m(histstruct, histslist, vallist, autoencoders)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m## Train autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n\u001b[0m\u001b[1;32m     47\u001b[0m                                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Main loop to iterate through possible histlists\n",
    "userfriendly = True\n",
    "top50 = []\n",
    "numModels = 0\n",
    "tracemalloc.start()\n",
    "for i,histnames in enumerate(histlists[0:60]):\n",
    "    (top50, numModels) = masterLoop(top50, numModels, histnames, histstruct)\n",
    "    snapshot = tracemalloc.take_snapshot()\n",
    "    display_top(snapshot)\n",
    "    gc.collect()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61821f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(top50, columns=['Histlist', 'Job', 'Train Time', \n",
    "                                  'Separability', 'Worst Case Separation',\n",
    "                                  'F_measure', 'Working Point'])\n",
    "csvu.write_csv(df, 'Top50.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histlists[46])\n",
    "print(histlists[49])\n",
    "print(histlists[50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
