{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40be8f3",
   "metadata": {},
   "source": [
    "# Concatamash Autoencoder\n",
    "## This notebook will demonstrate the capabilities and functionalities of the Concatamash autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba412492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 20:35:51.703368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.3-88592/x86_64-centos7-gcc11-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.3-35f7a/x86_64-centos7-gcc11-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/onnxruntime/capi/:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/11.0.14p1-8284a/x86_64-centos7-gcc11-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.37-355ed/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/4.1.2-f9ee4/x86_64-centos7-gcc11-opt/lib64/R/library/readr/rcon\n",
      "2022-07-28 20:35:51.703405: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/Merging Histogram Notebooks/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import SubHistStruct\n",
    "importlib.reload(SubHistStruct)\n",
    "import FlexiStruct\n",
    "importlib.reload(FlexiStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1ba66",
   "metadata": {},
   "source": [
    "### Controls and Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed Controls and Run Mode\n",
    "\n",
    "# Disables all plots for large datasets where speed is more important\n",
    "createPlots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2020c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation Parameters\n",
    "\n",
    "# Select the bias towards recall against precision, treated as a factor (so < 1 biases towards precision, 1 is equal importance, and > 1 biases towards recall)\n",
    "wpBiasFactor = 20\n",
    "fmBiasFactor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8eb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining bad runs\n",
    "badruns = {'2017B':\n",
    "                [\n",
    "                    297048,\n",
    "                    297282,\n",
    "                    297283,\n",
    "                    297284,\n",
    "                    297287,\n",
    "                    297288,\n",
    "                    297289,\n",
    "                    299316,\n",
    "                    299317,\n",
    "                    299318,\n",
    "                    299324,\n",
    "                    299326,\n",
    "                    301086,\n",
    "                    301086,\n",
    "                    303948,\n",
    "                    297047, #close but, true bad for all 8\n",
    "                    297169, #true bad for all 8\n",
    "                    297211, #Reconstructs well\n",
    "                    299325, #Reconstructs well\n",
    "                    297664, #true bad for all 8\n",
    "                    299317, #true bad for all 8\n",
    "                    297169, #true bad for all 8\n",
    "                    297502\n",
    "                ],\n",
    "             '2017C':[\n",
    "                  300781, # bad for tracking (pixels were excluded.\n",
    "                  300079, # is bad for strips and then also for tracking\n",
    "                  302029, # Poor detector elements for strips - Should be mildly anomalous, but technically good \n",
    "                  300576, # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                  300574, # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                  300282, # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                  301912, # Half bad for pixels (lost HV or readout card)  \n",
    "                  301086, # Half bad for pixels (lost HV or readout card)  \n",
    "                  300283, # Half bad for pixels (lost HV or readout card) \n",
    "                  300282, # Half bad for pixels (lost HV or readout card) \n",
    "                  300281, # Half bad for pixels (lost HV or readout card) \n",
    "                  300239, # Half bad for pixels (lost HV or readout card)\n",
    "                  301394, # Marginal for pixels\n",
    "                  301183, # Marginal for pixels\n",
    "                  300398, # Marginal for pixels\n",
    "                  300389, # Marginal for pixels\n",
    "                  300365  # Marginal for pixels\n",
    "             ],\n",
    "             '2017E':[\n",
    "                 304740, # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 304776, # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 304506, # Portcard problem for pixels\n",
    "                 304507, # Portcard problem for pixels \n",
    "                 303989, # Bad for pixels, power supply died\n",
    "                 303824  # Partly bad for strips due to a test\n",
    "             ],\n",
    "             '2017F':[\n",
    "                 306422, # Partly bad for strips - 2 data readouts failed \n",
    "                 306423, # Partly bad for strips - 2 data readouts failed\n",
    "                 306425, # Partly bad for strips - 2 data readouts failed\n",
    "                 305440, # Partly bad for strips - 1 data readout failed\n",
    "                 305441, # Partly bad for strips - 1 data readout failed\n",
    "                 305249, # Bad for pixels - half of disk failed \n",
    "                 305250, # Bad for pixels - half of disk failed\n",
    "                 305064, # Marginal for pixels - some readout failed\n",
    "             ],\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                [\n",
    "                317479,\n",
    "                317480,\n",
    "                317481,\n",
    "                317482,\n",
    "                319847\n",
    "                ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ed68a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found bad run :{'run_number': 303824, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 304158, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017E_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 303989, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 304158, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017E_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 304740, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 304158, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017E_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 305250, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 306459, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017F_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 306422, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 306459, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017F_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 305249, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 306459, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017F_UL2019/DQM'}\n"
     ]
    }
   ],
   "source": [
    "### Select a reference run and get data\n",
    "rundict = jsonu.loadjson('../jsons/CertHelperRefRuns.json')\n",
    "\n",
    "# Select any run numbers to get a training set from that run's reference.\n",
    "runNums = [303824, 306422]\n",
    "refRuns = []\n",
    "eras = []\n",
    "years = []\n",
    "dataDict = {}\n",
    "badrunsls = {}\n",
    "trainrunsls = {}\n",
    "goodrunsls = {}\n",
    "for runNum in runNums:\n",
    "    runls = {}\n",
    "    for run in rundict:\n",
    "        if run['run_number'] == runNum:\n",
    "            runls.update(run)\n",
    "    if runls == {}:\n",
    "        raise Exception('Run not found - ' + str(runNum))\n",
    "    \n",
    "    year = runls['dataset'][11:15]\n",
    "    if year not in years: years.append(year)\n",
    "    era = runls['dataset'][15]\n",
    "    if era not in eras: eras.append(era)\n",
    "    ref_run = runls['reference_run_number']\n",
    "    \n",
    "    # Don't need duplicates\n",
    "    if ref_run in refRuns:\n",
    "        continue\n",
    "    refRuns.append(ref_run)\n",
    "    \n",
    "    # Get the runs associated with found reference\n",
    "    outputRuns = {}\n",
    "    outputBad = {}\n",
    "    for run in rundict:\n",
    "        tempRef = run['reference_run_number']\n",
    "        if tempRef == ref_run:\n",
    "            runls = {}\n",
    "            runls[str(run['run_number'])] = [[-1]]\n",
    "            if run['run_number'] in badruns[year+era]:\n",
    "                print('Found bad run :' + str(run))\n",
    "                outputBad.update(runls)\n",
    "            else:\n",
    "                outputRuns.update(runls)\n",
    "    \n",
    "    # Perform structuring for compatibility with autoencoders\n",
    "    dataDict[year + era] = outputRuns\n",
    "    badrunsls[year + era] = outputBad\n",
    "    trainrunsls[year + era] = {}\n",
    "    goodrunsls[year + era] = {}\n",
    "    \n",
    "    # Select training and testing set\n",
    "    for i,run in enumerate(dataDict[year + era]):\n",
    "        if i > 5 and i < 11:\n",
    "            goodrunsls[year + era][str(run)] = [[-1]]\n",
    "        else:\n",
    "            trainrunsls[year + era][str(run)] = [[-1]]\n",
    "\n",
    "if len(years) != 1: raise Exception('Year of length 0 or >1 unimplemented!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4590f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = {}\n",
    "for era in eras:\n",
    "    datadir[year + era] = '../data/' + year + era + '/'\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = [['chargeInner_PXLayer_1', 'chargeInner_PXLayer_2', 'chargeInner_PXLayer_3', 'chargeInner_PXLayer_4', 'charge_PXDisk_+1', 'charge_PXDisk_+2', 'charge_PXDisk_+3', 'charge_PXDisk_-1', 'charge_PXDisk_-2', 'charge_PXDisk_-3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__1', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__2', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__3', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__5', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__6', 'Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__3'], ['Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__3'], ['Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__3', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__4', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__5', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__6', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__7', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__8', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__9'], ['Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__3', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__4', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__5', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__6', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__7', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__8', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__9'], ['NumberOfRecHitsPerTrack_lumiFlag_GenTk']]\n",
    "\n",
    "# Read new data or use previously saved data & should data be saved\n",
    "readnew = True\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ffebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Set whether to train globally or locally or in a development/testing mode\n",
    "training_mode = 'development'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6394238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4051dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected runs/lumisections for training: \n",
      "{'303819': [[-1]], '303999': [[-1]], '304119': [[-1]], '304120': [[-1]], '304197': [[-1]], '304505': [[-1]], '304449': [[-1]], '304452': [[-1]], '304508': [[-1]], '304625': [[-1]], '304655': [[-1]], '304737': [[-1]], '304778': [[-1]], '306459': [[-1]], '304196': [[-1]], '305310': [[-1]], '305040': [[-1]], '305043': [[-1]], '305185': [[-1]], '305204': [[-1]], '305234': [[-1]], '305376': [[-1]], '306042': [[-1]], '306051': [[-1]], '305406': [[-1]], '306122': [[-1]], '306134': [[-1]], '306137': [[-1]], '306154': [[-1]], '306170': [[-1]], '306417': [[-1]], '306432': [[-1]], '306456': [[-1]], '305516': [[-1]], '305586': [[-1]], '305588': [[-1]], '305590': [[-1]], '305809': [[-1]], '305832': [[-1]], '305840': [[-1]], '305898': [[-1]], '306029': [[-1]], '306037': [[-1]], '306095': [[-1]]}\n",
      "selected runs/lumisections as good test set:\n",
      "{'304198': [[-1]], '304199': [[-1]], '304209': [[-1]], '304333': [[-1]], '304446': [[-1]], '305247': [[-1]], '305313': [[-1]], '305338': [[-1]], '305350': [[-1]], '305364': [[-1]]}\n",
      "selected runs/lumisections as bad test set:\n",
      "{'303824': [[-1]], '303989': [[-1]], '304740': [[-1]], '305250': [[-1]], '306422': [[-1]], '305249': [[-1]]}\n"
     ]
    }
   ],
   "source": [
    "### Define Training Mode Parameters - Combined Autoencoder\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use averages of training set)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    # - this only works for a single era\n",
    "    \n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+era+'_'+histnames[0][0]+'.csv') ) )\n",
    "    # Cherry picked really bad run\n",
    "    run_application = 299316\n",
    "    #run_application = 299317\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5\n",
    "        offset = 0 # normal case: offset = 0 (just use 5 previous runs)\n",
    "        \n",
    "        # Selects the 5 previous runs for training\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    #runsls_bad = badrunsls[year]\n",
    "    #runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_good = runsls_training\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)\n",
    "        \n",
    "elif training_mode == 'development':\n",
    "    # train on a user-defined subset of runs\n",
    "    \n",
    "   # Select runs to be used in training from the user-defined list\n",
    "    runsls_training = {}\n",
    "    runsls_bad = {}\n",
    "    runsls_good = {}\n",
    "    for era in eras:\n",
    "        runsls_training.update(trainrunsls[year + era])\n",
    "        # Select bad runs to test on in the user-defined list\n",
    "        runsls_bad.update(badrunsls[year + era])\n",
    "        # Select good runs to test on in the user-defined list\n",
    "        runsls_good.update(goodrunsls[year + era])\n",
    "    \n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee44f14",
   "metadata": {},
   "source": [
    "### Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54180f06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Classifiers and masks cleared to preserve consistency\n",
      "Adding chargeInner_PXLayer_1E...\n",
      "Adding chargeInner_PXLayer_2E...\n",
      "Adding chargeInner_PXLayer_3E...\n",
      "Adding chargeInner_PXLayer_4E...\n",
      "Adding charge_PXDisk_+1E...\n",
      "Adding charge_PXDisk_+2E...\n",
      "Adding charge_PXDisk_+3E...\n",
      "Adding charge_PXDisk_-1E...\n",
      "Adding charge_PXDisk_-2E...\n",
      "Adding charge_PXDisk_-3E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__5E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__6E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__1E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__2E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__3E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__1E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__2E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__3E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__1E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__2E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__3E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__4E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__5E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__6E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__7E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__8E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__9E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__1E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__2E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__3E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__4E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__5E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__6E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__7E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__8E...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__9E...\n",
      "Adding NumberOfRecHitsPerTrack_lumiFlag_GenTkE...\n",
      "Found 9290 histograms\n",
      "Adding chargeInner_PXLayer_1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeInner_PXLayer_2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeInner_PXLayer_3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeInner_PXLayer_4F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_+1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_+2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_+3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_-1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_-2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_-3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__5F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__6F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__4F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__5F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__6F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__7F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__8F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__9F...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__1F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__2F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__3F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__4F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__5F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__6F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__7F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__8F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__9F...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NumberOfRecHitsPerTrack_lumiFlag_GenTkF...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Found 25676 histograms\n",
      "Created a histstruct with the following properties:\n",
      "- number of histogram types: 45\n",
      "- number of lumisections: 25676\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "\n",
    "# Create a new HistStruct from the data\n",
    "if readnew:\n",
    "    # Initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = FlexiStruct.FlexiStruct()\n",
    "    histstruct.reset_histlist(histnames)\n",
    "    \n",
    "    # Unpack histnames and add every histogram individually\n",
    "    for era in eras:\n",
    "        for histnamegroup in histnames:\n",
    "            for histname in histnamegroup:\n",
    "                print('Adding {}...'.format(histname + era))\n",
    "                \n",
    "                # Bring the histograms into memory from storage for later use\n",
    "                filename = datadir[year+era] + 'DF' + year + era + '_' + histname + '.csv'\n",
    "                df = dloader.get_dataframe_from_file( filename )\n",
    "                \n",
    "                # In case of local training, we can remove most of the histograms\n",
    "                if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "                    runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "                    df = dfu.select_runsls( df, runsls_total )    \n",
    "                \n",
    "                df = dfu.rm_duplicates(df)\n",
    "                # Store the data in the histstruct object managing this whole thing\n",
    "                histstruct.add_dataframe( df, rebinningfactor = 1, standardbincount = 102 )\n",
    "        print('Found {} histograms\\n'.format(len(histstruct.runnbs)))\n",
    "\n",
    "# Load a previously saved HistStruct\n",
    "else:\n",
    "    # Load histstruct from storage\n",
    "    histstruct = SubHistStruct.SubHistStruct.load( 'histstruct_global_20220201.zip', verbose=False )\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if ('bad' in name and name!='bad')])\n",
    "    \n",
    "    print('loaded a histstruct with the following properties:')\n",
    "    print(histstruct)\n",
    "    # Count of bad runs, presumably for later use\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "print('Created a histstruct with the following properties:')\n",
    "print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45931fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'303824': [[-1]], '303989': [[-1]], '304740': [[-1]], '305250': [[-1]], '306422': [[-1]], '305249': [[-1]]}\n",
      "Assigned masks: ['dcson', 'golden', 'highstat', 'lowstat', 'training', 'good', 'bad', 'bad0', 'bad1', 'bad2', 'bad3', 'bad4', 'bad5']\n"
     ]
    }
   ],
   "source": [
    "### Add Masks to Data\n",
    "\n",
    "if readnew:\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat', entries_to_bins_ratio=0 )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=0 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        print(runsls_bad)\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    if save:\n",
    "        histstruct.save('test.pk1')\n",
    "print('Assigned masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a4c3c",
   "metadata": {},
   "source": [
    "### Plotting and Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d6a8ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plotting the input data for analysis\n",
    "\n",
    "if((training_mode=='local' or training_mode == 'development') and createPlots):\n",
    "\n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad0']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )\n",
    "    \n",
    "elif( training_mode=='global' and createPlots):\n",
    "    \n",
    "    # bad test runs\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "                                labellist = ['typical good histograms','bad'],\n",
    "                                colorlist = ['blue','red'],\n",
    "                                transparencylist = [0.01,1.]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d16b59",
   "metadata": {},
   "source": [
    "### Concatamash Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_concatamash_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            # Half the total bin count\n",
    "            arch = 51 * len(histnamegroup)\n",
    "            \n",
    "            ## Model parameters\n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(arch * 2, activation=\"tanh\")(conc_layer)\n",
    "            encoder = Dense(arch/2, activation='relu')(encoder)\n",
    "            encoder = Dense(arch/8, activation='relu')(encoder)\n",
    "            encoder = Dense(arch/16, activation='relu')(encoder)\n",
    "            decoder = Dense(arch/8, activation=\"relu\")(encoder)\n",
    "            decoder = Dense(arch/2, activation='relu')(encoder)\n",
    "            decoder = Dense(arch * 2, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c76ea4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 20:38:45.028864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.3-88592/x86_64-centos7-gcc11-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.3-35f7a/x86_64-centos7-gcc11-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/onnxruntime/capi/:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/11.0.14p1-8284a/x86_64-centos7-gcc11-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.37-355ed/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/4.1.2-f9ee4/x86_64-centos7-gcc11-opt/lib64/R/library/readr/rcon\n",
      "2022-07-28 20:38:45.028946: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-28 20:38:45.028979: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-khowey): /proc/driver/nvidia/version does not exist\n",
      "2022-07-28 20:38:45.029699: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(histslist, vallist, autoencoders, train_normhist) = define_concatamash_autoencoder(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders):\n",
    "    \n",
    "    autoencodersTrain = []\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        print('Now training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 500\n",
    "        batch_size = 10000\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                epochs=nb_epoch,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                                verbose=1,\n",
    "                                callbacks= [earlystop],    \n",
    "                                )\n",
    "        tf.keras.utils.plot_model(\n",
    "                    autoencoder,\n",
    "                    to_file=\"models/model1D{}.png\".format(i),\n",
    "                    show_shapes=True,\n",
    "                    show_dtype=False,\n",
    "                    show_layer_names=False,\n",
    "                    rankdir=\"TB\")\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier) \n",
    "        autoencodersTrain.append(classifier)\n",
    "        K.clear_session()\n",
    "        del(autoencoder, classifier)\n",
    "    return autoencodersTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c02f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functionality doesn't seem to work at this time, so this function is empty\n",
    "def load_concatamash_autoencoder():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52397fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training model 1/5\n",
      "Epoch 1/500\n",
      "2/2 [==============================] - 13s 3s/step - loss: 0.0094 - dense_7_loss: 3.1945e-04 - dense_8_loss: 3.6562e-04 - dense_9_loss: 3.9275e-04 - dense_10_loss: 3.9130e-04 - dense_11_loss: 4.1819e-04 - dense_12_loss: 4.6894e-04 - dense_13_loss: 3.9149e-04 - dense_14_loss: 4.4071e-04 - dense_15_loss: 4.3127e-04 - dense_16_loss: 4.1454e-04 - dense_17_loss: 4.5893e-04 - dense_18_loss: 4.4152e-04 - dense_19_loss: 4.1080e-04 - dense_20_loss: 4.8804e-04 - dense_21_loss: 3.7801e-04 - dense_22_loss: 3.8213e-04 - dense_23_loss: 3.4787e-04 - dense_24_loss: 3.8693e-04 - dense_25_loss: 3.9001e-04 - dense_26_loss: 4.1069e-04 - dense_27_loss: 4.2719e-04 - dense_28_loss: 4.6217e-04 - dense_29_loss: 4.2567e-04 - val_loss: 0.0046 - val_dense_7_loss: 1.8979e-04 - val_dense_8_loss: 1.3782e-04 - val_dense_9_loss: 1.8327e-04 - val_dense_10_loss: 2.3975e-04 - val_dense_11_loss: 1.9047e-04 - val_dense_12_loss: 2.0909e-04 - val_dense_13_loss: 2.0146e-04 - val_dense_14_loss: 2.8666e-04 - val_dense_15_loss: 2.0911e-04 - val_dense_16_loss: 1.9615e-04 - val_dense_17_loss: 2.3441e-04 - val_dense_18_loss: 1.4598e-04 - val_dense_19_loss: 2.1323e-04 - val_dense_20_loss: 2.5823e-04 - val_dense_21_loss: 2.2326e-04 - val_dense_22_loss: 1.4381e-04 - val_dense_23_loss: 1.7844e-04 - val_dense_24_loss: 1.9704e-04 - val_dense_25_loss: 1.6752e-04 - val_dense_26_loss: 1.9460e-04 - val_dense_27_loss: 1.7722e-04 - val_dense_28_loss: 2.2548e-04 - val_dense_29_loss: 1.4732e-04\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.0042 - dense_7_loss: 1.7496e-04 - dense_8_loss: 1.3117e-04 - dense_9_loss: 1.7112e-04 - dense_10_loss: 2.2097e-04 - dense_11_loss: 1.7660e-04 - dense_12_loss: 1.9567e-04 - dense_13_loss: 1.8692e-04 - dense_14_loss: 2.6537e-04 - dense_15_loss: 1.9406e-04 - dense_16_loss: 1.8252e-04 - dense_17_loss: 2.1948e-04 - dense_18_loss: 1.4126e-04 - dense_19_loss: 1.9760e-04 - dense_20_loss: 2.3648e-04 - dense_21_loss: 2.0271e-04 - dense_22_loss: 1.3740e-04 - dense_23_loss: 1.6956e-04 - dense_24_loss: 1.8520e-04 - dense_25_loss: 1.5665e-04 - dense_26_loss: 1.8119e-04 - dense_27_loss: 1.6563e-04 - dense_28_loss: 2.1097e-04 - dense_29_loss: 1.3951e-04 - val_loss: 0.0062 - val_dense_7_loss: 2.9275e-04 - val_dense_8_loss: 3.1771e-04 - val_dense_9_loss: 2.3885e-04 - val_dense_10_loss: 2.8211e-04 - val_dense_11_loss: 2.9865e-04 - val_dense_12_loss: 2.5333e-04 - val_dense_13_loss: 3.1648e-04 - val_dense_14_loss: 2.2731e-04 - val_dense_15_loss: 2.5110e-04 - val_dense_16_loss: 2.5110e-04 - val_dense_17_loss: 2.8093e-04 - val_dense_18_loss: 2.6222e-04 - val_dense_19_loss: 2.7082e-04 - val_dense_20_loss: 2.2520e-04 - val_dense_21_loss: 2.4376e-04 - val_dense_22_loss: 2.8292e-04 - val_dense_23_loss: 2.5092e-04 - val_dense_24_loss: 2.9317e-04 - val_dense_25_loss: 2.5797e-04 - val_dense_26_loss: 2.3838e-04 - val_dense_27_loss: 3.0194e-04 - val_dense_28_loss: 2.1760e-04 - val_dense_29_loss: 3.1263e-04\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.0056 - dense_7_loss: 2.6311e-04 - dense_8_loss: 2.8799e-04 - dense_9_loss: 2.1726e-04 - dense_10_loss: 2.5467e-04 - dense_11_loss: 2.6846e-04 - dense_12_loss: 2.3005e-04 - dense_13_loss: 2.8755e-04 - dense_14_loss: 2.0870e-04 - dense_15_loss: 2.2788e-04 - dense_16_loss: 2.3089e-04 - dense_17_loss: 2.5309e-04 - dense_18_loss: 2.3837e-04 - dense_19_loss: 2.4876e-04 - dense_20_loss: 2.0908e-04 - dense_21_loss: 2.2173e-04 - dense_22_loss: 2.5525e-04 - dense_23_loss: 2.2807e-04 - dense_24_loss: 2.6471e-04 - dense_25_loss: 2.3568e-04 - dense_26_loss: 2.1792e-04 - dense_27_loss: 2.7223e-04 - dense_28_loss: 1.9960e-04 - dense_29_loss: 2.8560e-04 - val_loss: 0.0021 - val_dense_7_loss: 8.9450e-05 - val_dense_8_loss: 1.0231e-04 - val_dense_9_loss: 7.4140e-05 - val_dense_10_loss: 1.0031e-04 - val_dense_11_loss: 8.5854e-05 - val_dense_12_loss: 9.4040e-05 - val_dense_13_loss: 1.0887e-04 - val_dense_14_loss: 9.5458e-05 - val_dense_15_loss: 7.5929e-05 - val_dense_16_loss: 9.6521e-05 - val_dense_17_loss: 8.1859e-05 - val_dense_18_loss: 9.3075e-05 - val_dense_19_loss: 1.1524e-04 - val_dense_20_loss: 8.7427e-05 - val_dense_21_loss: 7.6042e-05 - val_dense_22_loss: 7.8635e-05 - val_dense_23_loss: 7.6740e-05 - val_dense_24_loss: 9.1546e-05 - val_dense_25_loss: 8.4330e-05 - val_dense_26_loss: 8.0390e-05 - val_dense_27_loss: 1.0216e-04 - val_dense_28_loss: 8.4216e-05 - val_dense_29_loss: 1.0415e-04\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.0020 - dense_7_loss: 8.6617e-05 - dense_8_loss: 9.9594e-05 - dense_9_loss: 7.2579e-05 - dense_10_loss: 9.7372e-05 - dense_11_loss: 8.2600e-05 - dense_12_loss: 9.1728e-05 - dense_13_loss: 1.0449e-04 - dense_14_loss: 9.2403e-05 - dense_15_loss: 7.3687e-05 - dense_16_loss: 9.2492e-05 - dense_17_loss: 8.0062e-05 - dense_18_loss: 8.9574e-05 - dense_19_loss: 1.1142e-04 - dense_20_loss: 8.3386e-05 - dense_21_loss: 7.3199e-05 - dense_22_loss: 7.5768e-05 - dense_23_loss: 7.3961e-05 - dense_24_loss: 8.9025e-05 - dense_25_loss: 8.1495e-05 - dense_26_loss: 7.8533e-05 - dense_27_loss: 9.8669e-05 - dense_28_loss: 8.1598e-05 - dense_29_loss: 9.8851e-05 - val_loss: 0.0011 - val_dense_7_loss: 4.8287e-05 - val_dense_8_loss: 6.6645e-05 - val_dense_9_loss: 4.6422e-05 - val_dense_10_loss: 5.3150e-05 - val_dense_11_loss: 4.0986e-05 - val_dense_12_loss: 5.2179e-05 - val_dense_13_loss: 4.8079e-05 - val_dense_14_loss: 4.6258e-05 - val_dense_15_loss: 4.0803e-05 - val_dense_16_loss: 4.9754e-05 - val_dense_17_loss: 4.7946e-05 - val_dense_18_loss: 5.2257e-05 - val_dense_19_loss: 4.9025e-05 - val_dense_20_loss: 3.5977e-05 - val_dense_21_loss: 4.3344e-05 - val_dense_22_loss: 4.4916e-05 - val_dense_23_loss: 4.6077e-05 - val_dense_24_loss: 5.4177e-05 - val_dense_25_loss: 4.4356e-05 - val_dense_26_loss: 3.9599e-05 - val_dense_27_loss: 5.4899e-05 - val_dense_28_loss: 4.1608e-05 - val_dense_29_loss: 5.3539e-05\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.0011 - dense_7_loss: 4.7783e-05 - dense_8_loss: 6.5059e-05 - dense_9_loss: 4.6510e-05 - dense_10_loss: 5.1495e-05 - dense_11_loss: 3.9910e-05 - dense_12_loss: 5.2783e-05 - dense_13_loss: 4.7807e-05 - dense_14_loss: 4.6345e-05 - dense_15_loss: 4.1278e-05 - dense_16_loss: 4.9138e-05 - dense_17_loss: 4.7186e-05 - dense_18_loss: 5.0876e-05 - dense_19_loss: 4.6724e-05 - dense_20_loss: 3.5865e-05 - dense_21_loss: 4.3203e-05 - dense_22_loss: 4.4683e-05 - dense_23_loss: 4.5739e-05 - dense_24_loss: 5.3822e-05 - dense_25_loss: 4.4415e-05 - dense_26_loss: 4.0035e-05 - dense_27_loss: 5.3814e-05 - dense_28_loss: 4.2342e-05 - dense_29_loss: 5.2930e-05 - val_loss: 8.0278e-04 - val_dense_7_loss: 3.4500e-05 - val_dense_8_loss: 4.2923e-05 - val_dense_9_loss: 3.8654e-05 - val_dense_10_loss: 3.4739e-05 - val_dense_11_loss: 3.2498e-05 - val_dense_12_loss: 3.7176e-05 - val_dense_13_loss: 3.7063e-05 - val_dense_14_loss: 4.0007e-05 - val_dense_15_loss: 3.6833e-05 - val_dense_16_loss: 3.6117e-05 - val_dense_17_loss: 3.6062e-05 - val_dense_18_loss: 3.1438e-05 - val_dense_19_loss: 2.9985e-05 - val_dense_20_loss: 2.8509e-05 - val_dense_21_loss: 2.9730e-05 - val_dense_22_loss: 3.0840e-05 - val_dense_23_loss: 2.9798e-05 - val_dense_24_loss: 3.9238e-05 - val_dense_25_loss: 3.6078e-05 - val_dense_26_loss: 3.2594e-05 - val_dense_27_loss: 3.4997e-05 - val_dense_28_loss: 3.8675e-05 - val_dense_29_loss: 3.4324e-05\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 7.9576e-04 - dense_7_loss: 3.4434e-05 - dense_8_loss: 4.2546e-05 - dense_9_loss: 3.8183e-05 - dense_10_loss: 3.4091e-05 - dense_11_loss: 3.2109e-05 - dense_12_loss: 3.7095e-05 - dense_13_loss: 3.7429e-05 - dense_14_loss: 4.0110e-05 - dense_15_loss: 3.5747e-05 - dense_16_loss: 3.5456e-05 - dense_17_loss: 3.5582e-05 - dense_18_loss: 3.1015e-05 - dense_19_loss: 3.0374e-05 - dense_20_loss: 2.7935e-05 - dense_21_loss: 2.9377e-05 - dense_22_loss: 3.0589e-05 - dense_23_loss: 2.8882e-05 - dense_24_loss: 3.9086e-05 - dense_25_loss: 3.5930e-05 - dense_26_loss: 3.2830e-05 - dense_27_loss: 3.4521e-05 - dense_28_loss: 3.8390e-05 - dense_29_loss: 3.4051e-05 - val_loss: 6.3502e-04 - val_dense_7_loss: 3.1179e-05 - val_dense_8_loss: 3.4344e-05 - val_dense_9_loss: 2.9017e-05 - val_dense_10_loss: 3.1576e-05 - val_dense_11_loss: 2.8472e-05 - val_dense_12_loss: 2.9912e-05 - val_dense_13_loss: 3.7954e-05 - val_dense_14_loss: 3.3064e-05 - val_dense_15_loss: 2.4804e-05 - val_dense_16_loss: 2.7145e-05 - val_dense_17_loss: 2.5989e-05 - val_dense_18_loss: 2.6324e-05 - val_dense_19_loss: 2.8491e-05 - val_dense_20_loss: 2.1542e-05 - val_dense_21_loss: 2.5194e-05 - val_dense_22_loss: 2.3523e-05 - val_dense_23_loss: 1.9645e-05 - val_dense_24_loss: 2.7996e-05 - val_dense_25_loss: 2.4134e-05 - val_dense_26_loss: 2.2548e-05 - val_dense_27_loss: 3.3362e-05 - val_dense_28_loss: 2.3784e-05 - val_dense_29_loss: 2.5018e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 6.2155e-04 - dense_7_loss: 3.0418e-05 - dense_8_loss: 3.3766e-05 - dense_9_loss: 2.8636e-05 - dense_10_loss: 3.0402e-05 - dense_11_loss: 2.7703e-05 - dense_12_loss: 2.9162e-05 - dense_13_loss: 3.6723e-05 - dense_14_loss: 3.2563e-05 - dense_15_loss: 2.4421e-05 - dense_16_loss: 2.6343e-05 - dense_17_loss: 2.5372e-05 - dense_18_loss: 2.5767e-05 - dense_19_loss: 2.7795e-05 - dense_20_loss: 2.1193e-05 - dense_21_loss: 2.4505e-05 - dense_22_loss: 2.2467e-05 - dense_23_loss: 1.9367e-05 - dense_24_loss: 2.7384e-05 - dense_25_loss: 2.3922e-05 - dense_26_loss: 2.2714e-05 - dense_27_loss: 3.2201e-05 - dense_28_loss: 2.3972e-05 - dense_29_loss: 2.4751e-05 - val_loss: 4.1575e-04 - val_dense_7_loss: 2.0648e-05 - val_dense_8_loss: 2.5515e-05 - val_dense_9_loss: 2.2449e-05 - val_dense_10_loss: 1.8221e-05 - val_dense_11_loss: 1.9055e-05 - val_dense_12_loss: 1.9100e-05 - val_dense_13_loss: 2.2303e-05 - val_dense_14_loss: 2.2100e-05 - val_dense_15_loss: 2.1730e-05 - val_dense_16_loss: 1.8469e-05 - val_dense_17_loss: 2.0148e-05 - val_dense_18_loss: 1.5727e-05 - val_dense_19_loss: 1.6631e-05 - val_dense_20_loss: 1.2762e-05 - val_dense_21_loss: 1.6258e-05 - val_dense_22_loss: 1.3889e-05 - val_dense_23_loss: 1.5099e-05 - val_dense_24_loss: 1.6576e-05 - val_dense_25_loss: 1.3540e-05 - val_dense_26_loss: 1.1517e-05 - val_dense_27_loss: 2.0016e-05 - val_dense_28_loss: 1.6467e-05 - val_dense_29_loss: 1.7532e-05\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 4.1223e-04 - dense_7_loss: 2.0640e-05 - dense_8_loss: 2.5411e-05 - dense_9_loss: 2.2211e-05 - dense_10_loss: 1.8111e-05 - dense_11_loss: 1.8731e-05 - dense_12_loss: 1.8981e-05 - dense_13_loss: 2.1741e-05 - dense_14_loss: 2.1609e-05 - dense_15_loss: 2.1100e-05 - dense_16_loss: 1.8034e-05 - dense_17_loss: 1.9738e-05 - dense_18_loss: 1.5197e-05 - dense_19_loss: 1.6017e-05 - dense_20_loss: 1.2509e-05 - dense_21_loss: 1.5853e-05 - dense_22_loss: 1.3740e-05 - dense_23_loss: 1.4660e-05 - dense_24_loss: 1.7174e-05 - dense_25_loss: 1.3911e-05 - dense_26_loss: 1.2563e-05 - dense_27_loss: 1.9535e-05 - dense_28_loss: 1.7172e-05 - dense_29_loss: 1.7591e-05 - val_loss: 3.1982e-04 - val_dense_7_loss: 1.8212e-05 - val_dense_8_loss: 2.2012e-05 - val_dense_9_loss: 1.7952e-05 - val_dense_10_loss: 1.4881e-05 - val_dense_11_loss: 1.3879e-05 - val_dense_12_loss: 1.6196e-05 - val_dense_13_loss: 1.3452e-05 - val_dense_14_loss: 1.6618e-05 - val_dense_15_loss: 1.4280e-05 - val_dense_16_loss: 1.4356e-05 - val_dense_17_loss: 1.4308e-05 - val_dense_18_loss: 1.1016e-05 - val_dense_19_loss: 1.0018e-05 - val_dense_20_loss: 1.0396e-05 - val_dense_21_loss: 1.1317e-05 - val_dense_22_loss: 1.1126e-05 - val_dense_23_loss: 1.1690e-05 - val_dense_24_loss: 1.5083e-05 - val_dense_25_loss: 1.1319e-05 - val_dense_26_loss: 1.1115e-05 - val_dense_27_loss: 1.3631e-05 - val_dense_28_loss: 1.4111e-05 - val_dense_29_loss: 1.2856e-05\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 3.2468e-04 - dense_7_loss: 1.8242e-05 - dense_8_loss: 2.2010e-05 - dense_9_loss: 1.8432e-05 - dense_10_loss: 1.4710e-05 - dense_11_loss: 1.3975e-05 - dense_12_loss: 1.6166e-05 - dense_13_loss: 1.3293e-05 - dense_14_loss: 1.6758e-05 - dense_15_loss: 1.4231e-05 - dense_16_loss: 1.4157e-05 - dense_17_loss: 1.4525e-05 - dense_18_loss: 1.1462e-05 - dense_19_loss: 1.0014e-05 - dense_20_loss: 1.0467e-05 - dense_21_loss: 1.1490e-05 - dense_22_loss: 1.1290e-05 - dense_23_loss: 1.1592e-05 - dense_24_loss: 1.5627e-05 - dense_25_loss: 1.2182e-05 - dense_26_loss: 1.2222e-05 - dense_27_loss: 1.3835e-05 - dense_28_loss: 1.4831e-05 - dense_29_loss: 1.3169e-05 - val_loss: 3.3385e-04 - val_dense_7_loss: 1.8077e-05 - val_dense_8_loss: 2.3429e-05 - val_dense_9_loss: 1.9993e-05 - val_dense_10_loss: 1.4322e-05 - val_dense_11_loss: 1.6215e-05 - val_dense_12_loss: 1.4967e-05 - val_dense_13_loss: 1.4822e-05 - val_dense_14_loss: 1.5623e-05 - val_dense_15_loss: 1.3828e-05 - val_dense_16_loss: 1.5387e-05 - val_dense_17_loss: 1.4201e-05 - val_dense_18_loss: 1.4402e-05 - val_dense_19_loss: 1.1081e-05 - val_dense_20_loss: 1.1386e-05 - val_dense_21_loss: 1.3939e-05 - val_dense_22_loss: 1.2208e-05 - val_dense_23_loss: 1.1710e-05 - val_dense_24_loss: 1.2506e-05 - val_dense_25_loss: 1.2724e-05 - val_dense_26_loss: 1.0944e-05 - val_dense_27_loss: 1.7311e-05 - val_dense_28_loss: 1.2708e-05 - val_dense_29_loss: 1.2066e-05\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 3.3471e-04 - dense_7_loss: 1.7938e-05 - dense_8_loss: 2.3322e-05 - dense_9_loss: 2.0192e-05 - dense_10_loss: 1.4033e-05 - dense_11_loss: 1.5994e-05 - dense_12_loss: 1.4944e-05 - dense_13_loss: 1.4601e-05 - dense_14_loss: 1.5982e-05 - dense_15_loss: 1.3802e-05 - dense_16_loss: 1.5070e-05 - dense_17_loss: 1.4119e-05 - dense_18_loss: 1.4175e-05 - dense_19_loss: 1.1098e-05 - dense_20_loss: 1.1202e-05 - dense_21_loss: 1.3744e-05 - dense_22_loss: 1.1956e-05 - dense_23_loss: 1.1446e-05 - dense_24_loss: 1.3055e-05 - dense_25_loss: 1.3300e-05 - dense_26_loss: 1.1915e-05 - dense_27_loss: 1.6817e-05 - dense_28_loss: 1.3328e-05 - dense_29_loss: 1.2682e-05 - val_loss: 2.9180e-04 - val_dense_7_loss: 1.4708e-05 - val_dense_8_loss: 2.0541e-05 - val_dense_9_loss: 1.9116e-05 - val_dense_10_loss: 1.1356e-05 - val_dense_11_loss: 1.4039e-05 - val_dense_12_loss: 1.4059e-05 - val_dense_13_loss: 1.3979e-05 - val_dense_14_loss: 1.7365e-05 - val_dense_15_loss: 1.4484e-05 - val_dense_16_loss: 1.4478e-05 - val_dense_17_loss: 1.1949e-05 - val_dense_18_loss: 1.0319e-05 - val_dense_19_loss: 1.0904e-05 - val_dense_20_loss: 8.9474e-06 - val_dense_21_loss: 1.0342e-05 - val_dense_22_loss: 9.4063e-06 - val_dense_23_loss: 9.1364e-06 - val_dense_24_loss: 1.0240e-05 - val_dense_25_loss: 1.0905e-05 - val_dense_26_loss: 8.1984e-06 - val_dense_27_loss: 1.2389e-05 - val_dense_28_loss: 1.1263e-05 - val_dense_29_loss: 1.3680e-05\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 2.9027e-04 - dense_7_loss: 1.4875e-05 - dense_8_loss: 2.0379e-05 - dense_9_loss: 1.8949e-05 - dense_10_loss: 1.1253e-05 - dense_11_loss: 1.3686e-05 - dense_12_loss: 1.3820e-05 - dense_13_loss: 1.3864e-05 - dense_14_loss: 1.6985e-05 - dense_15_loss: 1.4067e-05 - dense_16_loss: 1.3941e-05 - dense_17_loss: 1.1758e-05 - dense_18_loss: 1.0041e-05 - dense_19_loss: 1.0682e-05 - dense_20_loss: 8.9593e-06 - dense_21_loss: 1.0101e-05 - dense_22_loss: 9.1240e-06 - dense_23_loss: 8.9235e-06 - dense_24_loss: 1.0584e-05 - dense_25_loss: 1.1195e-05 - dense_26_loss: 9.1184e-06 - dense_27_loss: 1.2470e-05 - dense_28_loss: 1.1940e-05 - dense_29_loss: 1.3553e-05 - val_loss: 2.4680e-04 - val_dense_7_loss: 1.4807e-05 - val_dense_8_loss: 1.8311e-05 - val_dense_9_loss: 1.5388e-05 - val_dense_10_loss: 1.0983e-05 - val_dense_11_loss: 1.1638e-05 - val_dense_12_loss: 1.1096e-05 - val_dense_13_loss: 1.3794e-05 - val_dense_14_loss: 1.3290e-05 - val_dense_15_loss: 1.1567e-05 - val_dense_16_loss: 1.1464e-05 - val_dense_17_loss: 9.0056e-06 - val_dense_18_loss: 8.6318e-06 - val_dense_19_loss: 8.3350e-06 - val_dense_20_loss: 8.5251e-06 - val_dense_21_loss: 7.7466e-06 - val_dense_22_loss: 7.0974e-06 - val_dense_23_loss: 9.1546e-06 - val_dense_24_loss: 8.6431e-06 - val_dense_25_loss: 7.3489e-06 - val_dense_26_loss: 6.6759e-06 - val_dense_27_loss: 1.2965e-05 - val_dense_28_loss: 1.1012e-05 - val_dense_29_loss: 9.3203e-06\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 2.4608e-04 - dense_7_loss: 1.4695e-05 - dense_8_loss: 1.8206e-05 - dense_9_loss: 1.5301e-05 - dense_10_loss: 1.0794e-05 - dense_11_loss: 1.1472e-05 - dense_12_loss: 1.0952e-05 - dense_13_loss: 1.3406e-05 - dense_14_loss: 1.3260e-05 - dense_15_loss: 1.1219e-05 - dense_16_loss: 1.1079e-05 - dense_17_loss: 8.8520e-06 - dense_18_loss: 8.3883e-06 - dense_19_loss: 8.2075e-06 - dense_20_loss: 8.3119e-06 - dense_21_loss: 7.7118e-06 - dense_22_loss: 7.1021e-06 - dense_23_loss: 8.8262e-06 - dense_24_loss: 9.1563e-06 - dense_25_loss: 7.8264e-06 - dense_26_loss: 7.6504e-06 - dense_27_loss: 1.2648e-05 - dense_28_loss: 1.1579e-05 - dense_29_loss: 9.4334e-06 - val_loss: 1.9801e-04 - val_dense_7_loss: 1.2095e-05 - val_dense_8_loss: 1.6120e-05 - val_dense_9_loss: 1.3626e-05 - val_dense_10_loss: 9.2660e-06 - val_dense_11_loss: 1.0440e-05 - val_dense_12_loss: 9.0639e-06 - val_dense_13_loss: 9.7280e-06 - val_dense_14_loss: 1.2027e-05 - val_dense_15_loss: 9.5252e-06 - val_dense_16_loss: 9.0327e-06 - val_dense_17_loss: 7.3048e-06 - val_dense_18_loss: 5.7583e-06 - val_dense_19_loss: 5.3337e-06 - val_dense_20_loss: 5.3354e-06 - val_dense_21_loss: 6.9982e-06 - val_dense_22_loss: 6.6534e-06 - val_dense_23_loss: 6.3216e-06 - val_dense_24_loss: 6.9471e-06 - val_dense_25_loss: 5.4831e-06 - val_dense_26_loss: 5.6892e-06 - val_dense_27_loss: 9.1263e-06 - val_dense_28_loss: 8.5270e-06 - val_dense_29_loss: 7.6138e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 2.0122e-04 - dense_7_loss: 1.2281e-05 - dense_8_loss: 1.6233e-05 - dense_9_loss: 1.3790e-05 - dense_10_loss: 9.2716e-06 - dense_11_loss: 1.0478e-05 - dense_12_loss: 9.1317e-06 - dense_13_loss: 9.6545e-06 - dense_14_loss: 1.2007e-05 - dense_15_loss: 9.3213e-06 - dense_16_loss: 8.7722e-06 - dense_17_loss: 7.3458e-06 - dense_18_loss: 5.7634e-06 - dense_19_loss: 5.3518e-06 - dense_20_loss: 5.4940e-06 - dense_21_loss: 6.9836e-06 - dense_22_loss: 6.5459e-06 - dense_23_loss: 6.1543e-06 - dense_24_loss: 7.4868e-06 - dense_25_loss: 6.1079e-06 - dense_26_loss: 6.8212e-06 - dense_27_loss: 9.1451e-06 - dense_28_loss: 9.2829e-06 - dense_29_loss: 7.7974e-06 - val_loss: 1.7280e-04 - val_dense_7_loss: 1.1327e-05 - val_dense_8_loss: 1.5252e-05 - val_dense_9_loss: 1.2649e-05 - val_dense_10_loss: 8.4335e-06 - val_dense_11_loss: 9.5720e-06 - val_dense_12_loss: 8.0498e-06 - val_dense_13_loss: 8.5953e-06 - val_dense_14_loss: 9.7778e-06 - val_dense_15_loss: 8.8846e-06 - val_dense_16_loss: 7.2190e-06 - val_dense_17_loss: 6.9828e-06 - val_dense_18_loss: 5.5115e-06 - val_dense_19_loss: 4.3527e-06 - val_dense_20_loss: 5.3064e-06 - val_dense_21_loss: 5.7903e-06 - val_dense_22_loss: 4.5222e-06 - val_dense_23_loss: 5.0438e-06 - val_dense_24_loss: 5.3495e-06 - val_dense_25_loss: 4.3771e-06 - val_dense_26_loss: 4.8917e-06 - val_dense_27_loss: 7.5961e-06 - val_dense_28_loss: 7.1179e-06 - val_dense_29_loss: 6.1966e-06\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.7689e-04 - dense_7_loss: 1.1466e-05 - dense_8_loss: 1.5372e-05 - dense_9_loss: 1.2843e-05 - dense_10_loss: 8.3586e-06 - dense_11_loss: 9.6122e-06 - dense_12_loss: 8.1873e-06 - dense_13_loss: 8.5080e-06 - dense_14_loss: 9.8594e-06 - dense_15_loss: 8.8054e-06 - dense_16_loss: 7.0794e-06 - dense_17_loss: 7.0080e-06 - dense_18_loss: 5.5097e-06 - dense_19_loss: 4.4537e-06 - dense_20_loss: 5.3667e-06 - dense_21_loss: 5.8946e-06 - dense_22_loss: 4.5734e-06 - dense_23_loss: 4.9110e-06 - dense_24_loss: 5.9586e-06 - dense_25_loss: 5.1160e-06 - dense_26_loss: 5.9066e-06 - dense_27_loss: 7.5912e-06 - dense_28_loss: 7.9311e-06 - dense_29_loss: 6.5764e-06 - val_loss: 1.5985e-04 - val_dense_7_loss: 1.0471e-05 - val_dense_8_loss: 1.4897e-05 - val_dense_9_loss: 1.2267e-05 - val_dense_10_loss: 6.6667e-06 - val_dense_11_loss: 8.6972e-06 - val_dense_12_loss: 7.5138e-06 - val_dense_13_loss: 7.6030e-06 - val_dense_14_loss: 9.5764e-06 - val_dense_15_loss: 8.5507e-06 - val_dense_16_loss: 7.1943e-06 - val_dense_17_loss: 5.7672e-06 - val_dense_18_loss: 4.8088e-06 - val_dense_19_loss: 4.8729e-06 - val_dense_20_loss: 4.9418e-06 - val_dense_21_loss: 5.6519e-06 - val_dense_22_loss: 3.8200e-06 - val_dense_23_loss: 4.1385e-06 - val_dense_24_loss: 4.0194e-06 - val_dense_25_loss: 4.6188e-06 - val_dense_26_loss: 3.7458e-06 - val_dense_27_loss: 6.4243e-06 - val_dense_28_loss: 6.5971e-06 - val_dense_29_loss: 7.0024e-06\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.6374e-04 - dense_7_loss: 1.0658e-05 - dense_8_loss: 1.5079e-05 - dense_9_loss: 1.2478e-05 - dense_10_loss: 6.6639e-06 - dense_11_loss: 8.6838e-06 - dense_12_loss: 7.6638e-06 - dense_13_loss: 7.5465e-06 - dense_14_loss: 9.6167e-06 - dense_15_loss: 8.3601e-06 - dense_16_loss: 7.1004e-06 - dense_17_loss: 5.7135e-06 - dense_18_loss: 4.7077e-06 - dense_19_loss: 4.8595e-06 - dense_20_loss: 4.9982e-06 - dense_21_loss: 5.6631e-06 - dense_22_loss: 3.8811e-06 - dense_23_loss: 4.0053e-06 - dense_24_loss: 4.6724e-06 - dense_25_loss: 5.2540e-06 - dense_26_loss: 4.9039e-06 - dense_27_loss: 6.5128e-06 - dense_28_loss: 7.4128e-06 - dense_29_loss: 7.3105e-06 - val_loss: 1.5963e-04 - val_dense_7_loss: 1.0328e-05 - val_dense_8_loss: 1.4901e-05 - val_dense_9_loss: 1.2782e-05 - val_dense_10_loss: 7.1299e-06 - val_dense_11_loss: 8.0515e-06 - val_dense_12_loss: 7.9795e-06 - val_dense_13_loss: 7.0135e-06 - val_dense_14_loss: 1.0039e-05 - val_dense_15_loss: 7.8980e-06 - val_dense_16_loss: 7.9037e-06 - val_dense_17_loss: 5.5899e-06 - val_dense_18_loss: 3.8632e-06 - val_dense_19_loss: 4.3207e-06 - val_dense_20_loss: 4.6695e-06 - val_dense_21_loss: 4.5010e-06 - val_dense_22_loss: 3.8616e-06 - val_dense_23_loss: 4.4252e-06 - val_dense_24_loss: 4.5456e-06 - val_dense_25_loss: 5.0177e-06 - val_dense_26_loss: 4.5353e-06 - val_dense_27_loss: 7.1442e-06 - val_dense_28_loss: 6.6380e-06 - val_dense_29_loss: 6.4970e-06\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.6251e-04 - dense_7_loss: 1.0544e-05 - dense_8_loss: 1.5022e-05 - dense_9_loss: 1.2864e-05 - dense_10_loss: 7.0760e-06 - dense_11_loss: 8.0550e-06 - dense_12_loss: 8.0015e-06 - dense_13_loss: 7.0110e-06 - dense_14_loss: 9.9151e-06 - dense_15_loss: 7.6823e-06 - dense_16_loss: 7.6747e-06 - dense_17_loss: 5.4914e-06 - dense_18_loss: 3.8198e-06 - dense_19_loss: 4.2991e-06 - dense_20_loss: 4.6690e-06 - dense_21_loss: 4.5507e-06 - dense_22_loss: 3.9164e-06 - dense_23_loss: 4.2792e-06 - dense_24_loss: 5.1673e-06 - dense_25_loss: 5.5060e-06 - dense_26_loss: 5.5825e-06 - dense_27_loss: 7.1590e-06 - dense_28_loss: 7.4526e-06 - dense_29_loss: 6.7692e-06 - val_loss: 1.3742e-04 - val_dense_7_loss: 9.7328e-06 - val_dense_8_loss: 1.3896e-05 - val_dense_9_loss: 1.1340e-05 - val_dense_10_loss: 6.2175e-06 - val_dense_11_loss: 7.5177e-06 - val_dense_12_loss: 6.4807e-06 - val_dense_13_loss: 6.7205e-06 - val_dense_14_loss: 8.5468e-06 - val_dense_15_loss: 6.9041e-06 - val_dense_16_loss: 6.7024e-06 - val_dense_17_loss: 4.5910e-06 - val_dense_18_loss: 3.1198e-06 - val_dense_19_loss: 3.4857e-06 - val_dense_20_loss: 3.2963e-06 - val_dense_21_loss: 3.9251e-06 - val_dense_22_loss: 3.4041e-06 - val_dense_23_loss: 3.7715e-06 - val_dense_24_loss: 3.6451e-06 - val_dense_25_loss: 3.1250e-06 - val_dense_26_loss: 3.1259e-06 - val_dense_27_loss: 5.9729e-06 - val_dense_28_loss: 6.2353e-06 - val_dense_29_loss: 5.6597e-06\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.4172e-04 - dense_7_loss: 9.9308e-06 - dense_8_loss: 1.4040e-05 - dense_9_loss: 1.1510e-05 - dense_10_loss: 6.2441e-06 - dense_11_loss: 7.6208e-06 - dense_12_loss: 6.5684e-06 - dense_13_loss: 6.7282e-06 - dense_14_loss: 8.6198e-06 - dense_15_loss: 6.7699e-06 - dense_16_loss: 6.5105e-06 - dense_17_loss: 4.6602e-06 - dense_18_loss: 3.1387e-06 - dense_19_loss: 3.5351e-06 - dense_20_loss: 3.3945e-06 - dense_21_loss: 4.0270e-06 - dense_22_loss: 3.4699e-06 - dense_23_loss: 3.6521e-06 - dense_24_loss: 4.2914e-06 - dense_25_loss: 3.7636e-06 - dense_26_loss: 4.2354e-06 - dense_27_loss: 6.0239e-06 - dense_28_loss: 7.0395e-06 - dense_29_loss: 5.9434e-06 - val_loss: 1.3120e-04 - val_dense_7_loss: 9.4484e-06 - val_dense_8_loss: 1.3714e-05 - val_dense_9_loss: 1.0986e-05 - val_dense_10_loss: 6.3629e-06 - val_dense_11_loss: 7.6853e-06 - val_dense_12_loss: 6.2808e-06 - val_dense_13_loss: 6.4074e-06 - val_dense_14_loss: 8.2408e-06 - val_dense_15_loss: 6.7126e-06 - val_dense_16_loss: 6.0840e-06 - val_dense_17_loss: 4.3698e-06 - val_dense_18_loss: 3.0774e-06 - val_dense_19_loss: 3.1219e-06 - val_dense_20_loss: 3.1201e-06 - val_dense_21_loss: 3.9795e-06 - val_dense_22_loss: 3.1151e-06 - val_dense_23_loss: 3.3558e-06 - val_dense_24_loss: 3.0409e-06 - val_dense_25_loss: 2.7948e-06 - val_dense_26_loss: 2.7471e-06 - val_dense_27_loss: 5.5970e-06 - val_dense_28_loss: 5.6735e-06 - val_dense_29_loss: 5.2852e-06\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.3496e-04 - dense_7_loss: 9.6653e-06 - dense_8_loss: 1.3849e-05 - dense_9_loss: 1.1120e-05 - dense_10_loss: 6.3434e-06 - dense_11_loss: 7.7176e-06 - dense_12_loss: 6.4107e-06 - dense_13_loss: 6.3632e-06 - dense_14_loss: 8.2656e-06 - dense_15_loss: 6.5773e-06 - dense_16_loss: 5.8834e-06 - dense_17_loss: 4.3774e-06 - dense_18_loss: 3.0406e-06 - dense_19_loss: 3.1328e-06 - dense_20_loss: 3.1938e-06 - dense_21_loss: 4.0296e-06 - dense_22_loss: 3.1569e-06 - dense_23_loss: 3.2070e-06 - dense_24_loss: 3.6619e-06 - dense_25_loss: 3.4550e-06 - dense_26_loss: 3.8840e-06 - dense_27_loss: 5.6293e-06 - dense_28_loss: 6.4388e-06 - dense_29_loss: 5.5552e-06 - val_loss: 1.2402e-04 - val_dense_7_loss: 9.2681e-06 - val_dense_8_loss: 1.3322e-05 - val_dense_9_loss: 1.0561e-05 - val_dense_10_loss: 5.9431e-06 - val_dense_11_loss: 7.2456e-06 - val_dense_12_loss: 6.3642e-06 - val_dense_13_loss: 5.9509e-06 - val_dense_14_loss: 7.8397e-06 - val_dense_15_loss: 6.5652e-06 - val_dense_16_loss: 5.6786e-06 - val_dense_17_loss: 4.1090e-06 - val_dense_18_loss: 2.6429e-06 - val_dense_19_loss: 2.8572e-06 - val_dense_20_loss: 3.0197e-06 - val_dense_21_loss: 3.6721e-06 - val_dense_22_loss: 2.6633e-06 - val_dense_23_loss: 2.8486e-06 - val_dense_24_loss: 2.6884e-06 - val_dense_25_loss: 2.6908e-06 - val_dense_26_loss: 2.6952e-06 - val_dense_27_loss: 5.4402e-06 - val_dense_28_loss: 5.0405e-06 - val_dense_29_loss: 4.9121e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.2816e-04 - dense_7_loss: 9.4842e-06 - dense_8_loss: 1.3498e-05 - dense_9_loss: 1.0758e-05 - dense_10_loss: 5.9370e-06 - dense_11_loss: 7.2671e-06 - dense_12_loss: 6.4542e-06 - dense_13_loss: 5.9117e-06 - dense_14_loss: 7.8682e-06 - dense_15_loss: 6.4275e-06 - dense_16_loss: 5.5251e-06 - dense_17_loss: 4.1107e-06 - dense_18_loss: 2.6538e-06 - dense_19_loss: 2.9009e-06 - dense_20_loss: 3.0931e-06 - dense_21_loss: 3.7417e-06 - dense_22_loss: 2.7293e-06 - dense_23_loss: 2.7332e-06 - dense_24_loss: 3.3108e-06 - dense_25_loss: 3.3639e-06 - dense_26_loss: 3.8061e-06 - dense_27_loss: 5.4844e-06 - dense_28_loss: 5.8508e-06 - dense_29_loss: 5.2480e-06 - val_loss: 1.1920e-04 - val_dense_7_loss: 8.9743e-06 - val_dense_8_loss: 1.3256e-05 - val_dense_9_loss: 1.0606e-05 - val_dense_10_loss: 5.5569e-06 - val_dense_11_loss: 6.8856e-06 - val_dense_12_loss: 5.8280e-06 - val_dense_13_loss: 5.6081e-06 - val_dense_14_loss: 7.5077e-06 - val_dense_15_loss: 6.2988e-06 - val_dense_16_loss: 5.6280e-06 - val_dense_17_loss: 3.7294e-06 - val_dense_18_loss: 2.5983e-06 - val_dense_19_loss: 2.9323e-06 - val_dense_20_loss: 2.9957e-06 - val_dense_21_loss: 3.5151e-06 - val_dense_22_loss: 2.4704e-06 - val_dense_23_loss: 2.7410e-06 - val_dense_24_loss: 2.4129e-06 - val_dense_25_loss: 2.4735e-06 - val_dense_26_loss: 2.3133e-06 - val_dense_27_loss: 5.0793e-06 - val_dense_28_loss: 4.8285e-06 - val_dense_29_loss: 4.9582e-06\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.2324e-04 - dense_7_loss: 9.1980e-06 - dense_8_loss: 1.3400e-05 - dense_9_loss: 1.0779e-05 - dense_10_loss: 5.5387e-06 - dense_11_loss: 6.9211e-06 - dense_12_loss: 5.9257e-06 - dense_13_loss: 5.5828e-06 - dense_14_loss: 7.5498e-06 - dense_15_loss: 6.1510e-06 - dense_16_loss: 5.4643e-06 - dense_17_loss: 3.7342e-06 - dense_18_loss: 2.5868e-06 - dense_19_loss: 2.9664e-06 - dense_20_loss: 3.0619e-06 - dense_21_loss: 3.5607e-06 - dense_22_loss: 2.5304e-06 - dense_23_loss: 2.6387e-06 - dense_24_loss: 3.0459e-06 - dense_25_loss: 3.1193e-06 - dense_26_loss: 3.4271e-06 - dense_27_loss: 5.1249e-06 - dense_28_loss: 5.6612e-06 - dense_29_loss: 5.2687e-06 - val_loss: 1.1433e-04 - val_dense_7_loss: 8.8902e-06 - val_dense_8_loss: 1.3032e-05 - val_dense_9_loss: 1.0440e-05 - val_dense_10_loss: 5.3903e-06 - val_dense_11_loss: 6.7362e-06 - val_dense_12_loss: 5.5081e-06 - val_dense_13_loss: 5.2874e-06 - val_dense_14_loss: 7.2272e-06 - val_dense_15_loss: 6.1451e-06 - val_dense_16_loss: 5.4152e-06 - val_dense_17_loss: 3.6135e-06 - val_dense_18_loss: 2.2921e-06 - val_dense_19_loss: 2.5897e-06 - val_dense_20_loss: 2.6312e-06 - val_dense_21_loss: 2.8417e-06 - val_dense_22_loss: 2.2645e-06 - val_dense_23_loss: 2.7344e-06 - val_dense_24_loss: 2.2200e-06 - val_dense_25_loss: 2.3366e-06 - val_dense_26_loss: 2.0636e-06 - val_dense_27_loss: 4.9300e-06 - val_dense_28_loss: 4.9295e-06 - val_dense_29_loss: 4.8088e-06\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.1859e-04 - dense_7_loss: 9.0961e-06 - dense_8_loss: 1.3205e-05 - dense_9_loss: 1.0614e-05 - dense_10_loss: 5.3913e-06 - dense_11_loss: 6.7667e-06 - dense_12_loss: 5.6418e-06 - dense_13_loss: 5.2921e-06 - dense_14_loss: 7.2777e-06 - dense_15_loss: 6.0118e-06 - dense_16_loss: 5.2628e-06 - dense_17_loss: 3.5955e-06 - dense_18_loss: 2.2861e-06 - dense_19_loss: 2.6360e-06 - dense_20_loss: 2.7068e-06 - dense_21_loss: 2.9317e-06 - dense_22_loss: 2.3321e-06 - dense_23_loss: 2.6358e-06 - dense_24_loss: 2.8666e-06 - dense_25_loss: 2.9863e-06 - dense_26_loss: 3.1879e-06 - dense_27_loss: 4.9682e-06 - dense_28_loss: 5.7627e-06 - dense_29_loss: 5.1354e-06 - val_loss: 1.1087e-04 - val_dense_7_loss: 8.7000e-06 - val_dense_8_loss: 1.2996e-05 - val_dense_9_loss: 1.0265e-05 - val_dense_10_loss: 5.3279e-06 - val_dense_11_loss: 6.5986e-06 - val_dense_12_loss: 5.5101e-06 - val_dense_13_loss: 5.1905e-06 - val_dense_14_loss: 7.0306e-06 - val_dense_15_loss: 6.0285e-06 - val_dense_16_loss: 5.2298e-06 - val_dense_17_loss: 3.3582e-06 - val_dense_18_loss: 2.0664e-06 - val_dense_19_loss: 2.3711e-06 - val_dense_20_loss: 2.3630e-06 - val_dense_21_loss: 2.8321e-06 - val_dense_22_loss: 2.0974e-06 - val_dense_23_loss: 2.6512e-06 - val_dense_24_loss: 2.1332e-06 - val_dense_25_loss: 2.0721e-06 - val_dense_26_loss: 1.9755e-06 - val_dense_27_loss: 4.6592e-06 - val_dense_28_loss: 4.7068e-06 - val_dense_29_loss: 4.7114e-06\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.1514e-04 - dense_7_loss: 8.9239e-06 - dense_8_loss: 1.3167e-05 - dense_9_loss: 1.0429e-05 - dense_10_loss: 5.3308e-06 - dense_11_loss: 6.6380e-06 - dense_12_loss: 5.6454e-06 - dense_13_loss: 5.1818e-06 - dense_14_loss: 7.1037e-06 - dense_15_loss: 5.8794e-06 - dense_16_loss: 5.0684e-06 - dense_17_loss: 3.3810e-06 - dense_18_loss: 2.0656e-06 - dense_19_loss: 2.4107e-06 - dense_20_loss: 2.4333e-06 - dense_21_loss: 2.9160e-06 - dense_22_loss: 2.1634e-06 - dense_23_loss: 2.5344e-06 - dense_24_loss: 2.7792e-06 - dense_25_loss: 2.7174e-06 - dense_26_loss: 3.1244e-06 - dense_27_loss: 4.7218e-06 - dense_28_loss: 5.5069e-06 - dense_29_loss: 5.0216e-06 - val_loss: 1.0775e-04 - val_dense_7_loss: 8.5810e-06 - val_dense_8_loss: 1.2933e-05 - val_dense_9_loss: 1.0066e-05 - val_dense_10_loss: 5.1956e-06 - val_dense_11_loss: 6.5240e-06 - val_dense_12_loss: 5.5552e-06 - val_dense_13_loss: 5.0243e-06 - val_dense_14_loss: 7.0415e-06 - val_dense_15_loss: 5.7583e-06 - val_dense_16_loss: 5.1859e-06 - val_dense_17_loss: 3.2059e-06 - val_dense_18_loss: 1.8799e-06 - val_dense_19_loss: 2.2463e-06 - val_dense_20_loss: 2.2569e-06 - val_dense_21_loss: 2.8666e-06 - val_dense_22_loss: 1.9689e-06 - val_dense_23_loss: 2.4152e-06 - val_dense_24_loss: 1.8905e-06 - val_dense_25_loss: 1.7524e-06 - val_dense_26_loss: 2.0124e-06 - val_dense_27_loss: 4.6150e-06 - val_dense_28_loss: 4.3266e-06 - val_dense_29_loss: 4.4465e-06\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.1212e-04 - dense_7_loss: 8.7977e-06 - dense_8_loss: 1.3096e-05 - dense_9_loss: 1.0245e-05 - dense_10_loss: 5.2018e-06 - dense_11_loss: 6.5550e-06 - dense_12_loss: 5.6838e-06 - dense_13_loss: 5.0203e-06 - dense_14_loss: 7.1074e-06 - dense_15_loss: 5.6158e-06 - dense_16_loss: 5.0282e-06 - dense_17_loss: 3.2289e-06 - dense_18_loss: 1.8913e-06 - dense_19_loss: 2.2923e-06 - dense_20_loss: 2.3362e-06 - dense_21_loss: 2.9534e-06 - dense_22_loss: 2.0480e-06 - dense_23_loss: 2.3030e-06 - dense_24_loss: 2.5385e-06 - dense_25_loss: 2.4160e-06 - dense_26_loss: 3.1525e-06 - dense_27_loss: 4.6783e-06 - dense_28_loss: 5.1564e-06 - dense_29_loss: 4.7714e-06 - val_loss: 1.0636e-04 - val_dense_7_loss: 8.4380e-06 - val_dense_8_loss: 1.2843e-05 - val_dense_9_loss: 1.0010e-05 - val_dense_10_loss: 5.0752e-06 - val_dense_11_loss: 6.4066e-06 - val_dense_12_loss: 5.4081e-06 - val_dense_13_loss: 4.9065e-06 - val_dense_14_loss: 7.0060e-06 - val_dense_15_loss: 5.6687e-06 - val_dense_16_loss: 5.0636e-06 - val_dense_17_loss: 3.1864e-06 - val_dense_18_loss: 1.9218e-06 - val_dense_19_loss: 2.1840e-06 - val_dense_20_loss: 2.1916e-06 - val_dense_21_loss: 2.7602e-06 - val_dense_22_loss: 1.9197e-06 - val_dense_23_loss: 2.3212e-06 - val_dense_24_loss: 1.8522e-06 - val_dense_25_loss: 1.7983e-06 - val_dense_26_loss: 1.9963e-06 - val_dense_27_loss: 4.6312e-06 - val_dense_28_loss: 4.3779e-06 - val_dense_29_loss: 4.3950e-06\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.1043e-04 - dense_7_loss: 8.6494e-06 - dense_8_loss: 1.2980e-05 - dense_9_loss: 1.0187e-05 - dense_10_loss: 5.0728e-06 - dense_11_loss: 6.4357e-06 - dense_12_loss: 5.5133e-06 - dense_13_loss: 4.8966e-06 - dense_14_loss: 7.0486e-06 - dense_15_loss: 5.5239e-06 - dense_16_loss: 4.9039e-06 - dense_17_loss: 3.1814e-06 - dense_18_loss: 1.9152e-06 - dense_19_loss: 2.2179e-06 - dense_20_loss: 2.2584e-06 - dense_21_loss: 2.8362e-06 - dense_22_loss: 1.9842e-06 - dense_23_loss: 2.2058e-06 - dense_24_loss: 2.4931e-06 - dense_25_loss: 2.4460e-06 - dense_26_loss: 3.1053e-06 - dense_27_loss: 4.6675e-06 - dense_28_loss: 5.2014e-06 - dense_29_loss: 4.7046e-06 - val_loss: 1.0392e-04 - val_dense_7_loss: 8.4285e-06 - val_dense_8_loss: 1.2644e-05 - val_dense_9_loss: 9.9726e-06 - val_dense_10_loss: 5.0024e-06 - val_dense_11_loss: 6.3414e-06 - val_dense_12_loss: 5.1716e-06 - val_dense_13_loss: 4.8311e-06 - val_dense_14_loss: 6.7921e-06 - val_dense_15_loss: 5.6397e-06 - val_dense_16_loss: 5.0507e-06 - val_dense_17_loss: 2.9310e-06 - val_dense_18_loss: 1.8663e-06 - val_dense_19_loss: 2.1363e-06 - val_dense_20_loss: 2.0712e-06 - val_dense_21_loss: 2.6764e-06 - val_dense_22_loss: 1.8831e-06 - val_dense_23_loss: 2.2637e-06 - val_dense_24_loss: 1.6982e-06 - val_dense_25_loss: 1.6894e-06 - val_dense_26_loss: 1.7309e-06 - val_dense_27_loss: 4.4101e-06 - val_dense_28_loss: 4.3764e-06 - val_dense_29_loss: 4.3144e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0818e-04 - dense_7_loss: 8.6550e-06 - dense_8_loss: 1.2794e-05 - dense_9_loss: 1.0160e-05 - dense_10_loss: 5.0065e-06 - dense_11_loss: 6.3636e-06 - dense_12_loss: 5.2864e-06 - dense_13_loss: 4.8201e-06 - dense_14_loss: 6.8432e-06 - dense_15_loss: 5.4980e-06 - dense_16_loss: 4.8841e-06 - dense_17_loss: 2.9497e-06 - dense_18_loss: 1.8616e-06 - dense_19_loss: 2.1780e-06 - dense_20_loss: 2.1553e-06 - dense_21_loss: 2.7552e-06 - dense_22_loss: 1.9552e-06 - dense_23_loss: 2.1648e-06 - dense_24_loss: 2.3572e-06 - dense_25_loss: 2.3359e-06 - dense_26_loss: 2.8558e-06 - dense_27_loss: 4.4648e-06 - dense_28_loss: 5.2045e-06 - dense_29_loss: 4.6319e-06 - val_loss: 1.0229e-04 - val_dense_7_loss: 8.3582e-06 - val_dense_8_loss: 1.2581e-05 - val_dense_9_loss: 9.9357e-06 - val_dense_10_loss: 4.9415e-06 - val_dense_11_loss: 6.1480e-06 - val_dense_12_loss: 5.1147e-06 - val_dense_13_loss: 4.7606e-06 - val_dense_14_loss: 6.6948e-06 - val_dense_15_loss: 5.5740e-06 - val_dense_16_loss: 4.9373e-06 - val_dense_17_loss: 2.8610e-06 - val_dense_18_loss: 1.7218e-06 - val_dense_19_loss: 2.0857e-06 - val_dense_20_loss: 2.0828e-06 - val_dense_21_loss: 2.5902e-06 - val_dense_22_loss: 1.8299e-06 - val_dense_23_loss: 2.2737e-06 - val_dense_24_loss: 1.6535e-06 - val_dense_25_loss: 1.5504e-06 - val_dense_26_loss: 1.6442e-06 - val_dense_27_loss: 4.3461e-06 - val_dense_28_loss: 4.3382e-06 - val_dense_29_loss: 4.2720e-06\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0657e-04 - dense_7_loss: 8.5812e-06 - dense_8_loss: 1.2739e-05 - dense_9_loss: 1.0121e-05 - dense_10_loss: 4.9509e-06 - dense_11_loss: 6.1943e-06 - dense_12_loss: 5.2407e-06 - dense_13_loss: 4.7476e-06 - dense_14_loss: 6.7520e-06 - dense_15_loss: 5.4389e-06 - dense_16_loss: 4.7773e-06 - dense_17_loss: 2.8804e-06 - dense_18_loss: 1.7210e-06 - dense_19_loss: 2.1182e-06 - dense_20_loss: 2.1536e-06 - dense_21_loss: 2.6681e-06 - dense_22_loss: 1.8932e-06 - dense_23_loss: 2.1620e-06 - dense_24_loss: 2.3069e-06 - dense_25_loss: 2.2111e-06 - dense_26_loss: 2.7828e-06 - dense_27_loss: 4.3950e-06 - dense_28_loss: 5.1534e-06 - dense_29_loss: 4.5779e-06 - val_loss: 1.0058e-04 - val_dense_7_loss: 8.2796e-06 - val_dense_8_loss: 1.2553e-05 - val_dense_9_loss: 9.8437e-06 - val_dense_10_loss: 4.8749e-06 - val_dense_11_loss: 6.1428e-06 - val_dense_12_loss: 5.1548e-06 - val_dense_13_loss: 4.6420e-06 - val_dense_14_loss: 6.6647e-06 - val_dense_15_loss: 5.5297e-06 - val_dense_16_loss: 4.8778e-06 - val_dense_17_loss: 2.8244e-06 - val_dense_18_loss: 1.6674e-06 - val_dense_19_loss: 1.9580e-06 - val_dense_20_loss: 1.9287e-06 - val_dense_21_loss: 2.5223e-06 - val_dense_22_loss: 1.6698e-06 - val_dense_23_loss: 2.1223e-06 - val_dense_24_loss: 1.5545e-06 - val_dense_25_loss: 1.5561e-06 - val_dense_26_loss: 1.6442e-06 - val_dense_27_loss: 4.2452e-06 - val_dense_28_loss: 4.1684e-06 - val_dense_29_loss: 4.1606e-06\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0496e-04 - dense_7_loss: 8.5006e-06 - dense_8_loss: 1.2716e-05 - dense_9_loss: 1.0029e-05 - dense_10_loss: 4.8770e-06 - dense_11_loss: 6.1852e-06 - dense_12_loss: 5.2808e-06 - dense_13_loss: 4.6322e-06 - dense_14_loss: 6.7170e-06 - dense_15_loss: 5.3975e-06 - dense_16_loss: 4.7268e-06 - dense_17_loss: 2.8459e-06 - dense_18_loss: 1.6781e-06 - dense_19_loss: 2.0049e-06 - dense_20_loss: 2.0149e-06 - dense_21_loss: 2.6131e-06 - dense_22_loss: 1.7410e-06 - dense_23_loss: 2.0200e-06 - dense_24_loss: 2.2124e-06 - dense_25_loss: 2.2121e-06 - dense_26_loss: 2.7762e-06 - dense_27_loss: 4.3047e-06 - dense_28_loss: 4.9927e-06 - dense_29_loss: 4.4782e-06 - val_loss: 9.9417e-05 - val_dense_7_loss: 8.2043e-06 - val_dense_8_loss: 1.2487e-05 - val_dense_9_loss: 9.8202e-06 - val_dense_10_loss: 4.7320e-06 - val_dense_11_loss: 6.1045e-06 - val_dense_12_loss: 5.1520e-06 - val_dense_13_loss: 4.5609e-06 - val_dense_14_loss: 6.6125e-06 - val_dense_15_loss: 5.4933e-06 - val_dense_16_loss: 4.8416e-06 - val_dense_17_loss: 2.7638e-06 - val_dense_18_loss: 1.6735e-06 - val_dense_19_loss: 1.8641e-06 - val_dense_20_loss: 1.8892e-06 - val_dense_21_loss: 2.4866e-06 - val_dense_22_loss: 1.6159e-06 - val_dense_23_loss: 2.0741e-06 - val_dense_24_loss: 1.5307e-06 - val_dense_25_loss: 1.4980e-06 - val_dense_26_loss: 1.5992e-06 - val_dense_27_loss: 4.2300e-06 - val_dense_28_loss: 4.0515e-06 - val_dense_29_loss: 4.1323e-06\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0374e-04 - dense_7_loss: 8.4207e-06 - dense_8_loss: 1.2650e-05 - dense_9_loss: 1.0003e-05 - dense_10_loss: 4.7370e-06 - dense_11_loss: 6.1456e-06 - dense_12_loss: 5.2732e-06 - dense_13_loss: 4.5530e-06 - dense_14_loss: 6.6678e-06 - dense_15_loss: 5.3569e-06 - dense_16_loss: 4.6862e-06 - dense_17_loss: 2.7837e-06 - dense_18_loss: 1.6740e-06 - dense_19_loss: 1.9071e-06 - dense_20_loss: 1.9718e-06 - dense_21_loss: 2.5723e-06 - dense_22_loss: 1.6921e-06 - dense_23_loss: 1.9720e-06 - dense_24_loss: 2.1889e-06 - dense_25_loss: 2.1505e-06 - dense_26_loss: 2.7302e-06 - dense_27_loss: 4.2818e-06 - dense_28_loss: 4.8796e-06 - dense_29_loss: 4.4449e-06 - val_loss: 9.8445e-05 - val_dense_7_loss: 8.2013e-06 - val_dense_8_loss: 1.2463e-05 - val_dense_9_loss: 9.7462e-06 - val_dense_10_loss: 4.6980e-06 - val_dense_11_loss: 6.0478e-06 - val_dense_12_loss: 5.0766e-06 - val_dense_13_loss: 4.5408e-06 - val_dense_14_loss: 6.5606e-06 - val_dense_15_loss: 5.4072e-06 - val_dense_16_loss: 4.8196e-06 - val_dense_17_loss: 2.6907e-06 - val_dense_18_loss: 1.5898e-06 - val_dense_19_loss: 1.8510e-06 - val_dense_20_loss: 1.8616e-06 - val_dense_21_loss: 2.4740e-06 - val_dense_22_loss: 1.6297e-06 - val_dense_23_loss: 2.0556e-06 - val_dense_24_loss: 1.4879e-06 - val_dense_25_loss: 1.4229e-06 - val_dense_26_loss: 1.5593e-06 - val_dense_27_loss: 4.1324e-06 - val_dense_28_loss: 4.0512e-06 - val_dense_29_loss: 4.0783e-06\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0280e-04 - dense_7_loss: 8.4154e-06 - dense_8_loss: 1.2627e-05 - dense_9_loss: 9.9300e-06 - dense_10_loss: 4.7062e-06 - dense_11_loss: 6.0946e-06 - dense_12_loss: 5.1978e-06 - dense_13_loss: 4.5406e-06 - dense_14_loss: 6.6194e-06 - dense_15_loss: 5.2732e-06 - dense_16_loss: 4.6684e-06 - dense_17_loss: 2.7113e-06 - dense_18_loss: 1.5917e-06 - dense_19_loss: 1.8951e-06 - dense_20_loss: 1.9414e-06 - dense_21_loss: 2.5525e-06 - dense_22_loss: 1.7062e-06 - dense_23_loss: 1.9533e-06 - dense_24_loss: 2.1490e-06 - dense_25_loss: 2.0777e-06 - dense_26_loss: 2.6911e-06 - dense_27_loss: 4.1855e-06 - dense_28_loss: 4.8791e-06 - dense_29_loss: 4.3892e-06 - val_loss: 9.7530e-05 - val_dense_7_loss: 8.1627e-06 - val_dense_8_loss: 1.2413e-05 - val_dense_9_loss: 9.7281e-06 - val_dense_10_loss: 4.6937e-06 - val_dense_11_loss: 6.0227e-06 - val_dense_12_loss: 4.9972e-06 - val_dense_13_loss: 4.5447e-06 - val_dense_14_loss: 6.4994e-06 - val_dense_15_loss: 5.3672e-06 - val_dense_16_loss: 4.8029e-06 - val_dense_17_loss: 2.6118e-06 - val_dense_18_loss: 1.5323e-06 - val_dense_19_loss: 1.8311e-06 - val_dense_20_loss: 1.7888e-06 - val_dense_21_loss: 2.4232e-06 - val_dense_22_loss: 1.6126e-06 - val_dense_23_loss: 2.0391e-06 - val_dense_24_loss: 1.4587e-06 - val_dense_25_loss: 1.3763e-06 - val_dense_26_loss: 1.5054e-06 - val_dense_27_loss: 4.0761e-06 - val_dense_28_loss: 4.0234e-06 - val_dense_29_loss: 4.0188e-06\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0191e-04 - dense_7_loss: 8.3808e-06 - dense_8_loss: 1.2585e-05 - dense_9_loss: 9.9133e-06 - dense_10_loss: 4.6986e-06 - dense_11_loss: 6.0705e-06 - dense_12_loss: 5.1231e-06 - dense_13_loss: 4.5434e-06 - dense_14_loss: 6.5562e-06 - dense_15_loss: 5.2356e-06 - dense_16_loss: 4.6509e-06 - dense_17_loss: 2.6344e-06 - dense_18_loss: 1.5372e-06 - dense_19_loss: 1.8738e-06 - dense_20_loss: 1.8722e-06 - dense_21_loss: 2.5048e-06 - dense_22_loss: 1.6873e-06 - dense_23_loss: 1.9348e-06 - dense_24_loss: 2.1162e-06 - dense_25_loss: 2.0321e-06 - dense_26_loss: 2.6393e-06 - dense_27_loss: 4.1325e-06 - dense_28_loss: 4.8506e-06 - dense_29_loss: 4.3343e-06 - val_loss: 9.6925e-05 - val_dense_7_loss: 8.1412e-06 - val_dense_8_loss: 1.2379e-05 - val_dense_9_loss: 9.7397e-06 - val_dense_10_loss: 4.6801e-06 - val_dense_11_loss: 5.9860e-06 - val_dense_12_loss: 4.9999e-06 - val_dense_13_loss: 4.5174e-06 - val_dense_14_loss: 6.4804e-06 - val_dense_15_loss: 5.3474e-06 - val_dense_16_loss: 4.7669e-06 - val_dense_17_loss: 2.5919e-06 - val_dense_18_loss: 1.5043e-06 - val_dense_19_loss: 1.7895e-06 - val_dense_20_loss: 1.7775e-06 - val_dense_21_loss: 2.3863e-06 - val_dense_22_loss: 1.5633e-06 - val_dense_23_loss: 2.0239e-06 - val_dense_24_loss: 1.4222e-06 - val_dense_25_loss: 1.3690e-06 - val_dense_26_loss: 1.4777e-06 - val_dense_27_loss: 4.0335e-06 - val_dense_28_loss: 3.9712e-06 - val_dense_29_loss: 3.9763e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0131e-04 - dense_7_loss: 8.3628e-06 - dense_8_loss: 1.2551e-05 - dense_9_loss: 9.9205e-06 - dense_10_loss: 4.6865e-06 - dense_11_loss: 6.0340e-06 - dense_12_loss: 5.1294e-06 - dense_13_loss: 4.5162e-06 - dense_14_loss: 6.5392e-06 - dense_15_loss: 5.2157e-06 - dense_16_loss: 4.6130e-06 - dense_17_loss: 2.6186e-06 - dense_18_loss: 1.5107e-06 - dense_19_loss: 1.8310e-06 - dense_20_loss: 1.8601e-06 - dense_21_loss: 2.4684e-06 - dense_22_loss: 1.6368e-06 - dense_23_loss: 1.9168e-06 - dense_24_loss: 2.0794e-06 - dense_25_loss: 2.0257e-06 - dense_26_loss: 2.6132e-06 - dense_27_loss: 4.0903e-06 - dense_28_loss: 4.8003e-06 - dense_29_loss: 4.2952e-06 - val_loss: 9.6292e-05 - val_dense_7_loss: 8.1217e-06 - val_dense_8_loss: 1.2361e-05 - val_dense_9_loss: 9.6923e-06 - val_dense_10_loss: 4.6431e-06 - val_dense_11_loss: 5.9689e-06 - val_dense_12_loss: 5.0001e-06 - val_dense_13_loss: 4.4654e-06 - val_dense_14_loss: 6.4806e-06 - val_dense_15_loss: 5.3286e-06 - val_dense_16_loss: 4.7350e-06 - val_dense_17_loss: 2.5836e-06 - val_dense_18_loss: 1.4962e-06 - val_dense_19_loss: 1.7503e-06 - val_dense_20_loss: 1.7519e-06 - val_dense_21_loss: 2.3485e-06 - val_dense_22_loss: 1.5203e-06 - val_dense_23_loss: 1.9678e-06 - val_dense_24_loss: 1.3819e-06 - val_dense_25_loss: 1.3525e-06 - val_dense_26_loss: 1.4573e-06 - val_dense_27_loss: 3.9897e-06 - val_dense_28_loss: 3.9390e-06 - val_dense_29_loss: 3.9563e-06\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0067e-04 - dense_7_loss: 8.3456e-06 - dense_8_loss: 1.2528e-05 - dense_9_loss: 9.8727e-06 - dense_10_loss: 4.6478e-06 - dense_11_loss: 6.0142e-06 - dense_12_loss: 5.1277e-06 - dense_13_loss: 4.4649e-06 - dense_14_loss: 6.5388e-06 - dense_15_loss: 5.1960e-06 - dense_16_loss: 4.5818e-06 - dense_17_loss: 2.6052e-06 - dense_18_loss: 1.5016e-06 - dense_19_loss: 1.7933e-06 - dense_20_loss: 1.8316e-06 - dense_21_loss: 2.4309e-06 - dense_22_loss: 1.5946e-06 - dense_23_loss: 1.8641e-06 - dense_24_loss: 2.0394e-06 - dense_25_loss: 2.0077e-06 - dense_26_loss: 2.5923e-06 - dense_27_loss: 4.0475e-06 - dense_28_loss: 4.7673e-06 - dense_29_loss: 4.2745e-06 - val_loss: 9.5714e-05 - val_dense_7_loss: 8.0811e-06 - val_dense_8_loss: 1.2340e-05 - val_dense_9_loss: 9.6604e-06 - val_dense_10_loss: 4.5954e-06 - val_dense_11_loss: 5.9661e-06 - val_dense_12_loss: 4.9874e-06 - val_dense_13_loss: 4.4237e-06 - val_dense_14_loss: 6.4587e-06 - val_dense_15_loss: 5.3202e-06 - val_dense_16_loss: 4.7334e-06 - val_dense_17_loss: 2.5253e-06 - val_dense_18_loss: 1.4758e-06 - val_dense_19_loss: 1.7227e-06 - val_dense_20_loss: 1.7129e-06 - val_dense_21_loss: 2.3216e-06 - val_dense_22_loss: 1.5054e-06 - val_dense_23_loss: 1.9493e-06 - val_dense_24_loss: 1.3656e-06 - val_dense_25_loss: 1.3235e-06 - val_dense_26_loss: 1.4390e-06 - val_dense_27_loss: 3.9737e-06 - val_dense_28_loss: 3.9091e-06 - val_dense_29_loss: 3.9239e-06\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0010e-04 - dense_7_loss: 8.3073e-06 - dense_8_loss: 1.2505e-05 - dense_9_loss: 9.8451e-06 - dense_10_loss: 4.6038e-06 - dense_11_loss: 6.0100e-06 - dense_12_loss: 5.1123e-06 - dense_13_loss: 4.4263e-06 - dense_14_loss: 6.5183e-06 - dense_15_loss: 5.1863e-06 - dense_16_loss: 4.5778e-06 - dense_17_loss: 2.5475e-06 - dense_18_loss: 1.4793e-06 - dense_19_loss: 1.7662e-06 - dense_20_loss: 1.7938e-06 - dense_21_loss: 2.4060e-06 - dense_22_loss: 1.5818e-06 - dense_23_loss: 1.8461e-06 - dense_24_loss: 2.0255e-06 - dense_25_loss: 1.9811e-06 - dense_26_loss: 2.5758e-06 - dense_27_loss: 4.0316e-06 - dense_28_loss: 4.7346e-06 - dense_29_loss: 4.2393e-06 - val_loss: 9.5371e-05 - val_dense_7_loss: 8.0501e-06 - val_dense_8_loss: 1.2342e-05 - val_dense_9_loss: 9.6530e-06 - val_dense_10_loss: 4.5856e-06 - val_dense_11_loss: 5.9630e-06 - val_dense_12_loss: 4.9690e-06 - val_dense_13_loss: 4.4285e-06 - val_dense_14_loss: 6.4369e-06 - val_dense_15_loss: 5.3096e-06 - val_dense_16_loss: 4.7257e-06 - val_dense_17_loss: 2.4925e-06 - val_dense_18_loss: 1.4472e-06 - val_dense_19_loss: 1.7040e-06 - val_dense_20_loss: 1.6966e-06 - val_dense_21_loss: 2.3086e-06 - val_dense_22_loss: 1.5040e-06 - val_dense_23_loss: 1.9324e-06 - val_dense_24_loss: 1.3566e-06 - val_dense_25_loss: 1.3173e-06 - val_dense_26_loss: 1.4365e-06 - val_dense_27_loss: 3.9508e-06 - val_dense_28_loss: 3.8775e-06 - val_dense_29_loss: 3.8836e-06\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.9745e-05 - dense_7_loss: 8.2755e-06 - dense_8_loss: 1.2503e-05 - dense_9_loss: 9.8389e-06 - dense_10_loss: 4.5968e-06 - dense_11_loss: 6.0042e-06 - dense_12_loss: 5.0926e-06 - dense_13_loss: 4.4292e-06 - dense_14_loss: 6.4988e-06 - dense_15_loss: 5.1746e-06 - dense_16_loss: 4.5678e-06 - dense_17_loss: 2.5137e-06 - dense_18_loss: 1.4518e-06 - dense_19_loss: 1.7474e-06 - dense_20_loss: 1.7781e-06 - dense_21_loss: 2.3934e-06 - dense_22_loss: 1.5786e-06 - dense_23_loss: 1.8280e-06 - dense_24_loss: 2.0160e-06 - dense_25_loss: 1.9741e-06 - dense_26_loss: 2.5719e-06 - dense_27_loss: 4.0061e-06 - dense_28_loss: 4.7049e-06 - dense_29_loss: 4.1997e-06 - val_loss: 9.4953e-05 - val_dense_7_loss: 8.0383e-06 - val_dense_8_loss: 1.2322e-05 - val_dense_9_loss: 9.6466e-06 - val_dense_10_loss: 4.5893e-06 - val_dense_11_loss: 5.9427e-06 - val_dense_12_loss: 4.9473e-06 - val_dense_13_loss: 4.4262e-06 - val_dense_14_loss: 6.4200e-06 - val_dense_15_loss: 5.2829e-06 - val_dense_16_loss: 4.7107e-06 - val_dense_17_loss: 2.4603e-06 - val_dense_18_loss: 1.4325e-06 - val_dense_19_loss: 1.6854e-06 - val_dense_20_loss: 1.6790e-06 - val_dense_21_loss: 2.2917e-06 - val_dense_22_loss: 1.4847e-06 - val_dense_23_loss: 1.9055e-06 - val_dense_24_loss: 1.3469e-06 - val_dense_25_loss: 1.2926e-06 - val_dense_26_loss: 1.4167e-06 - val_dense_27_loss: 3.9125e-06 - val_dense_28_loss: 3.8607e-06 - val_dense_29_loss: 3.8580e-06\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.9351e-05 - dense_7_loss: 8.2655e-06 - dense_8_loss: 1.2485e-05 - dense_9_loss: 9.8360e-06 - dense_10_loss: 4.6004e-06 - dense_11_loss: 5.9872e-06 - dense_12_loss: 5.0738e-06 - dense_13_loss: 4.4261e-06 - dense_14_loss: 6.4845e-06 - dense_15_loss: 5.1510e-06 - dense_16_loss: 4.5542e-06 - dense_17_loss: 2.4833e-06 - dense_18_loss: 1.4367e-06 - dense_19_loss: 1.7284e-06 - dense_20_loss: 1.7598e-06 - dense_21_loss: 2.3764e-06 - dense_22_loss: 1.5589e-06 - dense_23_loss: 1.8043e-06 - dense_24_loss: 2.0074e-06 - dense_25_loss: 1.9511e-06 - dense_26_loss: 2.5538e-06 - dense_27_loss: 3.9670e-06 - dense_28_loss: 4.6863e-06 - dense_29_loss: 4.1741e-06 - val_loss: 9.4708e-05 - val_dense_7_loss: 8.0433e-06 - val_dense_8_loss: 1.2325e-05 - val_dense_9_loss: 9.6306e-06 - val_dense_10_loss: 4.5738e-06 - val_dense_11_loss: 5.9419e-06 - val_dense_12_loss: 4.9439e-06 - val_dense_13_loss: 4.4210e-06 - val_dense_14_loss: 6.4200e-06 - val_dense_15_loss: 5.2728e-06 - val_dense_16_loss: 4.7041e-06 - val_dense_17_loss: 2.4532e-06 - val_dense_18_loss: 1.4138e-06 - val_dense_19_loss: 1.6678e-06 - val_dense_20_loss: 1.6601e-06 - val_dense_21_loss: 2.2669e-06 - val_dense_22_loss: 1.4632e-06 - val_dense_23_loss: 1.8967e-06 - val_dense_24_loss: 1.3439e-06 - val_dense_25_loss: 1.2916e-06 - val_dense_26_loss: 1.4160e-06 - val_dense_27_loss: 3.8827e-06 - val_dense_28_loss: 3.8323e-06 - val_dense_29_loss: 3.8428e-06\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.9119e-05 - dense_7_loss: 8.2677e-06 - dense_8_loss: 1.2490e-05 - dense_9_loss: 9.8199e-06 - dense_10_loss: 4.5865e-06 - dense_11_loss: 5.9871e-06 - dense_12_loss: 5.0699e-06 - dense_13_loss: 4.4209e-06 - dense_14_loss: 6.4840e-06 - dense_15_loss: 5.1430e-06 - dense_16_loss: 4.5482e-06 - dense_17_loss: 2.4765e-06 - dense_18_loss: 1.4191e-06 - dense_19_loss: 1.7125e-06 - dense_20_loss: 1.7423e-06 - dense_21_loss: 2.3524e-06 - dense_22_loss: 1.5391e-06 - dense_23_loss: 1.7971e-06 - dense_24_loss: 2.0023e-06 - dense_25_loss: 1.9501e-06 - dense_26_loss: 2.5533e-06 - dense_27_loss: 3.9394e-06 - dense_28_loss: 4.6601e-06 - dense_29_loss: 4.1580e-06 - val_loss: 9.5035e-05 - val_dense_7_loss: 8.0364e-06 - val_dense_8_loss: 1.2336e-05 - val_dense_9_loss: 9.6505e-06 - val_dense_10_loss: 4.5965e-06 - val_dense_11_loss: 5.9778e-06 - val_dense_12_loss: 4.9664e-06 - val_dense_13_loss: 4.4391e-06 - val_dense_14_loss: 6.4474e-06 - val_dense_15_loss: 5.2788e-06 - val_dense_16_loss: 4.7225e-06 - val_dense_17_loss: 2.4441e-06 - val_dense_18_loss: 1.4269e-06 - val_dense_19_loss: 1.6822e-06 - val_dense_20_loss: 1.6872e-06 - val_dense_21_loss: 2.2669e-06 - val_dense_22_loss: 1.4793e-06 - val_dense_23_loss: 1.9161e-06 - val_dense_24_loss: 1.3469e-06 - val_dense_25_loss: 1.3281e-06 - val_dense_26_loss: 1.4329e-06 - val_dense_27_loss: 3.9029e-06 - val_dense_28_loss: 3.8229e-06 - val_dense_29_loss: 3.8469e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.9656e-05 - dense_7_loss: 8.2724e-06 - dense_8_loss: 1.2513e-05 - dense_9_loss: 9.8441e-06 - dense_10_loss: 4.6149e-06 - dense_11_loss: 6.0274e-06 - dense_12_loss: 5.0958e-06 - dense_13_loss: 4.4466e-06 - dense_14_loss: 6.5157e-06 - dense_15_loss: 5.1583e-06 - dense_16_loss: 4.5738e-06 - dense_17_loss: 2.4828e-06 - dense_18_loss: 1.4457e-06 - dense_19_loss: 1.7401e-06 - dense_20_loss: 1.7793e-06 - dense_21_loss: 2.3630e-06 - dense_22_loss: 1.5660e-06 - dense_23_loss: 1.8242e-06 - dense_24_loss: 2.0143e-06 - dense_25_loss: 1.9914e-06 - dense_26_loss: 2.5754e-06 - dense_27_loss: 3.9729e-06 - dense_28_loss: 4.6649e-06 - dense_29_loss: 4.1739e-06 - val_loss: 9.8769e-05 - val_dense_7_loss: 8.1729e-06 - val_dense_8_loss: 1.2485e-05 - val_dense_9_loss: 9.8249e-06 - val_dense_10_loss: 4.7578e-06 - val_dense_11_loss: 6.1455e-06 - val_dense_12_loss: 5.1290e-06 - val_dense_13_loss: 4.6237e-06 - val_dense_14_loss: 6.6283e-06 - val_dense_15_loss: 5.4023e-06 - val_dense_16_loss: 4.8825e-06 - val_dense_17_loss: 2.6037e-06 - val_dense_18_loss: 1.6171e-06 - val_dense_19_loss: 1.8626e-06 - val_dense_20_loss: 1.8328e-06 - val_dense_21_loss: 2.4026e-06 - val_dense_22_loss: 1.6488e-06 - val_dense_23_loss: 2.0979e-06 - val_dense_24_loss: 1.5148e-06 - val_dense_25_loss: 1.5258e-06 - val_dense_26_loss: 1.5918e-06 - val_dense_27_loss: 4.0773e-06 - val_dense_28_loss: 3.9493e-06 - val_dense_29_loss: 3.9926e-06\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0411e-04 - dense_7_loss: 8.4385e-06 - dense_8_loss: 1.2695e-05 - dense_9_loss: 1.0036e-05 - dense_10_loss: 4.7963e-06 - dense_11_loss: 6.2252e-06 - dense_12_loss: 5.2807e-06 - dense_13_loss: 4.6569e-06 - dense_14_loss: 6.7125e-06 - dense_15_loss: 5.3117e-06 - dense_16_loss: 4.7640e-06 - dense_17_loss: 2.6799e-06 - dense_18_loss: 1.6726e-06 - dense_19_loss: 1.9602e-06 - dense_20_loss: 1.9613e-06 - dense_21_loss: 2.5357e-06 - dense_22_loss: 1.7758e-06 - dense_23_loss: 2.0352e-06 - dense_24_loss: 2.2100e-06 - dense_25_loss: 2.2190e-06 - dense_26_loss: 2.7580e-06 - dense_27_loss: 4.1931e-06 - dense_28_loss: 4.8366e-06 - dense_29_loss: 4.3550e-06 - val_loss: 1.0026e-04 - val_dense_7_loss: 8.1871e-06 - val_dense_8_loss: 1.2584e-05 - val_dense_9_loss: 9.8540e-06 - val_dense_10_loss: 4.8470e-06 - val_dense_11_loss: 6.1843e-06 - val_dense_12_loss: 5.2430e-06 - val_dense_13_loss: 4.7533e-06 - val_dense_14_loss: 6.6990e-06 - val_dense_15_loss: 5.4774e-06 - val_dense_16_loss: 4.9307e-06 - val_dense_17_loss: 2.6719e-06 - val_dense_18_loss: 1.7010e-06 - val_dense_19_loss: 1.9227e-06 - val_dense_20_loss: 1.8816e-06 - val_dense_21_loss: 2.4544e-06 - val_dense_22_loss: 1.6826e-06 - val_dense_23_loss: 2.1726e-06 - val_dense_24_loss: 1.5784e-06 - val_dense_25_loss: 1.5667e-06 - val_dense_26_loss: 1.7008e-06 - val_dense_27_loss: 4.0851e-06 - val_dense_28_loss: 4.0427e-06 - val_dense_29_loss: 4.0443e-06\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0408e-04 - dense_7_loss: 8.3936e-06 - dense_8_loss: 1.2724e-05 - dense_9_loss: 1.0011e-05 - dense_10_loss: 4.8256e-06 - dense_11_loss: 6.2011e-06 - dense_12_loss: 5.3352e-06 - dense_13_loss: 4.7122e-06 - dense_14_loss: 6.7223e-06 - dense_15_loss: 5.3233e-06 - dense_16_loss: 4.7503e-06 - dense_17_loss: 2.6747e-06 - dense_18_loss: 1.6807e-06 - dense_19_loss: 1.9432e-06 - dense_20_loss: 1.9423e-06 - dense_21_loss: 2.5263e-06 - dense_22_loss: 1.7376e-06 - dense_23_loss: 2.0410e-06 - dense_24_loss: 2.2133e-06 - dense_25_loss: 2.1942e-06 - dense_26_loss: 2.8010e-06 - dense_27_loss: 4.1256e-06 - dense_28_loss: 4.8541e-06 - dense_29_loss: 4.3441e-06 - val_loss: 9.5611e-05 - val_dense_7_loss: 8.0827e-06 - val_dense_8_loss: 1.2370e-05 - val_dense_9_loss: 9.7005e-06 - val_dense_10_loss: 4.6388e-06 - val_dense_11_loss: 5.9859e-06 - val_dense_12_loss: 5.0023e-06 - val_dense_13_loss: 4.4568e-06 - val_dense_14_loss: 6.4560e-06 - val_dense_15_loss: 5.3107e-06 - val_dense_16_loss: 4.7436e-06 - val_dense_17_loss: 2.4608e-06 - val_dense_18_loss: 1.4700e-06 - val_dense_19_loss: 1.6925e-06 - val_dense_20_loss: 1.7027e-06 - val_dense_21_loss: 2.3023e-06 - val_dense_22_loss: 1.4870e-06 - val_dense_23_loss: 1.9720e-06 - val_dense_24_loss: 1.3758e-06 - val_dense_25_loss: 1.3329e-06 - val_dense_26_loss: 1.4682e-06 - val_dense_27_loss: 3.9031e-06 - val_dense_28_loss: 3.8618e-06 - val_dense_29_loss: 3.8347e-06\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.9821e-05 - dense_7_loss: 8.2943e-06 - dense_8_loss: 1.2526e-05 - dense_9_loss: 9.8719e-06 - dense_10_loss: 4.6445e-06 - dense_11_loss: 6.0236e-06 - dense_12_loss: 5.1188e-06 - dense_13_loss: 4.4510e-06 - dense_14_loss: 6.5135e-06 - dense_15_loss: 5.1746e-06 - dense_16_loss: 4.5835e-06 - dense_17_loss: 2.4733e-06 - dense_18_loss: 1.4636e-06 - dense_19_loss: 1.7292e-06 - dense_20_loss: 1.7776e-06 - dense_21_loss: 2.3775e-06 - dense_22_loss: 1.5573e-06 - dense_23_loss: 1.8587e-06 - dense_24_loss: 2.0262e-06 - dense_25_loss: 1.9857e-06 - dense_26_loss: 2.6014e-06 - dense_27_loss: 3.9498e-06 - dense_28_loss: 4.6780e-06 - dense_29_loss: 4.1407e-06 - val_loss: 9.5742e-05 - val_dense_7_loss: 8.0768e-06 - val_dense_8_loss: 1.2376e-05 - val_dense_9_loss: 9.6638e-06 - val_dense_10_loss: 4.6330e-06 - val_dense_11_loss: 5.9733e-06 - val_dense_12_loss: 4.9816e-06 - val_dense_13_loss: 4.4542e-06 - val_dense_14_loss: 6.4363e-06 - val_dense_15_loss: 5.2852e-06 - val_dense_16_loss: 4.7165e-06 - val_dense_17_loss: 2.5307e-06 - val_dense_18_loss: 1.4633e-06 - val_dense_19_loss: 1.7291e-06 - val_dense_20_loss: 1.7248e-06 - val_dense_21_loss: 2.3208e-06 - val_dense_22_loss: 1.4912e-06 - val_dense_23_loss: 1.9687e-06 - val_dense_24_loss: 1.3972e-06 - val_dense_25_loss: 1.3435e-06 - val_dense_26_loss: 1.4723e-06 - val_dense_27_loss: 3.9532e-06 - val_dense_28_loss: 3.8902e-06 - val_dense_29_loss: 3.8602e-06\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.9928e-05 - dense_7_loss: 8.2787e-06 - dense_8_loss: 1.2526e-05 - dense_9_loss: 9.8328e-06 - dense_10_loss: 4.6364e-06 - dense_11_loss: 6.0103e-06 - dense_12_loss: 5.1050e-06 - dense_13_loss: 4.4490e-06 - dense_14_loss: 6.4915e-06 - dense_15_loss: 5.1447e-06 - dense_16_loss: 4.5594e-06 - dense_17_loss: 2.5409e-06 - dense_18_loss: 1.4613e-06 - dense_19_loss: 1.7650e-06 - dense_20_loss: 1.8026e-06 - dense_21_loss: 2.3926e-06 - dense_22_loss: 1.5585e-06 - dense_23_loss: 1.8571e-06 - dense_24_loss: 2.0497e-06 - dense_25_loss: 1.9962e-06 - dense_26_loss: 2.6042e-06 - dense_27_loss: 3.9923e-06 - dense_28_loss: 4.7087e-06 - dense_29_loss: 4.1650e-06 - val_loss: 9.4460e-05 - val_dense_7_loss: 8.0145e-06 - val_dense_8_loss: 1.2306e-05 - val_dense_9_loss: 9.6063e-06 - val_dense_10_loss: 4.5913e-06 - val_dense_11_loss: 5.9476e-06 - val_dense_12_loss: 4.9447e-06 - val_dense_13_loss: 4.4397e-06 - val_dense_14_loss: 6.4090e-06 - val_dense_15_loss: 5.2664e-06 - val_dense_16_loss: 4.7000e-06 - val_dense_17_loss: 2.4036e-06 - val_dense_18_loss: 1.3963e-06 - val_dense_19_loss: 1.6407e-06 - val_dense_20_loss: 1.6773e-06 - val_dense_21_loss: 2.2496e-06 - val_dense_22_loss: 1.4506e-06 - val_dense_23_loss: 1.9201e-06 - val_dense_24_loss: 1.3395e-06 - val_dense_25_loss: 1.3179e-06 - val_dense_26_loss: 1.4412e-06 - val_dense_27_loss: 3.8273e-06 - val_dense_28_loss: 3.7883e-06 - val_dense_29_loss: 3.7826e-06\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.8856e-05 - dense_7_loss: 8.2329e-06 - dense_8_loss: 1.2472e-05 - dense_9_loss: 9.7913e-06 - dense_10_loss: 4.6085e-06 - dense_11_loss: 5.9909e-06 - dense_12_loss: 5.0673e-06 - dense_13_loss: 4.4411e-06 - dense_14_loss: 6.4723e-06 - dense_15_loss: 5.1349e-06 - dense_16_loss: 4.5438e-06 - dense_17_loss: 2.4265e-06 - dense_18_loss: 1.4031e-06 - dense_19_loss: 1.6862e-06 - dense_20_loss: 1.7598e-06 - dense_21_loss: 2.3339e-06 - dense_22_loss: 1.5274e-06 - dense_23_loss: 1.8159e-06 - dense_24_loss: 1.9991e-06 - dense_25_loss: 1.9720e-06 - dense_26_loss: 2.5780e-06 - dense_27_loss: 3.8841e-06 - dense_28_loss: 4.6165e-06 - dense_29_loss: 4.0992e-06 - val_loss: 9.3634e-05 - val_dense_7_loss: 7.9630e-06 - val_dense_8_loss: 1.2260e-05 - val_dense_9_loss: 9.5596e-06 - val_dense_10_loss: 4.5467e-06 - val_dense_11_loss: 5.8970e-06 - val_dense_12_loss: 4.9054e-06 - val_dense_13_loss: 4.3933e-06 - val_dense_14_loss: 6.3612e-06 - val_dense_15_loss: 5.2318e-06 - val_dense_16_loss: 4.6482e-06 - val_dense_17_loss: 2.3810e-06 - val_dense_18_loss: 1.3720e-06 - val_dense_19_loss: 1.6253e-06 - val_dense_20_loss: 1.6358e-06 - val_dense_21_loss: 2.2164e-06 - val_dense_22_loss: 1.4148e-06 - val_dense_23_loss: 1.8716e-06 - val_dense_24_loss: 1.3160e-06 - val_dense_25_loss: 1.2905e-06 - val_dense_26_loss: 1.4038e-06 - val_dense_27_loss: 3.8154e-06 - val_dense_28_loss: 3.7686e-06 - val_dense_29_loss: 3.7569e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.8131e-05 - dense_7_loss: 8.1912e-06 - dense_8_loss: 1.2432e-05 - dense_9_loss: 9.7451e-06 - dense_10_loss: 4.5612e-06 - dense_11_loss: 5.9439e-06 - dense_12_loss: 5.0350e-06 - dense_13_loss: 4.3968e-06 - dense_14_loss: 6.4243e-06 - dense_15_loss: 5.1023e-06 - dense_16_loss: 4.4980e-06 - dense_17_loss: 2.4104e-06 - dense_18_loss: 1.3834e-06 - dense_19_loss: 1.6719e-06 - dense_20_loss: 1.7235e-06 - dense_21_loss: 2.3053e-06 - dense_22_loss: 1.4960e-06 - dense_23_loss: 1.7750e-06 - dense_24_loss: 1.9786e-06 - dense_25_loss: 1.9516e-06 - dense_26_loss: 2.5433e-06 - dense_27_loss: 3.8789e-06 - dense_28_loss: 4.6044e-06 - dense_29_loss: 4.0785e-06 - val_loss: 9.3154e-05 - val_dense_7_loss: 7.9299e-06 - val_dense_8_loss: 1.2238e-05 - val_dense_9_loss: 9.5310e-06 - val_dense_10_loss: 4.5254e-06 - val_dense_11_loss: 5.8649e-06 - val_dense_12_loss: 4.8760e-06 - val_dense_13_loss: 4.3664e-06 - val_dense_14_loss: 6.3291e-06 - val_dense_15_loss: 5.1952e-06 - val_dense_16_loss: 4.6374e-06 - val_dense_17_loss: 2.3577e-06 - val_dense_18_loss: 1.3568e-06 - val_dense_19_loss: 1.6072e-06 - val_dense_20_loss: 1.6165e-06 - val_dense_21_loss: 2.1987e-06 - val_dense_22_loss: 1.4011e-06 - val_dense_23_loss: 1.8668e-06 - val_dense_24_loss: 1.2927e-06 - val_dense_25_loss: 1.2729e-06 - val_dense_26_loss: 1.4006e-06 - val_dense_27_loss: 3.7986e-06 - val_dense_28_loss: 3.7557e-06 - val_dense_29_loss: 3.7352e-06\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.7712e-05 - dense_7_loss: 8.1618e-06 - dense_8_loss: 1.2410e-05 - dense_9_loss: 9.7301e-06 - dense_10_loss: 4.5503e-06 - dense_11_loss: 5.9256e-06 - dense_12_loss: 5.0110e-06 - dense_13_loss: 4.3776e-06 - dense_14_loss: 6.4020e-06 - dense_15_loss: 5.0701e-06 - dense_16_loss: 4.4948e-06 - dense_17_loss: 2.3820e-06 - dense_18_loss: 1.3678e-06 - dense_19_loss: 1.6555e-06 - dense_20_loss: 1.7070e-06 - dense_21_loss: 2.2869e-06 - dense_22_loss: 1.4835e-06 - dense_23_loss: 1.7724e-06 - dense_24_loss: 1.9573e-06 - dense_25_loss: 1.9384e-06 - dense_26_loss: 2.5446e-06 - dense_27_loss: 3.8540e-06 - dense_28_loss: 4.5830e-06 - dense_29_loss: 4.0456e-06 - val_loss: 9.5563e-05 - val_dense_7_loss: 8.0036e-06 - val_dense_8_loss: 1.2330e-05 - val_dense_9_loss: 9.6167e-06 - val_dense_10_loss: 4.6295e-06 - val_dense_11_loss: 5.9750e-06 - val_dense_12_loss: 4.9729e-06 - val_dense_13_loss: 4.4810e-06 - val_dense_14_loss: 6.4289e-06 - val_dense_15_loss: 5.2721e-06 - val_dense_16_loss: 4.7150e-06 - val_dense_17_loss: 2.4872e-06 - val_dense_18_loss: 1.4836e-06 - val_dense_19_loss: 1.7393e-06 - val_dense_20_loss: 1.7175e-06 - val_dense_21_loss: 2.2810e-06 - val_dense_22_loss: 1.5140e-06 - val_dense_23_loss: 1.9870e-06 - val_dense_24_loss: 1.4091e-06 - val_dense_25_loss: 1.3886e-06 - val_dense_26_loss: 1.5072e-06 - val_dense_27_loss: 3.9134e-06 - val_dense_28_loss: 3.8663e-06 - val_dense_29_loss: 3.8450e-06\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0006e-04 - dense_7_loss: 8.2233e-06 - dense_8_loss: 1.2494e-05 - dense_9_loss: 9.8022e-06 - dense_10_loss: 4.6474e-06 - dense_11_loss: 6.0306e-06 - dense_12_loss: 5.1084e-06 - dense_13_loss: 4.4967e-06 - dense_14_loss: 6.4966e-06 - dense_15_loss: 5.1443e-06 - dense_16_loss: 4.5718e-06 - dense_17_loss: 2.5095e-06 - dense_18_loss: 1.4949e-06 - dense_19_loss: 1.7865e-06 - dense_20_loss: 1.8054e-06 - dense_21_loss: 2.3763e-06 - dense_22_loss: 1.5960e-06 - dense_23_loss: 1.8862e-06 - dense_24_loss: 2.0708e-06 - dense_25_loss: 2.0525e-06 - dense_26_loss: 2.6509e-06 - dense_27_loss: 3.9651e-06 - dense_28_loss: 4.6916e-06 - dense_29_loss: 4.1600e-06 - val_loss: 9.5620e-05 - val_dense_7_loss: 8.0459e-06 - val_dense_8_loss: 1.2332e-05 - val_dense_9_loss: 9.6243e-06 - val_dense_10_loss: 4.6183e-06 - val_dense_11_loss: 5.9683e-06 - val_dense_12_loss: 4.9503e-06 - val_dense_13_loss: 4.4752e-06 - val_dense_14_loss: 6.4177e-06 - val_dense_15_loss: 5.2759e-06 - val_dense_16_loss: 4.7178e-06 - val_dense_17_loss: 2.4730e-06 - val_dense_18_loss: 1.4961e-06 - val_dense_19_loss: 1.7269e-06 - val_dense_20_loss: 1.7407e-06 - val_dense_21_loss: 2.3111e-06 - val_dense_22_loss: 1.5302e-06 - val_dense_23_loss: 1.9878e-06 - val_dense_24_loss: 1.4072e-06 - val_dense_25_loss: 1.3958e-06 - val_dense_26_loss: 1.5126e-06 - val_dense_27_loss: 3.9156e-06 - val_dense_28_loss: 3.8626e-06 - val_dense_29_loss: 3.8342e-06\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.9659e-05 - dense_7_loss: 8.2485e-06 - dense_8_loss: 1.2486e-05 - dense_9_loss: 9.7982e-06 - dense_10_loss: 4.6210e-06 - dense_11_loss: 6.0021e-06 - dense_12_loss: 5.0721e-06 - dense_13_loss: 4.4637e-06 - dense_14_loss: 6.4696e-06 - dense_15_loss: 5.1330e-06 - dense_16_loss: 4.5540e-06 - dense_17_loss: 2.4713e-06 - dense_18_loss: 1.4799e-06 - dense_19_loss: 1.7544e-06 - dense_20_loss: 1.8054e-06 - dense_21_loss: 2.3772e-06 - dense_22_loss: 1.5881e-06 - dense_23_loss: 1.8679e-06 - dense_24_loss: 2.0479e-06 - dense_25_loss: 2.0387e-06 - dense_26_loss: 2.6369e-06 - dense_27_loss: 3.9460e-06 - dense_28_loss: 4.6678e-06 - dense_29_loss: 4.1290e-06 - val_loss: 9.3153e-05 - val_dense_7_loss: 7.9222e-06 - val_dense_8_loss: 1.2220e-05 - val_dense_9_loss: 9.5108e-06 - val_dense_10_loss: 4.5530e-06 - val_dense_11_loss: 5.8651e-06 - val_dense_12_loss: 4.8641e-06 - val_dense_13_loss: 4.3664e-06 - val_dense_14_loss: 6.3242e-06 - val_dense_15_loss: 5.1915e-06 - val_dense_16_loss: 4.6406e-06 - val_dense_17_loss: 2.3480e-06 - val_dense_18_loss: 1.3624e-06 - val_dense_19_loss: 1.6192e-06 - val_dense_20_loss: 1.6185e-06 - val_dense_21_loss: 2.2104e-06 - val_dense_22_loss: 1.4174e-06 - val_dense_23_loss: 1.8851e-06 - val_dense_24_loss: 1.3026e-06 - val_dense_25_loss: 1.2957e-06 - val_dense_26_loss: 1.4242e-06 - val_dense_27_loss: 3.7708e-06 - val_dense_28_loss: 3.7213e-06 - val_dense_29_loss: 3.7199e-06\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.7833e-05 - dense_7_loss: 8.1590e-06 - dense_8_loss: 1.2401e-05 - dense_9_loss: 9.7079e-06 - dense_10_loss: 4.5723e-06 - dense_11_loss: 5.9212e-06 - dense_12_loss: 5.0014e-06 - dense_13_loss: 4.3795e-06 - dense_14_loss: 6.3993e-06 - dense_15_loss: 5.0677e-06 - dense_16_loss: 4.4965e-06 - dense_17_loss: 2.3863e-06 - dense_18_loss: 1.3836e-06 - dense_19_loss: 1.6769e-06 - dense_20_loss: 1.7139e-06 - dense_21_loss: 2.3046e-06 - dense_22_loss: 1.5076e-06 - dense_23_loss: 1.7940e-06 - dense_24_loss: 1.9739e-06 - dense_25_loss: 1.9630e-06 - dense_26_loss: 2.5675e-06 - dense_27_loss: 3.8427e-06 - dense_28_loss: 4.5646e-06 - dense_29_loss: 4.0488e-06 - val_loss: 9.4788e-05 - val_dense_7_loss: 7.9446e-06 - val_dense_8_loss: 1.2290e-05 - val_dense_9_loss: 9.5507e-06 - val_dense_10_loss: 4.6241e-06 - val_dense_11_loss: 5.9324e-06 - val_dense_12_loss: 4.9725e-06 - val_dense_13_loss: 4.4671e-06 - val_dense_14_loss: 6.4000e-06 - val_dense_15_loss: 5.2334e-06 - val_dense_16_loss: 4.7119e-06 - val_dense_17_loss: 2.4163e-06 - val_dense_18_loss: 1.4471e-06 - val_dense_19_loss: 1.7125e-06 - val_dense_20_loss: 1.6986e-06 - val_dense_21_loss: 2.2537e-06 - val_dense_22_loss: 1.4850e-06 - val_dense_23_loss: 1.9532e-06 - val_dense_24_loss: 1.3655e-06 - val_dense_25_loss: 1.3775e-06 - val_dense_26_loss: 1.5070e-06 - val_dense_27_loss: 3.8434e-06 - val_dense_28_loss: 3.7936e-06 - val_dense_29_loss: 3.8078e-06\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.8926e-05 - dense_7_loss: 8.1565e-06 - dense_8_loss: 1.2448e-05 - dense_9_loss: 9.7250e-06 - dense_10_loss: 4.6225e-06 - dense_11_loss: 5.9651e-06 - dense_12_loss: 5.0817e-06 - dense_13_loss: 4.4528e-06 - dense_14_loss: 6.4473e-06 - dense_15_loss: 5.0920e-06 - dense_16_loss: 4.5423e-06 - dense_17_loss: 2.4326e-06 - dense_18_loss: 1.4424e-06 - dense_19_loss: 1.7422e-06 - dense_20_loss: 1.7709e-06 - dense_21_loss: 2.3303e-06 - dense_22_loss: 1.5514e-06 - dense_23_loss: 1.8396e-06 - dense_24_loss: 2.0164e-06 - dense_25_loss: 2.0204e-06 - dense_26_loss: 2.6265e-06 - dense_27_loss: 3.8910e-06 - dense_28_loss: 4.6144e-06 - dense_29_loss: 4.1143e-06 - val_loss: 9.2409e-05 - val_dense_7_loss: 7.8530e-06 - val_dense_8_loss: 1.2142e-05 - val_dense_9_loss: 9.4615e-06 - val_dense_10_loss: 4.5245e-06 - val_dense_11_loss: 5.8310e-06 - val_dense_12_loss: 4.8384e-06 - val_dense_13_loss: 4.3377e-06 - val_dense_14_loss: 6.2743e-06 - val_dense_15_loss: 5.1393e-06 - val_dense_16_loss: 4.6048e-06 - val_dense_17_loss: 2.3121e-06 - val_dense_18_loss: 1.3372e-06 - val_dense_19_loss: 1.5915e-06 - val_dense_20_loss: 1.6141e-06 - val_dense_21_loss: 2.1731e-06 - val_dense_22_loss: 1.3946e-06 - val_dense_23_loss: 1.8759e-06 - val_dense_24_loss: 1.2987e-06 - val_dense_25_loss: 1.2801e-06 - val_dense_26_loss: 1.4210e-06 - val_dense_27_loss: 3.7357e-06 - val_dense_28_loss: 3.6932e-06 - val_dense_29_loss: 3.6754e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.6722e-05 - dense_7_loss: 8.0719e-06 - dense_8_loss: 1.2305e-05 - dense_9_loss: 9.6410e-06 - dense_10_loss: 4.5351e-06 - dense_11_loss: 5.8751e-06 - dense_12_loss: 4.9613e-06 - dense_13_loss: 4.3360e-06 - dense_14_loss: 6.3360e-06 - dense_15_loss: 5.0072e-06 - dense_16_loss: 4.4505e-06 - dense_17_loss: 2.3290e-06 - dense_18_loss: 1.3382e-06 - dense_19_loss: 1.6297e-06 - dense_20_loss: 1.6918e-06 - dense_21_loss: 2.2544e-06 - dense_22_loss: 1.4675e-06 - dense_23_loss: 1.7680e-06 - dense_24_loss: 1.9526e-06 - dense_25_loss: 1.9344e-06 - dense_26_loss: 2.5545e-06 - dense_27_loss: 3.7850e-06 - dense_28_loss: 4.5126e-06 - dense_29_loss: 3.9847e-06 - val_loss: 9.3239e-05 - val_dense_7_loss: 7.9255e-06 - val_dense_8_loss: 1.2234e-05 - val_dense_9_loss: 9.4830e-06 - val_dense_10_loss: 4.5404e-06 - val_dense_11_loss: 5.8632e-06 - val_dense_12_loss: 4.8519e-06 - val_dense_13_loss: 4.3713e-06 - val_dense_14_loss: 6.2924e-06 - val_dense_15_loss: 5.1730e-06 - val_dense_16_loss: 4.6096e-06 - val_dense_17_loss: 2.3547e-06 - val_dense_18_loss: 1.3812e-06 - val_dense_19_loss: 1.6188e-06 - val_dense_20_loss: 1.6481e-06 - val_dense_21_loss: 2.2165e-06 - val_dense_22_loss: 1.4434e-06 - val_dense_23_loss: 1.9141e-06 - val_dense_24_loss: 1.3320e-06 - val_dense_25_loss: 1.3072e-06 - val_dense_26_loss: 1.4360e-06 - val_dense_27_loss: 3.7945e-06 - val_dense_28_loss: 3.7443e-06 - val_dense_29_loss: 3.7037e-06\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.7354e-05 - dense_7_loss: 8.1180e-06 - dense_8_loss: 1.2377e-05 - dense_9_loss: 9.6443e-06 - dense_10_loss: 4.5425e-06 - dense_11_loss: 5.8970e-06 - dense_12_loss: 4.9692e-06 - dense_13_loss: 4.3634e-06 - dense_14_loss: 6.3430e-06 - dense_15_loss: 5.0260e-06 - dense_16_loss: 4.4491e-06 - dense_17_loss: 2.3651e-06 - dense_18_loss: 1.3765e-06 - dense_19_loss: 1.6557e-06 - dense_20_loss: 1.7221e-06 - dense_21_loss: 2.2886e-06 - dense_22_loss: 1.5091e-06 - dense_23_loss: 1.8020e-06 - dense_24_loss: 1.9822e-06 - dense_25_loss: 1.9573e-06 - dense_26_loss: 2.5666e-06 - dense_27_loss: 3.8334e-06 - dense_28_loss: 4.5572e-06 - dense_29_loss: 4.0087e-06 - val_loss: 9.1782e-05 - val_dense_7_loss: 7.8029e-06 - val_dense_8_loss: 1.2081e-05 - val_dense_9_loss: 9.3934e-06 - val_dense_10_loss: 4.5052e-06 - val_dense_11_loss: 5.8025e-06 - val_dense_12_loss: 4.8184e-06 - val_dense_13_loss: 4.3199e-06 - val_dense_14_loss: 6.2304e-06 - val_dense_15_loss: 5.0916e-06 - val_dense_16_loss: 4.5689e-06 - val_dense_17_loss: 2.2769e-06 - val_dense_18_loss: 1.3196e-06 - val_dense_19_loss: 1.5782e-06 - val_dense_20_loss: 1.6020e-06 - val_dense_21_loss: 2.1602e-06 - val_dense_22_loss: 1.3765e-06 - val_dense_23_loss: 1.8565e-06 - val_dense_24_loss: 1.2937e-06 - val_dense_25_loss: 1.2867e-06 - val_dense_26_loss: 1.4236e-06 - val_dense_27_loss: 3.7072e-06 - val_dense_28_loss: 3.6525e-06 - val_dense_29_loss: 3.6343e-06\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.6278e-05 - dense_7_loss: 8.0233e-06 - dense_8_loss: 1.2248e-05 - dense_9_loss: 9.5786e-06 - dense_10_loss: 4.5222e-06 - dense_11_loss: 5.8519e-06 - dense_12_loss: 4.9472e-06 - dense_13_loss: 4.3260e-06 - dense_14_loss: 6.2956e-06 - dense_15_loss: 4.9663e-06 - dense_16_loss: 4.4192e-06 - dense_17_loss: 2.3051e-06 - dense_18_loss: 1.3335e-06 - dense_19_loss: 1.6273e-06 - dense_20_loss: 1.6900e-06 - dense_21_loss: 2.2500e-06 - dense_22_loss: 1.4592e-06 - dense_23_loss: 1.7578e-06 - dense_24_loss: 1.9565e-06 - dense_25_loss: 1.9477e-06 - dense_26_loss: 2.5632e-06 - dense_27_loss: 3.7678e-06 - dense_28_loss: 4.4843e-06 - dense_29_loss: 3.9567e-06 - val_loss: 9.5666e-05 - val_dense_7_loss: 7.9108e-06 - val_dense_8_loss: 1.2210e-05 - val_dense_9_loss: 9.4936e-06 - val_dense_10_loss: 4.6579e-06 - val_dense_11_loss: 5.9668e-06 - val_dense_12_loss: 4.9596e-06 - val_dense_13_loss: 4.5244e-06 - val_dense_14_loss: 6.3990e-06 - val_dense_15_loss: 5.2199e-06 - val_dense_16_loss: 4.7479e-06 - val_dense_17_loss: 2.4569e-06 - val_dense_18_loss: 1.5368e-06 - val_dense_19_loss: 1.7965e-06 - val_dense_20_loss: 1.7876e-06 - val_dense_21_loss: 2.2959e-06 - val_dense_22_loss: 1.5902e-06 - val_dense_23_loss: 2.0401e-06 - val_dense_24_loss: 1.4577e-06 - val_dense_25_loss: 1.4924e-06 - val_dense_26_loss: 1.5865e-06 - val_dense_27_loss: 3.9029e-06 - val_dense_28_loss: 3.8281e-06 - val_dense_29_loss: 3.8037e-06\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0097e-04 - dense_7_loss: 8.1791e-06 - dense_8_loss: 1.2427e-05 - dense_9_loss: 9.7066e-06 - dense_10_loss: 4.6980e-06 - dense_11_loss: 6.0360e-06 - dense_12_loss: 5.1090e-06 - dense_13_loss: 4.5496e-06 - dense_14_loss: 6.4819e-06 - dense_15_loss: 5.1204e-06 - dense_16_loss: 4.6130e-06 - dense_17_loss: 2.5462e-06 - dense_18_loss: 1.5870e-06 - dense_19_loss: 1.8862e-06 - dense_20_loss: 1.9060e-06 - dense_21_loss: 2.4296e-06 - dense_22_loss: 1.7121e-06 - dense_23_loss: 1.9818e-06 - dense_24_loss: 2.1512e-06 - dense_25_loss: 2.1764e-06 - dense_26_loss: 2.7470e-06 - dense_27_loss: 4.0338e-06 - dense_28_loss: 4.7153e-06 - dense_29_loss: 4.1796e-06 - val_loss: 9.7153e-05 - val_dense_7_loss: 7.9349e-06 - val_dense_8_loss: 1.2235e-05 - val_dense_9_loss: 9.4725e-06 - val_dense_10_loss: 4.7148e-06 - val_dense_11_loss: 6.0153e-06 - val_dense_12_loss: 5.0594e-06 - val_dense_13_loss: 4.6070e-06 - val_dense_14_loss: 6.4386e-06 - val_dense_15_loss: 5.2859e-06 - val_dense_16_loss: 4.7793e-06 - val_dense_17_loss: 2.5900e-06 - val_dense_18_loss: 1.6405e-06 - val_dense_19_loss: 1.8522e-06 - val_dense_20_loss: 1.8511e-06 - val_dense_21_loss: 2.4296e-06 - val_dense_22_loss: 1.6096e-06 - val_dense_23_loss: 2.1092e-06 - val_dense_24_loss: 1.5424e-06 - val_dense_25_loss: 1.5535e-06 - val_dense_26_loss: 1.6654e-06 - val_dense_27_loss: 3.9415e-06 - val_dense_28_loss: 3.9221e-06 - val_dense_29_loss: 3.9038e-06\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0091e-04 - dense_7_loss: 8.1433e-06 - dense_8_loss: 1.2382e-05 - dense_9_loss: 9.6385e-06 - dense_10_loss: 4.7018e-06 - dense_11_loss: 6.0303e-06 - dense_12_loss: 5.1523e-06 - dense_13_loss: 4.5704e-06 - dense_14_loss: 6.4717e-06 - dense_15_loss: 5.1252e-06 - dense_16_loss: 4.5952e-06 - dense_17_loss: 2.5805e-06 - dense_18_loss: 1.6119e-06 - dense_19_loss: 1.8636e-06 - dense_20_loss: 1.9077e-06 - dense_21_loss: 2.4839e-06 - dense_22_loss: 1.6611e-06 - dense_23_loss: 1.9800e-06 - dense_24_loss: 2.1762e-06 - dense_25_loss: 2.1768e-06 - dense_26_loss: 2.7719e-06 - dense_27_loss: 3.9709e-06 - dense_28_loss: 4.7215e-06 - dense_29_loss: 4.1914e-06 - val_loss: 9.4232e-05 - val_dense_7_loss: 7.8739e-06 - val_dense_8_loss: 1.2138e-05 - val_dense_9_loss: 9.4396e-06 - val_dense_10_loss: 4.6536e-06 - val_dense_11_loss: 5.8953e-06 - val_dense_12_loss: 4.8832e-06 - val_dense_13_loss: 4.4241e-06 - val_dense_14_loss: 6.2814e-06 - val_dense_15_loss: 5.1622e-06 - val_dense_16_loss: 4.6446e-06 - val_dense_17_loss: 2.3998e-06 - val_dense_18_loss: 1.4719e-06 - val_dense_19_loss: 1.6938e-06 - val_dense_20_loss: 1.7527e-06 - val_dense_21_loss: 2.2716e-06 - val_dense_22_loss: 1.4831e-06 - val_dense_23_loss: 2.0221e-06 - val_dense_24_loss: 1.4643e-06 - val_dense_25_loss: 1.4101e-06 - val_dense_26_loss: 1.5759e-06 - val_dense_27_loss: 3.8001e-06 - val_dense_28_loss: 3.7626e-06 - val_dense_29_loss: 3.7281e-06\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.8125e-05 - dense_7_loss: 8.0661e-06 - dense_8_loss: 1.2272e-05 - dense_9_loss: 9.5975e-06 - dense_10_loss: 4.6433e-06 - dense_11_loss: 5.9207e-06 - dense_12_loss: 4.9905e-06 - dense_13_loss: 4.4066e-06 - dense_14_loss: 6.3253e-06 - dense_15_loss: 5.0152e-06 - dense_16_loss: 4.4728e-06 - dense_17_loss: 2.3991e-06 - dense_18_loss: 1.4535e-06 - dense_19_loss: 1.7178e-06 - dense_20_loss: 1.8102e-06 - dense_21_loss: 2.3383e-06 - dense_22_loss: 1.5444e-06 - dense_23_loss: 1.8968e-06 - dense_24_loss: 2.0952e-06 - dense_25_loss: 2.0491e-06 - dense_26_loss: 2.6944e-06 - dense_27_loss: 3.8325e-06 - dense_28_loss: 4.5635e-06 - dense_29_loss: 4.0208e-06 - val_loss: 9.2182e-05 - val_dense_7_loss: 7.7437e-06 - val_dense_8_loss: 1.2003e-05 - val_dense_9_loss: 9.2475e-06 - val_dense_10_loss: 4.4918e-06 - val_dense_11_loss: 5.7666e-06 - val_dense_12_loss: 4.7974e-06 - val_dense_13_loss: 4.3227e-06 - val_dense_14_loss: 6.1968e-06 - val_dense_15_loss: 5.0562e-06 - val_dense_16_loss: 4.5486e-06 - val_dense_17_loss: 2.3725e-06 - val_dense_18_loss: 1.3950e-06 - val_dense_19_loss: 1.6477e-06 - val_dense_20_loss: 1.6548e-06 - val_dense_21_loss: 2.1966e-06 - val_dense_22_loss: 1.4247e-06 - val_dense_23_loss: 1.9395e-06 - val_dense_24_loss: 1.3733e-06 - val_dense_25_loss: 1.3342e-06 - val_dense_26_loss: 1.4972e-06 - val_dense_27_loss: 3.7494e-06 - val_dense_28_loss: 3.7427e-06 - val_dense_29_loss: 3.6799e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.6399e-05 - dense_7_loss: 7.9471e-06 - dense_8_loss: 1.2155e-05 - dense_9_loss: 9.4151e-06 - dense_10_loss: 4.4949e-06 - dense_11_loss: 5.8013e-06 - dense_12_loss: 4.9178e-06 - dense_13_loss: 4.3157e-06 - dense_14_loss: 6.2472e-06 - dense_15_loss: 4.9114e-06 - dense_16_loss: 4.3850e-06 - dense_17_loss: 2.3899e-06 - dense_18_loss: 1.3964e-06 - dense_19_loss: 1.6860e-06 - dense_20_loss: 1.7360e-06 - dense_21_loss: 2.2754e-06 - dense_22_loss: 1.4972e-06 - dense_23_loss: 1.8337e-06 - dense_24_loss: 2.0282e-06 - dense_25_loss: 1.9869e-06 - dense_26_loss: 2.6262e-06 - dense_27_loss: 3.7981e-06 - dense_28_loss: 4.5638e-06 - dense_29_loss: 3.9911e-06 - val_loss: 9.0063e-05 - val_dense_7_loss: 7.6134e-06 - val_dense_8_loss: 1.1824e-05 - val_dense_9_loss: 9.1466e-06 - val_dense_10_loss: 4.4319e-06 - val_dense_11_loss: 5.7095e-06 - val_dense_12_loss: 4.7018e-06 - val_dense_13_loss: 4.2492e-06 - val_dense_14_loss: 6.0928e-06 - val_dense_15_loss: 4.9414e-06 - val_dense_16_loss: 4.4738e-06 - val_dense_17_loss: 2.2309e-06 - val_dense_18_loss: 1.3001e-06 - val_dense_19_loss: 1.5639e-06 - val_dense_20_loss: 1.5890e-06 - val_dense_21_loss: 2.1268e-06 - val_dense_22_loss: 1.3785e-06 - val_dense_23_loss: 1.8721e-06 - val_dense_24_loss: 1.2952e-06 - val_dense_25_loss: 1.3049e-06 - val_dense_26_loss: 1.4471e-06 - val_dense_27_loss: 3.6258e-06 - val_dense_28_loss: 3.5932e-06 - val_dense_29_loss: 3.5503e-06\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.4544e-05 - dense_7_loss: 7.8345e-06 - dense_8_loss: 1.1992e-05 - dense_9_loss: 9.3331e-06 - dense_10_loss: 4.4549e-06 - dense_11_loss: 5.7555e-06 - dense_12_loss: 4.8319e-06 - dense_13_loss: 4.2587e-06 - dense_14_loss: 6.1578e-06 - dense_15_loss: 4.8141e-06 - dense_16_loss: 4.3224e-06 - dense_17_loss: 2.2591e-06 - dense_18_loss: 1.3125e-06 - dense_19_loss: 1.6105e-06 - dense_20_loss: 1.6757e-06 - dense_21_loss: 2.2146e-06 - dense_22_loss: 1.4559e-06 - dense_23_loss: 1.7723e-06 - dense_24_loss: 1.9600e-06 - dense_25_loss: 1.9636e-06 - dense_26_loss: 2.5903e-06 - dense_27_loss: 3.6816e-06 - dense_28_loss: 4.4229e-06 - dense_29_loss: 3.8698e-06 - val_loss: 8.9297e-05 - val_dense_7_loss: 7.5432e-06 - val_dense_8_loss: 1.1726e-05 - val_dense_9_loss: 9.0421e-06 - val_dense_10_loss: 4.4010e-06 - val_dense_11_loss: 5.6399e-06 - val_dense_12_loss: 4.6703e-06 - val_dense_13_loss: 4.2114e-06 - val_dense_14_loss: 6.0234e-06 - val_dense_15_loss: 4.8740e-06 - val_dense_16_loss: 4.4142e-06 - val_dense_17_loss: 2.2117e-06 - val_dense_18_loss: 1.2984e-06 - val_dense_19_loss: 1.5610e-06 - val_dense_20_loss: 1.5842e-06 - val_dense_21_loss: 2.0951e-06 - val_dense_22_loss: 1.3638e-06 - val_dense_23_loss: 1.8455e-06 - val_dense_24_loss: 1.2889e-06 - val_dense_25_loss: 1.3010e-06 - val_dense_26_loss: 1.4487e-06 - val_dense_27_loss: 3.6240e-06 - val_dense_28_loss: 3.5806e-06 - val_dense_29_loss: 3.5483e-06\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.3739e-05 - dense_7_loss: 7.7524e-06 - dense_8_loss: 1.1884e-05 - dense_9_loss: 9.2111e-06 - dense_10_loss: 4.4115e-06 - dense_11_loss: 5.6793e-06 - dense_12_loss: 4.7914e-06 - dense_13_loss: 4.2145e-06 - dense_14_loss: 6.0827e-06 - dense_15_loss: 4.7430e-06 - dense_16_loss: 4.2585e-06 - dense_17_loss: 2.2463e-06 - dense_18_loss: 1.3098e-06 - dense_19_loss: 1.6120e-06 - dense_20_loss: 1.6709e-06 - dense_21_loss: 2.1883e-06 - dense_22_loss: 1.4466e-06 - dense_23_loss: 1.7512e-06 - dense_24_loss: 1.9526e-06 - dense_25_loss: 1.9620e-06 - dense_26_loss: 2.5887e-06 - dense_27_loss: 3.6916e-06 - dense_28_loss: 4.4177e-06 - dense_29_loss: 3.8730e-06 - val_loss: 9.0823e-05 - val_dense_7_loss: 7.5299e-06 - val_dense_8_loss: 1.1682e-05 - val_dense_9_loss: 8.9762e-06 - val_dense_10_loss: 4.4511e-06 - val_dense_11_loss: 5.6682e-06 - val_dense_12_loss: 4.7149e-06 - val_dense_13_loss: 4.3102e-06 - val_dense_14_loss: 6.0713e-06 - val_dense_15_loss: 4.9159e-06 - val_dense_16_loss: 4.4867e-06 - val_dense_17_loss: 2.3126e-06 - val_dense_18_loss: 1.4003e-06 - val_dense_19_loss: 1.6686e-06 - val_dense_20_loss: 1.6822e-06 - val_dense_21_loss: 2.2002e-06 - val_dense_22_loss: 1.4430e-06 - val_dense_23_loss: 1.9614e-06 - val_dense_24_loss: 1.3831e-06 - val_dense_25_loss: 1.3741e-06 - val_dense_26_loss: 1.5526e-06 - val_dense_27_loss: 3.6954e-06 - val_dense_28_loss: 3.6951e-06 - val_dense_29_loss: 3.6478e-06\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 9.5002e-05 - dense_7_loss: 7.7391e-06 - dense_8_loss: 1.1837e-05 - dense_9_loss: 9.1492e-06 - dense_10_loss: 4.4553e-06 - dense_11_loss: 5.7019e-06 - dense_12_loss: 4.8261e-06 - dense_13_loss: 4.2979e-06 - dense_14_loss: 6.1170e-06 - dense_15_loss: 4.7681e-06 - dense_16_loss: 4.3163e-06 - dense_17_loss: 2.3317e-06 - dense_18_loss: 1.4020e-06 - dense_19_loss: 1.7032e-06 - dense_20_loss: 1.7574e-06 - dense_21_loss: 2.2791e-06 - dense_22_loss: 1.5164e-06 - dense_23_loss: 1.8516e-06 - dense_24_loss: 2.0345e-06 - dense_25_loss: 2.0263e-06 - dense_26_loss: 2.6816e-06 - dense_27_loss: 3.7443e-06 - dense_28_loss: 4.5119e-06 - dense_29_loss: 3.9542e-06 - val_loss: 9.7247e-05 - val_dense_7_loss: 7.7664e-06 - val_dense_8_loss: 1.1946e-05 - val_dense_9_loss: 9.4246e-06 - val_dense_10_loss: 4.7617e-06 - val_dense_11_loss: 6.0326e-06 - val_dense_12_loss: 4.8958e-06 - val_dense_13_loss: 4.6020e-06 - val_dense_14_loss: 6.3973e-06 - val_dense_15_loss: 5.2189e-06 - val_dense_16_loss: 4.8349e-06 - val_dense_17_loss: 2.5867e-06 - val_dense_18_loss: 1.6898e-06 - val_dense_19_loss: 1.9446e-06 - val_dense_20_loss: 1.9323e-06 - val_dense_21_loss: 2.3567e-06 - val_dense_22_loss: 1.7644e-06 - val_dense_23_loss: 2.2606e-06 - val_dense_24_loss: 1.6822e-06 - val_dense_25_loss: 1.7414e-06 - val_dense_26_loss: 1.7887e-06 - val_dense_27_loss: 3.9805e-06 - val_dense_28_loss: 3.8430e-06 - val_dense_29_loss: 3.7957e-06\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.0576e-04 - dense_7_loss: 8.1501e-06 - dense_8_loss: 1.2296e-05 - dense_9_loss: 9.7156e-06 - dense_10_loss: 4.9180e-06 - dense_11_loss: 6.2154e-06 - dense_12_loss: 5.1832e-06 - dense_13_loss: 4.7419e-06 - dense_14_loss: 6.6104e-06 - dense_15_loss: 5.2136e-06 - dense_16_loss: 4.8251e-06 - dense_17_loss: 2.8470e-06 - dense_18_loss: 1.9152e-06 - dense_19_loss: 2.2288e-06 - dense_20_loss: 2.1932e-06 - dense_21_loss: 2.6268e-06 - dense_22_loss: 2.0630e-06 - dense_23_loss: 2.3422e-06 - dense_24_loss: 2.4935e-06 - dense_25_loss: 2.5632e-06 - dense_26_loss: 3.0714e-06 - dense_27_loss: 4.3141e-06 - dense_28_loss: 4.8992e-06 - dense_29_loss: 4.3339e-06 - val_loss: 1.8879e-04 - val_dense_7_loss: 1.0353e-05 - val_dense_8_loss: 1.6017e-05 - val_dense_9_loss: 1.2786e-05 - val_dense_10_loss: 8.5126e-06 - val_dense_11_loss: 1.0162e-05 - val_dense_12_loss: 9.5429e-06 - val_dense_13_loss: 9.0128e-06 - val_dense_14_loss: 1.0191e-05 - val_dense_15_loss: 9.3754e-06 - val_dense_16_loss: 8.7417e-06 - val_dense_17_loss: 6.7312e-06 - val_dense_18_loss: 6.4243e-06 - val_dense_19_loss: 6.0906e-06 - val_dense_20_loss: 6.5640e-06 - val_dense_21_loss: 6.8505e-06 - val_dense_22_loss: 4.3177e-06 - val_dense_23_loss: 6.5539e-06 - val_dense_24_loss: 5.1762e-06 - val_dense_25_loss: 5.7601e-06 - val_dense_26_loss: 5.4614e-06 - val_dense_27_loss: 7.7153e-06 - val_dense_28_loss: 8.2269e-06 - val_dense_29_loss: 8.2245e-06\n",
      "Epoch 60/500\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "if trainnew: train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders)\n",
    "else: load_concatamash_autoencoder()\n",
    "stop = time.perf_counter()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1167afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        print('evaluating model for '+histgroup[0])\n",
    "        print(histstruct.evaluate_classifier(histgroup)[0].shape)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    print('Found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "            thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "            mse_good.append( thismse )\n",
    "            print(run)\n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    print('Found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        print('Found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34546ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct, mse_train):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    #for dims in dimslist:\n",
    "    #    thismse = mse_train[:,dims]\n",
    "    #    if training_mode=='global': \n",
    "    #        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "    #        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "    #        #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "    #        #                                                    'up')\n",
    "    #    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    #    #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "    #    #                onlycontour=False, xlims=30, ylims=30, \n",
    "    #    #                onlypositive=True, transparency=0.5,\n",
    "    #    #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "    #    #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "    #    #                title='density fit of lumisection MSE')\n",
    "    #    ##plt.close('all') # release plot memory\n",
    "    #    fitfunclist.append(fitfunc)\n",
    "    # \n",
    "    #    \n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "    else: \n",
    "        fitfunc = GaussianKdeFitter.GaussianKdeFitter()\n",
    "        fitfunc.fit(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4988fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = fit_mse_distribution(histstruct, mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    print('--- good lumesections ---')\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    print('length of log prob array: '+str(len(logprob_good)))\n",
    "    print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "    #print(sorted(logprob_good))\n",
    "    \n",
    "    print('--- bad lumisections ---')\n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    print(mse_bad_eval)\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "    \n",
    "    print('length of log prob array: '+str(len(logprob_bad)))\n",
    "    print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "    #print(sorted(logprob_good))\n",
    "    #print(sorted(logprob_bad))\n",
    "    #print(logprob_bad)\n",
    "    \n",
    "    sep = np.min(logprob_good) - np.max(logprob_bad)\n",
    "    print('Separability: ' + str(sep))\n",
    "    \n",
    "    return [logprob_good, logprob_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ed5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(logprob_good, logprob_bad) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad, fmBiasFactor, wpBiasFactor):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    badMin = min(np.where(logprob_bad != -np.inf, logprob_bad, -1))\n",
    "    goodMax = max(np.where(logprob_good != np.inf, logprob_good, 10001))\n",
    "    \n",
    "    logprob_good = np.where(logprob_good != np.inf, logprob_good, goodMax)\n",
    "    logprob_bad = np.where(logprob_bad != -np.inf, logprob_bad, badMin)\n",
    "    \n",
    "    # These only take effect if a histogram is grossly misclassified\n",
    "    logprob_good[logprob_good == -np.inf] = badMin\n",
    "    logprob_bad[logprob_bad == np.inf] = goodMax\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    avSep = np.mean(logprob_good) - np.mean(logprob_bad)\n",
    "    \n",
    "    print('Average Separation: ' + str(avSep))\n",
    "    \n",
    "    pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                       bcklabel='good', bckcolor='g', \n",
    "                       nbins=200, normalize=True,\n",
    "                       xaxtitle='negative logarithmic probability',\n",
    "                       yaxtitle='number of lumisections (normalized)')\n",
    "      \n",
    "    # Plot ROC curve for analysis\n",
    "    auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    # Average is biased towards better recall per user specifications\n",
    "    logprob_threshold = (1/(wpBiasFactor + 1)) * (wpBiasFactor*np.mean(logprob_good) + np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "    # logprob_threshold = 100\n",
    "    (_, _, _, tp, fp, tn, fn) = aeu.get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    print('Selected logprob threshold of ' + str(logprob_threshold))\n",
    "    \n",
    "    # Get metrics for analysis\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = (1 + fmBiasFactor * fmBiasFactor) * ((precision * recall) / ((fmBiasFactor * fmBiasFactor * precision) + recall)) \n",
    "    \n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('F-Measure: ' + str(f_measure))\n",
    "    \n",
    "    return logprob_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbddf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_threshold = evaluate_autoencoders_combined(logprob_good, logprob_bad, fmBiasFactor, wpBiasFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0cc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
