{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba412492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 19:37:43.451423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.3-88592/x86_64-centos7-gcc11-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.3-35f7a/x86_64-centos7-gcc11-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/onnxruntime/capi/:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/11.0.14p1-8284a/x86_64-centos7-gcc11-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.37-355ed/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/4.1.2-f9ee4/x86_64-centos7-gcc11-opt/lib64/R/library/readr/rcon\n",
      "2022-07-28 19:37:43.451474: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'HyperRectangleFitter' from '/eos/home-i01/k/khowey/SWAN_projects/ML4DQMDC-PixelAE/Merging Histogram Notebooks/../src/cloudfitters/HyperRectangleFitter.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import importlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import SubHistStruct\n",
    "importlib.reload(SubHistStruct)\n",
    "import FlexiStruct\n",
    "importlib.reload(FlexiStruct)\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed Controls and Run Mode\n",
    "\n",
    "# Disables all plots for large datasets where speed is more important\n",
    "createPlots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2020c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation Parameters\n",
    "\n",
    "# Select the bias towards recall against precision, treated as a factor (so < 1 biases towards precision, 1 is equal importance, and > 1 biases towards recall)\n",
    "wpBiasFactor = 20\n",
    "fmBiasFactor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8eb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining bad runs\n",
    "badruns = {'2017B':\n",
    "                [\n",
    "                    297048,\n",
    "                    297282,\n",
    "                    297283,\n",
    "                    297284,\n",
    "                    297287,\n",
    "                    297288,\n",
    "                    297289,\n",
    "                    299316,\n",
    "                    299317,\n",
    "                    299318,\n",
    "                    299324,\n",
    "                    299326,\n",
    "                    301086,\n",
    "                    301086,\n",
    "                    303948,\n",
    "                    297047, #close but, true bad for all 8\n",
    "                    297169, #true bad for all 8\n",
    "                    297211, #Reconstructs well\n",
    "                    299325, #Reconstructs well\n",
    "                    297664, #true bad for all 8\n",
    "                    299317, #true bad for all 8\n",
    "                    297169, #true bad for all 8\n",
    "                    297502\n",
    "                ],\n",
    "             '2017C':[\n",
    "                  300781, # bad for tracking (pixels were excluded.\n",
    "                  300079, # is bad for strips and then also for tracking\n",
    "                  302029, # Poor detector elements for strips - Should be mildly anomalous, but technically good \n",
    "                  300576, # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                  300574, # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                  300282, # Poor detector elements for strips - Should be mildly anomalous, but technically good\n",
    "                  301912, # Half bad for pixels (lost HV or readout card)  \n",
    "                  301086, # Half bad for pixels (lost HV or readout card)  \n",
    "                  300283, # Half bad for pixels (lost HV or readout card) \n",
    "                  300282, # Half bad for pixels (lost HV or readout card) \n",
    "                  300281, # Half bad for pixels (lost HV or readout card) \n",
    "                  300239, # Half bad for pixels (lost HV or readout card)\n",
    "                  301394, # Marginal for pixels\n",
    "                  301183, # Marginal for pixels\n",
    "                  300398, # Marginal for pixels\n",
    "                  300389, # Marginal for pixels\n",
    "                  300365  # Marginal for pixels\n",
    "             ],\n",
    "             '2017E':[\n",
    "                 304740, # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 304776, # Bad for pixels and tracking - holes in PXLayer 1\n",
    "                 304506, # Portcard problem for pixels\n",
    "                 304507, # Portcard problem for pixels \n",
    "                 303989, # Bad for pixels, power supply died\n",
    "                 303824  # Partly bad for strips due to a test\n",
    "             ],\n",
    "             '2017F':[\n",
    "                 306422, # Partly bad for strips - 2 data readouts failed \n",
    "                 306423, # Partly bad for strips - 2 data readouts failed\n",
    "                 306425, # Partly bad for strips - 2 data readouts failed\n",
    "                 305440, # Partly bad for strips - 1 data readout failed\n",
    "                 305441, # Partly bad for strips - 1 data readout failed\n",
    "                 305249, # Bad for pixels - half of disk failed \n",
    "                 305250, # Bad for pixels - half of disk failed\n",
    "                 305064, # Marginal for pixels - some readout failed\n",
    "             ],\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                [\n",
    "                317479,\n",
    "                317480,\n",
    "                317481,\n",
    "                317482,\n",
    "                319847\n",
    "                ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ed68a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found bad run :{'run_number': 303824, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 304158, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017E_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 303989, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 304158, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017E_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 304740, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 304158, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017E_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 305250, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 306459, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017F_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 306422, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 306459, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017F_UL2019/DQM'}\n",
      "Found bad run :{'run_number': 305249, 'run_reconstruction_type': 'rerecoul', 'reference_run_number': 306459, 'reference_run_reconstruction_type': 'rerecoul', 'dataset': '/ReReco/Run2017F_UL2019/DQM'}\n"
     ]
    }
   ],
   "source": [
    "### Select a reference run and get data\n",
    "rundict = jsonu.loadjson('../jsons/CertHelperRefRuns.json')\n",
    "\n",
    "# Select any run numbers to get a training set from that run's reference.\n",
    "runNums = [303824, 306422]\n",
    "refRuns = []\n",
    "eras = []\n",
    "years = []\n",
    "dataDict = {}\n",
    "badrunsls = {}\n",
    "trainrunsls = {}\n",
    "goodrunsls = {}\n",
    "for runNum in runNums:\n",
    "    runls = {}\n",
    "    for run in rundict:\n",
    "        if run['run_number'] == runNum:\n",
    "            runls.update(run)\n",
    "    if runls == {}:\n",
    "        raise Exception('Run not found - ' + str(runNum))\n",
    "    \n",
    "    year = runls['dataset'][11:15]\n",
    "    if year not in years: years.append(year)\n",
    "    era = runls['dataset'][15]\n",
    "    if era not in eras: eras.append(era)\n",
    "    ref_run = runls['reference_run_number']\n",
    "    \n",
    "    # Don't need duplicates\n",
    "    if ref_run in refRuns:\n",
    "        continue\n",
    "    refRuns.append(ref_run)\n",
    "    \n",
    "    # Get the runs associated with found reference\n",
    "    outputRuns = {}\n",
    "    outputBad = {}\n",
    "    for run in rundict:\n",
    "        tempRef = run['reference_run_number']\n",
    "        if tempRef == ref_run:\n",
    "            runls = {}\n",
    "            runls[str(run['run_number'])] = [[-1]]\n",
    "            if run['run_number'] in badruns[year+era]:\n",
    "                print('Found bad run :' + str(run))\n",
    "                outputBad.update(runls)\n",
    "            else:\n",
    "                outputRuns.update(runls)\n",
    "    \n",
    "    # Perform structuring for compatibility with autoencoders\n",
    "    dataDict[year + era] = outputRuns\n",
    "    badrunsls[year + era] = outputBad\n",
    "    trainrunsls[year + era] = {}\n",
    "    goodrunsls[year + era] = {}\n",
    "    \n",
    "    # Select training and testing set\n",
    "    for i,run in enumerate(dataDict[year + era]):\n",
    "        if i > 5 and i < 11:\n",
    "            goodrunsls[year + era][str(run)] = [[-1]]\n",
    "        else:\n",
    "            trainrunsls[year + era][str(run)] = [[-1]]\n",
    "\n",
    "if len(years) != 1: raise Exception('Year of length 0 or >1 unimplemented!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4590f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Controls and Selection - 1D Autoncoder\n",
    "\n",
    "# The directory data is located in\n",
    "datadir = {}\n",
    "for era in eras:\n",
    "    datadir[year + era] = '../data/' + year + era + '/'\n",
    "\n",
    "# Create a list of histograms to include\n",
    "# Pair histograms to be combined on the same line\n",
    "histnames = [['chargeInner_PXLayer_1', 'chargeInner_PXLayer_2', 'chargeInner_PXLayer_3', 'chargeInner_PXLayer_4', 'chargeOuter_PXLayer_1', 'chargeOuter_PXLayer_2', 'chargeOuter_PXLayer_3', 'chargeOuter_PXLayer_4', 'adc_PXLayer_1', 'adc_PXLayer_2', 'adc_PXLayer_3', 'adc_PXLayer_4', 'size_PXLayer_1', 'size_PXLayer_2', 'size_PXLayer_3', 'size_PXLayer_4'], ['charge_PXDisk_+1', 'charge_PXDisk_+2', 'charge_PXDisk_+3', 'adc_PXDisk_+1', 'adc_PXDisk_+2', 'adc_PXDisk_+3', 'size_PXDisk_+1', 'size_PXDisk_+2', 'size_PXDisk_+3'], ['charge_PXDisk_-1', 'charge_PXDisk_-2', 'charge_PXDisk_-3', 'adc_PXDisk_-1', 'adc_PXDisk_-2', 'adc_PXDisk_-3', 'size_PXDisk_-1', 'size_PXDisk_-2', 'size_PXDisk_-3'], ['NormalizedHitResiduals_TIB__Layer__1', 'NormalizedHitResiduals_TIB__Layer__2', 'NormalizedHitResiduals_TIB__Layer__3', 'NormalizedHitResiduals_TIB__Layer__4', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__1', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__2', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__3', 'Summary_ClusterStoNCorr__OnTrack__TIB__layer__4'], ['NormalizedHitResiduals_TOB__Layer__1', 'NormalizedHitResiduals_TOB__Layer__2', 'NormalizedHitResiduals_TOB__Layer__3', 'NormalizedHitResiduals_TOB__Layer__4', 'NormalizedHitResiduals_TOB__Layer__5', 'NormalizedHitResiduals_TOB__Layer__6', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__1', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__2', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__3', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__4', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__5', 'Summary_ClusterStoNCorr__OnTrack__TOB__layer__6'], ['Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__3'], ['NormalizedHitResiduals_TID__wheel__1', 'NormalizedHitResiduals_TID__wheel__2', 'NormalizedHitResiduals_TID__wheel__3', 'Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__3'], ['Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__3', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__4', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__5', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__6', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__7', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__8', 'Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__9'], ['NormalizedHitResiduals_TEC__wheel__1', 'NormalizedHitResiduals_TEC__wheel__2', 'NormalizedHitResiduals_TEC__wheel__3', 'NormalizedHitResiduals_TEC__wheel__4', 'NormalizedHitResiduals_TEC__wheel__5', 'NormalizedHitResiduals_TEC__wheel__6', 'NormalizedHitResiduals_TEC__wheel__7', 'NormalizedHitResiduals_TEC__wheel__8', 'NormalizedHitResiduals_TEC__wheel__9', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__1', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__2', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__3', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__4', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__5', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__6', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__7', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__8', 'Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__9'], ['NumberOfRecHitsPerTrack_lumiFlag_GenTk', 'Chi2oNDF_lumiFlag_GenTk', 'goodvtxNbr'], ['num_clusters_ontrack_PXBarrel', 'num_clusters_ontrack_PXForward']]\n",
    "\n",
    "# Read new data or use previously saved data & should data be saved\n",
    "readnew = True\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ffebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Run Properties - Combined Autoencoder\n",
    "# in this cell all major run properties are going to be set,\n",
    "\n",
    "# Set whether to train globally or locally or in a development/testing mode\n",
    "training_mode = 'development'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6394238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Controls and Selection - 1D Autoencoder\n",
    "\n",
    "plotNames = 'Test'\n",
    "name = plotNames+'plots'\n",
    "\n",
    "# Choose whether to train a new model or load one\n",
    "trainnew = True\n",
    "savemodel = True\n",
    "modelname = plotNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4051dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected runs/lumisections for training: \n",
      "{'303819': [[-1]], '303999': [[-1]], '304119': [[-1]], '304120': [[-1]], '304197': [[-1]], '304505': [[-1]], '304449': [[-1]], '304452': [[-1]], '304508': [[-1]], '304625': [[-1]], '304655': [[-1]], '304737': [[-1]], '304778': [[-1]], '306459': [[-1]], '304196': [[-1]], '305310': [[-1]], '305040': [[-1]], '305043': [[-1]], '305185': [[-1]], '305204': [[-1]], '305234': [[-1]], '305376': [[-1]], '306042': [[-1]], '306051': [[-1]], '305406': [[-1]], '306122': [[-1]], '306134': [[-1]], '306137': [[-1]], '306154': [[-1]], '306170': [[-1]], '306417': [[-1]], '306432': [[-1]], '306456': [[-1]], '305516': [[-1]], '305586': [[-1]], '305588': [[-1]], '305590': [[-1]], '305809': [[-1]], '305832': [[-1]], '305840': [[-1]], '305898': [[-1]], '306029': [[-1]], '306037': [[-1]], '306095': [[-1]]}\n",
      "selected runs/lumisections as good test set:\n",
      "{'304198': [[-1]], '304199': [[-1]], '304209': [[-1]], '304333': [[-1]], '304446': [[-1]], '305247': [[-1]], '305313': [[-1]], '305338': [[-1]], '305350': [[-1]], '305364': [[-1]]}\n",
      "selected runs/lumisections as bad test set:\n",
      "{'303824': [[-1]], '303989': [[-1]], '304740': [[-1]], '305250': [[-1]], '306422': [[-1]], '305249': [[-1]]}\n"
     ]
    }
   ],
   "source": [
    "### Define Training Mode Parameters - Combined Autoencoder\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use averages of training set)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    # - this only works for a single era\n",
    "    \n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+era+'_'+histnames[0][0]+'.csv') ) )\n",
    "    # Cherry picked really bad run\n",
    "    run_application = 299316\n",
    "    #run_application = 299317\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5\n",
    "        offset = 0 # normal case: offset = 0 (just use 5 previous runs)\n",
    "        \n",
    "        # Selects the 5 previous runs for training\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    #runsls_bad = badrunsls[year]\n",
    "    #runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_good = runsls_training\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)\n",
    "        \n",
    "elif training_mode == 'development':\n",
    "    # train on a user-defined subset of runs\n",
    "    \n",
    "   # Select runs to be used in training from the user-defined list\n",
    "    runsls_training = {}\n",
    "    runsls_bad = {}\n",
    "    runsls_good = {}\n",
    "    for era in eras:\n",
    "        runsls_training.update(trainrunsls[year + era])\n",
    "        # Select bad runs to test on in the user-defined list\n",
    "        runsls_bad.update(badrunsls[year + era])\n",
    "        # Select good runs to test on in the user-defined list\n",
    "        runsls_good.update(goodrunsls[year + era])\n",
    "    \n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54180f06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Classifiers and masks cleared to preserve consistency\n",
      "Adding chargeInner_PXLayer_1...\n",
      "Adding chargeInner_PXLayer_2...\n",
      "Adding chargeInner_PXLayer_3...\n",
      "Adding chargeInner_PXLayer_4...\n",
      "Adding chargeOuter_PXLayer_1...\n",
      "Adding chargeOuter_PXLayer_2...\n",
      "Adding chargeOuter_PXLayer_3...\n",
      "Adding chargeOuter_PXLayer_4...\n",
      "Adding adc_PXLayer_1...\n",
      "Adding adc_PXLayer_2...\n",
      "Adding adc_PXLayer_3...\n",
      "Adding adc_PXLayer_4...\n",
      "Adding size_PXLayer_1...\n",
      "Adding size_PXLayer_2...\n",
      "Adding size_PXLayer_3...\n",
      "Adding size_PXLayer_4...\n",
      "Adding charge_PXDisk_+1...\n",
      "Adding charge_PXDisk_+2...\n",
      "Adding charge_PXDisk_+3...\n",
      "Adding adc_PXDisk_+1...\n",
      "Adding adc_PXDisk_+2...\n",
      "Adding adc_PXDisk_+3...\n",
      "Adding size_PXDisk_+1...\n",
      "Adding size_PXDisk_+2...\n",
      "Adding size_PXDisk_+3...\n",
      "Adding charge_PXDisk_-1...\n",
      "Adding charge_PXDisk_-2...\n",
      "Adding charge_PXDisk_-3...\n",
      "Adding adc_PXDisk_-1...\n",
      "Adding adc_PXDisk_-2...\n",
      "Adding adc_PXDisk_-3...\n",
      "Adding size_PXDisk_-1...\n",
      "Adding size_PXDisk_-2...\n",
      "Adding size_PXDisk_-3...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__1...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__2...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__3...\n",
      "Adding NormalizedHitResiduals_TIB__Layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__1...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__2...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__3...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__4...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__5...\n",
      "Adding NormalizedHitResiduals_TOB__Layer__6...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__5...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__6...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__3...\n",
      "Adding NormalizedHitResiduals_TID__wheel__1...\n",
      "Adding NormalizedHitResiduals_TID__wheel__2...\n",
      "Adding NormalizedHitResiduals_TID__wheel__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__5...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__6...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__7...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__8...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__9...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__1...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__2...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__3...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__4...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__5...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__6...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__7...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__8...\n",
      "Adding NormalizedHitResiduals_TEC__wheel__9...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__1...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__2...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__3...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__4...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__5...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__6...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__7...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__8...\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__9...\n",
      "Adding NumberOfRecHitsPerTrack_lumiFlag_GenTk...\n",
      "Adding Chi2oNDF_lumiFlag_GenTk...\n",
      "Adding goodvtxNbr...\n",
      "Adding num_clusters_ontrack_PXBarrel...\n",
      "Adding num_clusters_ontrack_PXForward...\n",
      "Found 9290 histograms\n",
      "Adding chargeInner_PXLayer_1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeInner_PXLayer_2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeInner_PXLayer_3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeInner_PXLayer_4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeOuter_PXLayer_1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeOuter_PXLayer_2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeOuter_PXLayer_3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding chargeOuter_PXLayer_4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXLayer_1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXLayer_2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXLayer_3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXLayer_4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXLayer_1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXLayer_2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXLayer_3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXLayer_4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_+1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_+2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_+3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXDisk_+1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXDisk_+2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXDisk_+3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXDisk_+1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXDisk_+2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXDisk_+3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_-1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_-2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding charge_PXDisk_-3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding adc_PXDisk_-1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXDisk_-2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding adc_PXDisk_-3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXDisk_-1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXDisk_-2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding size_PXDisk_-3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TIB__Layer__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TIB__Layer__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TIB__Layer__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TIB__Layer__4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TIB__layer__4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TOB__Layer__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TOB__Layer__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TOB__Layer__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TOB__Layer__4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TOB__Layer__5...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TOB__Layer__6...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__5...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TOB__layer__6...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__PLUS__wheel__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TID__wheel__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TID__wheel__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TID__wheel__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TID__MINUS__wheel__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__5...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__6...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__7...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__8...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__PLUS__wheel__9...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__5...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__6...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__7...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NormalizedHitResiduals_TEC__wheel__8...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NormalizedHitResiduals_TEC__wheel__9...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__1...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__2...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__3...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__4...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__5...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__6...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__7...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__8...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Summary_ClusterStoNCorr__OnTrack__TEC__MINUS__wheel__9...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding NumberOfRecHitsPerTrack_lumiFlag_GenTk...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding Chi2oNDF_lumiFlag_GenTk...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding goodvtxNbr...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding num_clusters_ontrack_PXBarrel...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Adding num_clusters_ontrack_PXForward...\n",
      "WARNING: Histogram already in HistStruct. Error checking is disabled, so ensure histograms have same features.\n",
      "Found 25676 histograms\n",
      "Created a histstruct with the following properties:\n",
      "- number of histogram types: 95\n",
      "- number of lumisections: 25676\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "\n",
    "# Create a new HistStruct from the data\n",
    "if readnew:\n",
    "    # Initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = FlexiStruct.FlexiStruct()\n",
    "    histstruct.reset_histlist(histnames)\n",
    "    \n",
    "    # Unpack histnames and add every histogram individually\n",
    "    for era in eras:\n",
    "        for histnamegroup in histnames:\n",
    "            for histname in histnamegroup:\n",
    "                print('Adding {}...'.format(histname))\n",
    "                \n",
    "                # Bring the histograms into memory from storage for later use\n",
    "                filename = datadir[year+era] + 'DF' + year + era + '_' + histname + '.csv'\n",
    "                df = dloader.get_dataframe_from_file( filename )\n",
    "                \n",
    "                # In case of local training, we can remove most of the histograms\n",
    "                if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "                    runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "                    df = dfu.select_runsls( df, runsls_total )    \n",
    "                \n",
    "                df = dfu.rm_duplicates(df)\n",
    "                # Store the data in the histstruct object managing this whole thing\n",
    "                histstruct.add_dataframe( df, rebinningfactor = 1, standardbincount = 102 )\n",
    "        print('Found {} histograms'.format(len(histstruct.runnbs)))\n",
    "\n",
    "# Load a previously saved HistStruct\n",
    "else:\n",
    "    # Load histstruct from storage\n",
    "    histstruct = SubHistStruct.SubHistStruct.load( 'histstruct_global_20220201.zip', verbose=False )\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if ('bad' in name and name!='bad')])\n",
    "    \n",
    "    print('loaded a histstruct with the following properties:')\n",
    "    print(histstruct)\n",
    "    # Count of bad runs, presumably for later use\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "print('Created a histstruct with the following properties:')\n",
    "print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45931fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'303824': [[-1]], '303989': [[-1]], '304740': [[-1]], '305250': [[-1]], '306422': [[-1]], '305249': [[-1]]}\n",
      "Assigned masks: ['dcson', 'golden', 'highstat', 'lowstat', 'training', 'good', 'bad', 'bad0', 'bad1', 'bad2', 'bad3', 'bad4', 'bad5']\n"
     ]
    }
   ],
   "source": [
    "### Add Masks to Data\n",
    "\n",
    "if readnew:\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat', entries_to_bins_ratio=0 )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=0 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "        \n",
    "    # Distinguishing bad runs\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        print(runsls_bad)\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        \n",
    "        # Special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "            \n",
    "    if save:\n",
    "        histstruct.save('test.pk1')\n",
    "print('Assigned masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d6a8ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plotting the input data for analysis\n",
    "\n",
    "if((training_mode=='local' or training_mode == 'development') and createPlots):\n",
    "\n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad0']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )\n",
    "    \n",
    "elif( training_mode=='global' and createPlots):\n",
    "    \n",
    "    # bad test runs\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "                                labellist = ['typical good histograms','bad'],\n",
    "                                colorlist = ['blue','red'],\n",
    "                                transparencylist = [0.01,1.]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_concatamash_autoencoder(histstruct):\n",
    "    \n",
    "    histslist = []\n",
    "    vallist = []\n",
    "    autoencoders = []\n",
    "    if trainnew:\n",
    "        for i,histnamegroup in enumerate(histnames):\n",
    "            \n",
    "            train_normhist = np.array([hu.normalize(histstruct.get_histograms(\n",
    "                histname = hname, masknames = ['dcson','highstat', 'training']), \n",
    "                                                 norm=\"l1\", axis=1) \n",
    "                                       for hname in histnamegroup]).transpose((1,0,2))\n",
    "            X_train, X_val = train_test_split(train_normhist, test_size=0.4, random_state=42)\n",
    "            \n",
    "            # Half the total bin count\n",
    "            arch = 51 * len(histnamegroup)\n",
    "            \n",
    "            ## Model parameters\n",
    "            input_dim = X_train.shape[2] #num of predictor variables\n",
    "            Input_layers=[Input(shape=input_dim) for i in range((X_train.shape[1]))]\n",
    "            \n",
    "            # Defining layers\n",
    "            conc_layer = Concatenate()(Input_layers)\n",
    "            encoder = Dense(arch * 2, activation=\"tanh\")(conc_layer)\n",
    "            encoder = Dense(arch/2, activation='relu')(encoder)\n",
    "            encoder = Dense(arch/8, activation='relu')(encoder)\n",
    "            encoder = Dense(arch/16, activation='relu')(encoder)\n",
    "            decoder = Dense(arch/8, activation=\"relu\")(encoder)\n",
    "            decoder = Dense(arch/2, activation='relu')(encoder)\n",
    "            decoder = Dense(arch * 2, activation=\"tanh\")(decoder)\n",
    "            \n",
    "            Output_layers=[Dense(input_dim, activation=\"tanh\")(decoder) for i in range(X_train.shape[1])]\n",
    "\n",
    "            autoencoder = Model(inputs=Input_layers, outputs=Output_layers)\n",
    "            autoencoders.append(autoencoder)\n",
    "            \n",
    "            histslist.append(X_train)\n",
    "            vallist.append(X_val)\n",
    "     \n",
    "    # Return the histograms stored 2-Dimensionally and the autoencoders corresponding\n",
    "    return(histslist, vallist, autoencoders, train_normhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c76ea4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 19:44:46.152845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.3-88592/x86_64-centos7-gcc11-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.3-35f7a/x86_64-centos7-gcc11-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/onnxruntime/capi/:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/11.0.14p1-8284a/x86_64-centos7-gcc11-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.2.0-8a51a/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.37-355ed/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/4.1.2-f9ee4/x86_64-centos7-gcc11-opt/lib64/R/library/readr/rcon\n",
      "2022-07-28 19:44:46.152962: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-28 19:44:46.153014: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-khowey): /proc/driver/nvidia/version does not exist\n",
      "2022-07-28 19:44:46.154035: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(histslist, vallist, autoencoders, train_normhist) = define_concatamash_autoencoder(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trains a combined autoencoder for every merge set\n",
    "def train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders):\n",
    "    \n",
    "    autoencodersTrain = []\n",
    "    for i in range(len(histslist)):\n",
    "        \n",
    "        print('Now training model {}/'.format(i + 1) + str(len(histslist)))\n",
    "        \n",
    "        # Set variables to temporary values for better transparency\n",
    "        X_train = histslist[i]\n",
    "        X_val = vallist[i]\n",
    "        autoencoder = autoencoders[i]\n",
    "        \n",
    "        \n",
    "        ## Model parameters\n",
    "        nb_epoch = 500\n",
    "        batch_size = 10000\n",
    "        \n",
    "        #checkpoint_filepath = 'checkpoint'\n",
    "        #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #   filepath=checkpoint_filepath,\n",
    "        #   save_weights_only=False,\n",
    "        #   verbose=1,\n",
    "        #   save_best_only=True,\n",
    "        #   monitor='val_loss',\n",
    "        #   mode='min')\n",
    "        \n",
    "        # Tell the model when to stop\n",
    "        earlystop = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=1e-7,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        lr =0.001\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        \n",
    "        autoencoder.compile(loss='mse',\n",
    "                            optimizer=opt)\n",
    "        \n",
    "        ## Train autoencoder\n",
    "        train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                y=[X_train[:,i] for i in range(X_train.shape[1])],\n",
    "                                epochs=nb_epoch,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                validation_data=([X_val[:,i] for i in range(X_val.shape[1])], [X_val[:,i] for i in range(X_val.shape[1])]),\n",
    "                                verbose=1,\n",
    "                                callbacks= [earlystop],    \n",
    "                                )\n",
    "        tf.keras.utils.plot_model(\n",
    "                    autoencoder,\n",
    "                    to_file=\"models/model1D{}.png\".format(i),\n",
    "                    show_shapes=True,\n",
    "                    show_dtype=False,\n",
    "                    show_layer_names=False,\n",
    "                    rankdir=\"TB\")\n",
    "        \n",
    "        # Save classifier for evaluation\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier) \n",
    "        autoencodersTrain.append(classifier)\n",
    "        K.clear_session()\n",
    "        del(autoencoder, classifier)\n",
    "    return autoencodersTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c02f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_concatamash_autoencoder():\n",
    "    for i in range(len(histnames)):\n",
    "        autoencoder = tf.keras.models.load_model('../SavedModels/Permutations/Job1/AE{}'.format(i))\n",
    "        classifier = AutoEncoder.AutoEncoder(model=autoencoder)\n",
    "        histstruct.add_classifier(histnames[i][0], classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52397fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training model 1/11\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 19:44:59.940936: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65280000 exceeds 10% of free system memory.\n",
      "2022-07-28 19:44:59.972807: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65280000 exceeds 10% of free system memory.\n",
      "2022-07-28 19:45:00.554714: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65280000 exceeds 10% of free system memory.\n",
      "2022-07-28 19:45:01.170058: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65280000 exceeds 10% of free system memory.\n",
      "2022-07-28 19:45:01.170160: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step - loss: 0.0122 - dense_7_loss: 3.5038e-04 - dense_8_loss: 4.2873e-04 - dense_9_loss: 3.8053e-04 - dense_10_loss: 4.0401e-04 - dense_11_loss: 3.2226e-04 - dense_12_loss: 3.9287e-04 - dense_13_loss: 4.0873e-04 - dense_14_loss: 3.5784e-04 - dense_15_loss: 6.1863e-04 - dense_16_loss: 4.8779e-04 - dense_17_loss: 5.3696e-04 - dense_18_loss: 5.2762e-04 - dense_19_loss: 0.0013 - dense_20_loss: 0.0014 - dense_21_loss: 0.0019 - dense_22_loss: 0.0024 - val_loss: 0.0064 - val_dense_7_loss: 2.2580e-04 - val_dense_8_loss: 2.2078e-04 - val_dense_9_loss: 2.0372e-04 - val_dense_10_loss: 2.1014e-04 - val_dense_11_loss: 1.9502e-04 - val_dense_12_loss: 2.2262e-04 - val_dense_13_loss: 2.6642e-04 - val_dense_14_loss: 2.2604e-04 - val_dense_15_loss: 3.5610e-04 - val_dense_16_loss: 2.2763e-04 - val_dense_17_loss: 2.7806e-04 - val_dense_18_loss: 2.8596e-04 - val_dense_19_loss: 6.4221e-04 - val_dense_20_loss: 6.8241e-04 - val_dense_21_loss: 9.9209e-04 - val_dense_22_loss: 0.0012\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 3s 694ms/step - loss: 0.0061 - dense_7_loss: 2.3382e-04 - dense_8_loss: 2.1974e-04 - dense_9_loss: 2.0740e-04 - dense_10_loss: 2.2329e-04 - dense_11_loss: 1.9449e-04 - dense_12_loss: 2.2851e-04 - dense_13_loss: 2.6666e-04 - dense_14_loss: 2.2599e-04 - dense_15_loss: 3.4743e-04 - dense_16_loss: 2.2907e-04 - dense_17_loss: 2.8226e-04 - dense_18_loss: 2.7673e-04 - dense_19_loss: 5.9818e-04 - dense_20_loss: 6.3676e-04 - dense_21_loss: 8.9725e-04 - dense_22_loss: 0.0011 - val_loss: 0.0024 - val_dense_7_loss: 9.4711e-05 - val_dense_8_loss: 1.0711e-04 - val_dense_9_loss: 8.5841e-05 - val_dense_10_loss: 7.9938e-05 - val_dense_11_loss: 8.8696e-05 - val_dense_12_loss: 9.1225e-05 - val_dense_13_loss: 8.9505e-05 - val_dense_14_loss: 9.4156e-05 - val_dense_15_loss: 1.1601e-04 - val_dense_16_loss: 8.7955e-05 - val_dense_17_loss: 1.2098e-04 - val_dense_18_loss: 8.4190e-05 - val_dense_19_loss: 2.4717e-04 - val_dense_20_loss: 2.0192e-04 - val_dense_21_loss: 3.2395e-04 - val_dense_22_loss: 4.4668e-04\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 3s 793ms/step - loss: 0.0023 - dense_7_loss: 9.5820e-05 - dense_8_loss: 1.0730e-04 - dense_9_loss: 8.7095e-05 - dense_10_loss: 8.0645e-05 - dense_11_loss: 8.8693e-05 - dense_12_loss: 9.4956e-05 - dense_13_loss: 8.9200e-05 - dense_14_loss: 9.1918e-05 - dense_15_loss: 1.1236e-04 - dense_16_loss: 8.8556e-05 - dense_17_loss: 1.2058e-04 - dense_18_loss: 8.4586e-05 - dense_19_loss: 2.3039e-04 - dense_20_loss: 1.8925e-04 - dense_21_loss: 3.0260e-04 - dense_22_loss: 4.1640e-04 - val_loss: 0.0020 - val_dense_7_loss: 1.4692e-04 - val_dense_8_loss: 1.4227e-04 - val_dense_9_loss: 1.2444e-04 - val_dense_10_loss: 1.4608e-04 - val_dense_11_loss: 1.1438e-04 - val_dense_12_loss: 1.4276e-04 - val_dense_13_loss: 1.3162e-04 - val_dense_14_loss: 1.2466e-04 - val_dense_15_loss: 1.4099e-04 - val_dense_16_loss: 1.1397e-04 - val_dense_17_loss: 1.1273e-04 - val_dense_18_loss: 1.0902e-04 - val_dense_19_loss: 1.2497e-04 - val_dense_20_loss: 1.0278e-04 - val_dense_21_loss: 1.1347e-04 - val_dense_22_loss: 1.5719e-04\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 2s 765ms/step - loss: 0.0020 - dense_7_loss: 1.3737e-04 - dense_8_loss: 1.3407e-04 - dense_9_loss: 1.1698e-04 - dense_10_loss: 1.3913e-04 - dense_11_loss: 1.1012e-04 - dense_12_loss: 1.3572e-04 - dense_13_loss: 1.2525e-04 - dense_14_loss: 1.1952e-04 - dense_15_loss: 1.3515e-04 - dense_16_loss: 1.0921e-04 - dense_17_loss: 1.0725e-04 - dense_18_loss: 1.0482e-04 - dense_19_loss: 1.2548e-04 - dense_20_loss: 9.9928e-05 - dense_21_loss: 1.0967e-04 - dense_22_loss: 1.5556e-04 - val_loss: 9.6384e-04 - val_dense_7_loss: 5.1590e-05 - val_dense_8_loss: 5.7192e-05 - val_dense_9_loss: 5.2776e-05 - val_dense_10_loss: 6.2850e-05 - val_dense_11_loss: 5.3000e-05 - val_dense_12_loss: 5.4448e-05 - val_dense_13_loss: 5.7434e-05 - val_dense_14_loss: 5.4067e-05 - val_dense_15_loss: 5.3804e-05 - val_dense_16_loss: 5.0649e-05 - val_dense_17_loss: 5.9437e-05 - val_dense_18_loss: 5.4940e-05 - val_dense_19_loss: 9.4947e-05 - val_dense_20_loss: 6.6843e-05 - val_dense_21_loss: 5.3951e-05 - val_dense_22_loss: 8.5908e-05\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 2s 709ms/step - loss: 9.6102e-04 - dense_7_loss: 5.3354e-05 - dense_8_loss: 5.8086e-05 - dense_9_loss: 5.3667e-05 - dense_10_loss: 6.2582e-05 - dense_11_loss: 5.3825e-05 - dense_12_loss: 5.4379e-05 - dense_13_loss: 5.7021e-05 - dense_14_loss: 5.2712e-05 - dense_15_loss: 5.3789e-05 - dense_16_loss: 5.0260e-05 - dense_17_loss: 6.0918e-05 - dense_18_loss: 5.5457e-05 - dense_19_loss: 9.2828e-05 - dense_20_loss: 6.7313e-05 - dense_21_loss: 5.4116e-05 - dense_22_loss: 8.0713e-05 - val_loss: 7.2253e-04 - val_dense_7_loss: 4.6191e-05 - val_dense_8_loss: 5.5829e-05 - val_dense_9_loss: 4.6707e-05 - val_dense_10_loss: 4.7574e-05 - val_dense_11_loss: 4.9836e-05 - val_dense_12_loss: 4.6961e-05 - val_dense_13_loss: 4.3874e-05 - val_dense_14_loss: 4.0611e-05 - val_dense_15_loss: 3.3270e-05 - val_dense_16_loss: 3.2472e-05 - val_dense_17_loss: 4.4757e-05 - val_dense_18_loss: 4.1347e-05 - val_dense_19_loss: 5.1957e-05 - val_dense_20_loss: 4.2690e-05 - val_dense_21_loss: 4.4707e-05 - val_dense_22_loss: 5.3751e-05\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 2s 705ms/step - loss: 7.2278e-04 - dense_7_loss: 4.6111e-05 - dense_8_loss: 5.5916e-05 - dense_9_loss: 4.6389e-05 - dense_10_loss: 4.7019e-05 - dense_11_loss: 4.9355e-05 - dense_12_loss: 4.7530e-05 - dense_13_loss: 4.4117e-05 - dense_14_loss: 4.1343e-05 - dense_15_loss: 3.3977e-05 - dense_16_loss: 3.3622e-05 - dense_17_loss: 4.3010e-05 - dense_18_loss: 4.1804e-05 - dense_19_loss: 5.2063e-05 - dense_20_loss: 4.2076e-05 - dense_21_loss: 4.4702e-05 - dense_22_loss: 5.3742e-05 - val_loss: 6.0635e-04 - val_dense_7_loss: 3.9483e-05 - val_dense_8_loss: 4.4287e-05 - val_dense_9_loss: 3.5635e-05 - val_dense_10_loss: 3.8850e-05 - val_dense_11_loss: 3.8816e-05 - val_dense_12_loss: 4.4775e-05 - val_dense_13_loss: 4.2163e-05 - val_dense_14_loss: 3.9517e-05 - val_dense_15_loss: 3.2470e-05 - val_dense_16_loss: 3.9064e-05 - val_dense_17_loss: 2.6029e-05 - val_dense_18_loss: 3.7889e-05 - val_dense_19_loss: 4.8949e-05 - val_dense_20_loss: 3.1041e-05 - val_dense_21_loss: 3.1828e-05 - val_dense_22_loss: 3.5557e-05\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 2s 727ms/step - loss: 5.9753e-04 - dense_7_loss: 3.9345e-05 - dense_8_loss: 4.3314e-05 - dense_9_loss: 3.5472e-05 - dense_10_loss: 3.8362e-05 - dense_11_loss: 3.7858e-05 - dense_12_loss: 4.4154e-05 - dense_13_loss: 4.1350e-05 - dense_14_loss: 3.8740e-05 - dense_15_loss: 3.2657e-05 - dense_16_loss: 3.8475e-05 - dense_17_loss: 2.5879e-05 - dense_18_loss: 3.7080e-05 - dense_19_loss: 4.9006e-05 - dense_20_loss: 3.0421e-05 - dense_21_loss: 3.1156e-05 - dense_22_loss: 3.4261e-05 - val_loss: 4.5043e-04 - val_dense_7_loss: 3.1574e-05 - val_dense_8_loss: 3.2091e-05 - val_dense_9_loss: 3.0996e-05 - val_dense_10_loss: 2.8543e-05 - val_dense_11_loss: 2.6616e-05 - val_dense_12_loss: 3.1784e-05 - val_dense_13_loss: 3.0224e-05 - val_dense_14_loss: 2.6031e-05 - val_dense_15_loss: 2.6538e-05 - val_dense_16_loss: 2.4925e-05 - val_dense_17_loss: 2.6218e-05 - val_dense_18_loss: 2.5887e-05 - val_dense_19_loss: 4.1181e-05 - val_dense_20_loss: 2.3103e-05 - val_dense_21_loss: 2.2924e-05 - val_dense_22_loss: 2.1800e-05\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 2s 724ms/step - loss: 4.4519e-04 - dense_7_loss: 3.1060e-05 - dense_8_loss: 3.1831e-05 - dense_9_loss: 3.0407e-05 - dense_10_loss: 2.7745e-05 - dense_11_loss: 2.6354e-05 - dense_12_loss: 3.1187e-05 - dense_13_loss: 2.9772e-05 - dense_14_loss: 2.5145e-05 - dense_15_loss: 2.6429e-05 - dense_16_loss: 2.4093e-05 - dense_17_loss: 2.6081e-05 - dense_18_loss: 2.5181e-05 - dense_19_loss: 4.1268e-05 - dense_20_loss: 2.3167e-05 - dense_21_loss: 2.3044e-05 - dense_22_loss: 2.2427e-05 - val_loss: 3.7248e-04 - val_dense_7_loss: 2.8052e-05 - val_dense_8_loss: 2.9920e-05 - val_dense_9_loss: 2.5843e-05 - val_dense_10_loss: 2.3427e-05 - val_dense_11_loss: 2.4706e-05 - val_dense_12_loss: 2.5821e-05 - val_dense_13_loss: 2.6014e-05 - val_dense_14_loss: 2.1668e-05 - val_dense_15_loss: 2.0136e-05 - val_dense_16_loss: 1.5984e-05 - val_dense_17_loss: 2.4239e-05 - val_dense_18_loss: 1.7445e-05 - val_dense_19_loss: 3.3189e-05 - val_dense_20_loss: 1.8934e-05 - val_dense_21_loss: 1.7565e-05 - val_dense_22_loss: 1.9539e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500\n",
      "2/2 [==============================] - 2s 710ms/step - loss: 3.7186e-04 - dense_7_loss: 2.8131e-05 - dense_8_loss: 2.9989e-05 - dense_9_loss: 2.5890e-05 - dense_10_loss: 2.3357e-05 - dense_11_loss: 2.4792e-05 - dense_12_loss: 2.5976e-05 - dense_13_loss: 2.6072e-05 - dense_14_loss: 2.1538e-05 - dense_15_loss: 2.0199e-05 - dense_16_loss: 1.5817e-05 - dense_17_loss: 2.3534e-05 - dense_18_loss: 1.7473e-05 - dense_19_loss: 3.3254e-05 - dense_20_loss: 1.8839e-05 - dense_21_loss: 1.7555e-05 - dense_22_loss: 1.9443e-05 - val_loss: 3.4444e-04 - val_dense_7_loss: 2.1107e-05 - val_dense_8_loss: 2.6057e-05 - val_dense_9_loss: 2.1455e-05 - val_dense_10_loss: 2.0113e-05 - val_dense_11_loss: 2.0484e-05 - val_dense_12_loss: 2.4170e-05 - val_dense_13_loss: 2.2318e-05 - val_dense_14_loss: 1.6676e-05 - val_dense_15_loss: 1.5082e-05 - val_dense_16_loss: 1.2606e-05 - val_dense_17_loss: 1.7643e-05 - val_dense_18_loss: 1.7128e-05 - val_dense_19_loss: 3.4979e-05 - val_dense_20_loss: 2.1994e-05 - val_dense_21_loss: 2.6687e-05 - val_dense_22_loss: 2.5936e-05\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 2s 773ms/step - loss: 3.4078e-04 - dense_7_loss: 2.1338e-05 - dense_8_loss: 2.6214e-05 - dense_9_loss: 2.1555e-05 - dense_10_loss: 2.0036e-05 - dense_11_loss: 2.0374e-05 - dense_12_loss: 2.4131e-05 - dense_13_loss: 2.2403e-05 - dense_14_loss: 1.6896e-05 - dense_15_loss: 1.5163e-05 - dense_16_loss: 1.2849e-05 - dense_17_loss: 1.7054e-05 - dense_18_loss: 1.7173e-05 - dense_19_loss: 3.4424e-05 - dense_20_loss: 2.1151e-05 - dense_21_loss: 2.5421e-05 - dense_22_loss: 2.4600e-05 - val_loss: 2.8602e-04 - val_dense_7_loss: 2.0406e-05 - val_dense_8_loss: 2.5314e-05 - val_dense_9_loss: 1.9811e-05 - val_dense_10_loss: 1.8926e-05 - val_dense_11_loss: 1.7500e-05 - val_dense_12_loss: 2.0599e-05 - val_dense_13_loss: 2.2067e-05 - val_dense_14_loss: 1.7435e-05 - val_dense_15_loss: 1.3562e-05 - val_dense_16_loss: 1.4112e-05 - val_dense_17_loss: 1.3282e-05 - val_dense_18_loss: 1.7120e-05 - val_dense_19_loss: 2.8089e-05 - val_dense_20_loss: 1.4088e-05 - val_dense_21_loss: 1.2475e-05 - val_dense_22_loss: 1.1230e-05\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 2s 717ms/step - loss: 2.8391e-04 - dense_7_loss: 2.0182e-05 - dense_8_loss: 2.4802e-05 - dense_9_loss: 1.9557e-05 - dense_10_loss: 1.8618e-05 - dense_11_loss: 1.7008e-05 - dense_12_loss: 2.0527e-05 - dense_13_loss: 2.1856e-05 - dense_14_loss: 1.6896e-05 - dense_15_loss: 1.3509e-05 - dense_16_loss: 1.4152e-05 - dense_17_loss: 1.2960e-05 - dense_18_loss: 1.6514e-05 - dense_19_loss: 2.8621e-05 - dense_20_loss: 1.3914e-05 - dense_21_loss: 1.2921e-05 - dense_22_loss: 1.1877e-05 - val_loss: 2.2452e-04 - val_dense_7_loss: 1.6780e-05 - val_dense_8_loss: 1.9577e-05 - val_dense_9_loss: 1.6102e-05 - val_dense_10_loss: 1.5161e-05 - val_dense_11_loss: 1.3094e-05 - val_dense_12_loss: 1.7823e-05 - val_dense_13_loss: 1.8570e-05 - val_dense_14_loss: 1.1325e-05 - val_dense_15_loss: 1.0777e-05 - val_dense_16_loss: 1.2493e-05 - val_dense_17_loss: 1.0983e-05 - val_dense_18_loss: 1.0632e-05 - val_dense_19_loss: 2.4961e-05 - val_dense_20_loss: 8.9557e-06 - val_dense_21_loss: 9.0000e-06 - val_dense_22_loss: 8.2876e-06\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 2s 709ms/step - loss: 2.2421e-04 - dense_7_loss: 1.6904e-05 - dense_8_loss: 1.9681e-05 - dense_9_loss: 1.6314e-05 - dense_10_loss: 1.4871e-05 - dense_11_loss: 1.3115e-05 - dense_12_loss: 1.7995e-05 - dense_13_loss: 1.8469e-05 - dense_14_loss: 1.1233e-05 - dense_15_loss: 1.1146e-05 - dense_16_loss: 1.2431e-05 - dense_17_loss: 1.0855e-05 - dense_18_loss: 1.0516e-05 - dense_19_loss: 2.5122e-05 - dense_20_loss: 8.6765e-06 - dense_21_loss: 8.7812e-06 - dense_22_loss: 8.0963e-06 - val_loss: 1.9997e-04 - val_dense_7_loss: 1.5640e-05 - val_dense_8_loss: 1.8537e-05 - val_dense_9_loss: 1.6319e-05 - val_dense_10_loss: 1.0813e-05 - val_dense_11_loss: 1.2864e-05 - val_dense_12_loss: 1.7103e-05 - val_dense_13_loss: 1.5696e-05 - val_dense_14_loss: 1.0830e-05 - val_dense_15_loss: 8.4399e-06 - val_dense_16_loss: 9.2588e-06 - val_dense_17_loss: 1.0257e-05 - val_dense_18_loss: 8.8752e-06 - val_dense_19_loss: 2.2664e-05 - val_dense_20_loss: 6.0108e-06 - val_dense_21_loss: 8.5313e-06 - val_dense_22_loss: 8.1323e-06\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 2s 782ms/step - loss: 1.9987e-04 - dense_7_loss: 1.5715e-05 - dense_8_loss: 1.8646e-05 - dense_9_loss: 1.6477e-05 - dense_10_loss: 1.0644e-05 - dense_11_loss: 1.2870e-05 - dense_12_loss: 1.7259e-05 - dense_13_loss: 1.5671e-05 - dense_14_loss: 1.0772e-05 - dense_15_loss: 8.7008e-06 - dense_16_loss: 9.1737e-06 - dense_17_loss: 1.0121e-05 - dense_18_loss: 8.9388e-06 - dense_19_loss: 2.2886e-05 - dense_20_loss: 5.8565e-06 - dense_21_loss: 8.2665e-06 - dense_22_loss: 7.8700e-06 - val_loss: 1.8233e-04 - val_dense_7_loss: 1.3809e-05 - val_dense_8_loss: 1.8101e-05 - val_dense_9_loss: 1.4995e-05 - val_dense_10_loss: 9.6573e-06 - val_dense_11_loss: 1.1794e-05 - val_dense_12_loss: 1.6333e-05 - val_dense_13_loss: 1.4081e-05 - val_dense_14_loss: 8.8014e-06 - val_dense_15_loss: 6.9749e-06 - val_dense_16_loss: 7.2855e-06 - val_dense_17_loss: 1.0389e-05 - val_dense_18_loss: 9.1058e-06 - val_dense_19_loss: 2.1781e-05 - val_dense_20_loss: 6.3704e-06 - val_dense_21_loss: 6.9684e-06 - val_dense_22_loss: 5.8808e-06\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 2s 717ms/step - loss: 1.8282e-04 - dense_7_loss: 1.3963e-05 - dense_8_loss: 1.8234e-05 - dense_9_loss: 1.5116e-05 - dense_10_loss: 9.7775e-06 - dense_11_loss: 1.1691e-05 - dense_12_loss: 1.6484e-05 - dense_13_loss: 1.4189e-05 - dense_14_loss: 8.8644e-06 - dense_15_loss: 7.0852e-06 - dense_16_loss: 7.4170e-06 - dense_17_loss: 1.0120e-05 - dense_18_loss: 9.0851e-06 - dense_19_loss: 2.1995e-05 - dense_20_loss: 6.2647e-06 - dense_21_loss: 6.7475e-06 - dense_22_loss: 5.7854e-06 - val_loss: 1.6631e-04 - val_dense_7_loss: 1.2657e-05 - val_dense_8_loss: 1.7368e-05 - val_dense_9_loss: 1.3291e-05 - val_dense_10_loss: 1.0660e-05 - val_dense_11_loss: 9.6431e-06 - val_dense_12_loss: 1.5242e-05 - val_dense_13_loss: 1.3826e-05 - val_dense_14_loss: 8.3489e-06 - val_dense_15_loss: 5.0391e-06 - val_dense_16_loss: 7.3488e-06 - val_dense_17_loss: 8.4316e-06 - val_dense_18_loss: 8.0687e-06 - val_dense_19_loss: 2.0140e-05 - val_dense_20_loss: 6.2628e-06 - val_dense_21_loss: 5.5151e-06 - val_dense_22_loss: 4.4703e-06\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 3s 766ms/step - loss: 1.6714e-04 - dense_7_loss: 1.2763e-05 - dense_8_loss: 1.7427e-05 - dense_9_loss: 1.3376e-05 - dense_10_loss: 1.0633e-05 - dense_11_loss: 9.6343e-06 - dense_12_loss: 1.5422e-05 - dense_13_loss: 1.3894e-05 - dense_14_loss: 8.3328e-06 - dense_15_loss: 5.4307e-06 - dense_16_loss: 7.4579e-06 - dense_17_loss: 8.1920e-06 - dense_18_loss: 8.0001e-06 - dense_19_loss: 2.0575e-05 - dense_20_loss: 6.1765e-06 - dense_21_loss: 5.4798e-06 - dense_22_loss: 4.3433e-06 - val_loss: 1.5267e-04 - val_dense_7_loss: 1.1360e-05 - val_dense_8_loss: 1.6303e-05 - val_dense_9_loss: 1.2422e-05 - val_dense_10_loss: 9.6477e-06 - val_dense_11_loss: 8.8476e-06 - val_dense_12_loss: 1.4413e-05 - val_dense_13_loss: 1.3723e-05 - val_dense_14_loss: 7.0413e-06 - val_dense_15_loss: 5.6630e-06 - val_dense_16_loss: 7.1874e-06 - val_dense_17_loss: 6.6449e-06 - val_dense_18_loss: 6.6041e-06 - val_dense_19_loss: 1.9770e-05 - val_dense_20_loss: 4.8797e-06 - val_dense_21_loss: 4.6758e-06 - val_dense_22_loss: 3.4874e-06\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 2s 701ms/step - loss: 1.5320e-04 - dense_7_loss: 1.1522e-05 - dense_8_loss: 1.6400e-05 - dense_9_loss: 1.2580e-05 - dense_10_loss: 9.5281e-06 - dense_11_loss: 8.8847e-06 - dense_12_loss: 1.4534e-05 - dense_13_loss: 1.3767e-05 - dense_14_loss: 6.9712e-06 - dense_15_loss: 5.9728e-06 - dense_16_loss: 7.2911e-06 - dense_17_loss: 6.4693e-06 - dense_18_loss: 6.5702e-06 - dense_19_loss: 2.0143e-05 - dense_20_loss: 4.6479e-06 - dense_21_loss: 4.5064e-06 - dense_22_loss: 3.4102e-06 - val_loss: 1.3791e-04 - val_dense_7_loss: 1.0674e-05 - val_dense_8_loss: 1.5037e-05 - val_dense_9_loss: 1.2332e-05 - val_dense_10_loss: 7.6713e-06 - val_dense_11_loss: 8.1522e-06 - val_dense_12_loss: 1.3199e-05 - val_dense_13_loss: 1.2887e-05 - val_dense_14_loss: 5.8522e-06 - val_dense_15_loss: 4.5442e-06 - val_dense_16_loss: 6.5472e-06 - val_dense_17_loss: 6.1910e-06 - val_dense_18_loss: 5.7186e-06 - val_dense_19_loss: 1.9390e-05 - val_dense_20_loss: 2.9574e-06 - val_dense_21_loss: 3.5551e-06 - val_dense_22_loss: 3.1963e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500\n",
      "2/2 [==============================] - 2s 768ms/step - loss: 1.3858e-04 - dense_7_loss: 1.0893e-05 - dense_8_loss: 1.5178e-05 - dense_9_loss: 1.2509e-05 - dense_10_loss: 7.5679e-06 - dense_11_loss: 8.2200e-06 - dense_12_loss: 1.3360e-05 - dense_13_loss: 1.2869e-05 - dense_14_loss: 5.8443e-06 - dense_15_loss: 4.8281e-06 - dense_16_loss: 6.5840e-06 - dense_17_loss: 6.0119e-06 - dense_18_loss: 5.7018e-06 - dense_19_loss: 1.9749e-05 - dense_20_loss: 2.7970e-06 - dense_21_loss: 3.3851e-06 - dense_22_loss: 3.0788e-06 - val_loss: 1.2715e-04 - val_dense_7_loss: 1.0333e-05 - val_dense_8_loss: 1.4424e-05 - val_dense_9_loss: 1.2104e-05 - val_dense_10_loss: 6.3374e-06 - val_dense_11_loss: 7.6517e-06 - val_dense_12_loss: 1.2780e-05 - val_dense_13_loss: 1.1382e-05 - val_dense_14_loss: 5.1238e-06 - val_dense_15_loss: 3.7932e-06 - val_dense_16_loss: 5.3746e-06 - val_dense_17_loss: 5.7641e-06 - val_dense_18_loss: 5.1425e-06 - val_dense_19_loss: 1.8604e-05 - val_dense_20_loss: 2.6367e-06 - val_dense_21_loss: 2.9372e-06 - val_dense_22_loss: 2.7647e-06\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 2s 707ms/step - loss: 1.2831e-04 - dense_7_loss: 1.0551e-05 - dense_8_loss: 1.4561e-05 - dense_9_loss: 1.2240e-05 - dense_10_loss: 6.3478e-06 - dense_11_loss: 7.7411e-06 - dense_12_loss: 1.2976e-05 - dense_13_loss: 1.1443e-05 - dense_14_loss: 5.2083e-06 - dense_15_loss: 4.0552e-06 - dense_16_loss: 5.4460e-06 - dense_17_loss: 5.6305e-06 - dense_18_loss: 5.1699e-06 - dense_19_loss: 1.8903e-05 - dense_20_loss: 2.5551e-06 - dense_21_loss: 2.8314e-06 - dense_22_loss: 2.6519e-06 - val_loss: 1.2232e-04 - val_dense_7_loss: 9.9421e-06 - val_dense_8_loss: 1.3956e-05 - val_dense_9_loss: 1.1382e-05 - val_dense_10_loss: 6.4294e-06 - val_dense_11_loss: 7.3200e-06 - val_dense_12_loss: 1.2784e-05 - val_dense_13_loss: 1.0978e-05 - val_dense_14_loss: 5.3473e-06 - val_dense_15_loss: 3.0173e-06 - val_dense_16_loss: 4.8074e-06 - val_dense_17_loss: 5.7323e-06 - val_dense_18_loss: 5.0969e-06 - val_dense_19_loss: 1.7762e-05 - val_dense_20_loss: 2.7700e-06 - val_dense_21_loss: 2.6825e-06 - val_dense_22_loss: 2.3162e-06\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 2s 710ms/step - loss: 1.2369e-04 - dense_7_loss: 1.0137e-05 - dense_8_loss: 1.4096e-05 - dense_9_loss: 1.1504e-05 - dense_10_loss: 6.4480e-06 - dense_11_loss: 7.3661e-06 - dense_12_loss: 1.2976e-05 - dense_13_loss: 1.1047e-05 - dense_14_loss: 5.3757e-06 - dense_15_loss: 3.3578e-06 - dense_16_loss: 4.9093e-06 - dense_17_loss: 5.5620e-06 - dense_18_loss: 5.1312e-06 - dense_19_loss: 1.8170e-05 - dense_20_loss: 2.6883e-06 - dense_21_loss: 2.6283e-06 - dense_22_loss: 2.2933e-06 - val_loss: 1.1854e-04 - val_dense_7_loss: 9.4354e-06 - val_dense_8_loss: 1.3734e-05 - val_dense_9_loss: 1.0803e-05 - val_dense_10_loss: 6.5842e-06 - val_dense_11_loss: 6.6851e-06 - val_dense_12_loss: 1.2463e-05 - val_dense_13_loss: 1.0837e-05 - val_dense_14_loss: 5.2769e-06 - val_dense_15_loss: 2.8274e-06 - val_dense_16_loss: 4.7932e-06 - val_dense_17_loss: 5.2133e-06 - val_dense_18_loss: 4.9902e-06 - val_dense_19_loss: 1.7539e-05 - val_dense_20_loss: 2.5094e-06 - val_dense_21_loss: 2.5553e-06 - val_dense_22_loss: 2.2903e-06\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 2s 711ms/step - loss: 1.1963e-04 - dense_7_loss: 9.6314e-06 - dense_8_loss: 1.3886e-05 - dense_9_loss: 1.0972e-05 - dense_10_loss: 6.5764e-06 - dense_11_loss: 6.7464e-06 - dense_12_loss: 1.2607e-05 - dense_13_loss: 1.0953e-05 - dense_14_loss: 5.2866e-06 - dense_15_loss: 3.1662e-06 - dense_16_loss: 4.9122e-06 - dense_17_loss: 5.0234e-06 - dense_18_loss: 4.9892e-06 - dense_19_loss: 1.7869e-05 - dense_20_loss: 2.3849e-06 - dense_21_loss: 2.4359e-06 - dense_22_loss: 2.1878e-06 - val_loss: 1.1257e-04 - val_dense_7_loss: 9.0202e-06 - val_dense_8_loss: 1.3511e-05 - val_dense_9_loss: 1.0663e-05 - val_dense_10_loss: 6.1904e-06 - val_dense_11_loss: 6.4130e-06 - val_dense_12_loss: 1.1715e-05 - val_dense_13_loss: 1.0693e-05 - val_dense_14_loss: 4.5632e-06 - val_dense_15_loss: 2.5574e-06 - val_dense_16_loss: 4.7776e-06 - val_dense_17_loss: 4.5633e-06 - val_dense_18_loss: 4.3767e-06 - val_dense_19_loss: 1.7552e-05 - val_dense_20_loss: 2.0429e-06 - val_dense_21_loss: 2.0459e-06 - val_dense_22_loss: 1.8833e-06\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 2s 716ms/step - loss: 1.1361e-04 - dense_7_loss: 9.2337e-06 - dense_8_loss: 1.3663e-05 - dense_9_loss: 1.0858e-05 - dense_10_loss: 6.1566e-06 - dense_11_loss: 6.4679e-06 - dense_12_loss: 1.1881e-05 - dense_13_loss: 1.0797e-05 - dense_14_loss: 4.5482e-06 - dense_15_loss: 2.8957e-06 - dense_16_loss: 4.8696e-06 - dense_17_loss: 4.3965e-06 - dense_18_loss: 4.3786e-06 - dense_19_loss: 1.7839e-05 - dense_20_loss: 1.9341e-06 - dense_21_loss: 1.9166e-06 - dense_22_loss: 1.7712e-06 - val_loss: 1.0777e-04 - val_dense_7_loss: 8.9749e-06 - val_dense_8_loss: 1.3296e-05 - val_dense_9_loss: 1.0723e-05 - val_dense_10_loss: 5.6103e-06 - val_dense_11_loss: 6.2244e-06 - val_dense_12_loss: 1.1416e-05 - val_dense_13_loss: 1.0418e-05 - val_dense_14_loss: 3.8492e-06 - val_dense_15_loss: 2.4738e-06 - val_dense_16_loss: 4.4903e-06 - val_dense_17_loss: 4.2686e-06 - val_dense_18_loss: 3.9921e-06 - val_dense_19_loss: 1.7201e-05 - val_dense_20_loss: 1.8584e-06 - val_dense_21_loss: 1.5864e-06 - val_dense_22_loss: 1.3883e-06\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 2s 714ms/step - loss: 1.0898e-04 - dense_7_loss: 9.1920e-06 - dense_8_loss: 1.3423e-05 - dense_9_loss: 1.0896e-05 - dense_10_loss: 5.5828e-06 - dense_11_loss: 6.2670e-06 - dense_12_loss: 1.1623e-05 - dense_13_loss: 1.0502e-05 - dense_14_loss: 3.8941e-06 - dense_15_loss: 2.7789e-06 - dense_16_loss: 4.5684e-06 - dense_17_loss: 4.1313e-06 - dense_18_loss: 4.0076e-06 - dense_19_loss: 1.7505e-05 - dense_20_loss: 1.7657e-06 - dense_21_loss: 1.5045e-06 - dense_22_loss: 1.3365e-06 - val_loss: 1.0459e-04 - val_dense_7_loss: 8.8339e-06 - val_dense_8_loss: 1.2842e-05 - val_dense_9_loss: 1.0304e-05 - val_dense_10_loss: 5.2627e-06 - val_dense_11_loss: 5.9840e-06 - val_dense_12_loss: 1.1441e-05 - val_dense_13_loss: 9.9387e-06 - val_dense_14_loss: 3.8507e-06 - val_dense_15_loss: 2.1700e-06 - val_dense_16_loss: 4.0956e-06 - val_dense_17_loss: 4.2247e-06 - val_dense_18_loss: 3.9296e-06 - val_dense_19_loss: 1.6863e-05 - val_dense_20_loss: 1.7603e-06 - val_dense_21_loss: 1.6245e-06 - val_dense_22_loss: 1.4703e-06\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 2s 780ms/step - loss: 1.0590e-04 - dense_7_loss: 9.0411e-06 - dense_8_loss: 1.2989e-05 - dense_9_loss: 1.0463e-05 - dense_10_loss: 5.2693e-06 - dense_11_loss: 6.0445e-06 - dense_12_loss: 1.1641e-05 - dense_13_loss: 1.0022e-05 - dense_14_loss: 3.9059e-06 - dense_15_loss: 2.5035e-06 - dense_16_loss: 4.1924e-06 - dense_17_loss: 4.0912e-06 - dense_18_loss: 3.9650e-06 - dense_19_loss: 1.7160e-05 - dense_20_loss: 1.6611e-06 - dense_21_loss: 1.5405e-06 - dense_22_loss: 1.4074e-06 - val_loss: 1.0250e-04 - val_dense_7_loss: 8.5841e-06 - val_dense_8_loss: 1.2641e-05 - val_dense_9_loss: 9.8508e-06 - val_dense_10_loss: 5.2738e-06 - val_dense_11_loss: 5.8840e-06 - val_dense_12_loss: 1.1275e-05 - val_dense_13_loss: 9.7130e-06 - val_dense_14_loss: 4.0168e-06 - val_dense_15_loss: 1.9844e-06 - val_dense_16_loss: 3.9439e-06 - val_dense_17_loss: 4.1699e-06 - val_dense_18_loss: 4.0231e-06 - val_dense_19_loss: 1.6522e-05 - val_dense_20_loss: 1.5346e-06 - val_dense_21_loss: 1.6434e-06 - val_dense_22_loss: 1.4452e-06\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 2s 778ms/step - loss: 1.0381e-04 - dense_7_loss: 8.7839e-06 - dense_8_loss: 1.2803e-05 - dense_9_loss: 1.0041e-05 - dense_10_loss: 5.2889e-06 - dense_11_loss: 5.9512e-06 - dense_12_loss: 1.1467e-05 - dense_13_loss: 9.8031e-06 - dense_14_loss: 4.0501e-06 - dense_15_loss: 2.3211e-06 - dense_16_loss: 4.0569e-06 - dense_17_loss: 4.0305e-06 - dense_18_loss: 4.0478e-06 - dense_19_loss: 1.6831e-05 - dense_20_loss: 1.4330e-06 - dense_21_loss: 1.5424e-06 - dense_22_loss: 1.3615e-06 - val_loss: 1.0052e-04 - val_dense_7_loss: 8.3366e-06 - val_dense_8_loss: 1.2614e-05 - val_dense_9_loss: 9.9259e-06 - val_dense_10_loss: 5.2812e-06 - val_dense_11_loss: 5.7436e-06 - val_dense_12_loss: 1.1072e-05 - val_dense_13_loss: 9.6666e-06 - val_dense_14_loss: 3.8063e-06 - val_dense_15_loss: 1.8781e-06 - val_dense_16_loss: 3.9212e-06 - val_dense_17_loss: 3.9996e-06 - val_dense_18_loss: 3.9127e-06 - val_dense_19_loss: 1.6292e-05 - val_dense_20_loss: 1.4005e-06 - val_dense_21_loss: 1.4569e-06 - val_dense_22_loss: 1.2120e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "2/2 [==============================] - 3s 717ms/step - loss: 1.0186e-04 - dense_7_loss: 8.5513e-06 - dense_8_loss: 1.2784e-05 - dense_9_loss: 1.0123e-05 - dense_10_loss: 5.2801e-06 - dense_11_loss: 5.8160e-06 - dense_12_loss: 1.1271e-05 - dense_13_loss: 9.7696e-06 - dense_14_loss: 3.8275e-06 - dense_15_loss: 2.2180e-06 - dense_16_loss: 4.0377e-06 - dense_17_loss: 3.8523e-06 - dense_18_loss: 3.9201e-06 - dense_19_loss: 1.6637e-05 - dense_20_loss: 1.3059e-06 - dense_21_loss: 1.3419e-06 - dense_22_loss: 1.1272e-06 - val_loss: 9.8852e-05 - val_dense_7_loss: 8.2837e-06 - val_dense_8_loss: 1.2600e-05 - val_dense_9_loss: 1.0002e-05 - val_dense_10_loss: 5.0838e-06 - val_dense_11_loss: 5.5920e-06 - val_dense_12_loss: 1.0947e-05 - val_dense_13_loss: 9.6936e-06 - val_dense_14_loss: 3.4982e-06 - val_dense_15_loss: 1.7942e-06 - val_dense_16_loss: 3.8864e-06 - val_dense_17_loss: 3.7941e-06 - val_dense_18_loss: 3.6684e-06 - val_dense_19_loss: 1.6229e-05 - val_dense_20_loss: 1.3855e-06 - val_dense_21_loss: 1.2745e-06 - val_dense_22_loss: 1.1185e-06\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 2s 714ms/step - loss: 1.0019e-04 - dense_7_loss: 8.5004e-06 - dense_8_loss: 1.2759e-05 - dense_9_loss: 1.0173e-05 - dense_10_loss: 5.0825e-06 - dense_11_loss: 5.6713e-06 - dense_12_loss: 1.1143e-05 - dense_13_loss: 9.7775e-06 - dense_14_loss: 3.5246e-06 - dense_15_loss: 2.1399e-06 - dense_16_loss: 3.9939e-06 - dense_17_loss: 3.6489e-06 - dense_18_loss: 3.6879e-06 - dense_19_loss: 1.6580e-05 - dense_20_loss: 1.2881e-06 - dense_21_loss: 1.1761e-06 - dense_22_loss: 1.0446e-06 - val_loss: 9.7340e-05 - val_dense_7_loss: 8.2841e-06 - val_dense_8_loss: 1.2464e-05 - val_dense_9_loss: 9.8144e-06 - val_dense_10_loss: 4.9325e-06 - val_dense_11_loss: 5.5502e-06 - val_dense_12_loss: 1.0818e-05 - val_dense_13_loss: 9.4914e-06 - val_dense_14_loss: 3.3102e-06 - val_dense_15_loss: 1.7856e-06 - val_dense_16_loss: 3.7602e-06 - val_dense_17_loss: 3.6722e-06 - val_dense_18_loss: 3.5766e-06 - val_dense_19_loss: 1.6151e-05 - val_dense_20_loss: 1.3553e-06 - val_dense_21_loss: 1.2590e-06 - val_dense_22_loss: 1.1153e-06\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 2s 711ms/step - loss: 9.8707e-05 - dense_7_loss: 8.4935e-06 - dense_8_loss: 1.2612e-05 - dense_9_loss: 9.9728e-06 - dense_10_loss: 4.9340e-06 - dense_11_loss: 5.6283e-06 - dense_12_loss: 1.1014e-05 - dense_13_loss: 9.5746e-06 - dense_14_loss: 3.3634e-06 - dense_15_loss: 2.1206e-06 - dense_16_loss: 3.8645e-06 - dense_17_loss: 3.5393e-06 - dense_18_loss: 3.6127e-06 - dense_19_loss: 1.6492e-05 - dense_20_loss: 1.2601e-06 - dense_21_loss: 1.1715e-06 - dense_22_loss: 1.0533e-06 - val_loss: 9.6128e-05 - val_dense_7_loss: 8.1856e-06 - val_dense_8_loss: 1.2285e-05 - val_dense_9_loss: 9.6069e-06 - val_dense_10_loss: 4.8471e-06 - val_dense_11_loss: 5.4995e-06 - val_dense_12_loss: 1.0743e-05 - val_dense_13_loss: 9.3041e-06 - val_dense_14_loss: 3.3831e-06 - val_dense_15_loss: 1.7064e-06 - val_dense_16_loss: 3.6504e-06 - val_dense_17_loss: 3.6833e-06 - val_dense_18_loss: 3.6266e-06 - val_dense_19_loss: 1.5978e-05 - val_dense_20_loss: 1.3010e-06 - val_dense_21_loss: 1.2148e-06 - val_dense_22_loss: 1.1130e-06\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 2s 712ms/step - loss: 9.7474e-05 - dense_7_loss: 8.3940e-06 - dense_8_loss: 1.2441e-05 - dense_9_loss: 9.7776e-06 - dense_10_loss: 4.8524e-06 - dense_11_loss: 5.5690e-06 - dense_12_loss: 1.0938e-05 - dense_13_loss: 9.4000e-06 - dense_14_loss: 3.4314e-06 - dense_15_loss: 2.0421e-06 - dense_16_loss: 3.7565e-06 - dense_17_loss: 3.5460e-06 - dense_18_loss: 3.6587e-06 - dense_19_loss: 1.6313e-05 - dense_20_loss: 1.2003e-06 - dense_21_loss: 1.1168e-06 - dense_22_loss: 1.0379e-06 - val_loss: 9.4988e-05 - val_dense_7_loss: 8.0596e-06 - val_dense_8_loss: 1.2206e-05 - val_dense_9_loss: 9.5776e-06 - val_dense_10_loss: 4.8110e-06 - val_dense_11_loss: 5.4229e-06 - val_dense_12_loss: 1.0695e-05 - val_dense_13_loss: 9.2867e-06 - val_dense_14_loss: 3.3694e-06 - val_dense_15_loss: 1.6048e-06 - val_dense_16_loss: 3.5889e-06 - val_dense_17_loss: 3.6782e-06 - val_dense_18_loss: 3.5869e-06 - val_dense_19_loss: 1.5819e-05 - val_dense_20_loss: 1.1676e-06 - val_dense_21_loss: 1.0981e-06 - val_dense_22_loss: 1.0165e-06\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 2s 729ms/step - loss: 9.6373e-05 - dense_7_loss: 8.2799e-06 - dense_8_loss: 1.2371e-05 - dense_9_loss: 9.7608e-06 - dense_10_loss: 4.8132e-06 - dense_11_loss: 5.4943e-06 - dense_12_loss: 1.0891e-05 - dense_13_loss: 9.3839e-06 - dense_14_loss: 3.4057e-06 - dense_15_loss: 1.9465e-06 - dense_16_loss: 3.6964e-06 - dense_17_loss: 3.5324e-06 - dense_18_loss: 3.6123e-06 - dense_19_loss: 1.6165e-05 - dense_20_loss: 1.0701e-06 - dense_21_loss: 1.0064e-06 - dense_22_loss: 9.4345e-07 - val_loss: 9.4280e-05 - val_dense_7_loss: 8.0036e-06 - val_dense_8_loss: 1.2201e-05 - val_dense_9_loss: 9.6243e-06 - val_dense_10_loss: 4.7675e-06 - val_dense_11_loss: 5.4042e-06 - val_dense_12_loss: 1.0648e-05 - val_dense_13_loss: 9.2464e-06 - val_dense_14_loss: 3.2288e-06 - val_dense_15_loss: 1.5677e-06 - val_dense_16_loss: 3.5740e-06 - val_dense_17_loss: 3.5934e-06 - val_dense_18_loss: 3.5093e-06 - val_dense_19_loss: 1.5775e-05 - val_dense_20_loss: 1.0908e-06 - val_dense_21_loss: 1.0675e-06 - val_dense_22_loss: 9.7847e-07\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 2s 719ms/step - loss: 9.5671e-05 - dense_7_loss: 8.2309e-06 - dense_8_loss: 1.2362e-05 - dense_9_loss: 9.8036e-06 - dense_10_loss: 4.7673e-06 - dense_11_loss: 5.4783e-06 - dense_12_loss: 1.0843e-05 - dense_13_loss: 9.3376e-06 - dense_14_loss: 3.2686e-06 - dense_15_loss: 1.9085e-06 - dense_16_loss: 3.6830e-06 - dense_17_loss: 3.4492e-06 - dense_18_loss: 3.5371e-06 - dense_19_loss: 1.6113e-05 - dense_20_loss: 9.9965e-07 - dense_21_loss: 9.8099e-07 - dense_22_loss: 9.0846e-07 - val_loss: 9.3635e-05 - val_dense_7_loss: 7.9929e-06 - val_dense_8_loss: 1.2138e-05 - val_dense_9_loss: 9.5381e-06 - val_dense_10_loss: 4.7031e-06 - val_dense_11_loss: 5.3674e-06 - val_dense_12_loss: 1.0580e-05 - val_dense_13_loss: 9.1313e-06 - val_dense_14_loss: 3.1580e-06 - val_dense_15_loss: 1.5416e-06 - val_dense_16_loss: 3.5763e-06 - val_dense_17_loss: 3.5322e-06 - val_dense_18_loss: 3.4791e-06 - val_dense_19_loss: 1.5731e-05 - val_dense_20_loss: 1.1196e-06 - val_dense_21_loss: 1.0762e-06 - val_dense_22_loss: 9.7020e-07\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 2s 711ms/step - loss: 9.5014e-05 - dense_7_loss: 8.2150e-06 - dense_8_loss: 1.2294e-05 - dense_9_loss: 9.7160e-06 - dense_10_loss: 4.7050e-06 - dense_11_loss: 5.4408e-06 - dense_12_loss: 1.0773e-05 - dense_13_loss: 9.2254e-06 - dense_14_loss: 3.2024e-06 - dense_15_loss: 1.8849e-06 - dense_16_loss: 3.6845e-06 - dense_17_loss: 3.3924e-06 - dense_18_loss: 3.5055e-06 - dense_19_loss: 1.6061e-05 - dense_20_loss: 1.0299e-06 - dense_21_loss: 9.8399e-07 - dense_22_loss: 9.0056e-07 - val_loss: 9.3020e-05 - val_dense_7_loss: 7.9636e-06 - val_dense_8_loss: 1.2060e-05 - val_dense_9_loss: 9.4130e-06 - val_dense_10_loss: 4.6636e-06 - val_dense_11_loss: 5.3195e-06 - val_dense_12_loss: 1.0520e-05 - val_dense_13_loss: 9.0796e-06 - val_dense_14_loss: 3.1642e-06 - val_dense_15_loss: 1.5154e-06 - val_dense_16_loss: 3.5118e-06 - val_dense_17_loss: 3.5090e-06 - val_dense_18_loss: 3.4524e-06 - val_dense_19_loss: 1.5722e-05 - val_dense_20_loss: 1.1240e-06 - val_dense_21_loss: 1.0389e-06 - val_dense_22_loss: 9.6301e-07\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 2s 708ms/step - loss: 9.4409e-05 - dense_7_loss: 8.1764e-06 - dense_8_loss: 1.2215e-05 - dense_9_loss: 9.5974e-06 - dense_10_loss: 4.6666e-06 - dense_11_loss: 5.3937e-06 - dense_12_loss: 1.0712e-05 - dense_13_loss: 9.1754e-06 - dense_14_loss: 3.2069e-06 - dense_15_loss: 1.8650e-06 - dense_16_loss: 3.6208e-06 - dense_17_loss: 3.3750e-06 - dense_18_loss: 3.4823e-06 - dense_19_loss: 1.6037e-05 - dense_20_loss: 1.0363e-06 - dense_21_loss: 9.5045e-07 - dense_22_loss: 8.9860e-07 - val_loss: 9.3042e-05 - val_dense_7_loss: 7.9426e-06 - val_dense_8_loss: 1.2035e-05 - val_dense_9_loss: 9.4175e-06 - val_dense_10_loss: 4.6374e-06 - val_dense_11_loss: 5.3093e-06 - val_dense_12_loss: 1.0478e-05 - val_dense_13_loss: 9.0962e-06 - val_dense_14_loss: 3.1664e-06 - val_dense_15_loss: 1.4954e-06 - val_dense_16_loss: 3.4789e-06 - val_dense_17_loss: 3.5324e-06 - val_dense_18_loss: 3.4646e-06 - val_dense_19_loss: 1.5702e-05 - val_dense_20_loss: 1.1430e-06 - val_dense_21_loss: 1.0909e-06 - val_dense_22_loss: 1.0524e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500\n",
      "2/2 [==============================] - 2s 704ms/step - loss: 9.4391e-05 - dense_7_loss: 8.1416e-06 - dense_8_loss: 1.2184e-05 - dense_9_loss: 9.5964e-06 - dense_10_loss: 4.6409e-06 - dense_11_loss: 5.3816e-06 - dense_12_loss: 1.0668e-05 - dense_13_loss: 9.1790e-06 - dense_14_loss: 3.2090e-06 - dense_15_loss: 1.8474e-06 - dense_16_loss: 3.5910e-06 - dense_17_loss: 3.4023e-06 - dense_18_loss: 3.4987e-06 - dense_19_loss: 1.6007e-05 - dense_20_loss: 1.0542e-06 - dense_21_loss: 1.0060e-06 - dense_22_loss: 9.8335e-07 - val_loss: 9.2407e-05 - val_dense_7_loss: 7.8845e-06 - val_dense_8_loss: 1.1981e-05 - val_dense_9_loss: 9.4139e-06 - val_dense_10_loss: 4.6012e-06 - val_dense_11_loss: 5.2912e-06 - val_dense_12_loss: 1.0449e-05 - val_dense_13_loss: 9.0273e-06 - val_dense_14_loss: 3.1183e-06 - val_dense_15_loss: 1.4738e-06 - val_dense_16_loss: 3.4770e-06 - val_dense_17_loss: 3.5098e-06 - val_dense_18_loss: 3.4501e-06 - val_dense_19_loss: 1.5616e-05 - val_dense_20_loss: 1.0903e-06 - val_dense_21_loss: 1.0370e-06 - val_dense_22_loss: 9.8651e-07\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 2s 720ms/step - loss: 9.3706e-05 - dense_7_loss: 8.0852e-06 - dense_8_loss: 1.2123e-05 - dense_9_loss: 9.5858e-06 - dense_10_loss: 4.6027e-06 - dense_11_loss: 5.3600e-06 - dense_12_loss: 1.0640e-05 - dense_13_loss: 9.1108e-06 - dense_14_loss: 3.1592e-06 - dense_15_loss: 1.8188e-06 - dense_16_loss: 3.5877e-06 - dense_17_loss: 3.3769e-06 - dense_18_loss: 3.4809e-06 - dense_19_loss: 1.5917e-05 - dense_20_loss: 9.9649e-07 - dense_21_loss: 9.4773e-07 - dense_22_loss: 9.1483e-07 - val_loss: 9.1463e-05 - val_dense_7_loss: 7.8187e-06 - val_dense_8_loss: 1.1879e-05 - val_dense_9_loss: 9.3509e-06 - val_dense_10_loss: 4.5476e-06 - val_dense_11_loss: 5.2469e-06 - val_dense_12_loss: 1.0384e-05 - val_dense_13_loss: 8.9288e-06 - val_dense_14_loss: 3.0748e-06 - val_dense_15_loss: 1.4522e-06 - val_dense_16_loss: 3.4582e-06 - val_dense_17_loss: 3.4804e-06 - val_dense_18_loss: 3.4235e-06 - val_dense_19_loss: 1.5466e-05 - val_dense_20_loss: 1.0457e-06 - val_dense_21_loss: 9.8503e-07 - val_dense_22_loss: 9.2166e-07\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 2s 766ms/step - loss: 9.2839e-05 - dense_7_loss: 8.0341e-06 - dense_8_loss: 1.2034e-05 - dense_9_loss: 9.5253e-06 - dense_10_loss: 4.5541e-06 - dense_11_loss: 5.3187e-06 - dense_12_loss: 1.0579e-05 - dense_13_loss: 9.0228e-06 - dense_14_loss: 3.1158e-06 - dense_15_loss: 1.7987e-06 - dense_16_loss: 3.5705e-06 - dense_17_loss: 3.3452e-06 - dense_18_loss: 3.4495e-06 - dense_19_loss: 1.5792e-05 - dense_20_loss: 9.5283e-07 - dense_21_loss: 8.9413e-07 - dense_22_loss: 8.5287e-07 - val_loss: 9.1294e-05 - val_dense_7_loss: 7.7980e-06 - val_dense_8_loss: 1.1812e-05 - val_dense_9_loss: 9.2918e-06 - val_dense_10_loss: 4.5385e-06 - val_dense_11_loss: 5.2174e-06 - val_dense_12_loss: 1.0323e-05 - val_dense_13_loss: 8.8933e-06 - val_dense_14_loss: 3.0693e-06 - val_dense_15_loss: 1.4640e-06 - val_dense_16_loss: 3.4353e-06 - val_dense_17_loss: 3.4841e-06 - val_dense_18_loss: 3.4278e-06 - val_dense_19_loss: 1.5412e-05 - val_dense_20_loss: 1.0870e-06 - val_dense_21_loss: 1.0487e-06 - val_dense_22_loss: 9.9217e-07\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 2s 776ms/step - loss: 9.2698e-05 - dense_7_loss: 8.0224e-06 - dense_8_loss: 1.1976e-05 - dense_9_loss: 9.4689e-06 - dense_10_loss: 4.5449e-06 - dense_11_loss: 5.2941e-06 - dense_12_loss: 1.0520e-05 - dense_13_loss: 8.9858e-06 - dense_14_loss: 3.1108e-06 - dense_15_loss: 1.8149e-06 - dense_16_loss: 3.5491e-06 - dense_17_loss: 3.3469e-06 - dense_18_loss: 3.4531e-06 - dense_19_loss: 1.5754e-05 - dense_20_loss: 9.9146e-07 - dense_21_loss: 9.4856e-07 - dense_22_loss: 9.1631e-07 - val_loss: 9.1056e-05 - val_dense_7_loss: 7.7621e-06 - val_dense_8_loss: 1.1762e-05 - val_dense_9_loss: 9.2493e-06 - val_dense_10_loss: 4.5187e-06 - val_dense_11_loss: 5.2045e-06 - val_dense_12_loss: 1.0271e-05 - val_dense_13_loss: 8.8615e-06 - val_dense_14_loss: 3.0599e-06 - val_dense_15_loss: 1.4634e-06 - val_dense_16_loss: 3.4220e-06 - val_dense_17_loss: 3.4862e-06 - val_dense_18_loss: 3.4302e-06 - val_dense_19_loss: 1.5362e-05 - val_dense_20_loss: 1.1068e-06 - val_dense_21_loss: 1.0702e-06 - val_dense_22_loss: 1.0270e-06\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 2s 788ms/step - loss: 9.2418e-05 - dense_7_loss: 7.9822e-06 - dense_8_loss: 1.1922e-05 - dense_9_loss: 9.4249e-06 - dense_10_loss: 4.5214e-06 - dense_11_loss: 5.2808e-06 - dense_12_loss: 1.0467e-05 - dense_13_loss: 8.9480e-06 - dense_14_loss: 3.1019e-06 - dense_15_loss: 1.8124e-06 - dense_16_loss: 3.5329e-06 - dense_17_loss: 3.3480e-06 - dense_18_loss: 3.4585e-06 - dense_19_loss: 1.5700e-05 - dense_20_loss: 1.0076e-06 - dense_21_loss: 9.6693e-07 - dense_22_loss: 9.4402e-07 - val_loss: 9.0297e-05 - val_dense_7_loss: 7.7001e-06 - val_dense_8_loss: 1.1692e-05 - val_dense_9_loss: 9.1986e-06 - val_dense_10_loss: 4.4725e-06 - val_dense_11_loss: 5.1779e-06 - val_dense_12_loss: 1.0210e-05 - val_dense_13_loss: 8.8001e-06 - val_dense_14_loss: 3.0256e-06 - val_dense_15_loss: 1.4367e-06 - val_dense_16_loss: 3.4024e-06 - val_dense_17_loss: 3.4745e-06 - val_dense_18_loss: 3.4073e-06 - val_dense_19_loss: 1.5285e-05 - val_dense_20_loss: 1.0641e-06 - val_dense_21_loss: 9.9953e-07 - val_dense_22_loss: 9.5039e-07\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 2s 718ms/step - loss: 9.1642e-05 - dense_7_loss: 7.9172e-06 - dense_8_loss: 1.1846e-05 - dense_9_loss: 9.3739e-06 - dense_10_loss: 4.4759e-06 - dense_11_loss: 5.2513e-06 - dense_12_loss: 1.0404e-05 - dense_13_loss: 8.8858e-06 - dense_14_loss: 3.0675e-06 - dense_15_loss: 1.7817e-06 - dense_16_loss: 3.5116e-06 - dense_17_loss: 3.3361e-06 - dense_18_loss: 3.4365e-06 - dense_19_loss: 1.5618e-05 - dense_20_loss: 9.6578e-07 - dense_21_loss: 8.9978e-07 - dense_22_loss: 8.7053e-07 - val_loss: 8.9714e-05 - val_dense_7_loss: 7.6696e-06 - val_dense_8_loss: 1.1607e-05 - val_dense_9_loss: 9.1391e-06 - val_dense_10_loss: 4.4443e-06 - val_dense_11_loss: 5.1481e-06 - val_dense_12_loss: 1.0151e-05 - val_dense_13_loss: 8.7192e-06 - val_dense_14_loss: 3.0071e-06 - val_dense_15_loss: 1.4328e-06 - val_dense_16_loss: 3.3859e-06 - val_dense_17_loss: 3.4703e-06 - val_dense_18_loss: 3.4010e-06 - val_dense_19_loss: 1.5219e-05 - val_dense_20_loss: 1.0371e-06 - val_dense_21_loss: 9.6833e-07 - val_dense_22_loss: 9.1394e-07\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 2s 708ms/step - loss: 9.1071e-05 - dense_7_loss: 7.8791e-06 - dense_8_loss: 1.1757e-05 - dense_9_loss: 9.3144e-06 - dense_10_loss: 4.4489e-06 - dense_11_loss: 5.2191e-06 - dense_12_loss: 1.0339e-05 - dense_13_loss: 8.8071e-06 - dense_14_loss: 3.0494e-06 - dense_15_loss: 1.7782e-06 - dense_16_loss: 3.4985e-06 - dense_17_loss: 3.3343e-06 - dense_18_loss: 3.4309e-06 - dense_19_loss: 1.5539e-05 - dense_20_loss: 9.4703e-07 - dense_21_loss: 8.8012e-07 - dense_22_loss: 8.4922e-07 - val_loss: 8.9478e-05 - val_dense_7_loss: 7.6486e-06 - val_dense_8_loss: 1.1519e-05 - val_dense_9_loss: 9.0684e-06 - val_dense_10_loss: 4.4232e-06 - val_dense_11_loss: 5.1311e-06 - val_dense_12_loss: 1.0082e-05 - val_dense_13_loss: 8.6623e-06 - val_dense_14_loss: 3.0016e-06 - val_dense_15_loss: 1.4467e-06 - val_dense_16_loss: 3.3855e-06 - val_dense_17_loss: 3.4728e-06 - val_dense_18_loss: 3.4189e-06 - val_dense_19_loss: 1.5203e-05 - val_dense_20_loss: 1.0595e-06 - val_dense_21_loss: 1.0013e-06 - val_dense_22_loss: 9.5416e-07\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 2s 706ms/step - loss: 9.0831e-05 - dense_7_loss: 7.8530e-06 - dense_8_loss: 1.1665e-05 - dense_9_loss: 9.2458e-06 - dense_10_loss: 4.4283e-06 - dense_11_loss: 5.2007e-06 - dense_12_loss: 1.0266e-05 - dense_13_loss: 8.7477e-06 - dense_14_loss: 3.0446e-06 - dense_15_loss: 1.7939e-06 - dense_16_loss: 3.4983e-06 - dense_17_loss: 3.3400e-06 - dense_18_loss: 3.4492e-06 - dense_19_loss: 1.5517e-05 - dense_20_loss: 9.7184e-07 - dense_21_loss: 9.1629e-07 - dense_22_loss: 8.9383e-07 - val_loss: 8.9205e-05 - val_dense_7_loss: 7.6072e-06 - val_dense_8_loss: 1.1442e-05 - val_dense_9_loss: 9.0040e-06 - val_dense_10_loss: 4.4020e-06 - val_dense_11_loss: 5.1071e-06 - val_dense_12_loss: 1.0008e-05 - val_dense_13_loss: 8.6100e-06 - val_dense_14_loss: 2.9941e-06 - val_dense_15_loss: 1.4530e-06 - val_dense_16_loss: 3.3749e-06 - val_dense_17_loss: 3.4882e-06 - val_dense_18_loss: 3.4244e-06 - val_dense_19_loss: 1.5158e-05 - val_dense_20_loss: 1.1007e-06 - val_dense_21_loss: 1.0370e-06 - val_dense_22_loss: 9.9368e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "2/2 [==============================] - 2s 709ms/step - loss: 9.0530e-05 - dense_7_loss: 7.8092e-06 - dense_8_loss: 1.1580e-05 - dense_9_loss: 9.1761e-06 - dense_10_loss: 4.4057e-06 - dense_11_loss: 5.1757e-06 - dense_12_loss: 1.0188e-05 - dense_13_loss: 8.6905e-06 - dense_14_loss: 3.0363e-06 - dense_15_loss: 1.8025e-06 - dense_16_loss: 3.4874e-06 - dense_17_loss: 3.3559e-06 - dense_18_loss: 3.4566e-06 - dense_19_loss: 1.5467e-05 - dense_20_loss: 1.0114e-06 - dense_21_loss: 9.5332e-07 - dense_22_loss: 9.3331e-07 - val_loss: 8.8757e-05 - val_dense_7_loss: 7.5543e-06 - val_dense_8_loss: 1.1352e-05 - val_dense_9_loss: 8.9392e-06 - val_dense_10_loss: 4.3757e-06 - val_dense_11_loss: 5.0758e-06 - val_dense_12_loss: 9.9244e-06 - val_dense_13_loss: 8.5435e-06 - val_dense_14_loss: 2.9734e-06 - val_dense_15_loss: 1.4519e-06 - val_dense_16_loss: 3.3656e-06 - val_dense_17_loss: 3.5020e-06 - val_dense_18_loss: 3.4235e-06 - val_dense_19_loss: 1.5077e-05 - val_dense_20_loss: 1.1300e-06 - val_dense_21_loss: 1.0575e-06 - val_dense_22_loss: 1.0113e-06\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 2s 711ms/step - loss: 9.0048e-05 - dense_7_loss: 7.7528e-06 - dense_8_loss: 1.1483e-05 - dense_9_loss: 9.1033e-06 - dense_10_loss: 4.3780e-06 - dense_11_loss: 5.1441e-06 - dense_12_loss: 1.0102e-05 - dense_13_loss: 8.6194e-06 - dense_14_loss: 3.0167e-06 - dense_15_loss: 1.8045e-06 - dense_16_loss: 3.4766e-06 - dense_17_loss: 3.3706e-06 - dense_18_loss: 3.4588e-06 - dense_19_loss: 1.5369e-05 - dense_20_loss: 1.0417e-06 - dense_21_loss: 9.7578e-07 - dense_22_loss: 9.5371e-07 - val_loss: 8.8122e-05 - val_dense_7_loss: 7.5025e-06 - val_dense_8_loss: 1.1229e-05 - val_dense_9_loss: 8.8564e-06 - val_dense_10_loss: 4.3430e-06 - val_dense_11_loss: 5.0369e-06 - val_dense_12_loss: 9.8189e-06 - val_dense_13_loss: 8.4515e-06 - val_dense_14_loss: 2.9540e-06 - val_dense_15_loss: 1.4544e-06 - val_dense_16_loss: 3.3550e-06 - val_dense_17_loss: 3.5090e-06 - val_dense_18_loss: 3.4308e-06 - val_dense_19_loss: 1.4990e-05 - val_dense_20_loss: 1.1253e-06 - val_dense_21_loss: 1.0515e-06 - val_dense_22_loss: 1.0148e-06\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 2s 775ms/step - loss: 8.9368e-05 - dense_7_loss: 7.6959e-06 - dense_8_loss: 1.1352e-05 - dense_9_loss: 9.0108e-06 - dense_10_loss: 4.3428e-06 - dense_11_loss: 5.1016e-06 - dense_12_loss: 9.9929e-06 - dense_13_loss: 8.5232e-06 - dense_14_loss: 2.9972e-06 - dense_15_loss: 1.8078e-06 - dense_16_loss: 3.4644e-06 - dense_17_loss: 3.3783e-06 - dense_18_loss: 3.4661e-06 - dense_19_loss: 1.5265e-05 - dense_20_loss: 1.0377e-06 - dense_21_loss: 9.7218e-07 - dense_22_loss: 9.5969e-07 - val_loss: 8.7207e-05 - val_dense_7_loss: 7.4279e-06 - val_dense_8_loss: 1.1050e-05 - val_dense_9_loss: 8.7236e-06 - val_dense_10_loss: 4.2982e-06 - val_dense_11_loss: 4.9838e-06 - val_dense_12_loss: 9.6729e-06 - val_dense_13_loss: 8.3179e-06 - val_dense_14_loss: 2.9379e-06 - val_dense_15_loss: 1.4717e-06 - val_dense_16_loss: 3.3335e-06 - val_dense_17_loss: 3.5221e-06 - val_dense_18_loss: 3.4448e-06 - val_dense_19_loss: 1.4843e-05 - val_dense_20_loss: 1.1189e-06 - val_dense_21_loss: 1.0460e-06 - val_dense_22_loss: 1.0150e-06\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 2s 771ms/step - loss: 8.8490e-05 - dense_7_loss: 7.6268e-06 - dense_8_loss: 1.1176e-05 - dense_9_loss: 8.8772e-06 - dense_10_loss: 4.3000e-06 - dense_11_loss: 5.0538e-06 - dense_12_loss: 9.8513e-06 - dense_13_loss: 8.3900e-06 - dense_14_loss: 2.9806e-06 - dense_15_loss: 1.8260e-06 - dense_16_loss: 3.4424e-06 - dense_17_loss: 3.3933e-06 - dense_18_loss: 3.4807e-06 - dense_19_loss: 1.5120e-05 - dense_20_loss: 1.0382e-06 - dense_21_loss: 9.7041e-07 - dense_22_loss: 9.6328e-07 - val_loss: 8.7230e-05 - val_dense_7_loss: 7.4143e-06 - val_dense_8_loss: 1.0944e-05 - val_dense_9_loss: 8.6365e-06 - val_dense_10_loss: 4.2820e-06 - val_dense_11_loss: 4.9721e-06 - val_dense_12_loss: 9.5799e-06 - val_dense_13_loss: 8.2463e-06 - val_dense_14_loss: 2.9462e-06 - val_dense_15_loss: 1.5174e-06 - val_dense_16_loss: 3.3430e-06 - val_dense_17_loss: 3.5480e-06 - val_dense_18_loss: 3.4838e-06 - val_dense_19_loss: 1.4920e-05 - val_dense_20_loss: 1.1858e-06 - val_dense_21_loss: 1.1204e-06 - val_dense_22_loss: 1.0899e-06\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 2s 712ms/step - loss: 8.8586e-05 - dense_7_loss: 7.6065e-06 - dense_8_loss: 1.1068e-05 - dense_9_loss: 8.7930e-06 - dense_10_loss: 4.2869e-06 - dense_11_loss: 5.0421e-06 - dense_12_loss: 9.7600e-06 - dense_13_loss: 8.3191e-06 - dense_14_loss: 2.9913e-06 - dense_15_loss: 1.8752e-06 - dense_16_loss: 3.4563e-06 - dense_17_loss: 3.4273e-06 - dense_18_loss: 3.5252e-06 - dense_19_loss: 1.5183e-05 - dense_20_loss: 1.1237e-06 - dense_21_loss: 1.0680e-06 - dense_22_loss: 1.0603e-06 - val_loss: 8.9127e-05 - val_dense_7_loss: 7.4850e-06 - val_dense_8_loss: 1.0883e-05 - val_dense_9_loss: 8.6002e-06 - val_dense_10_loss: 4.2947e-06 - val_dense_11_loss: 5.0287e-06 - val_dense_12_loss: 9.5427e-06 - val_dense_13_loss: 8.2269e-06 - val_dense_14_loss: 3.0249e-06 - val_dense_15_loss: 1.6655e-06 - val_dense_16_loss: 3.4208e-06 - val_dense_17_loss: 3.6566e-06 - val_dense_18_loss: 3.6250e-06 - val_dense_19_loss: 1.5267e-05 - val_dense_20_loss: 1.4669e-06 - val_dense_21_loss: 1.4856e-06 - val_dense_22_loss: 1.4532e-06\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 2s 724ms/step - loss: 9.0362e-05 - dense_7_loss: 7.6498e-06 - dense_8_loss: 1.0990e-05 - dense_9_loss: 8.7495e-06 - dense_10_loss: 4.2967e-06 - dense_11_loss: 5.0810e-06 - dense_12_loss: 9.7070e-06 - dense_13_loss: 8.2917e-06 - dense_14_loss: 3.0670e-06 - dense_15_loss: 2.0163e-06 - dense_16_loss: 3.5343e-06 - dense_17_loss: 3.5400e-06 - dense_18_loss: 3.6640e-06 - dense_19_loss: 1.5498e-05 - dense_20_loss: 1.4126e-06 - dense_21_loss: 1.4358e-06 - dense_22_loss: 1.4288e-06 - val_loss: 8.8209e-05 - val_dense_7_loss: 7.4590e-06 - val_dense_8_loss: 1.0693e-05 - val_dense_9_loss: 8.4831e-06 - val_dense_10_loss: 4.2154e-06 - val_dense_11_loss: 4.9924e-06 - val_dense_12_loss: 9.4126e-06 - val_dense_13_loss: 8.1475e-06 - val_dense_14_loss: 2.9831e-06 - val_dense_15_loss: 1.6474e-06 - val_dense_16_loss: 3.3742e-06 - val_dense_17_loss: 3.6689e-06 - val_dense_18_loss: 3.6387e-06 - val_dense_19_loss: 1.5226e-05 - val_dense_20_loss: 1.4444e-06 - val_dense_21_loss: 1.4585e-06 - val_dense_22_loss: 1.3650e-06\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 2s 787ms/step - loss: 8.8927e-05 - dense_7_loss: 7.6069e-06 - dense_8_loss: 1.0772e-05 - dense_9_loss: 8.6085e-06 - dense_10_loss: 4.2043e-06 - dense_11_loss: 5.0267e-06 - dense_12_loss: 9.5498e-06 - dense_13_loss: 8.1875e-06 - dense_14_loss: 3.0123e-06 - dense_15_loss: 1.9797e-06 - dense_16_loss: 3.4667e-06 - dense_17_loss: 3.5291e-06 - dense_18_loss: 3.6561e-06 - dense_19_loss: 1.5397e-05 - dense_20_loss: 1.3287e-06 - dense_21_loss: 1.3342e-06 - dense_22_loss: 1.2686e-06 - val_loss: 8.3002e-05 - val_dense_7_loss: 7.0451e-06 - val_dense_8_loss: 1.0181e-05 - val_dense_9_loss: 8.1266e-06 - val_dense_10_loss: 4.0725e-06 - val_dense_11_loss: 4.7428e-06 - val_dense_12_loss: 9.0010e-06 - val_dense_13_loss: 7.7815e-06 - val_dense_14_loss: 2.8647e-06 - val_dense_15_loss: 1.5293e-06 - val_dense_16_loss: 3.1808e-06 - val_dense_17_loss: 3.5712e-06 - val_dense_18_loss: 3.4994e-06 - val_dense_19_loss: 1.4191e-05 - val_dense_20_loss: 1.1392e-06 - val_dense_21_loss: 1.0630e-06 - val_dense_22_loss: 1.0127e-06\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 2s 704ms/step - loss: 8.4488e-05 - dense_7_loss: 7.2659e-06 - dense_8_loss: 1.0317e-05 - dense_9_loss: 8.2861e-06 - dense_10_loss: 4.0803e-06 - dense_11_loss: 4.8180e-06 - dense_12_loss: 9.1774e-06 - dense_13_loss: 7.8626e-06 - dense_14_loss: 2.9106e-06 - dense_15_loss: 1.8858e-06 - dense_16_loss: 3.3052e-06 - dense_17_loss: 3.4439e-06 - dense_18_loss: 3.5405e-06 - dense_19_loss: 1.4562e-05 - dense_20_loss: 1.0715e-06 - dense_21_loss: 9.9717e-07 - dense_22_loss: 9.6372e-07 - val_loss: 8.4284e-05 - val_dense_7_loss: 6.9942e-06 - val_dense_8_loss: 9.9781e-06 - val_dense_9_loss: 7.9599e-06 - val_dense_10_loss: 4.0659e-06 - val_dense_11_loss: 4.7222e-06 - val_dense_12_loss: 8.8144e-06 - val_dense_13_loss: 7.6355e-06 - val_dense_14_loss: 2.9048e-06 - val_dense_15_loss: 1.7055e-06 - val_dense_16_loss: 3.2698e-06 - val_dense_17_loss: 3.7031e-06 - val_dense_18_loss: 3.6609e-06 - val_dense_19_loss: 1.4242e-05 - val_dense_20_loss: 1.5365e-06 - val_dense_21_loss: 1.5158e-06 - val_dense_22_loss: 1.5757e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "2/2 [==============================] - 2s 712ms/step - loss: 8.5370e-05 - dense_7_loss: 7.2005e-06 - dense_8_loss: 1.0088e-05 - dense_9_loss: 8.1025e-06 - dense_10_loss: 4.0625e-06 - dense_11_loss: 4.7896e-06 - dense_12_loss: 8.9715e-06 - dense_13_loss: 7.7012e-06 - dense_14_loss: 2.9376e-06 - dense_15_loss: 2.0499e-06 - dense_16_loss: 3.3736e-06 - dense_17_loss: 3.5683e-06 - dense_18_loss: 3.6887e-06 - dense_19_loss: 1.4525e-05 - dense_20_loss: 1.4268e-06 - dense_21_loss: 1.4105e-06 - dense_22_loss: 1.4733e-06 - val_loss: 8.0885e-05 - val_dense_7_loss: 6.8233e-06 - val_dense_8_loss: 9.5890e-06 - val_dense_9_loss: 7.6530e-06 - val_dense_10_loss: 3.9074e-06 - val_dense_11_loss: 4.5967e-06 - val_dense_12_loss: 8.4990e-06 - val_dense_13_loss: 7.3730e-06 - val_dense_14_loss: 2.8077e-06 - val_dense_15_loss: 1.6160e-06 - val_dense_16_loss: 3.1287e-06 - val_dense_17_loss: 3.6204e-06 - val_dense_18_loss: 3.6010e-06 - val_dense_19_loss: 1.3850e-05 - val_dense_20_loss: 1.3222e-06 - val_dense_21_loss: 1.2567e-06 - val_dense_22_loss: 1.2410e-06\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 2s 708ms/step - loss: 8.1803e-05 - dense_7_loss: 7.0121e-06 - dense_8_loss: 9.6842e-06 - dense_9_loss: 7.7818e-06 - dense_10_loss: 3.8968e-06 - dense_11_loss: 4.6513e-06 - dense_12_loss: 8.6449e-06 - dense_13_loss: 7.4207e-06 - dense_14_loss: 2.8335e-06 - dense_15_loss: 1.9550e-06 - dense_16_loss: 3.2266e-06 - dense_17_loss: 3.4782e-06 - dense_18_loss: 3.6216e-06 - dense_19_loss: 1.4141e-05 - dense_20_loss: 1.2009e-06 - dense_21_loss: 1.1289e-06 - dense_22_loss: 1.1251e-06 - val_loss: 7.8229e-05 - val_dense_7_loss: 6.6096e-06 - val_dense_8_loss: 9.1870e-06 - val_dense_9_loss: 7.3839e-06 - val_dense_10_loss: 3.7967e-06 - val_dense_11_loss: 4.4801e-06 - val_dense_12_loss: 8.1684e-06 - val_dense_13_loss: 7.0906e-06 - val_dense_14_loss: 2.7400e-06 - val_dense_15_loss: 1.6199e-06 - val_dense_16_loss: 3.0136e-06 - val_dense_17_loss: 3.6233e-06 - val_dense_18_loss: 3.5832e-06 - val_dense_19_loss: 1.3329e-05 - val_dense_20_loss: 1.2762e-06 - val_dense_21_loss: 1.1802e-06 - val_dense_22_loss: 1.1481e-06\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 2s 708ms/step - loss: 7.9242e-05 - dense_7_loss: 6.7803e-06 - dense_8_loss: 9.2682e-06 - dense_9_loss: 7.5017e-06 - dense_10_loss: 3.7859e-06 - dense_11_loss: 4.5296e-06 - dense_12_loss: 8.3011e-06 - dense_13_loss: 7.1321e-06 - dense_14_loss: 2.7695e-06 - dense_15_loss: 1.9693e-06 - dense_16_loss: 3.1239e-06 - dense_17_loss: 3.4923e-06 - dense_18_loss: 3.6180e-06 - dense_19_loss: 1.3597e-05 - dense_20_loss: 1.1887e-06 - dense_21_loss: 1.0984e-06 - dense_22_loss: 1.0861e-06 - val_loss: 7.6074e-05 - val_dense_7_loss: 6.4568e-06 - val_dense_8_loss: 8.7710e-06 - val_dense_9_loss: 7.0500e-06 - val_dense_10_loss: 3.6850e-06 - val_dense_11_loss: 4.3621e-06 - val_dense_12_loss: 7.7781e-06 - val_dense_13_loss: 6.8130e-06 - val_dense_14_loss: 2.6746e-06 - val_dense_15_loss: 1.6119e-06 - val_dense_16_loss: 2.9527e-06 - val_dense_17_loss: 3.6079e-06 - val_dense_18_loss: 3.5953e-06 - val_dense_19_loss: 1.3181e-05 - val_dense_20_loss: 1.2719e-06 - val_dense_21_loss: 1.1563e-06 - val_dense_22_loss: 1.1067e-06\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 3s 817ms/step - loss: 7.7130e-05 - dense_7_loss: 6.6057e-06 - dense_8_loss: 8.8296e-06 - dense_9_loss: 7.1644e-06 - dense_10_loss: 3.6772e-06 - dense_11_loss: 4.4132e-06 - dense_12_loss: 7.9123e-06 - dense_13_loss: 6.8474e-06 - dense_14_loss: 2.7134e-06 - dense_15_loss: 1.9812e-06 - dense_16_loss: 3.0629e-06 - dense_17_loss: 3.4933e-06 - dense_18_loss: 3.6465e-06 - dense_19_loss: 1.3367e-05 - dense_20_loss: 1.2157e-06 - dense_21_loss: 1.1117e-06 - dense_22_loss: 1.0882e-06 - val_loss: 7.7027e-05 - val_dense_7_loss: 6.5693e-06 - val_dense_8_loss: 8.6659e-06 - val_dense_9_loss: 6.9674e-06 - val_dense_10_loss: 3.7125e-06 - val_dense_11_loss: 4.4551e-06 - val_dense_12_loss: 7.6652e-06 - val_dense_13_loss: 6.7363e-06 - val_dense_14_loss: 2.7319e-06 - val_dense_15_loss: 1.7322e-06 - val_dense_16_loss: 2.9937e-06 - val_dense_17_loss: 3.6811e-06 - val_dense_18_loss: 3.7243e-06 - val_dense_19_loss: 1.3532e-05 - val_dense_20_loss: 1.4096e-06 - val_dense_21_loss: 1.2803e-06 - val_dense_22_loss: 1.1704e-06\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 3s 795ms/step - loss: 7.7733e-05 - dense_7_loss: 6.6711e-06 - dense_8_loss: 8.6722e-06 - dense_9_loss: 7.0432e-06 - dense_10_loss: 3.6893e-06 - dense_11_loss: 4.4713e-06 - dense_12_loss: 7.7580e-06 - dense_13_loss: 6.7332e-06 - dense_14_loss: 2.7602e-06 - dense_15_loss: 2.0959e-06 - dense_16_loss: 3.0910e-06 - dense_17_loss: 3.5666e-06 - dense_18_loss: 3.7694e-06 - dense_19_loss: 1.3627e-05 - dense_20_loss: 1.3582e-06 - dense_21_loss: 1.2511e-06 - dense_22_loss: 1.1748e-06 - val_loss: 7.4481e-05 - val_dense_7_loss: 6.2226e-06 - val_dense_8_loss: 8.0131e-06 - val_dense_9_loss: 6.4789e-06 - val_dense_10_loss: 3.5111e-06 - val_dense_11_loss: 4.2363e-06 - val_dense_12_loss: 7.1205e-06 - val_dense_13_loss: 6.2833e-06 - val_dense_14_loss: 2.6703e-06 - val_dense_15_loss: 1.7969e-06 - val_dense_16_loss: 2.9149e-06 - val_dense_17_loss: 3.7004e-06 - val_dense_18_loss: 3.7710e-06 - val_dense_19_loss: 1.3154e-05 - val_dense_20_loss: 1.6181e-06 - val_dense_21_loss: 1.5260e-06 - val_dense_22_loss: 1.4631e-06\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 2s 705ms/step - loss: 7.5089e-05 - dense_7_loss: 6.3324e-06 - dense_8_loss: 8.0180e-06 - dense_9_loss: 6.5541e-06 - dense_10_loss: 3.4892e-06 - dense_11_loss: 4.2605e-06 - dense_12_loss: 7.2088e-06 - dense_13_loss: 6.2810e-06 - dense_14_loss: 2.6920e-06 - dense_15_loss: 2.1542e-06 - dense_16_loss: 3.0120e-06 - dense_17_loss: 3.5814e-06 - dense_18_loss: 3.8154e-06 - dense_19_loss: 1.3253e-05 - dense_20_loss: 1.5492e-06 - dense_21_loss: 1.4654e-06 - dense_22_loss: 1.4230e-06 - val_loss: 6.9005e-05 - val_dense_7_loss: 5.8709e-06 - val_dense_8_loss: 7.3125e-06 - val_dense_9_loss: 5.9036e-06 - val_dense_10_loss: 3.2702e-06 - val_dense_11_loss: 3.9809e-06 - val_dense_12_loss: 6.5222e-06 - val_dense_13_loss: 5.7693e-06 - val_dense_14_loss: 2.5024e-06 - val_dense_15_loss: 1.7271e-06 - val_dense_16_loss: 2.6922e-06 - val_dense_17_loss: 3.5927e-06 - val_dense_18_loss: 3.7021e-06 - val_dense_19_loss: 1.2293e-05 - val_dense_20_loss: 1.4115e-06 - val_dense_21_loss: 1.2800e-06 - val_dense_22_loss: 1.1747e-06\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 2s 790ms/step - loss: 6.9551e-05 - dense_7_loss: 5.9811e-06 - dense_8_loss: 7.3153e-06 - dense_9_loss: 5.9729e-06 - dense_10_loss: 3.2471e-06 - dense_11_loss: 4.0062e-06 - dense_12_loss: 6.6010e-06 - dense_13_loss: 5.7603e-06 - dense_14_loss: 2.5249e-06 - dense_15_loss: 2.0851e-06 - dense_16_loss: 2.7874e-06 - dense_17_loss: 3.4726e-06 - dense_18_loss: 3.7449e-06 - dense_19_loss: 1.2404e-05 - dense_20_loss: 1.3306e-06 - dense_21_loss: 1.2014e-06 - dense_22_loss: 1.1163e-06 - val_loss: 6.4570e-05 - val_dense_7_loss: 5.4205e-06 - val_dense_8_loss: 6.5277e-06 - val_dense_9_loss: 5.3138e-06 - val_dense_10_loss: 3.0784e-06 - val_dense_11_loss: 3.7413e-06 - val_dense_12_loss: 5.8692e-06 - val_dense_13_loss: 5.2362e-06 - val_dense_14_loss: 2.3860e-06 - val_dense_15_loss: 1.7725e-06 - val_dense_16_loss: 2.5391e-06 - val_dense_17_loss: 3.5979e-06 - val_dense_18_loss: 3.7372e-06 - val_dense_19_loss: 1.1316e-05 - val_dense_20_loss: 1.4583e-06 - val_dense_21_loss: 1.3300e-06 - val_dense_22_loss: 1.2456e-06\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 2s 713ms/step - loss: 6.5262e-05 - dense_7_loss: 5.5599e-06 - dense_8_loss: 6.5514e-06 - dense_9_loss: 5.3909e-06 - dense_10_loss: 3.0575e-06 - dense_11_loss: 3.7759e-06 - dense_12_loss: 5.9568e-06 - dense_13_loss: 5.2370e-06 - dense_14_loss: 2.4102e-06 - dense_15_loss: 2.1329e-06 - dense_16_loss: 2.6419e-06 - dense_17_loss: 3.4705e-06 - dense_18_loss: 3.7777e-06 - dense_19_loss: 1.1517e-05 - dense_20_loss: 1.3718e-06 - dense_21_loss: 1.2404e-06 - dense_22_loss: 1.1699e-06 - val_loss: 6.2290e-05 - val_dense_7_loss: 5.0033e-06 - val_dense_8_loss: 5.9125e-06 - val_dense_9_loss: 4.8900e-06 - val_dense_10_loss: 2.9628e-06 - val_dense_11_loss: 3.5696e-06 - val_dense_12_loss: 5.3675e-06 - val_dense_13_loss: 4.8015e-06 - val_dense_14_loss: 2.3761e-06 - val_dense_15_loss: 1.9245e-06 - val_dense_16_loss: 2.4636e-06 - val_dense_17_loss: 3.6848e-06 - val_dense_18_loss: 3.8622e-06 - val_dense_19_loss: 1.0451e-05 - val_dense_20_loss: 1.7420e-06 - val_dense_21_loss: 1.6655e-06 - val_dense_22_loss: 1.6141e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "2/2 [==============================] - 2s 700ms/step - loss: 6.3444e-05 - dense_7_loss: 5.2377e-06 - dense_8_loss: 6.0300e-06 - dense_9_loss: 5.0206e-06 - dense_10_loss: 2.9601e-06 - dense_11_loss: 3.6555e-06 - dense_12_loss: 5.5312e-06 - dense_13_loss: 4.8632e-06 - dense_14_loss: 2.4042e-06 - dense_15_loss: 2.2727e-06 - dense_16_loss: 2.5785e-06 - dense_17_loss: 3.5473e-06 - dense_18_loss: 3.8931e-06 - dense_19_loss: 1.0834e-05 - dense_20_loss: 1.6160e-06 - dense_21_loss: 1.5283e-06 - dense_22_loss: 1.4714e-06 - val_loss: 7.0951e-05 - val_dense_7_loss: 5.2358e-06 - val_dense_8_loss: 6.8091e-06 - val_dense_9_loss: 5.6661e-06 - val_dense_10_loss: 3.4210e-06 - val_dense_11_loss: 3.9693e-06 - val_dense_12_loss: 6.1340e-06 - val_dense_13_loss: 5.3876e-06 - val_dense_14_loss: 2.7571e-06 - val_dense_15_loss: 2.3264e-06 - val_dense_16_loss: 2.7087e-06 - val_dense_17_loss: 4.1037e-06 - val_dense_18_loss: 4.1635e-06 - val_dense_19_loss: 1.0574e-05 - val_dense_20_loss: 2.4383e-06 - val_dense_21_loss: 2.6282e-06 - val_dense_22_loss: 2.6284e-06\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 2s 782ms/step - loss: 7.3962e-05 - dense_7_loss: 5.7218e-06 - dense_8_loss: 7.1249e-06 - dense_9_loss: 5.9416e-06 - dense_10_loss: 3.4932e-06 - dense_11_loss: 4.2047e-06 - dense_12_loss: 6.4917e-06 - dense_13_loss: 5.5912e-06 - dense_14_loss: 2.8314e-06 - dense_15_loss: 2.7046e-06 - dense_16_loss: 2.8868e-06 - dense_17_loss: 3.9941e-06 - dense_18_loss: 4.2388e-06 - dense_19_loss: 1.1418e-05 - dense_20_loss: 2.3475e-06 - dense_21_loss: 2.5056e-06 - dense_22_loss: 2.4650e-06 - val_loss: 6.1213e-05 - val_dense_7_loss: 4.7674e-06 - val_dense_8_loss: 5.5535e-06 - val_dense_9_loss: 4.6143e-06 - val_dense_10_loss: 2.8883e-06 - val_dense_11_loss: 3.4903e-06 - val_dense_12_loss: 5.0509e-06 - val_dense_13_loss: 4.5040e-06 - val_dense_14_loss: 2.4140e-06 - val_dense_15_loss: 2.0819e-06 - val_dense_16_loss: 2.3495e-06 - val_dense_17_loss: 3.7944e-06 - val_dense_18_loss: 3.9718e-06 - val_dense_19_loss: 9.8392e-06 - val_dense_20_loss: 1.9986e-06 - val_dense_21_loss: 1.9943e-06 - val_dense_22_loss: 1.9001e-06\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 2s 695ms/step - loss: 6.1105e-05 - dense_7_loss: 4.8884e-06 - dense_8_loss: 5.5077e-06 - dense_9_loss: 4.6148e-06 - dense_10_loss: 2.8283e-06 - dense_11_loss: 3.5076e-06 - dense_12_loss: 5.0753e-06 - dense_13_loss: 4.4427e-06 - dense_14_loss: 2.3889e-06 - dense_15_loss: 2.4168e-06 - dense_16_loss: 2.4278e-06 - dense_17_loss: 3.6363e-06 - dense_18_loss: 3.9908e-06 - dense_19_loss: 9.9565e-06 - dense_20_loss: 1.8491e-06 - dense_21_loss: 1.8292e-06 - dense_22_loss: 1.7447e-06 - val_loss: 6.3111e-05 - val_dense_7_loss: 5.5832e-06 - val_dense_8_loss: 6.1525e-06 - val_dense_9_loss: 4.8376e-06 - val_dense_10_loss: 2.9903e-06 - val_dense_11_loss: 3.8196e-06 - val_dense_12_loss: 5.3907e-06 - val_dense_13_loss: 4.7995e-06 - val_dense_14_loss: 2.3515e-06 - val_dense_15_loss: 1.9741e-06 - val_dense_16_loss: 2.3730e-06 - val_dense_17_loss: 3.5473e-06 - val_dense_18_loss: 3.8629e-06 - val_dense_19_loss: 1.1218e-05 - val_dense_20_loss: 1.5807e-06 - val_dense_21_loss: 1.4522e-06 - val_dense_22_loss: 1.1784e-06\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 2s 702ms/step - loss: 6.2487e-05 - dense_7_loss: 5.5430e-06 - dense_8_loss: 5.9507e-06 - dense_9_loss: 4.7565e-06 - dense_10_loss: 2.9096e-06 - dense_11_loss: 3.7522e-06 - dense_12_loss: 5.3204e-06 - dense_13_loss: 4.6526e-06 - dense_14_loss: 2.3408e-06 - dense_15_loss: 2.3394e-06 - dense_16_loss: 2.4301e-06 - dense_17_loss: 3.4339e-06 - dense_18_loss: 3.9126e-06 - dense_19_loss: 1.1069e-05 - dense_20_loss: 1.5240e-06 - dense_21_loss: 1.3982e-06 - dense_22_loss: 1.1545e-06 - val_loss: 4.9732e-05 - val_dense_7_loss: 4.1419e-06 - val_dense_8_loss: 4.0578e-06 - val_dense_9_loss: 3.2952e-06 - val_dense_10_loss: 2.3138e-06 - val_dense_11_loss: 2.8892e-06 - val_dense_12_loss: 3.6453e-06 - val_dense_13_loss: 3.3816e-06 - val_dense_14_loss: 1.9533e-06 - val_dense_15_loss: 1.9452e-06 - val_dense_16_loss: 1.9033e-06 - val_dense_17_loss: 3.4262e-06 - val_dense_18_loss: 3.8141e-06 - val_dense_19_loss: 8.4863e-06 - val_dense_20_loss: 1.6119e-06 - val_dense_21_loss: 1.5135e-06 - val_dense_22_loss: 1.3536e-06\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 2s 723ms/step - loss: 5.0760e-05 - dense_7_loss: 4.3459e-06 - dense_8_loss: 4.1498e-06 - dense_9_loss: 3.3985e-06 - dense_10_loss: 2.3068e-06 - dense_11_loss: 2.9799e-06 - dense_12_loss: 3.7927e-06 - dense_13_loss: 3.4111e-06 - dense_14_loss: 1.9692e-06 - dense_15_loss: 2.2984e-06 - dense_16_loss: 2.0164e-06 - dense_17_loss: 3.2985e-06 - dense_18_loss: 3.8564e-06 - dense_19_loss: 8.7433e-06 - dense_20_loss: 1.5172e-06 - dense_21_loss: 1.4142e-06 - dense_22_loss: 1.2621e-06 - val_loss: 4.8510e-05 - val_dense_7_loss: 3.9082e-06 - val_dense_8_loss: 4.0315e-06 - val_dense_9_loss: 3.2735e-06 - val_dense_10_loss: 2.3381e-06 - val_dense_11_loss: 2.7887e-06 - val_dense_12_loss: 3.6153e-06 - val_dense_13_loss: 3.3467e-06 - val_dense_14_loss: 1.9569e-06 - val_dense_15_loss: 1.9488e-06 - val_dense_16_loss: 1.8574e-06 - val_dense_17_loss: 3.4432e-06 - val_dense_18_loss: 3.7785e-06 - val_dense_19_loss: 7.7492e-06 - val_dense_20_loss: 1.6180e-06 - val_dense_21_loss: 1.5307e-06 - val_dense_22_loss: 1.3253e-06\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 2s 759ms/step - loss: 4.8330e-05 - dense_7_loss: 4.0093e-06 - dense_8_loss: 3.9180e-06 - dense_9_loss: 3.2284e-06 - dense_10_loss: 2.2529e-06 - dense_11_loss: 2.7981e-06 - dense_12_loss: 3.5822e-06 - dense_13_loss: 3.2314e-06 - dense_14_loss: 1.9297e-06 - dense_15_loss: 2.2947e-06 - dense_16_loss: 1.9357e-06 - dense_17_loss: 3.2997e-06 - dense_18_loss: 3.8139e-06 - dense_19_loss: 7.8417e-06 - dense_20_loss: 1.5211e-06 - dense_21_loss: 1.4292e-06 - dense_22_loss: 1.2435e-06 - val_loss: 4.6220e-05 - val_dense_7_loss: 4.1167e-06 - val_dense_8_loss: 3.3718e-06 - val_dense_9_loss: 2.6397e-06 - val_dense_10_loss: 2.0873e-06 - val_dense_11_loss: 2.8329e-06 - val_dense_12_loss: 3.1199e-06 - val_dense_13_loss: 2.8456e-06 - val_dense_14_loss: 1.7914e-06 - val_dense_15_loss: 2.0198e-06 - val_dense_16_loss: 1.7175e-06 - val_dense_17_loss: 3.3443e-06 - val_dense_18_loss: 3.8573e-06 - val_dense_19_loss: 7.6835e-06 - val_dense_20_loss: 1.7496e-06 - val_dense_21_loss: 1.6489e-06 - val_dense_22_loss: 1.3939e-06\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 2s 713ms/step - loss: 4.6725e-05 - dense_7_loss: 4.1384e-06 - dense_8_loss: 3.4314e-06 - dense_9_loss: 2.7464e-06 - dense_10_loss: 2.0879e-06 - dense_11_loss: 2.8199e-06 - dense_12_loss: 3.2338e-06 - dense_13_loss: 2.8565e-06 - dense_14_loss: 1.8183e-06 - dense_15_loss: 2.3770e-06 - dense_16_loss: 1.8347e-06 - dense_17_loss: 3.2463e-06 - dense_18_loss: 3.9035e-06 - dense_19_loss: 7.6701e-06 - dense_20_loss: 1.6613e-06 - dense_21_loss: 1.5676e-06 - dense_22_loss: 1.3315e-06 - val_loss: 3.9992e-05 - val_dense_7_loss: 3.6105e-06 - val_dense_8_loss: 2.5887e-06 - val_dense_9_loss: 2.0571e-06 - val_dense_10_loss: 1.7597e-06 - val_dense_11_loss: 2.4589e-06 - val_dense_12_loss: 2.3675e-06 - val_dense_13_loss: 2.2461e-06 - val_dense_14_loss: 1.5743e-06 - val_dense_15_loss: 1.9097e-06 - val_dense_16_loss: 1.4599e-06 - val_dense_17_loss: 3.1717e-06 - val_dense_18_loss: 3.6901e-06 - val_dense_19_loss: 6.6517e-06 - val_dense_20_loss: 1.6262e-06 - val_dense_21_loss: 1.5319e-06 - val_dense_22_loss: 1.2879e-06\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 2s 716ms/step - loss: 4.0645e-05 - dense_7_loss: 3.6765e-06 - dense_8_loss: 2.5661e-06 - dense_9_loss: 2.0879e-06 - dense_10_loss: 1.7341e-06 - dense_11_loss: 2.4716e-06 - dense_12_loss: 2.4227e-06 - dense_13_loss: 2.2070e-06 - dense_14_loss: 1.5975e-06 - dense_15_loss: 2.2998e-06 - dense_16_loss: 1.5864e-06 - dense_17_loss: 3.0855e-06 - dense_18_loss: 3.7720e-06 - dense_19_loss: 6.7107e-06 - dense_20_loss: 1.6063e-06 - dense_21_loss: 1.5240e-06 - dense_22_loss: 1.2973e-06 - val_loss: 4.1173e-05 - val_dense_7_loss: 3.1103e-06 - val_dense_8_loss: 2.8248e-06 - val_dense_9_loss: 2.3080e-06 - val_dense_10_loss: 1.9345e-06 - val_dense_11_loss: 2.2571e-06 - val_dense_12_loss: 2.5908e-06 - val_dense_13_loss: 2.4261e-06 - val_dense_14_loss: 1.6949e-06 - val_dense_15_loss: 2.0247e-06 - val_dense_16_loss: 1.5992e-06 - val_dense_17_loss: 3.3652e-06 - val_dense_18_loss: 3.8330e-06 - val_dense_19_loss: 5.5300e-06 - val_dense_20_loss: 1.9228e-06 - val_dense_21_loss: 1.9423e-06 - val_dense_22_loss: 1.8091e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/500\n",
      "2/2 [==============================] - 2s 719ms/step - loss: 4.0598e-05 - dense_7_loss: 3.2026e-06 - dense_8_loss: 2.7004e-06 - dense_9_loss: 2.2476e-06 - dense_10_loss: 1.8344e-06 - dense_11_loss: 2.2661e-06 - dense_12_loss: 2.5440e-06 - dense_13_loss: 2.2934e-06 - dense_14_loss: 1.6495e-06 - dense_15_loss: 2.3444e-06 - dense_16_loss: 1.6619e-06 - dense_17_loss: 3.2010e-06 - dense_18_loss: 3.8447e-06 - dense_19_loss: 5.5807e-06 - dense_20_loss: 1.7822e-06 - dense_21_loss: 1.7845e-06 - dense_22_loss: 1.6605e-06 - val_loss: 4.0851e-05 - val_dense_7_loss: 3.1812e-06 - val_dense_8_loss: 2.1635e-06 - val_dense_9_loss: 1.7783e-06 - val_dense_10_loss: 1.6939e-06 - val_dense_11_loss: 2.2011e-06 - val_dense_12_loss: 2.0050e-06 - val_dense_13_loss: 1.9257e-06 - val_dense_14_loss: 1.6296e-06 - val_dense_15_loss: 2.2161e-06 - val_dense_16_loss: 1.5680e-06 - val_dense_17_loss: 3.3545e-06 - val_dense_18_loss: 3.9700e-06 - val_dense_19_loss: 5.7671e-06 - val_dense_20_loss: 2.4417e-06 - val_dense_21_loss: 2.5394e-06 - val_dense_22_loss: 2.4156e-06\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 2s 775ms/step - loss: 4.0561e-05 - dense_7_loss: 3.2213e-06 - dense_8_loss: 2.1313e-06 - dense_9_loss: 1.7956e-06 - dense_10_loss: 1.6407e-06 - dense_11_loss: 2.1927e-06 - dense_12_loss: 2.0446e-06 - dense_13_loss: 1.8679e-06 - dense_14_loss: 1.6061e-06 - dense_15_loss: 2.5419e-06 - dense_16_loss: 1.6537e-06 - dense_17_loss: 3.2087e-06 - dense_18_loss: 3.9894e-06 - dense_19_loss: 5.7514e-06 - dense_20_loss: 2.2885e-06 - dense_21_loss: 2.3665e-06 - dense_22_loss: 2.2606e-06 - val_loss: 3.1637e-05 - val_dense_7_loss: 2.6489e-06 - val_dense_8_loss: 1.8422e-06 - val_dense_9_loss: 1.5253e-06 - val_dense_10_loss: 1.4136e-06 - val_dense_11_loss: 1.8216e-06 - val_dense_12_loss: 1.6935e-06 - val_dense_13_loss: 1.6761e-06 - val_dense_14_loss: 1.2921e-06 - val_dense_15_loss: 1.6864e-06 - val_dense_16_loss: 1.1755e-06 - val_dense_17_loss: 2.9132e-06 - val_dense_18_loss: 3.5181e-06 - val_dense_19_loss: 4.3873e-06 - val_dense_20_loss: 1.4809e-06 - val_dense_21_loss: 1.3505e-06 - val_dense_22_loss: 1.2116e-06\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 2s 771ms/step - loss: 3.2576e-05 - dense_7_loss: 2.7831e-06 - dense_8_loss: 1.8621e-06 - dense_9_loss: 1.5646e-06 - dense_10_loss: 1.3979e-06 - dense_11_loss: 1.8795e-06 - dense_12_loss: 1.7819e-06 - dense_13_loss: 1.6456e-06 - dense_14_loss: 1.3065e-06 - dense_15_loss: 2.0791e-06 - dense_16_loss: 1.3139e-06 - dense_17_loss: 2.8259e-06 - dense_18_loss: 3.5954e-06 - dense_19_loss: 4.5175e-06 - dense_20_loss: 1.4525e-06 - dense_21_loss: 1.3428e-06 - dense_22_loss: 1.2273e-06 - val_loss: 3.0767e-05 - val_dense_7_loss: 2.5507e-06 - val_dense_8_loss: 1.8450e-06 - val_dense_9_loss: 1.5061e-06 - val_dense_10_loss: 1.3857e-06 - val_dense_11_loss: 1.7460e-06 - val_dense_12_loss: 1.6772e-06 - val_dense_13_loss: 1.6585e-06 - val_dense_14_loss: 1.2538e-06 - val_dense_15_loss: 1.6217e-06 - val_dense_16_loss: 1.1547e-06 - val_dense_17_loss: 2.8551e-06 - val_dense_18_loss: 3.4634e-06 - val_dense_19_loss: 4.0686e-06 - val_dense_20_loss: 1.4427e-06 - val_dense_21_loss: 1.3208e-06 - val_dense_22_loss: 1.2172e-06\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 2s 759ms/step - loss: 3.1021e-05 - dense_7_loss: 2.6429e-06 - dense_8_loss: 1.7899e-06 - dense_9_loss: 1.5022e-06 - dense_10_loss: 1.3271e-06 - dense_11_loss: 1.7690e-06 - dense_12_loss: 1.6973e-06 - dense_13_loss: 1.5725e-06 - dense_14_loss: 1.2375e-06 - dense_15_loss: 1.9808e-06 - dense_16_loss: 1.2687e-06 - dense_17_loss: 2.7400e-06 - dense_18_loss: 3.5169e-06 - dense_19_loss: 4.1751e-06 - dense_20_loss: 1.3780e-06 - dense_21_loss: 1.2546e-06 - dense_22_loss: 1.1690e-06 - val_loss: 3.2023e-05 - val_dense_7_loss: 2.6359e-06 - val_dense_8_loss: 1.6056e-06 - val_dense_9_loss: 1.3334e-06 - val_dense_10_loss: 1.3176e-06 - val_dense_11_loss: 1.7513e-06 - val_dense_12_loss: 1.4720e-06 - val_dense_13_loss: 1.4623e-06 - val_dense_14_loss: 1.2451e-06 - val_dense_15_loss: 1.7958e-06 - val_dense_16_loss: 1.1996e-06 - val_dense_17_loss: 2.9217e-06 - val_dense_18_loss: 3.5718e-06 - val_dense_19_loss: 4.3262e-06 - val_dense_20_loss: 1.7982e-06 - val_dense_21_loss: 1.7989e-06 - val_dense_22_loss: 1.7873e-06\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 3s 771ms/step - loss: 3.1546e-05 - dense_7_loss: 2.7195e-06 - dense_8_loss: 1.5821e-06 - dense_9_loss: 1.3398e-06 - dense_10_loss: 1.2605e-06 - dense_11_loss: 1.7622e-06 - dense_12_loss: 1.5269e-06 - dense_13_loss: 1.3953e-06 - dense_14_loss: 1.2029e-06 - dense_15_loss: 2.1000e-06 - dense_16_loss: 1.2776e-06 - dense_17_loss: 2.7607e-06 - dense_18_loss: 3.5750e-06 - dense_19_loss: 4.3291e-06 - dense_20_loss: 1.5960e-06 - dense_21_loss: 1.5673e-06 - dense_22_loss: 1.5511e-06 - val_loss: 3.1693e-05 - val_dense_7_loss: 2.6174e-06 - val_dense_8_loss: 2.1686e-06 - val_dense_9_loss: 1.7484e-06 - val_dense_10_loss: 1.4261e-06 - val_dense_11_loss: 1.7457e-06 - val_dense_12_loss: 1.9464e-06 - val_dense_13_loss: 1.8394e-06 - val_dense_14_loss: 1.2361e-06 - val_dense_15_loss: 1.5405e-06 - val_dense_16_loss: 1.2134e-06 - val_dense_17_loss: 2.8249e-06 - val_dense_18_loss: 3.4597e-06 - val_dense_19_loss: 3.9135e-06 - val_dense_20_loss: 1.4414e-06 - val_dense_21_loss: 1.3226e-06 - val_dense_22_loss: 1.2488e-06\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 2s 708ms/step - loss: 3.1195e-05 - dense_7_loss: 2.6922e-06 - dense_8_loss: 2.0607e-06 - dense_9_loss: 1.6976e-06 - dense_10_loss: 1.3431e-06 - dense_11_loss: 1.7564e-06 - dense_12_loss: 1.9186e-06 - dense_13_loss: 1.7193e-06 - dense_14_loss: 1.1860e-06 - dense_15_loss: 1.8660e-06 - dense_16_loss: 1.2892e-06 - dense_17_loss: 2.6776e-06 - dense_18_loss: 3.4756e-06 - dense_19_loss: 3.9688e-06 - dense_20_loss: 1.2885e-06 - dense_21_loss: 1.1590e-06 - dense_22_loss: 1.0967e-06 - val_loss: 2.8033e-05 - val_dense_7_loss: 2.4935e-06 - val_dense_8_loss: 1.4945e-06 - val_dense_9_loss: 1.2321e-06 - val_dense_10_loss: 1.1528e-06 - val_dense_11_loss: 1.6025e-06 - val_dense_12_loss: 1.3446e-06 - val_dense_13_loss: 1.3280e-06 - val_dense_14_loss: 1.0677e-06 - val_dense_15_loss: 1.5104e-06 - val_dense_16_loss: 1.0247e-06 - val_dense_17_loss: 2.6689e-06 - val_dense_18_loss: 3.3652e-06 - val_dense_19_loss: 3.8108e-06 - val_dense_20_loss: 1.3677e-06 - val_dense_21_loss: 1.2940e-06 - val_dense_22_loss: 1.2751e-06\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 2s 779ms/step - loss: 2.8106e-05 - dense_7_loss: 2.5908e-06 - dense_8_loss: 1.4644e-06 - dense_9_loss: 1.2437e-06 - dense_10_loss: 1.0984e-06 - dense_11_loss: 1.6322e-06 - dense_12_loss: 1.3872e-06 - dense_13_loss: 1.2606e-06 - dense_14_loss: 1.0407e-06 - dense_15_loss: 1.8536e-06 - dense_16_loss: 1.1296e-06 - dense_17_loss: 2.5446e-06 - dense_18_loss: 3.3992e-06 - dense_19_loss: 3.8999e-06 - dense_20_loss: 1.2499e-06 - dense_21_loss: 1.1635e-06 - dense_22_loss: 1.1479e-06 - val_loss: 2.5810e-05 - val_dense_7_loss: 2.4050e-06 - val_dense_8_loss: 1.6269e-06 - val_dense_9_loss: 1.2905e-06 - val_dense_10_loss: 1.1481e-06 - val_dense_11_loss: 1.5297e-06 - val_dense_12_loss: 1.4543e-06 - val_dense_13_loss: 1.4288e-06 - val_dense_14_loss: 9.8986e-07 - val_dense_15_loss: 1.3029e-06 - val_dense_16_loss: 9.4871e-07 - val_dense_17_loss: 2.5298e-06 - val_dense_18_loss: 3.1951e-06 - val_dense_19_loss: 3.4151e-06 - val_dense_20_loss: 9.8442e-07 - val_dense_21_loss: 8.1228e-07 - val_dense_22_loss: 7.4862e-07\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 2s 770ms/step - loss: 2.6142e-05 - dense_7_loss: 2.5252e-06 - dense_8_loss: 1.6007e-06 - dense_9_loss: 1.3074e-06 - dense_10_loss: 1.0951e-06 - dense_11_loss: 1.5785e-06 - dense_12_loss: 1.5113e-06 - dense_13_loss: 1.3620e-06 - dense_14_loss: 9.7380e-07 - dense_15_loss: 1.6616e-06 - dense_16_loss: 1.0612e-06 - dense_17_loss: 2.4173e-06 - dense_18_loss: 3.2458e-06 - dense_19_loss: 3.4826e-06 - dense_20_loss: 9.0008e-07 - dense_21_loss: 7.3264e-07 - dense_22_loss: 6.8692e-07 - val_loss: 2.5807e-05 - val_dense_7_loss: 2.4055e-06 - val_dense_8_loss: 1.6872e-06 - val_dense_9_loss: 1.3725e-06 - val_dense_10_loss: 1.1442e-06 - val_dense_11_loss: 1.5514e-06 - val_dense_12_loss: 1.4948e-06 - val_dense_13_loss: 1.4548e-06 - val_dense_14_loss: 9.6889e-07 - val_dense_15_loss: 1.2870e-06 - val_dense_16_loss: 9.4463e-07 - val_dense_17_loss: 2.5068e-06 - val_dense_18_loss: 3.1827e-06 - val_dense_19_loss: 3.3312e-06 - val_dense_20_loss: 9.5047e-07 - val_dense_21_loss: 7.9348e-07 - val_dense_22_loss: 7.3126e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "2/2 [==============================] - 2s 779ms/step - loss: 2.5863e-05 - dense_7_loss: 2.4960e-06 - dense_8_loss: 1.6124e-06 - dense_9_loss: 1.3519e-06 - dense_10_loss: 1.0742e-06 - dense_11_loss: 1.5772e-06 - dense_12_loss: 1.4998e-06 - dense_13_loss: 1.3545e-06 - dense_14_loss: 9.4271e-07 - dense_15_loss: 1.6356e-06 - dense_16_loss: 1.0498e-06 - dense_17_loss: 2.3879e-06 - dense_18_loss: 3.2295e-06 - dense_19_loss: 3.4156e-06 - dense_20_loss: 8.6667e-07 - dense_21_loss: 7.0666e-07 - dense_22_loss: 6.6203e-07 - val_loss: 2.5443e-05 - val_dense_7_loss: 2.4026e-06 - val_dense_8_loss: 1.3437e-06 - val_dense_9_loss: 1.1068e-06 - val_dense_10_loss: 1.0108e-06 - val_dense_11_loss: 1.5187e-06 - val_dense_12_loss: 1.1898e-06 - val_dense_13_loss: 1.2053e-06 - val_dense_14_loss: 9.4908e-07 - val_dense_15_loss: 1.3763e-06 - val_dense_16_loss: 9.1376e-07 - val_dense_17_loss: 2.5121e-06 - val_dense_18_loss: 3.2389e-06 - val_dense_19_loss: 3.4120e-06 - val_dense_20_loss: 1.1747e-06 - val_dense_21_loss: 1.0500e-06 - val_dense_22_loss: 1.0378e-06\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 2s 722ms/step - loss: 2.5178e-05 - dense_7_loss: 2.4709e-06 - dense_8_loss: 1.2964e-06 - dense_9_loss: 1.1082e-06 - dense_10_loss: 9.4988e-07 - dense_11_loss: 1.5310e-06 - dense_12_loss: 1.2242e-06 - dense_13_loss: 1.1241e-06 - dense_14_loss: 9.1435e-07 - dense_15_loss: 1.7025e-06 - dense_16_loss: 1.0071e-06 - dense_17_loss: 2.3821e-06 - dense_18_loss: 3.2661e-06 - dense_19_loss: 3.3983e-06 - dense_20_loss: 1.0251e-06 - dense_21_loss: 8.9115e-07 - dense_22_loss: 8.8709e-07 - val_loss: 2.3762e-05 - val_dense_7_loss: 2.2948e-06 - val_dense_8_loss: 1.3361e-06 - val_dense_9_loss: 1.1099e-06 - val_dense_10_loss: 1.0021e-06 - val_dense_11_loss: 1.4479e-06 - val_dense_12_loss: 1.2179e-06 - val_dense_13_loss: 1.2174e-06 - val_dense_14_loss: 9.0046e-07 - val_dense_15_loss: 1.2952e-06 - val_dense_16_loss: 8.6685e-07 - val_dense_17_loss: 2.4483e-06 - val_dense_18_loss: 3.1760e-06 - val_dense_19_loss: 2.8567e-06 - val_dense_20_loss: 9.6772e-07 - val_dense_21_loss: 8.2767e-07 - val_dense_22_loss: 7.9726e-07\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 2s 721ms/step - loss: 2.3552e-05 - dense_7_loss: 2.3542e-06 - dense_8_loss: 1.2700e-06 - dense_9_loss: 1.0896e-06 - dense_10_loss: 9.3142e-07 - dense_11_loss: 1.4573e-06 - dense_12_loss: 1.2262e-06 - dense_13_loss: 1.1168e-06 - dense_14_loss: 8.6842e-07 - dense_15_loss: 1.6282e-06 - dense_16_loss: 9.6571e-07 - dense_17_loss: 2.3291e-06 - dense_18_loss: 3.2159e-06 - dense_19_loss: 2.8399e-06 - dense_20_loss: 8.5617e-07 - dense_21_loss: 7.0981e-07 - dense_22_loss: 6.9351e-07 - val_loss: 2.1394e-05 - val_dense_7_loss: 2.2426e-06 - val_dense_8_loss: 9.8479e-07 - val_dense_9_loss: 8.2795e-07 - val_dense_10_loss: 8.4407e-07 - val_dense_11_loss: 1.3824e-06 - val_dense_12_loss: 9.1184e-07 - val_dense_13_loss: 9.3939e-07 - val_dense_14_loss: 7.9975e-07 - val_dense_15_loss: 1.2471e-06 - val_dense_16_loss: 7.3531e-07 - val_dense_17_loss: 2.3533e-06 - val_dense_18_loss: 3.0993e-06 - val_dense_19_loss: 2.7499e-06 - val_dense_20_loss: 8.7808e-07 - val_dense_21_loss: 7.2744e-07 - val_dense_22_loss: 6.7070e-07\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 2s 771ms/step - loss: 2.1511e-05 - dense_7_loss: 2.2880e-06 - dense_8_loss: 9.6962e-07 - dense_9_loss: 8.5256e-07 - dense_10_loss: 8.0132e-07 - dense_11_loss: 1.3881e-06 - dense_12_loss: 9.6913e-07 - dense_13_loss: 8.8495e-07 - dense_14_loss: 7.8565e-07 - dense_15_loss: 1.5922e-06 - dense_16_loss: 8.5604e-07 - dense_17_loss: 2.2514e-06 - dense_18_loss: 3.1519e-06 - dense_19_loss: 2.7136e-06 - dense_20_loss: 7.8213e-07 - dense_21_loss: 6.2977e-07 - dense_22_loss: 5.9474e-07 - val_loss: 2.0978e-05 - val_dense_7_loss: 2.3016e-06 - val_dense_8_loss: 9.7907e-07 - val_dense_9_loss: 8.1049e-07 - val_dense_10_loss: 8.1477e-07 - val_dense_11_loss: 1.4053e-06 - val_dense_12_loss: 9.0065e-07 - val_dense_13_loss: 9.2164e-07 - val_dense_14_loss: 7.6852e-07 - val_dense_15_loss: 1.2077e-06 - val_dense_16_loss: 6.9559e-07 - val_dense_17_loss: 2.3006e-06 - val_dense_18_loss: 3.0548e-06 - val_dense_19_loss: 2.7459e-06 - val_dense_20_loss: 8.0919e-07 - val_dense_21_loss: 6.6297e-07 - val_dense_22_loss: 5.9965e-07\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 2s 705ms/step - loss: 2.1150e-05 - dense_7_loss: 2.3326e-06 - dense_8_loss: 9.6892e-07 - dense_9_loss: 8.4046e-07 - dense_10_loss: 7.7663e-07 - dense_11_loss: 1.4023e-06 - dense_12_loss: 9.6118e-07 - dense_13_loss: 8.7242e-07 - dense_14_loss: 7.5803e-07 - dense_15_loss: 1.5573e-06 - dense_16_loss: 8.2288e-07 - dense_17_loss: 2.2063e-06 - dense_18_loss: 3.1134e-06 - dense_19_loss: 2.7087e-06 - dense_20_loss: 7.2408e-07 - dense_21_loss: 5.7493e-07 - dense_22_loss: 5.3043e-07 - val_loss: 2.1759e-05 - val_dense_7_loss: 2.3622e-06 - val_dense_8_loss: 1.0356e-06 - val_dense_9_loss: 8.6889e-07 - val_dense_10_loss: 8.3130e-07 - val_dense_11_loss: 1.4456e-06 - val_dense_12_loss: 9.4301e-07 - val_dense_13_loss: 9.5813e-07 - val_dense_14_loss: 7.8411e-07 - val_dense_15_loss: 1.2309e-06 - val_dense_16_loss: 7.2176e-07 - val_dense_17_loss: 2.3171e-06 - val_dense_18_loss: 3.0659e-06 - val_dense_19_loss: 2.9119e-06 - val_dense_20_loss: 8.6056e-07 - val_dense_21_loss: 7.4215e-07 - val_dense_22_loss: 6.7986e-07\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 2s 717ms/step - loss: 2.1768e-05 - dense_7_loss: 2.3739e-06 - dense_8_loss: 1.0273e-06 - dense_9_loss: 8.9789e-07 - dense_10_loss: 7.9350e-07 - dense_11_loss: 1.4303e-06 - dense_12_loss: 1.0062e-06 - dense_13_loss: 9.1258e-07 - dense_14_loss: 7.7293e-07 - dense_15_loss: 1.5692e-06 - dense_16_loss: 8.4382e-07 - dense_17_loss: 2.2208e-06 - dense_18_loss: 3.1190e-06 - dense_19_loss: 2.8311e-06 - dense_20_loss: 7.5400e-07 - dense_21_loss: 6.2974e-07 - dense_22_loss: 5.8605e-07 - val_loss: 2.1986e-05 - val_dense_7_loss: 2.3625e-06 - val_dense_8_loss: 1.1044e-06 - val_dense_9_loss: 9.1112e-07 - val_dense_10_loss: 8.5811e-07 - val_dense_11_loss: 1.4591e-06 - val_dense_12_loss: 1.0057e-06 - val_dense_13_loss: 1.0192e-06 - val_dense_14_loss: 8.0458e-07 - val_dense_15_loss: 1.2415e-06 - val_dense_16_loss: 7.3867e-07 - val_dense_17_loss: 2.3300e-06 - val_dense_18_loss: 3.0712e-06 - val_dense_19_loss: 2.8298e-06 - val_dense_20_loss: 8.4892e-07 - val_dense_21_loss: 7.3597e-07 - val_dense_22_loss: 6.6524e-07\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 2s 697ms/step - loss: 2.1915e-05 - dense_7_loss: 2.3710e-06 - dense_8_loss: 1.0878e-06 - dense_9_loss: 9.3200e-07 - dense_10_loss: 8.1720e-07 - dense_11_loss: 1.4395e-06 - dense_12_loss: 1.0614e-06 - dense_13_loss: 9.6592e-07 - dense_14_loss: 7.8945e-07 - dense_15_loss: 1.5787e-06 - dense_16_loss: 8.5911e-07 - dense_17_loss: 2.2304e-06 - dense_18_loss: 3.1209e-06 - dense_19_loss: 2.7377e-06 - dense_20_loss: 7.3846e-07 - dense_21_loss: 6.1789e-07 - dense_22_loss: 5.6754e-07 - val_loss: 2.1115e-05 - val_dense_7_loss: 2.2668e-06 - val_dense_8_loss: 1.0076e-06 - val_dense_9_loss: 8.4670e-07 - val_dense_10_loss: 8.2175e-07 - val_dense_11_loss: 1.3862e-06 - val_dense_12_loss: 9.1051e-07 - val_dense_13_loss: 9.4069e-07 - val_dense_14_loss: 7.7215e-07 - val_dense_15_loss: 1.2119e-06 - val_dense_16_loss: 7.0885e-07 - val_dense_17_loss: 2.3111e-06 - val_dense_18_loss: 3.0481e-06 - val_dense_19_loss: 2.7357e-06 - val_dense_20_loss: 8.2137e-07 - val_dense_21_loss: 7.0188e-07 - val_dense_22_loss: 6.2321e-07\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 2s 725ms/step - loss: 2.1125e-05 - dense_7_loss: 2.2900e-06 - dense_8_loss: 9.8640e-07 - dense_9_loss: 8.6473e-07 - dense_10_loss: 7.7844e-07 - dense_11_loss: 1.3752e-06 - dense_12_loss: 9.6329e-07 - dense_13_loss: 8.8430e-07 - dense_14_loss: 7.5798e-07 - dense_15_loss: 1.5550e-06 - dense_16_loss: 8.3121e-07 - dense_17_loss: 2.2148e-06 - dense_18_loss: 3.1031e-06 - dense_19_loss: 2.6562e-06 - dense_20_loss: 7.2345e-07 - dense_21_loss: 5.9895e-07 - dense_22_loss: 5.4203e-07 - val_loss: 2.0305e-05 - val_dense_7_loss: 2.1743e-06 - val_dense_8_loss: 9.5623e-07 - val_dense_9_loss: 8.0120e-07 - val_dense_10_loss: 8.0210e-07 - val_dense_11_loss: 1.3289e-06 - val_dense_12_loss: 8.6303e-07 - val_dense_13_loss: 9.0660e-07 - val_dense_14_loss: 7.5631e-07 - val_dense_15_loss: 1.1930e-06 - val_dense_16_loss: 6.9307e-07 - val_dense_17_loss: 2.3075e-06 - val_dense_18_loss: 3.0316e-06 - val_dense_19_loss: 2.4944e-06 - val_dense_20_loss: 7.7667e-07 - val_dense_21_loss: 6.4843e-07 - val_dense_22_loss: 5.7155e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "2/2 [==============================] - 2s 786ms/step - loss: 2.0356e-05 - dense_7_loss: 2.2029e-06 - dense_8_loss: 9.3994e-07 - dense_9_loss: 8.2349e-07 - dense_10_loss: 7.6022e-07 - dense_11_loss: 1.3245e-06 - dense_12_loss: 9.1935e-07 - dense_13_loss: 8.5280e-07 - dense_14_loss: 7.4190e-07 - dense_15_loss: 1.5357e-06 - dense_16_loss: 8.1521e-07 - dense_17_loss: 2.2096e-06 - dense_18_loss: 3.0865e-06 - dense_19_loss: 2.4275e-06 - dense_20_loss: 6.7881e-07 - dense_21_loss: 5.4713e-07 - dense_22_loss: 4.9009e-07 - val_loss: 2.0371e-05 - val_dense_7_loss: 2.1404e-06 - val_dense_8_loss: 9.4336e-07 - val_dense_9_loss: 7.9744e-07 - val_dense_10_loss: 8.0555e-07 - val_dense_11_loss: 1.3146e-06 - val_dense_12_loss: 8.5435e-07 - val_dense_13_loss: 9.0441e-07 - val_dense_14_loss: 7.6237e-07 - val_dense_15_loss: 1.2077e-06 - val_dense_16_loss: 7.1118e-07 - val_dense_17_loss: 2.3306e-06 - val_dense_18_loss: 3.0514e-06 - val_dense_19_loss: 2.4182e-06 - val_dense_20_loss: 8.1208e-07 - val_dense_21_loss: 6.8974e-07 - val_dense_22_loss: 6.2779e-07\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 2s 713ms/step - loss: 2.0347e-05 - dense_7_loss: 2.1767e-06 - dense_8_loss: 9.2318e-07 - dense_9_loss: 8.1456e-07 - dense_10_loss: 7.6009e-07 - dense_11_loss: 1.3119e-06 - dense_12_loss: 9.0718e-07 - dense_13_loss: 8.4539e-07 - dense_14_loss: 7.4327e-07 - dense_15_loss: 1.5466e-06 - dense_16_loss: 8.2714e-07 - dense_17_loss: 2.2259e-06 - dense_18_loss: 3.0993e-06 - dense_19_loss: 2.3569e-06 - dense_20_loss: 7.0337e-07 - dense_21_loss: 5.7536e-07 - dense_22_loss: 5.3016e-07 - val_loss: 2.0152e-05 - val_dense_7_loss: 2.0921e-06 - val_dense_8_loss: 9.4532e-07 - val_dense_9_loss: 8.0173e-07 - val_dense_10_loss: 8.0886e-07 - val_dense_11_loss: 1.2945e-06 - val_dense_12_loss: 8.5065e-07 - val_dense_13_loss: 9.0565e-07 - val_dense_14_loss: 7.6203e-07 - val_dense_15_loss: 1.2011e-06 - val_dense_16_loss: 7.1143e-07 - val_dense_17_loss: 2.3341e-06 - val_dense_18_loss: 3.0462e-06 - val_dense_19_loss: 2.3366e-06 - val_dense_20_loss: 7.9699e-07 - val_dense_21_loss: 6.7139e-07 - val_dense_22_loss: 5.9332e-07\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 2s 794ms/step - loss: 2.0163e-05 - dense_7_loss: 2.1341e-06 - dense_8_loss: 9.2102e-07 - dense_9_loss: 8.1524e-07 - dense_10_loss: 7.6097e-07 - dense_11_loss: 1.2956e-06 - dense_12_loss: 9.0008e-07 - dense_13_loss: 8.4346e-07 - dense_14_loss: 7.4288e-07 - dense_15_loss: 1.5407e-06 - dense_16_loss: 8.2778e-07 - dense_17_loss: 2.2307e-06 - dense_18_loss: 3.0966e-06 - dense_19_loss: 2.2840e-06 - dense_20_loss: 6.9450e-07 - dense_21_loss: 5.6675e-07 - dense_22_loss: 5.0852e-07 - val_loss: 1.9889e-05 - val_dense_7_loss: 2.0636e-06 - val_dense_8_loss: 9.3271e-07 - val_dense_9_loss: 7.9354e-07 - val_dense_10_loss: 8.0197e-07 - val_dense_11_loss: 1.2795e-06 - val_dense_12_loss: 8.4231e-07 - val_dense_13_loss: 8.9841e-07 - val_dense_14_loss: 7.5198e-07 - val_dense_15_loss: 1.1835e-06 - val_dense_16_loss: 7.0128e-07 - val_dense_17_loss: 2.3297e-06 - val_dense_18_loss: 3.0300e-06 - val_dense_19_loss: 2.2904e-06 - val_dense_20_loss: 7.7315e-07 - val_dense_21_loss: 6.4713e-07 - val_dense_22_loss: 5.6970e-07\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 2s 702ms/step - loss: 1.9938e-05 - dense_7_loss: 2.1085e-06 - dense_8_loss: 9.1267e-07 - dense_9_loss: 8.1045e-07 - dense_10_loss: 7.5620e-07 - dense_11_loss: 1.2825e-06 - dense_12_loss: 8.9457e-07 - dense_13_loss: 8.3852e-07 - dense_14_loss: 7.3421e-07 - dense_15_loss: 1.5259e-06 - dense_16_loss: 8.1954e-07 - dense_17_loss: 2.2273e-06 - dense_18_loss: 3.0816e-06 - dense_19_loss: 2.2425e-06 - dense_20_loss: 6.7347e-07 - dense_21_loss: 5.4463e-07 - dense_22_loss: 4.8557e-07 - val_loss: 1.9903e-05 - val_dense_7_loss: 2.0513e-06 - val_dense_8_loss: 9.4500e-07 - val_dense_9_loss: 8.0364e-07 - val_dense_10_loss: 8.0723e-07 - val_dense_11_loss: 1.2747e-06 - val_dense_12_loss: 8.4918e-07 - val_dense_13_loss: 9.0712e-07 - val_dense_14_loss: 7.5289e-07 - val_dense_15_loss: 1.1804e-06 - val_dense_16_loss: 7.0787e-07 - val_dense_17_loss: 2.3347e-06 - val_dense_18_loss: 3.0303e-06 - val_dense_19_loss: 2.2675e-06 - val_dense_20_loss: 7.7267e-07 - val_dense_21_loss: 6.4909e-07 - val_dense_22_loss: 5.6974e-07\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 2s 699ms/step - loss: 1.9944e-05 - dense_7_loss: 2.1034e-06 - dense_8_loss: 9.2496e-07 - dense_9_loss: 8.1855e-07 - dense_10_loss: 7.6026e-07 - dense_11_loss: 1.2817e-06 - dense_12_loss: 9.0254e-07 - dense_13_loss: 8.4629e-07 - dense_14_loss: 7.3410e-07 - dense_15_loss: 1.5226e-06 - dense_16_loss: 8.2433e-07 - dense_17_loss: 2.2297e-06 - dense_18_loss: 3.0803e-06 - dense_19_loss: 2.2198e-06 - dense_20_loss: 6.7023e-07 - dense_21_loss: 5.4284e-07 - dense_22_loss: 4.8270e-07 - val_loss: 2.0179e-05 - val_dense_7_loss: 2.0393e-06 - val_dense_8_loss: 1.0091e-06 - val_dense_9_loss: 8.5061e-07 - val_dense_10_loss: 8.3003e-07 - val_dense_11_loss: 1.2763e-06 - val_dense_12_loss: 9.0335e-07 - val_dense_13_loss: 9.5501e-07 - val_dense_14_loss: 7.7193e-07 - val_dense_15_loss: 1.1796e-06 - val_dense_16_loss: 7.2833e-07 - val_dense_17_loss: 2.3515e-06 - val_dense_18_loss: 3.0325e-06 - val_dense_19_loss: 2.2346e-06 - val_dense_20_loss: 7.7955e-07 - val_dense_21_loss: 6.5607e-07 - val_dense_22_loss: 5.8115e-07\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 2s 697ms/step - loss: 2.0214e-05 - dense_7_loss: 2.1000e-06 - dense_8_loss: 9.8171e-07 - dense_9_loss: 8.6132e-07 - dense_10_loss: 7.8016e-07 - dense_11_loss: 1.2870e-06 - dense_12_loss: 9.4900e-07 - dense_13_loss: 8.8865e-07 - dense_14_loss: 7.4996e-07 - dense_15_loss: 1.5205e-06 - dense_16_loss: 8.4313e-07 - dense_17_loss: 2.2444e-06 - dense_18_loss: 3.0813e-06 - dense_19_loss: 2.2079e-06 - dense_20_loss: 6.7690e-07 - dense_21_loss: 5.4949e-07 - dense_22_loss: 4.9305e-07 - val_loss: 2.0858e-05 - val_dense_7_loss: 2.0752e-06 - val_dense_8_loss: 1.1111e-06 - val_dense_9_loss: 9.3125e-07 - val_dense_10_loss: 8.6583e-07 - val_dense_11_loss: 1.2992e-06 - val_dense_12_loss: 9.9085e-07 - val_dense_13_loss: 1.0304e-06 - val_dense_14_loss: 7.9308e-07 - val_dense_15_loss: 1.1842e-06 - val_dense_16_loss: 7.6219e-07 - val_dense_17_loss: 2.3691e-06 - val_dense_18_loss: 3.0345e-06 - val_dense_19_loss: 2.3611e-06 - val_dense_20_loss: 7.9202e-07 - val_dense_21_loss: 6.7068e-07 - val_dense_22_loss: 5.8727e-07\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 2s 699ms/step - loss: 2.1044e-05 - dense_7_loss: 2.1600e-06 - dense_8_loss: 1.1029e-06 - dense_9_loss: 9.5556e-07 - dense_10_loss: 8.2086e-07 - dense_11_loss: 1.3277e-06 - dense_12_loss: 1.0533e-06 - dense_13_loss: 9.7505e-07 - dense_14_loss: 7.7467e-07 - dense_15_loss: 1.5269e-06 - dense_16_loss: 8.7744e-07 - dense_17_loss: 2.2581e-06 - dense_18_loss: 3.0827e-06 - dense_19_loss: 2.3773e-06 - dense_20_loss: 6.8865e-07 - dense_21_loss: 5.6350e-07 - dense_22_loss: 4.9931e-07 - val_loss: 2.4467e-05 - val_dense_7_loss: 2.3345e-06 - val_dense_8_loss: 1.7413e-06 - val_dense_9_loss: 1.4160e-06 - val_dense_10_loss: 1.0825e-06 - val_dense_11_loss: 1.4689e-06 - val_dense_12_loss: 1.5319e-06 - val_dense_13_loss: 1.4908e-06 - val_dense_14_loss: 9.2640e-07 - val_dense_15_loss: 1.1747e-06 - val_dense_16_loss: 9.2819e-07 - val_dense_17_loss: 2.4415e-06 - val_dense_18_loss: 3.0513e-06 - val_dense_19_loss: 2.8533e-06 - val_dense_20_loss: 7.8535e-07 - val_dense_21_loss: 6.6281e-07 - val_dense_22_loss: 5.7757e-07\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 2s 774ms/step - loss: 2.5207e-05 - dense_7_loss: 2.5049e-06 - dense_8_loss: 1.8059e-06 - dense_9_loss: 1.4925e-06 - dense_10_loss: 1.0553e-06 - dense_11_loss: 1.5518e-06 - dense_12_loss: 1.6541e-06 - dense_13_loss: 1.4851e-06 - dense_14_loss: 9.1645e-07 - dense_15_loss: 1.5216e-06 - dense_16_loss: 1.0563e-06 - dense_17_loss: 2.3266e-06 - dense_18_loss: 3.0976e-06 - dense_19_loss: 3.0120e-06 - dense_20_loss: 6.8105e-07 - dense_21_loss: 5.5633e-07 - dense_22_loss: 4.8956e-07 - val_loss: 3.9141e-05 - val_dense_7_loss: 3.4289e-06 - val_dense_8_loss: 4.1068e-06 - val_dense_9_loss: 3.2259e-06 - val_dense_10_loss: 1.8907e-06 - val_dense_11_loss: 2.2096e-06 - val_dense_12_loss: 3.5330e-06 - val_dense_13_loss: 3.1894e-06 - val_dense_14_loss: 1.4459e-06 - val_dense_15_loss: 1.2104e-06 - val_dense_16_loss: 1.5280e-06 - val_dense_17_loss: 2.6872e-06 - val_dense_18_loss: 3.1356e-06 - val_dense_19_loss: 5.2565e-06 - val_dense_20_loss: 8.6292e-07 - val_dense_21_loss: 7.6289e-07 - val_dense_22_loss: 6.6707e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "2/2 [==============================] - 2s 776ms/step - loss: 3.9800e-05 - dense_7_loss: 3.6603e-06 - dense_8_loss: 4.1040e-06 - dense_9_loss: 3.2455e-06 - dense_10_loss: 1.8319e-06 - dense_11_loss: 2.3063e-06 - dense_12_loss: 3.6037e-06 - dense_13_loss: 3.1328e-06 - dense_14_loss: 1.4239e-06 - dense_15_loss: 1.5657e-06 - dense_16_loss: 1.6407e-06 - dense_17_loss: 2.5573e-06 - dense_18_loss: 3.1801e-06 - dense_19_loss: 5.5147e-06 - dense_20_loss: 7.7290e-07 - dense_21_loss: 6.6983e-07 - dense_22_loss: 5.9054e-07 - val_loss: 4.0729e-05 - val_dense_7_loss: 3.5367e-06 - val_dense_8_loss: 4.1953e-06 - val_dense_9_loss: 3.3334e-06 - val_dense_10_loss: 1.9132e-06 - val_dense_11_loss: 2.2738e-06 - val_dense_12_loss: 3.5693e-06 - val_dense_13_loss: 3.2446e-06 - val_dense_14_loss: 1.4787e-06 - val_dense_15_loss: 1.2525e-06 - val_dense_16_loss: 1.5623e-06 - val_dense_17_loss: 2.7166e-06 - val_dense_18_loss: 3.1620e-06 - val_dense_19_loss: 5.9216e-06 - val_dense_20_loss: 9.4336e-07 - val_dense_21_loss: 8.7209e-07 - val_dense_22_loss: 7.5379e-07\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 2s 701ms/step - loss: 3.8704e-05 - dense_7_loss: 3.5102e-06 - dense_8_loss: 3.8385e-06 - dense_9_loss: 3.0827e-06 - dense_10_loss: 1.7405e-06 - dense_11_loss: 2.2169e-06 - dense_12_loss: 3.3363e-06 - dense_13_loss: 2.9322e-06 - dense_14_loss: 1.3763e-06 - dense_15_loss: 1.5931e-06 - dense_16_loss: 1.5966e-06 - dense_17_loss: 2.5681e-06 - dense_18_loss: 3.1966e-06 - dense_19_loss: 5.5036e-06 - dense_20_loss: 8.2165e-07 - dense_21_loss: 7.4091e-07 - dense_22_loss: 6.4985e-07 - val_loss: 2.0400e-05 - val_dense_7_loss: 2.1419e-06 - val_dense_8_loss: 1.0302e-06 - val_dense_9_loss: 8.6866e-07 - val_dense_10_loss: 8.2727e-07 - val_dense_11_loss: 1.3201e-06 - val_dense_12_loss: 9.1169e-07 - val_dense_13_loss: 9.6167e-07 - val_dense_14_loss: 7.7549e-07 - val_dense_15_loss: 1.1884e-06 - val_dense_16_loss: 7.2487e-07 - val_dense_17_loss: 2.3176e-06 - val_dense_18_loss: 3.0236e-06 - val_dense_19_loss: 2.2744e-06 - val_dense_20_loss: 7.8268e-07 - val_dense_21_loss: 6.6270e-07 - val_dense_22_loss: 5.8839e-07\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 2s 705ms/step - loss: 2.1482e-05 - dense_7_loss: 2.2419e-06 - dense_8_loss: 1.1785e-06 - dense_9_loss: 1.0113e-06 - dense_10_loss: 8.4308e-07 - dense_11_loss: 1.3551e-06 - dense_12_loss: 1.1062e-06 - dense_13_loss: 1.0272e-06 - dense_14_loss: 7.9874e-07 - dense_15_loss: 1.5353e-06 - dense_16_loss: 8.9147e-07 - dense_17_loss: 2.2425e-06 - dense_18_loss: 3.0875e-06 - dense_19_loss: 2.3914e-06 - dense_20_loss: 6.9218e-07 - dense_21_loss: 5.6907e-07 - dense_22_loss: 5.1106e-07 - val_loss: 2.7564e-05 - val_dense_7_loss: 3.0183e-06 - val_dense_8_loss: 2.0134e-06 - val_dense_9_loss: 1.6124e-06 - val_dense_10_loss: 1.1173e-06 - val_dense_11_loss: 1.8386e-06 - val_dense_12_loss: 1.7549e-06 - val_dense_13_loss: 1.6169e-06 - val_dense_14_loss: 9.7562e-07 - val_dense_15_loss: 1.2227e-06 - val_dense_16_loss: 9.3175e-07 - val_dense_17_loss: 2.3269e-06 - val_dense_18_loss: 3.0404e-06 - val_dense_19_loss: 3.8231e-06 - val_dense_20_loss: 8.5980e-07 - val_dense_21_loss: 7.4732e-07 - val_dense_22_loss: 6.6492e-07\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 2s 709ms/step - loss: 2.6624e-05 - dense_7_loss: 2.9107e-06 - dense_8_loss: 1.8669e-06 - dense_9_loss: 1.5382e-06 - dense_10_loss: 1.0441e-06 - dense_11_loss: 1.7403e-06 - dense_12_loss: 1.7014e-06 - dense_13_loss: 1.4843e-06 - dense_14_loss: 9.3957e-07 - dense_15_loss: 1.5575e-06 - dense_16_loss: 1.0173e-06 - dense_17_loss: 2.2238e-06 - dense_18_loss: 3.0934e-06 - dense_19_loss: 3.5611e-06 - dense_20_loss: 7.4872e-07 - dense_21_loss: 6.3043e-07 - dense_22_loss: 5.6677e-07 - val_loss: 2.2983e-05 - val_dense_7_loss: 2.1374e-06 - val_dense_8_loss: 1.4638e-06 - val_dense_9_loss: 1.2109e-06 - val_dense_10_loss: 1.0061e-06 - val_dense_11_loss: 1.3310e-06 - val_dense_12_loss: 1.2747e-06 - val_dense_13_loss: 1.3045e-06 - val_dense_14_loss: 9.0765e-07 - val_dense_15_loss: 1.2110e-06 - val_dense_16_loss: 8.8405e-07 - val_dense_17_loss: 2.4429e-06 - val_dense_18_loss: 3.0775e-06 - val_dense_19_loss: 2.5548e-06 - val_dense_20_loss: 8.2834e-07 - val_dense_21_loss: 7.1899e-07 - val_dense_22_loss: 6.2903e-07\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 2s 706ms/step - loss: 2.3280e-05 - dense_7_loss: 2.2985e-06 - dense_8_loss: 1.4571e-06 - dense_9_loss: 1.2315e-06 - dense_10_loss: 9.5142e-07 - dense_11_loss: 1.3914e-06 - dense_12_loss: 1.3372e-06 - dense_13_loss: 1.2416e-06 - dense_14_loss: 8.8286e-07 - dense_15_loss: 1.5509e-06 - dense_16_loss: 9.8912e-07 - dense_17_loss: 2.3156e-06 - dense_18_loss: 3.1202e-06 - dense_19_loss: 2.6387e-06 - dense_20_loss: 7.2295e-07 - dense_21_loss: 6.0986e-07 - dense_22_loss: 5.4114e-07 - val_loss: 2.0778e-05 - val_dense_7_loss: 2.0747e-06 - val_dense_8_loss: 1.1713e-06 - val_dense_9_loss: 9.8045e-07 - val_dense_10_loss: 8.8848e-07 - val_dense_11_loss: 1.2814e-06 - val_dense_12_loss: 1.0332e-06 - val_dense_13_loss: 1.0759e-06 - val_dense_14_loss: 8.1320e-07 - val_dense_15_loss: 1.1718e-06 - val_dense_16_loss: 7.7487e-07 - val_dense_17_loss: 2.3650e-06 - val_dense_18_loss: 3.0327e-06 - val_dense_19_loss: 2.1275e-06 - val_dense_20_loss: 7.7004e-07 - val_dense_21_loss: 6.4872e-07 - val_dense_22_loss: 5.6874e-07\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 2s 698ms/step - loss: 2.0921e-05 - dense_7_loss: 2.1420e-06 - dense_8_loss: 1.1602e-06 - dense_9_loss: 1.0047e-06 - dense_10_loss: 8.4419e-07 - dense_11_loss: 1.2954e-06 - dense_12_loss: 1.0918e-06 - dense_13_loss: 1.0231e-06 - dense_14_loss: 7.9767e-07 - dense_15_loss: 1.5147e-06 - dense_16_loss: 8.9203e-07 - dense_17_loss: 2.2603e-06 - dense_18_loss: 3.0843e-06 - dense_19_loss: 2.1022e-06 - dense_20_loss: 6.7293e-07 - dense_21_loss: 5.4740e-07 - dense_22_loss: 4.8817e-07 - val_loss: 2.3404e-05 - val_dense_7_loss: 2.5371e-06 - val_dense_8_loss: 1.4031e-06 - val_dense_9_loss: 1.1281e-06 - val_dense_10_loss: 9.2940e-07 - val_dense_11_loss: 1.5168e-06 - val_dense_12_loss: 1.2258e-06 - val_dense_13_loss: 1.2037e-06 - val_dense_14_loss: 8.4160e-07 - val_dense_15_loss: 1.1900e-06 - val_dense_16_loss: 7.9664e-07 - val_dense_17_loss: 2.3039e-06 - val_dense_18_loss: 3.0145e-06 - val_dense_19_loss: 3.2142e-06 - val_dense_20_loss: 8.0027e-07 - val_dense_21_loss: 6.9938e-07 - val_dense_22_loss: 5.9960e-07\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 2s 772ms/step - loss: 2.3009e-05 - dense_7_loss: 2.5181e-06 - dense_8_loss: 1.3377e-06 - dense_9_loss: 1.1143e-06 - dense_10_loss: 8.7476e-07 - dense_11_loss: 1.4766e-06 - dense_12_loss: 1.2424e-06 - dense_13_loss: 1.1215e-06 - dense_14_loss: 8.2046e-07 - dense_15_loss: 1.5260e-06 - dense_16_loss: 8.9763e-07 - dense_17_loss: 2.1973e-06 - dense_18_loss: 3.0632e-06 - dense_19_loss: 3.0284e-06 - dense_20_loss: 6.9475e-07 - dense_21_loss: 5.8690e-07 - dense_22_loss: 5.0949e-07 - val_loss: 2.0822e-05 - val_dense_7_loss: 2.0672e-06 - val_dense_8_loss: 1.1761e-06 - val_dense_9_loss: 9.8961e-07 - val_dense_10_loss: 8.8788e-07 - val_dense_11_loss: 1.2766e-06 - val_dense_12_loss: 1.0525e-06 - val_dense_13_loss: 1.0773e-06 - val_dense_14_loss: 8.1420e-07 - val_dense_15_loss: 1.1624e-06 - val_dense_16_loss: 7.7548e-07 - val_dense_17_loss: 2.3640e-06 - val_dense_18_loss: 3.0189e-06 - val_dense_19_loss: 2.1270e-06 - val_dense_20_loss: 7.8083e-07 - val_dense_21_loss: 6.6113e-07 - val_dense_22_loss: 5.9095e-07\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 2s 777ms/step - loss: 2.1064e-05 - dense_7_loss: 2.1899e-06 - dense_8_loss: 1.1581e-06 - dense_9_loss: 1.0033e-06 - dense_10_loss: 8.3607e-07 - dense_11_loss: 1.3158e-06 - dense_12_loss: 1.1051e-06 - dense_13_loss: 1.0136e-06 - dense_14_loss: 7.9251e-07 - dense_15_loss: 1.5056e-06 - dense_16_loss: 8.8289e-07 - dense_17_loss: 2.2431e-06 - dense_18_loss: 3.0645e-06 - dense_19_loss: 2.2160e-06 - dense_20_loss: 6.7966e-07 - dense_21_loss: 5.5627e-07 - dense_22_loss: 5.0192e-07 - val_loss: 2.0488e-05 - val_dense_7_loss: 2.0403e-06 - val_dense_8_loss: 1.1127e-06 - val_dense_9_loss: 9.3182e-07 - val_dense_10_loss: 8.6866e-07 - val_dense_11_loss: 1.2578e-06 - val_dense_12_loss: 9.9647e-07 - val_dense_13_loss: 1.0301e-06 - val_dense_14_loss: 8.0300e-07 - val_dense_15_loss: 1.1597e-06 - val_dense_16_loss: 7.5610e-07 - val_dense_17_loss: 2.3492e-06 - val_dense_18_loss: 3.0082e-06 - val_dense_19_loss: 2.1301e-06 - val_dense_20_loss: 7.8386e-07 - val_dense_21_loss: 6.6134e-07 - val_dense_22_loss: 5.9911e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      "2/2 [==============================] - 2s 704ms/step - loss: 2.0443e-05 - dense_7_loss: 2.0924e-06 - dense_8_loss: 1.0801e-06 - dense_9_loss: 9.3969e-07 - dense_10_loss: 8.1685e-07 - dense_11_loss: 1.2628e-06 - dense_12_loss: 1.0376e-06 - dense_13_loss: 9.6139e-07 - dense_14_loss: 7.8088e-07 - dense_15_loss: 1.5001e-06 - dense_16_loss: 8.6640e-07 - dense_17_loss: 2.2402e-06 - dense_18_loss: 3.0554e-06 - dense_19_loss: 2.0756e-06 - dense_20_loss: 6.7634e-07 - dense_21_loss: 5.5028e-07 - dense_22_loss: 5.0666e-07 - val_loss: 2.1477e-05 - val_dense_7_loss: 2.3450e-06 - val_dense_8_loss: 1.1474e-06 - val_dense_9_loss: 9.3701e-07 - val_dense_10_loss: 8.4889e-07 - val_dense_11_loss: 1.4131e-06 - val_dense_12_loss: 1.0222e-06 - val_dense_13_loss: 1.0312e-06 - val_dense_14_loss: 7.9265e-07 - val_dense_15_loss: 1.1609e-06 - val_dense_16_loss: 7.2253e-07 - val_dense_17_loss: 2.2696e-06 - val_dense_18_loss: 2.9820e-06 - val_dense_19_loss: 2.7836e-06 - val_dense_20_loss: 7.8796e-07 - val_dense_21_loss: 6.6289e-07 - val_dense_22_loss: 5.7001e-07\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 2s 771ms/step - loss: 2.1330e-05 - dense_7_loss: 2.3362e-06 - dense_8_loss: 1.1171e-06 - dense_9_loss: 9.5113e-07 - dense_10_loss: 8.0627e-07 - dense_11_loss: 1.3832e-06 - dense_12_loss: 1.0661e-06 - dense_13_loss: 9.7181e-07 - dense_14_loss: 7.7776e-07 - dense_15_loss: 1.5014e-06 - dense_16_loss: 8.3692e-07 - dense_17_loss: 2.1713e-06 - dense_18_loss: 3.0344e-06 - dense_19_loss: 2.6473e-06 - dense_20_loss: 6.8358e-07 - dense_21_loss: 5.5878e-07 - dense_22_loss: 4.8710e-07 - val_loss: 1.9809e-05 - val_dense_7_loss: 2.0004e-06 - val_dense_8_loss: 1.0058e-06 - val_dense_9_loss: 8.5227e-07 - val_dense_10_loss: 8.3013e-07 - val_dense_11_loss: 1.2390e-06 - val_dense_12_loss: 9.0610e-07 - val_dense_13_loss: 9.5660e-07 - val_dense_14_loss: 7.7696e-07 - val_dense_15_loss: 1.1477e-06 - val_dense_16_loss: 7.1541e-07 - val_dense_17_loss: 2.3152e-06 - val_dense_18_loss: 2.9806e-06 - val_dense_19_loss: 2.1243e-06 - val_dense_20_loss: 7.6242e-07 - val_dense_21_loss: 6.3684e-07 - val_dense_22_loss: 5.5873e-07\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 2s 704ms/step - loss: 1.9951e-05 - dense_7_loss: 2.0819e-06 - dense_8_loss: 9.8838e-07 - dense_9_loss: 8.6948e-07 - dense_10_loss: 7.8274e-07 - dense_11_loss: 1.2601e-06 - dense_12_loss: 9.6079e-07 - dense_13_loss: 8.9749e-07 - dense_14_loss: 7.5821e-07 - dense_15_loss: 1.4898e-06 - dense_16_loss: 8.2579e-07 - dense_17_loss: 2.2010e-06 - dense_18_loss: 3.0286e-06 - dense_19_loss: 2.1402e-06 - dense_20_loss: 6.6180e-07 - dense_21_loss: 5.3270e-07 - dense_22_loss: 4.7209e-07 - val_loss: 2.0258e-05 - val_dense_7_loss: 1.9899e-06 - val_dense_8_loss: 1.0561e-06 - val_dense_9_loss: 8.9909e-07 - val_dense_10_loss: 8.5386e-07 - val_dense_11_loss: 1.2472e-06 - val_dense_12_loss: 9.4979e-07 - val_dense_13_loss: 9.9426e-07 - val_dense_14_loss: 7.9589e-07 - val_dense_15_loss: 1.1599e-06 - val_dense_16_loss: 7.3811e-07 - val_dense_17_loss: 2.3359e-06 - val_dense_18_loss: 2.9863e-06 - val_dense_19_loss: 2.2160e-06 - val_dense_20_loss: 7.7982e-07 - val_dense_21_loss: 6.6750e-07 - val_dense_22_loss: 5.8837e-07\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 2s 715ms/step - loss: 2.0175e-05 - dense_7_loss: 2.0393e-06 - dense_8_loss: 1.0182e-06 - dense_9_loss: 9.0169e-07 - dense_10_loss: 8.0066e-07 - dense_11_loss: 1.2520e-06 - dense_12_loss: 9.8693e-07 - dense_13_loss: 9.2149e-07 - dense_14_loss: 7.7231e-07 - dense_15_loss: 1.5000e-06 - dense_16_loss: 8.4662e-07 - dense_17_loss: 2.2253e-06 - dense_18_loss: 3.0334e-06 - dense_19_loss: 2.1510e-06 - dense_20_loss: 6.7380e-07 - dense_21_loss: 5.5563e-07 - dense_22_loss: 4.9634e-07 - val_loss: 2.0180e-05 - val_dense_7_loss: 2.1109e-06 - val_dense_8_loss: 1.0142e-06 - val_dense_9_loss: 8.6130e-07 - val_dense_10_loss: 8.2412e-07 - val_dense_11_loss: 1.3030e-06 - val_dense_12_loss: 9.1232e-07 - val_dense_13_loss: 9.5497e-07 - val_dense_14_loss: 7.6788e-07 - val_dense_15_loss: 1.1571e-06 - val_dense_16_loss: 7.0047e-07 - val_dense_17_loss: 2.2770e-06 - val_dense_18_loss: 2.9667e-06 - val_dense_19_loss: 2.3578e-06 - val_dense_20_loss: 7.6756e-07 - val_dense_21_loss: 6.4308e-07 - val_dense_22_loss: 5.6154e-07\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 2s 720ms/step - loss: 2.0177e-05 - dense_7_loss: 2.1306e-06 - dense_8_loss: 9.9351e-07 - dense_9_loss: 8.7955e-07 - dense_10_loss: 7.8270e-07 - dense_11_loss: 1.2916e-06 - dense_12_loss: 9.6571e-07 - dense_13_loss: 8.9948e-07 - dense_14_loss: 7.5363e-07 - dense_15_loss: 1.4979e-06 - dense_16_loss: 8.1638e-07 - dense_17_loss: 2.1769e-06 - dense_18_loss: 3.0177e-06 - dense_19_loss: 2.2885e-06 - dense_20_loss: 6.6673e-07 - dense_21_loss: 5.3962e-07 - dense_22_loss: 4.7638e-07 - val_loss: 1.9491e-05 - val_dense_7_loss: 1.9670e-06 - val_dense_8_loss: 9.4200e-07 - val_dense_9_loss: 8.0965e-07 - val_dense_10_loss: 8.1149e-07 - val_dense_11_loss: 1.2353e-06 - val_dense_12_loss: 8.5114e-07 - val_dense_13_loss: 9.1166e-07 - val_dense_14_loss: 7.6314e-07 - val_dense_15_loss: 1.1558e-06 - val_dense_16_loss: 6.9299e-07 - val_dense_17_loss: 2.2946e-06 - val_dense_18_loss: 2.9631e-06 - val_dense_19_loss: 2.1153e-06 - val_dense_20_loss: 7.6541e-07 - val_dense_21_loss: 6.4337e-07 - val_dense_22_loss: 5.6911e-07\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 2s 722ms/step - loss: 1.9539e-05 - dense_7_loss: 2.0211e-06 - dense_8_loss: 9.2137e-07 - dense_9_loss: 8.2575e-07 - dense_10_loss: 7.6479e-07 - dense_11_loss: 1.2405e-06 - dense_12_loss: 9.0408e-07 - dense_13_loss: 8.5176e-07 - dense_14_loss: 7.4484e-07 - dense_15_loss: 1.4965e-06 - dense_16_loss: 8.0590e-07 - dense_17_loss: 2.1869e-06 - dense_18_loss: 3.0130e-06 - dense_19_loss: 2.0830e-06 - dense_20_loss: 6.6233e-07 - dense_21_loss: 5.3654e-07 - dense_22_loss: 4.8050e-07 - val_loss: 1.9946e-05 - val_dense_7_loss: 1.9399e-06 - val_dense_8_loss: 1.0266e-06 - val_dense_9_loss: 8.7693e-07 - val_dense_10_loss: 8.4609e-07 - val_dense_11_loss: 1.2291e-06 - val_dense_12_loss: 9.1887e-07 - val_dense_13_loss: 9.7816e-07 - val_dense_14_loss: 7.8613e-07 - val_dense_15_loss: 1.1601e-06 - val_dense_16_loss: 7.3637e-07 - val_dense_17_loss: 2.3285e-06 - val_dense_18_loss: 2.9731e-06 - val_dense_19_loss: 2.1302e-06 - val_dense_20_loss: 7.7994e-07 - val_dense_21_loss: 6.6018e-07 - val_dense_22_loss: 5.7615e-07\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 2s 700ms/step - loss: 1.9888e-05 - dense_7_loss: 1.9950e-06 - dense_8_loss: 9.8758e-07 - dense_9_loss: 8.7904e-07 - dense_10_loss: 7.9198e-07 - dense_11_loss: 1.2362e-06 - dense_12_loss: 9.5618e-07 - dense_13_loss: 9.0336e-07 - dense_14_loss: 7.6194e-07 - dense_15_loss: 1.5010e-06 - dense_16_loss: 8.4506e-07 - dense_17_loss: 2.2193e-06 - dense_18_loss: 3.0208e-06 - dense_19_loss: 2.0812e-06 - dense_20_loss: 6.7335e-07 - dense_21_loss: 5.4989e-07 - dense_22_loss: 4.8658e-07 - val_loss: 1.9442e-05 - val_dense_7_loss: 1.9940e-06 - val_dense_8_loss: 9.2394e-07 - val_dense_9_loss: 7.9328e-07 - val_dense_10_loss: 8.0123e-07 - val_dense_11_loss: 1.2564e-06 - val_dense_12_loss: 8.3765e-07 - val_dense_13_loss: 8.9533e-07 - val_dense_14_loss: 7.5192e-07 - val_dense_15_loss: 1.1517e-06 - val_dense_16_loss: 6.7891e-07 - val_dense_17_loss: 2.2710e-06 - val_dense_18_loss: 2.9468e-06 - val_dense_19_loss: 2.1902e-06 - val_dense_20_loss: 7.5802e-07 - val_dense_21_loss: 6.3523e-07 - val_dense_22_loss: 5.5618e-07\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 2s 698ms/step - loss: 1.9498e-05 - dense_7_loss: 2.0299e-06 - dense_8_loss: 9.1160e-07 - dense_9_loss: 8.1741e-07 - dense_10_loss: 7.5973e-07 - dense_11_loss: 1.2521e-06 - dense_12_loss: 8.9816e-07 - dense_13_loss: 8.4304e-07 - dense_14_loss: 7.3756e-07 - dense_15_loss: 1.4939e-06 - dense_16_loss: 7.9896e-07 - dense_17_loss: 2.1732e-06 - dense_18_loss: 2.9996e-06 - dense_19_loss: 2.1250e-06 - dense_20_loss: 6.5682e-07 - dense_21_loss: 5.3081e-07 - dense_22_loss: 4.7063e-07 - val_loss: 1.9494e-05 - val_dense_7_loss: 1.9998e-06 - val_dense_8_loss: 9.2402e-07 - val_dense_9_loss: 7.9432e-07 - val_dense_10_loss: 8.0034e-07 - val_dense_11_loss: 1.2576e-06 - val_dense_12_loss: 8.3712e-07 - val_dense_13_loss: 8.9529e-07 - val_dense_14_loss: 7.5113e-07 - val_dense_15_loss: 1.1529e-06 - val_dense_16_loss: 6.7957e-07 - val_dense_17_loss: 2.2682e-06 - val_dense_18_loss: 2.9426e-06 - val_dense_19_loss: 2.2262e-06 - val_dense_20_loss: 7.6220e-07 - val_dense_21_loss: 6.4099e-07 - val_dense_22_loss: 5.6128e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1719/1575630703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtrainnew\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_concatamash_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiststruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistslist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvallist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_concatamash_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1719/2905991435.py\u001b[0m in \u001b[0;36mtrain_concatamash_autoencoder\u001b[0;34m(histstruct, histslist, vallist, autoencoders)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m## Train autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         train = autoencoder.fit(x=[X_train[:,i] for i in range(X_train.shape[1])],\n\u001b[0m\u001b[1;32m     45\u001b[0m                                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "if trainnew: train_concatamash_autoencoder(histstruct, histslist, vallist, autoencoders)\n",
    "else: load_concatamash_autoencoder()\n",
    "stop = time.perf_counter()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1167afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the Models for WP definition\n",
    "def evaluate_models_train(histstruct):\n",
    "    \n",
    "    for histgroup in histnames:\n",
    "        print('evaluating model for '+histgroup[0])\n",
    "        print(histstruct.evaluate_classifier(histgroup)[0].shape)\n",
    "    \n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys(): masknames = ['dcson','highstat', 'training']\n",
    "    else: masknames = ['dcson','highstat']\n",
    "    mse_train = histstruct.get_scores_array( masknames=masknames )\n",
    "    print('Found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    \n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            mse_good.append(histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] ))\n",
    "    else:\n",
    "        mse_good = []\n",
    "        for histname in histstruct.histnames:\n",
    "            hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "            thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "            mse_good.append( thismse )\n",
    "            print(run)\n",
    "    mse_good = np.array(mse_good)\n",
    "    mse_good = np.transpose(mse_good)\n",
    "    print('Found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    \n",
    "    # get mse for bad sets\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores_array( masknames=['dcson','highstat','bad{}'.format(i)] ) )\n",
    "        print('Found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))\n",
    "        \n",
    "    return [mse_train, mse_good, mse_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34546ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mse_train, mse_good_eval, mse_bad_eval) = evaluate_models_train(histstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots and Distribution Analysis\n",
    "def fit_mse_distribution(histstruct, mse_train):\n",
    "    dimslist = []\n",
    "    fitfunclist = []\n",
    "    \n",
    "    \n",
    "    nhisttypes = len(histstruct.histnames)\n",
    "    for i in range(0,nhisttypes-1):\n",
    "        for j in range(i+1,nhisttypes):\n",
    "            dimslist.append((i, j))\n",
    "    \n",
    "    plt.close('all')\n",
    "    (npoints,ndims) = mse_train.shape\n",
    "    \n",
    "    \n",
    "    # settings for GaussianKdeFitter\n",
    "    scott_bw = npoints**(-1./(ndims+4))\n",
    "    bw_method = 20*scott_bw\n",
    "    # settings for HyperRectangleFitter\n",
    "    quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "                 0.0003,0.0003,0.00053,0.00065])\n",
    "    \n",
    "    \n",
    "    #for dims in dimslist:\n",
    "    #    thismse = mse_train[:,dims]\n",
    "    #    if training_mode=='global': \n",
    "    #        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "    #        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "    #        #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "    #        #                                                    'up')\n",
    "    #    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    #    #pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "    #    #                onlycontour=False, xlims=30, ylims=30, \n",
    "    #    #                onlypositive=True, transparency=0.5,\n",
    "    #    #                xaxtitle=histstruct.histnames[dims[0]], \n",
    "    #    #                yaxtitle=histstruct.histnames[dims[1]],\n",
    "    #    #                title='density fit of lumisection MSE')\n",
    "    #    ##plt.close('all') # release plot memory\n",
    "    #    fitfunclist.append(fitfunc)\n",
    "    # \n",
    "    #    \n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "    else: \n",
    "        fitfunc = GaussianKdeFitter.GaussianKdeFitter()\n",
    "        fitfunc.fit(mse_train,bw_method=bw_method)\n",
    "    \n",
    "    return fitfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4988fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = fit_mse_distribution(histstruct, mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare MSEs for Working Point Definition\n",
    "def mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc):\n",
    "    \n",
    "    # Get the minimum log probability of histograms in good set\n",
    "    print('--- good lumesections ---')\n",
    "    logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "    print('length of log prob array: '+str(len(logprob_good)))\n",
    "    print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "    #print(sorted(logprob_good))\n",
    "    \n",
    "    print('--- bad lumisections ---')\n",
    "    logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "    print(mse_bad_eval)\n",
    "    #for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "    logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "    \n",
    "    print('length of log prob array: '+str(len(logprob_bad)))\n",
    "    print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "    #print(sorted(logprob_good))\n",
    "    #print(sorted(logprob_bad))\n",
    "    #print(logprob_bad)\n",
    "    \n",
    "    sep = np.min(logprob_good) - np.max(logprob_bad)\n",
    "    print('Separability: ' + str(sep))\n",
    "    \n",
    "    return [logprob_good, logprob_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ed5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(logprob_good, logprob_bad) = mse_analysis(histstruct, mse_good_eval, mse_bad_eval, fitfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoencoders_combined(logprob_good, logprob_bad, fmBiasFactor, wpBiasFactor):\n",
    "    labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "    labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "    \n",
    "    badMin = min(np.where(logprob_bad != -np.inf, logprob_bad, -1))\n",
    "    goodMax = max(np.where(logprob_good != np.inf, logprob_good, 10001))\n",
    "    \n",
    "    logprob_good = np.where(logprob_good != np.inf, logprob_good, goodMax)\n",
    "    logprob_bad = np.where(logprob_bad != -np.inf, logprob_bad, badMin)\n",
    "    \n",
    "    # These only take effect if a histogram is grossly misclassified\n",
    "    logprob_good[logprob_good == -np.inf] = badMin\n",
    "    logprob_bad[logprob_bad == np.inf] = goodMax\n",
    "    \n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "    scores = aeu.clip_scores( scores )\n",
    "    \n",
    "    avSep = np.mean(logprob_good) - np.mean(logprob_bad)\n",
    "    \n",
    "    print('Average Separation: ' + str(avSep))\n",
    "    \n",
    "    pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                       bcklabel='good', bckcolor='g', \n",
    "                       nbins=200, normalize=True,\n",
    "                       xaxtitle='negative logarithmic probability',\n",
    "                       yaxtitle='number of lumisections (normalized)')\n",
    "      \n",
    "    # Plot ROC curve for analysis\n",
    "    auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "    \n",
    "    # Setting a threshold, below this working point defines anomalous data\n",
    "    # Average is biased towards better recall per user specifications\n",
    "    logprob_threshold = (1/(wpBiasFactor + 1)) * (wpBiasFactor*np.mean(logprob_good) + np.mean(logprob_bad))\n",
    "    # Or set manual\n",
    "    # logprob_threshold = 100\n",
    "    (_, _, _, tp, fp, tn, fn) = aeu.get_confusion_matrix(scores,labels,-logprob_threshold)\n",
    "    print('Selected logprob threshold of ' + str(logprob_threshold))\n",
    "    \n",
    "    # Get metrics for analysis\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_measure = (1 + fmBiasFactor * fmBiasFactor) * ((precision * recall) / ((fmBiasFactor * fmBiasFactor * precision) + recall)) \n",
    "    \n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('F-Measure: ' + str(f_measure))\n",
    "    \n",
    "    return logprob_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbddf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_threshold = evaluate_autoencoders_combined(logprob_good, logprob_bad, fmBiasFactor, wpBiasFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0cc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
