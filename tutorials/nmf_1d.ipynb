{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test an NMF model for a type of 1D monitoring element\n",
    "\n",
    "This notebook showcases how to use an NMF model for a 1D monitoring element.  \n",
    "It consists of the following steps:\n",
    "   - Loading the data\n",
    "   - Applying selections (e.g. DCS-bit on and sufficient statistics)\n",
    "   - Preprocessing (e.g. normalizing)\n",
    "   - Building an NMF model\n",
    "   - Investigating the output  \n",
    "   \n",
    "You can use this notebook both for global training (training on a large dataset) and for local training (training on a small number of well-chosen runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import dataframe_utils as dfu\n",
    "import json_utils as jsonu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import DataLoader\n",
    "import HistStruct\n",
    "import ModelInterface\n",
    "import NMFClassifier\n",
    "import IdentityFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define run properties\n",
    "# in this cell all major run properties are going to be set,\n",
    "# e.g. what runs to train on and what runs to test on\n",
    "\n",
    "# define a list of good 'reference' runs \n",
    "# (e.g. found by eye)\n",
    "goodrunsls = {'2017':\n",
    "                {\n",
    "                \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]],\n",
    "                }\n",
    "             }\n",
    "\n",
    "# define core test set of clearly bad runs \n",
    "# (e.g. found by eye)\n",
    "badrunsls = {'2017':\n",
    "                {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                \"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "                #\"299326\":[[-1]],\n",
    "                }\n",
    "            }\n",
    "\n",
    "# set year to use\n",
    "year = '2017'\n",
    "\n",
    "# set histogram names to use \n",
    "histname = 'chargeInner_PXLayer_2'\n",
    "            \n",
    "# set whether to train globally or locally\n",
    "training_mode = 'global'\n",
    "\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use templates)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # for now on n runs preceding a chosen application run,\n",
    "    # to be extended with choosing reference runs.\n",
    "    \n",
    "    # select application run\n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+'_'+histname+'.csv') ) )\n",
    "    run_application = 305351\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    ntraining = 5\n",
    "    runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining:run_application_index]])\n",
    "    runsls_bad = badrunsls[year]\n",
    "    runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data based on the configuration defined above\n",
    "\n",
    "readnew = True\n",
    "\n",
    "if readnew:\n",
    "    \n",
    "    # initializations\n",
    "    dloader = DataLoader.DataLoader()\n",
    "    histstruct = HistStruct.HistStruct()\n",
    "    print('adding {}...'.format(histname))\n",
    "    # read the histograms from the correct csv files\n",
    "    filename = '../data/DF'+year+'_'+histname+'.csv'\n",
    "    df = dloader.get_dataframe_from_file( filename )\n",
    "    # in case of local training, we can remove most of the histograms\n",
    "    if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "        runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "        df = dfu.select_runsls( df, runsls_total )\n",
    "    histstruct.add_dataframe( df )\n",
    "    print('found {} histograms'.format(len(histstruct.runnbs)))\n",
    "    \n",
    "    # add masks\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat' )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        # special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "        \n",
    "if not readnew:\n",
    "    \n",
    "    histstruct = HistStruct.HistStruct.load( hsfilename )\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "print('created a histstruct with the following properties:')\n",
    "print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))\n",
    "print('- masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipthiscell = False\n",
    "\n",
    "if( training_mode=='local' and not skipthiscell ):\n",
    "    \n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the training set using artificial data\n",
    "\n",
    "extendtraining = False\n",
    "\n",
    "if extendtraining:\n",
    "    histstruct.exthistograms['training'] = {}\n",
    "    print('generating artificial training data for '+histname)\n",
    "    hists = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat','training'] )\n",
    "    print('  original number of histograms: {}'.format(len(hists)))\n",
    "    (exthists,_,_) = gdu.upsample_hist_set(hists, 5e4, doplot=True )\n",
    "    histstruct.add_exthistograms( 'training', histname, exthists )\n",
    "    print('  -> generated {} histograms'.format(len(histstruct.exthistograms['training'][histname])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and train an NMF model\n",
    "\n",
    "modelname = 'nmfclassifier'\n",
    "model = ModelInterface.ModelInterface( histstruct.histnames )\n",
    "\n",
    "if training_mode=='local':\n",
    "    training_masks = ['dcson','highstat','training']\n",
    "    hists_train = histstruct.get_histograms( histname=histname, masknames=training_masks )\n",
    "elif training_mode=='global':\n",
    "    training_masks = ['dcson','highstat']\n",
    "    # use all available data for training (with DCS-on and statistics selection)\n",
    "    #hists_train = histstruct.get_histograms( histname=histname, masknames=training_masks )\n",
    "    # this can however take a long time... alternatively, use averaged histograms for training\n",
    "    hists_train = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=training_masks ), 1000 )\n",
    "if extendtraining: hists_train = histstruct.get_exthistograms( 'training', histname=histname )\n",
    "classifier = NMFClassifier.NMFClassifier( ncomponents=3 )\n",
    "classifier.train( hists_train )\n",
    "classifier.set_nmax( 10 )\n",
    "classifier.set_loss_type( 'chi2' )\n",
    "\n",
    "model.set_classifiers( {histname: classifier} )\n",
    "histstruct.add_model( modelname, model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the NMF components\n",
    "\n",
    "components = classifier.get_components()\n",
    "_ = pu.plot_hists_multi( components, colorlist=list(range(len(components))), xaxtitle='bin number', yaxtitle='arbitrary units', title='NMF components' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the models on all histograms in the (non-extended) histstruct\n",
    "\n",
    "print('evaluating model for '+histname)\n",
    "histstruct.evaluate_classifier( modelname, histname )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train a density fitter on the scores obtained by the NMF model\n",
    "\n",
    "histstruct.set_fitter( modelname, IdentityFitter.IdentityFitter() )\n",
    "histstruct.train_fitter( modelname, masknames=training_masks )\n",
    "histstruct.evaluate_fitter( modelname )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the test set using artificial data generation and evaluate the model on the extended test set\n",
    "\n",
    "# make the extra data\n",
    "print('generating data for '+histname)\n",
    "if 'good' in histstruct.masks.keys():\n",
    "    goodhists = histstruct.get_histograms( histname=histname,masknames=['dcson','highstat','good'] )\n",
    "else:\n",
    "    goodhists = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "(goodexthists,_,_) = gdu.upsample_hist_set( goodhists,ntarget=nbadruns*5e3,fourierstdfactor=20., doplot=False)\n",
    "histstruct.add_exthistograms( 'good', histname, goodexthists, overwrite=True )\n",
    "# alternative: copy original good set (e.g. for using resampled bad but original good)\n",
    "#histstruct.add_exthistograms( 'good', histname, goodhists )\n",
    "for i in range(nbadruns):\n",
    "    badhists = histstruct.get_histograms( histname=histname,masknames=['dcson','highstat','bad{}'.format(i)] )\n",
    "    (badexthists,_,_) = gdu.upsample_hist_set( badhists,ntarget=5e3,fourierstdfactor=20., doplot=False)\n",
    "    histstruct.add_exthistograms( 'bad{}'.format(i), histname, badexthists, overwrite=True )\n",
    "\n",
    "# evaluate the classifiers\n",
    "print('evaluating: '+histname)\n",
    "histstruct.evaluate_classifier( modelname, histname, setnames=['good'] )\n",
    "for i in range(nbadruns):\n",
    "    histstruct.evaluate_classifier( modelname, histname, setnames=['bad{}'.format(i)])\n",
    "    \n",
    "# evaluate the fitter\n",
    "print('evaluating fitter')\n",
    "histstruct.evaluate_fitter( modelname, setnames=['good'] )\n",
    "for i in range(nbadruns):\n",
    "    histstruct.evaluate_fitter( modelname, setnames=['bad{}'.format(i)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the scores\n",
    "\n",
    "# get the log probability for good set\n",
    "prob_good = histstruct.get_globalscores( modelname, setnames=['good'] )\n",
    "logprob_good = np.log(prob_good)\n",
    "# get the log probability for bad set\n",
    "prob_bad = histstruct.get_globalscores( modelname, setnames=['bad{}'.format(i) for i in range(nbadruns)] )\n",
    "logprob_bad = np.log(prob_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a roc curve based on the test results above\n",
    "\n",
    "labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "\n",
    "labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "\n",
    "pu.plot_score_dist(scores, labels, nbins=1000, normalize=True)\n",
    "\n",
    "auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "\n",
    "aeu.get_confusion_matrix(scores, labels, wp='maxauc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot some random examples\n",
    "\n",
    "# define reference histograms\n",
    "refhists = {}\n",
    "if( 'good' in histstruct.masks.keys() ): \n",
    "    refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['highstat','dcson','good']), 15 )\n",
    "else: \n",
    "    refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "\n",
    "# define number of plots to make\n",
    "nplot = 10\n",
    "\n",
    "# make plots for good histograms\n",
    "print('example histograms from the good test set:')\n",
    "runnbs_good = histstruct.get_runnbs( masknames=['highstat','dcson'] )\n",
    "lsnbs_good = histstruct.get_lsnbs( masknames=['highstat','dcson'] )\n",
    "indices = np.random.choice( np.arange(len(runnbs_good)), size=nplot, replace=False )\n",
    "for i in indices:\n",
    "    _ = histstruct.plot_ls( runnbs_good[i], lsnbs_good[i], recohist='nmfclassifier', refhists=refhists )\n",
    "    plt.show()\n",
    "    \n",
    "# make plots for bad histograms\n",
    "print('example histograms from the bad test set:')\n",
    "runnbs_bad = histstruct.get_runnbs( masknames=['dcson','bad'] )\n",
    "lsnbs_bad = histstruct.get_lsnbs( masknames=['dcson','bad'] )\n",
    "indices = np.random.choice( np.arange(len(runnbs_bad)), size=nplot, replace=False )\n",
    "for i in indices:\n",
    "    _ = histstruct.plot_ls( runnbs_bad[i], lsnbs_bad[i], recohist='nmfclassifier', refhists=refhists )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate particular lumisections\n",
    "\n",
    "# initialization: general\n",
    "mode = 'run'\n",
    "run = 299316\n",
    "# for mode 'ls' (ignored if mode is 'run'):\n",
    "ls = 70\n",
    "# for mode 'run' (ignored if mode is 'ls'):\n",
    "run_masknames = ['dcson','highstat']\n",
    "\n",
    "# initialization: reference scores\n",
    "plot_refscores = True\n",
    "refscore_masknames = ['dcson','highstat']\n",
    "\n",
    "# initialization: reference histograms\n",
    "refhists = {}\n",
    "for histname in histstruct.histnames: \n",
    "    refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['highstat','dcson']), 50 )\n",
    "\n",
    "if mode=='ls':\n",
    "    # plot this particular run/ls\n",
    "    fig,axs = histstruct.plot_ls( run, ls, recohist=None, refhists=refhists, \n",
    "                                opaque_legend=True,\n",
    "                                ncols = 3,\n",
    "                                physicalxax = True,\n",
    "                                ymaxfactor = 1.3,\n",
    "                                legendsize = 13\n",
    "                              )\n",
    "    \n",
    "    # print the mses\n",
    "    msepoint = histstruct.get_scores_ls( modelname, run, ls )\n",
    "    logprob = np.log( histstruct.evaluate_fitter_on_point( modelname, msepoint ) )\n",
    "    print('-------------')\n",
    "    print('MSE values:')\n",
    "    for histname in histstruct.histnames: print('{} : {}'.format(histname,msepoint[histname]))\n",
    "    print('-------------')\n",
    "    print('logprob: '+str(logprob))\n",
    "    \n",
    "    # plot mse distribution\n",
    "    if plot_refscores:\n",
    "        fig,axs = histstruct.plot_ls_score( modelname, run, ls, masknames=refscore_masknames, \n",
    "                        nbins=100, normalize=True,\n",
    "                        siglabel='This lumisection', bcklabel='All lumisections',\n",
    "                        sigcolor='k', bckcolor='b',\n",
    "                        title=None, \n",
    "                        xaxtitle='MSE', xaxtitlesize=15,\n",
    "                        yaxtitle='Normalized number of lumisections', yaxtitlesize=15,\n",
    "                        doshow=False)\n",
    "\n",
    "\n",
    "if mode=='run':\n",
    "    # plot given run\n",
    "    runnbs = histstruct.get_runnbs( masknames=run_masknames )\n",
    "    lsnbs = histstruct.get_lsnbs( masknames=run_masknames )\n",
    "    runsel = np.where(runnbs==run)\n",
    "    lsnbs = lsnbs[runsel]\n",
    "    print('plotting {} lumisections...'.format(len(lsnbs)))\n",
    "    for lsnb in lsnbs:\n",
    "        fig,ax = histstruct.plot_ls(run, lsnb, recohist=None, refhists=refhists, opaque_legend=True )\n",
    "        plt.show()\n",
    "        msepoint = histstruct.get_scores_ls( modelname, run, lsnb )\n",
    "        msepointarray = np.array([msepoint[histname] for histname in histstruct.histnames])\n",
    "        logprob = np.log( histstruct.evaluate_fitter_on_point( modelname, msepoint ) )\n",
    "        print('-------------')\n",
    "        print('MSE values:')\n",
    "        for histname in histstruct.histnames: print('{} : {}'.format(histname,msepoint[histname]))\n",
    "        print('-------------')\n",
    "        print('logprob: '+str(logprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
